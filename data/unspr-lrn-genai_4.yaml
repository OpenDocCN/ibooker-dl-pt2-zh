- en: 4 Association rules
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 关联规则
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章内容包括
- en: Association rule learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则学习
- en: Different types of association rules algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同类型的关联规则算法
- en: Implementation of different association rules algorithm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同关联规则算法的实现
- en: Sequence learning using SPADE
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SPADE 进行序列学习
- en: Case study
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 案例研究
- en: “The power of association is stronger than the power of beauty; therefore the
    power of association is the power of beauty– John Ruskin”
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “关联的力量比美的力量更强大；因此关联的力量就是美的力量– 约翰·罗斯金”
- en: Congratulations on finishing the first part of the book! You explored the basics
    of unsupervised learning and algorithms like k-means clustering, hierarchical
    clustering, DBSCAN, principal component analysis, and others. It is expected that
    you have covered the mathematical concepts in the first part and created the Python
    codes to solve the exercise given at the end of each chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了本书的第一部分！你探索了无监督学习的基础知识以及 k-means 聚类、层次聚类、DBSCAN、主成分分析等算法。预计你已经掌握了第一部分的数学概念，并创建了解决每章末尾练习的
    Python 代码。
- en: Welcome to the second part of the book wherein we leverage the concepts learned
    in the first part and explore slightly more complex topics. We are starting with
    association rules in chapter 4 of this book. All the very best!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本书的第二部分，在这一部分中，我们将利用第一部分学到的概念，并探索稍微复杂一些的主题。我们将从本书的第四章开始学习关联规则。祝你好运！
- en: Next time you visit a nearby grocery store, look around inside the store and
    the arrangements of various items. You would find shelves with items like milk,
    eggs, bread, sugar, washing powder, soaps, fruits, vegetables, cookies and various
    other items neatly stacked. Have you ever wondered what is the logic of this arrangement
    and how these items are laid out? Why certain products are kept near each other
    while others are quite far from each other? Obviously, the arrangement cannot
    be done in a random manner and there has to be scientific reasoning behind it.
    Or do you wonder, how does Netflix recommend movies to you based on your movie
    history like a sequence? We are going to find the answers to these questions in
    this chapter. Like always, we will study the concepts first. We will go through
    the mathematical logic for different algorithms, the pros and cons of each, and
    practical implementations using Python. A business case study is provided at the
    end of the chapter to complement the knowledge.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 下次你去附近的杂货店时，看看店内各种物品的摆放。你会发现架子上摆放着牛奶、鸡蛋、面包、糖、洗衣粉、肥皂、水果、蔬菜、饼干和其他各种物品。你有没有想过这种摆放的逻辑是什么，以及这些物品是如何摆放的？为什么某些产品放在一起，而另一些则相距很远？显然，这种摆放不可能是随意的，背后必须有科学的原理。或者你是否想知道，Netflix
    是如何根据你的观影历史为你推荐电影的？我们将在本章中找到这些问题的答案。和往常一样，我们将先学习概念。我们将通过数学逻辑来讨论不同算法的优缺点，并使用 Python
    进行实际实现。本章末尾提供了一个商业案例研究来补充知识。
- en: Welcome to the fourth chapter and all the very best!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到第四章，祝一切顺利！
- en: 4.1 Technical toolkit
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 技术工具包
- en: We will continue to use the same version of Python and Jupyter notebook as we
    have used so far. The codes and datasets used in this chapter have been checked-in
    at this location.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用迄今为止使用的相同版本的 Python 和 Jupyter 笔记本。本章使用的代码和数据集已经存储在此位置。
- en: You would need to install a few Python libraries in this chapter which are –
    apyori, pyECLAT, fpgrowth_py and pyspade. Along with this we will need numpy and
    pandas. Using libraries, we can implement the algorithms very quickly. Otherwise,
    coding these algorithms is quite a time-consuming and painstaking task.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要安装几个 Python 库 – apyori、pyECLAT、fpgrowth_py 和 pyspade。除此之外，我们还需要 numpy 和
    pandas。使用库，我们可以很快地实现这些算法。否则，编写这些算法将是一项耗时且痛苦的任务。
- en: Let’s get started with association rules.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始关联规则的学习。
- en: 4.2 Association rule learning
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 关联规则学习
- en: You might have heard the famous “*beer and diaper story*”. As per this anecdote,
    customers (mostly young men) of a supermarket who buy diapers also buy beer in
    the same invoice. In other words, young men who are buying diapers for their babies
    have quite a high probability to buy beers in the same transaction. We will not
    comment on the authenticity of the story, but *association rule learning* can
    be attributed as the logic derived from this story.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过著名的“*啤酒和尿布故事*”。根据这个轶事，超市的顾客（主要是年轻男子）购买尿布的同时也购买啤酒在同一张发票上。换句话说，购买尿布给他们的宝宝的年轻男子在同一笔交易中购买啤酒的概率相当高。我们不评论这个故事的真实性，但是可以归因于此故事的逻辑是*关联规则学习*。
- en: Formally put - association rules can be used to find compelling relationships
    between the variables which are present in the data sets. We can use association
    rules for measuring the correlations and co-occurrences between the variables
    in a dataset. In the example given above (assuming the story is true), one could
    analyse the daily customer transactions. And if a relationship emerges between
    beer and diapers, it is a very strong insight for the supermarket, which can allow
    them to customize their placements of beer and diapers or tailor the marketing
    strategy or even alter the prices.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正式来说 - 关联规则可以用来发现数据集中存在的变量之间的有力关系。我们可以使用关联规则来测量数据集中变量之间的相关性和共同出现。在上述示例中（假设故事是真实的），人们可以分析每日的顾客交易。如果啤酒和尿布之间存在关系，这对超市来说是非常强大的洞察力，可以让他们定制啤酒和尿布的摆放位置，或者调整营销策略，甚至改变价格。
- en: We can understand by a different example in a supermarket. Consider the example
    below. Assume that by analyzing five invoices generated in a supermarket, we get
    the data below as shown in Table 4.1\. In this example, in invoice number 1001
    milk is purchased hence it has a value of 1, whereas cheese is not purchased,
    hence it is 0.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过超市中的另一个例子来理解。考虑下面的例子。假设通过分析在超市生成的五张发票，我们得到了如下表4.1所示的数据。在这个例子中，发票编号1001购买了牛奶，因此它的值为1，而奶酪没有购买，因此它是0。
- en: Table 4.1 Examples of invoices generated in a supermarket. The first invoice
    number is 1001 and, in that invoice, milk is bought. Hence, there is 1 in front
    of milk. While cheese is not bought in 1001 and hence, there is 0 in front of
    cheese.
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.1 超市生成的发票示例。第一个发票编号是1001，在该发票中购买了牛奶。因此，在牛奶前面有1。而奶酪在1001中没有购买，因此，在奶酪前面有0。
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 发票编号 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1 | 1 | 0 |'
- en: '| 1002 | 0 | 0 | 0 | 1 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 0 | 0 | 0 | 1 |'
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 1 | 1 | 0 |'
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 0 | 1 | 0 | 1 |'
- en: '| 1005 | 1 | 1 | 0 | 1 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 1 | 1 | 0 | 1 |'
- en: So, in invoice number 1001, milk, eggs, and bread are purchased while in invoice
    number 1002 only cheese is purchased. Here, we can see that whenever milk and
    eggs are purchased together, bread is always purchased in the same invoice. It
    is an important discovery indeed.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在发票编号1001中，购买了牛奶、鸡蛋和面包，而在发票编号1002中只购买了奶酪。在这里，我们可以看到每当牛奶和鸡蛋一起购买时，面包总是在同一张发票中购买。这确实是一个重要的发现。
- en: Now scale up this understanding to thousands of transactions made in a day.
    It will lead to very strong relationships which human eyes are generally oblivious
    to, but association rule algorithms can uncover them for us. It can lead to better
    product placements, better prices of the products and much more optimized marketing
    spending. Such patterns will enhance the customer experience and prove quite handy
    to improve overall customer satisfaction.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将这种理解扩展到一天内数千笔交易。这将导致非常强大的关系，人眼通常忽视，但关联规则算法可以为我们揭示它们。它可以导致更好的产品摆放、产品更好的价格和更优化的营销支出。这些模式将提升客户体验，并且被证明对于改善整体客户满意度非常有用。
- en: We can visualize association rules as shown in Figure 4.1\. Here, there are
    some incoming variables represented as nodes 1,2,3,4 etc. These nodes are related
    to each other as shown by the arrows. This relationship between them gives rise
    to rules A and B. If we relate back to the beer/diaper story we mentioned at the
    start of this section, rule A can be that when a young male customer buys diapers
    they also often buy beer; while a rule B can be that when milk and eggs are purchased,
    often bread is bought too.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将关联规则可视化，如图 4.1 所示。在这里，有一些表示为节点1、2、3、4等的传入变量。这些节点之间存在关联，如箭头所示。它们之间的这种关系导致了规则A和B的产生。如果我们回顾一下本节开头提到的啤酒/尿布故事，规则A可能是，当年轻男性顾客购买尿布时，他们也经常购买啤酒；而规则B可能是，当购买牛奶和鸡蛋时，经常也会购买面包。
- en: Figure 4.1 Association rule can be visualized as the relationships between various
    variables in the dataset. These variables are linked to each other, and significant
    relationships are established between them.
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1 关联规则可以被视为数据集中各种变量之间的关系。这些变量之间相互关联，并建立了重要的关系。
- en: '![04_01](images/04_01.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![04_01](images/04_01.png)'
- en: The example of the supermarket discussed above is sometimes referred to as *Market
    Basket Analysis.* But association rules are applicable not only in grocery retail.
    Their utility has been proven in other sectors like bioinformatics and the medical
    industry, intrusion detection etc. They can be utilized by Netflix or Spotify
    to analyze historical user behavior and then recommend the content which the user
    most likely is going to like. Web developers can analyze the historical clicks
    and usages of the customers on their websites. By identifying the patterns, they
    can find out what user tends to click and which features will maximize their engagements.
    Medical practitioners can use association rules to better diagnose patients. The
    doctors can compare the probability of the symptoms in relationships with other
    symptoms and provide more accurate diagnoses. The use cases are across multiple
    business domains and business functions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 上面讨论的超市示例有时被称为*市场篮子分析*。但是关联规则不仅适用于杂货零售。它们在生物信息学、医疗行业、入侵检测等其他领域的效用已被证明。Netflix或Spotify可以利用它们分析历史用户行为，然后推荐用户最有可能喜欢的内容。Web开发人员可以分析客户在其网站上的历史点击和使用情况。通过识别模式，他们可以找出用户倾向于点击的内容和哪些功能将最大化他们的参与度。医生可以使用关联规则更好地诊断患者。医生可以比较症状与其他症状之间的关系的概率，并提供更准确的诊断。用例跨越多个业务领域和业务功能。
- en: We will now understand the building blocks for association rules.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将了解关联规则的构建模块。
- en: 4.3 Building blocks of association rule
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 关联规则的构建模块
- en: We covered the definition of the association rule in the last section.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中介绍了关联规则的定义。
- en: Now let's understand the mathematical concept behind association rules. Assume
    that we have the following datasets in a retail store-
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们了解关联规则背后的数学概念。假设我们在零售店有以下数据集-
- en: Let X = {x[, x[2], x[3], x[4], x[5] …., x[n]} are the *n* items available in
    the retail store. For example, they can be milk, eggs, bread, cheese, apples and
    so on.]
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让 X = {x[, x[2], x[3], x[4], x[5] …., x[n]} 代表零售店中可用的*n*种商品。例如，它们可以是牛奶、鸡蛋、面包、奶酪、苹果等等。
- en: Let Y = {y[, y[2], y[3], y[4], y[5] …., y[m]} are the *m* transactions generated
    in that retail store. Each transaction could have all or some items from the retail
    store.]
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让 Y = {y[, y[2], y[3], y[4], y[5] …., y[m]} 代表在该零售店生成的*m*笔交易。每笔交易可能包含来自零售店的全部或部分商品。
- en: Obviously, each item in the transactions will be bought from the retail store
    only. Or, in other words, every item in transactions in set Y will be a subset
    of items in set X. At the same time, each item would have a unique identifier
    attached to it and each transaction would have a unique invoice number attached
    to it.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，交易中的每个商品都只能从零售店购买。换句话说，在集合Y中的交易中的每个商品都是集合X中商品的子集。同时，每个商品都会附带一个唯一的标识符，每个交易都会附带一个唯一的发票号码。
- en: Now, we are interested to analyze the patterns and discover the relationships.
    This will be used to generate any rule or insight. So, let’s define the meaning
    of the rule first.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有兴趣分析模式并发现关系。这将用于生成任何规则或见解。因此，让我们首先定义规则的含义。
- en: 'Assume that we find a rule that whenever items in list P are bought, items
    in list Q are also bought. This rule can be written as follows:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们发现一条规则，即每当购买列表P中的商品时，列表Q中的商品也会被购买。这条规则可以写成如下形式：
- en: The rule is **P -> Q**. It means that whenever items defined in P are bought
    it leads to the purchase of Q too.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规则是**P -> Q**。这意味着当购买了P中定义的物品时，也会购买Q。
- en: Items in P will be a subset of X or **P** **Í** X.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P中的物品将是X的子集或**P** **Í** X。
- en: Similarly, items in Q will be a subset of X or **Q** **Í** X.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，Q中的物品将是X的子集或**Q** **Í** X。
- en: P and Q cannot have any common element or **P** **Ç** Q = 0
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P和Q不能有任何共同的元素，即**P** **Ç** Q = 0
- en: Now, let’s understand these mathematical concepts with a real-world example.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个实际案例来理解这些数学概念。
- en: Assume that X = {milk, bananas, eggs, cheese, apples, bread, salt, sugar, cookies,
    butter, cold drinks, water}. These are the total items available in the retail
    shop.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设X = {牛奶，香蕉，鸡蛋，奶酪，苹果，面包，盐，糖，饼干，黄油，冷饮料，水}。这是零售店中所有可用的物品。
- en: Y = {1001, 1002, 1003, 1004, 1005}. These are the five invoices generated in
    that retail store. The respective items purchased in each of these invoices are
    given in Table 4.2.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Y = {1001, 1002, 1003, 1004, 1005}。这是在该零售店生成的五张发票。每张发票中购买的相应物品如表4.2所示。
- en: Table 4.2 Example of five invoices generated in a retail store. Note how for
    each invoice, we have 0 and 1 associated for each of the items. These invoices
    are just for illustration purposes. In the actual invoices, the number of items
    can be much more.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.2 零售店生成的五张发票示例。请注意，对于每张发票，我们对每个物品都有0和1相关联。这些发票仅用于说明目的。实际发票中物品的数量可以更多。
- en: '![04_T02](images/04_T02.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![04_T02](images/04_T02.png)'
- en: Using this dataset, let’s assume we create two rules that {milk, bananas} ->
    {eggs} and {milk, bananas} -> {bread}.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数据集，让我们假设我们创建了两个规则：{牛奶，香蕉} -> {鸡蛋}和{牛奶，香蕉} -> {面包}。
- en: First rule means that whenever milk and bananas are bought together, eggs are
    also purchased in the same transaction. And second rule means that whenever milk
    and bananas are bought together, bread is also bought in the same transaction.
    By analyzing the dataset above, we can clearly see that rule 1 is always true
    whereas rule 2 is not.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个规则意味着每当购买牛奶和香蕉，鸡蛋也会在同一次交易中购买。第二个规则意味着每当购买牛奶和香蕉，面包也会在同一次交易中购买。通过分析上述数据集，我们可以清楚地看到规则1始终为真，而规则2不是。
- en: The items on the left side are called the *antecedent* or the LHS and the ones
    on the right side are called the *consequents* or the RHS.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 左边的物品称为*前项*或LHS，右边的物品称为*后项*或RHS。
- en: In the real-world, for any such rule to have significance, the same pattern
    must repeat itself across several hundreds and thousands of transactions. Then
    only we would conclude that the rule is indeed true and can be generalized across
    the entire database.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，对于任何这样的规则来说，同样的模式必须在数百甚至数千个交易中重复出现。只有在这种情况下，我们才会得出这个规则确实是真实存在的，并且可以推广到整个数据库。
- en: At the same time, there can be many such rules. In a retail shop where daily
    thousands of invoices are generated, there can be hundreds of such rules. How
    can be find out which rules are significant, and which are not? This can be understood
    using the concept of *support, confidence, and lift* which we will study in the
    next section.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，可能会有很多这样的规则。在一个每天生成数千份发票的零售店中，可能会有数百个这样的规则。我们如何发现哪些规则是重要的，哪些是不重要的呢？这可以通过我们将在下一节学习的支持度、置信度和提升度的概念来理解。
- en: 4.3.1 Support, confidence, lift, and conviction
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 支持度、置信度、提升度和确信度
- en: We identified the meaning of a rule in association rule in the last sections.
    We also understand that there can be hundreds of rules based on the transactional
    data set. In this section, we will explore, how we can measure the effectiveness
    of such rules and can shortlist the most interesting ones. This can be achieved
    using the concepts of support, confidence, lift, and conviction.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们确定了关联规则中规则的含义。我们也理解，基于事务数据集，可能会有数百条规则。在本节中，我们将探讨如何测量这些规则的有效性，并筛选出最有趣的规则。这可以通过支持度、置信度、提升度和确信度的概念来实现。
- en: Recall in the last section we discussed the generalization of a rule. Support,
    confidence, lift, and conviction allow us to measure the level of generalization.
    In simple words, using these four parameters we can determine how useful the rule
    can be in our pragmatic real-world business. After all, if a rule is not useful
    or is not powerful enough, it is not required to be implemented. Support, confidence,
    lift, and conviction are the parameters to check the efficacy of the rule. We
    will look at these concepts in detail now.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾上一节我们讨论了规则的泛化。支持度、置信度、提升度和确信度可以帮助我们衡量泛化程度。简而言之，使用这四个参数，我们可以确定规则在我们实际的商业中有多么有用。毕竟，如果一个规则不实用或者不够强大，就没有必要实施。支持度、置信度、提升度和确信度是检查规则效力的参数。我们现在将详细介绍这些概念。
- en: We will use the below data set in Table 4.3 to understand the concept of support,
    confidence, and lift.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用表 4.3 中的以下数据集来理解支持度、置信度和提升度的概念。
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased. Again, for the sake of this example, we have taken only 4 items
    in total.
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.3 我们将用来理解支持度、置信度和提升度概念的数据集。第一张发票 1001 包含牛奶、鸡蛋和面包，而奶酪没有购买。同样，为了这个例子，我们总共只考虑了
    4 个项目。
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 发票号码 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1 | 1 | 0 |'
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 0 | 1 | 1 | 1 |'
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 1 | 1 | 0 |'
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 0 | 1 | 0 | 1 |'
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 0 | 1 | 1 | 0 |'
- en: Here, for an invoice, 1 represents if an item is present in that invoice while
    0 shows that the item was not purchased in that particular invoice. For example,
    invoice number 1001 has milk, eggs and bread while 1002 has eggs, bread and cheese.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，对于一个发票，1 表示该发票中是否有购买该商品，而 0 则表示该发票中没有购买该商品。例如，发票编号 1001 包含牛奶、鸡蛋和面包，而 1002
    包含鸡蛋、面包和奶酪。
- en: Let’s study support now.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们研究支持度。
- en: Support
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 支持
- en: Support measures the frequency percentage of the items in the datasets. In other
    words, it measures the percentage of transactions in which the items are occurring
    in the data set.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度测量数据集中项目的频率百分比。换句话说，它测量了项目在数据集中出现的交易百分比。
- en: Support can be denoted as shown below
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度可以表示如下
- en: '![04_01a](images/04_01a.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![04_01a](images/04_01a.png)'
- en: Refer to Table 4.3, if we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which all three items (milk,
    eggs, and bread) are present. The total number of transactions is five. So, it
    means that the support for the rule is 2 / 5 which is 0.4 or 40%.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参考表 4.3，如果我们对规则 {牛奶, 鸡蛋} -> {面包} 感兴趣。在这种情况下，有两笔交易中同时包含这三种项目（牛奶、鸡蛋和面包）。总交易数为五笔。因此，该规则的支持度为
    2 / 5，即 0.4 或 40%。
- en: If we are interested in the rule {bread, eggs} -> {cheese}. In such a scenario,
    there is only one transaction in which all three items are present. The total
    number of transactions is five. So, it means that the support for the rule is
    1 / 5 which is 0.2 or 20%.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对规则 {面包, 鸡蛋} -> {奶酪} 感兴趣。在这种情况下，只有一笔交易中同时包含这三种商品。总交易数为五笔。因此，该规则的支持度为 1 /
    5，即 0.2 或 20%。
- en: Higher the support for a rule, better it is. Generally, we put a minimum threshold
    to get support. Minimum threshold is generally determined in consultation with
    the business stakeholders.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度越高，规则越好。通常，我们设定一个最低阈值来获取支持度。最低阈值通常是与业务利益相关者协商确定的。
- en: We will now study confidence for a rule.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将研究规则的置信度。
- en: Confidence
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 置信度
- en: Confidence measures how often the rule is true. In other words, it measures
    the percentage of transactions which if contain antecedents also contain consequents.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 置信度测量规则的真实频率。换句话说，它测量了包含前提的交易中也包含结果的百分比。
- en: So, if we wish to measure the confidence of the rule A->B
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们想要测量规则 A->B 的置信度
- en: '![04_01b](images/04_01b.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![04_01b](images/04_01b.png)'
- en: Here, the numerator is supported when both A and B are present in the transaction,
    while the denominator refers to the support only for A.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，分子在交易中同时存在 A 和 B 时为支持度，而分母则指的是仅 A 的支持度。
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased. Again, for the sake of this example, we have taken only 4 items
    in total.
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.3 我们将用于理解支持度、确信度和提升度概念的数据集。第一张发票 1001 有牛奶、鸡蛋和面包，而奶酪没有购买。同样，为了本例，我们只考虑了总共
    4 个物品。
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 发票号码 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1 | 1 | 0 |'
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 0 | 1 | 1 | 1 |'
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 1 | 1 | 0 |'
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 0 | 1 | 0 | 1 |'
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 0 | 1 | 1 | 0 |'
- en: Refer to Table 4.3, if we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which both milk and eggs are
    present. Hence, the support is 2/5 = 0.4\. It is the denominator. There are two
    transactions in which all three (milk, eggs, bread) are present. Hence, support
    is 2/5 = 0.4, which is the numerator. Putting in the equation above, the confidence
    for the rule {milk, eggs} -> {bread} is 0.4/0.4 = 1.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参考表 4.3，如果我们对规则 {牛奶，鸡蛋} -> {面包}感兴趣。在这种情况下，有两个交易中同时存在牛奶和鸡蛋。因此，支持度为 2/5 = 0.4。这是分母。有两个交易中同时存在三个物品（牛奶，鸡蛋，面包）。因此，支持度为
    2/5 = 0.4，这是分子。放入上面的方程，规则 {牛奶，鸡蛋} -> {面包}的确信度为 0.4/0.4 = 1。
- en: If we are interested in the rule {eggs, bread} -> {cheese}. In such a scenario,
    there are three transactions in which (eggs, bread) are present. The total number
    of transactions are five. So, it means that the support is 3 / 5 which is 0.6\.
    There is only one transaction in which all the three items (eggs, bread, cheese)
    are present. So, the support is 1/5 = 0.2\. Hence the confidence for the rule
    {eggs, bread} -> {cheese}is 0.2/0.6 = 0.33.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对规则 {鸡蛋，面包} -> {奶酪}感兴趣。在这种情况下，有三个交易中存在 (鸡蛋，面包)。总交易数为五。所以，这意味着支持度为 3/5，即
    0.6。只有一个交易中同时存在三个物品（鸡蛋，面包，奶酪）。所以，支持度为 1/5 = 0.2。因此，规则 {鸡蛋，面包} -> {奶酪}的确信度为 0.2/0.6
    = 0.33。
- en: The higher the confidence in the rule, the better it is. Like support, we put
    a minimum threshold on confidence.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于规则的信心越高，它就越好。像支持一样，我们对确信度设置了最低阈值。
- en: Sometimes, it is also referred to as the *conditional probability* of A on B.
    It can be understood as the probability of B occurring provided A has already
    occurred and can be written as P(A|B). So, in the examples quoted above, the probability
    of cheese to be bought provided eggs, bread is already bought is 33% while the
    probability of bread to be purchased, provided milk, eggs are already purchased
    is 100%
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，它也被称为 A 在 B 上的*条件概率*。它可以理解为在 A 已经发生的情况下 B 发生的概率，并且可以写成 P(A|B)。因此，在上面引用的例子中，提前购买了鸡蛋、面包的情况下购买奶酪的概率为
    33%，而购买了牛奶、鸡蛋的情况下购买面包的概率为 100%。
- en: We have covered confidence and support so far. We will now study lift and conviction
    for a rule which are real criteria to evaluate a rule.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了信心和支持。现在我们将研究提升度和确信度，这是评估规则的真正标准。
- en: Lift and conviction
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提升度和确信度
- en: Lift is a very important measurement criteria for a rule. Lift for a rule A->
    B can be defined as
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 提升度是一种非常重要的规则测量标准。规则 A-> B 的提升度可以定义为
- en: '![04_01c](images/04_01c.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![04_01c](images/04_01c.png)'
- en: Here, the numerator is supported when both A and B are present in the transaction,
    while the denominator refers to the support for A multiplied by the support for
    B.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，分子在交易中同时存在 A 和 B 时得到支持，而分母则是指 A 的支持乘以 B 的支持。
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased. Again, for the sake of this example, we have taken only 4 items
    in total.
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.3 我们将用于理解支持度、确信度和提升度概念的数据集。第一张发票 1001 有牛奶、鸡蛋和面包，而奶酪没有购买。同样，为了本例，我们只考虑了总共
    4 个物品。
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 发票号码 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1 | 1 | 0 |'
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 0 | 1 | 1 | 1 |'
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 1 | 1 | 0 |'
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 0 | 1 | 0 | 1 |'
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 0 | 1 | 1 | 0 |'
- en: Refer to Table 4.3, if we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which all three (milk, eggs,
    bread) are present. Hence, support is again 2/5 = 0.4, which is the numerator.
    There are two transactions in which only (milk, eggs) are present, so the support
    is 2/5 = 0.4\. There are four transactions in which bread is present, hence the
    support is 4/5 = 0.8\. Putting in the equation above, the lift for the rule {milk,
    eggs} -> {bread} is 0.4/(0.4x0.8) = 1.25.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 参考表 4.3，如果我们对规则{牛奶，鸡蛋} -> {面包}感兴趣。在这种情况下，有两个交易中都存在所有三个（牛奶，鸡蛋，面包）。因此，支持度再次为 2/5
    = 0.4，这是分子。有两个交易中只有（牛奶，鸡蛋）存在，所以支持度为 2/5 = 0.4。有四个交易中存在面包，因此支持度为 4/5 = 0.8。将其代入上述方程中，规则{牛奶，鸡蛋}
    -> {面包}的提升度为 0.4/(0.4x0.8) = 1.25。
- en: If we are interested in the rule {eggs, bread} -> {cheese}. In such a scenario,
    there is only one transaction in which (eggs, bread, cheese) are present. The
    total number of transactions is five. So, it means that the support is 1 / 5 which
    is 0.2\. There are two transactions in which (cheese) is present. So, the support
    is 2/5 = 0.4\. There are four transactions in which (eggs, bread) are present,
    so the support is 4/5 = 0.8\. Putting in the equation above, the lift for the
    rule {eggs, bread} -> {cheese} is 0.2/(0.4x0.8) = 0.625.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对规则{鸡蛋，面包} -> {奶酪}感兴趣。在这种情况下，只有一个交易中存在（鸡蛋，面包，奶酪）。总交易数为五。因此，支持度为 1 / 5，即
    0.2。有两个交易中存在（奶酪）。因此，支持度为 2/5 = 0.4。有四个交易中存在（鸡蛋，面包），因此支持度为 4/5 = 0.8。将其代入上述方程中，规则{鸡蛋，面包}
    -> {奶酪}的提升度为 0.2/(0.4x0.8) = 0.625。
- en: If the value of the lift is *equal to 1*, it means that the antecedent and precedent
    are independent of each other, and no rule can be drawn from it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提升度的值*等于1*，则意味着前项和后项彼此独立，不能从中得出任何规则。
- en: If the value of lift is *greater than one*, it means that the antecedent and
    precedent are dependent on each other. This rule can be used for predicting the
    antecedent in future transactions. This is the insight we want to draw from the
    data set.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提升度的值*大于1*，则意味着前项和后项是相互依赖的。此规则可用于预测未来交易中的前项。这是我们想要从数据集中得出的见解。
- en: The value of lift is *lesser than one*, it means that the antecedent and precedent
    are substitutes of each other. The presence of one can have a negative impact
    on the other. It is also an important insightthath can be used by the business
    teams for strategic planning.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 提升度的值*小于1*，意味着前项和后项是彼此替代的。其中一个的存在可能对另一个产生负面影响。这也是业务团队进行战略规划的重要洞察。
- en: While we evaluate any rule using the lift, it is imperative that we apply domain
    knowledge to it. For example, if we evaluate the rule {eggs, bread} -> {cheese},
    it suggests that eggs, bread can be a substitute for cheese. We know that it is
    not true in the real life. Hence, in such a scenario we cannot make any decision
    for this role. We must take help of domain knowledge to draw any conclusions for
    this rule.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估任何规则时，使用提升度时，必须将领域知识应用于其中。例如，如果我们评估规则{鸡蛋，面包} -> {奶酪}，它表明鸡蛋、面包可以替代奶酪。我们知道这在现实生活中是不正确的。因此，在这种情况下，我们不能对此规则做出任何决定。我们必须借助领域知识来对该规则进行任何结论。
- en: At the same time, rule {milk, eggs} -> {bread} might be a rule which can be
    true for a large number of times. For many customers, when they purchase milk
    and eggs together it is highly likely that bread will be purchased too in the
    same transaction. Hence this rule makes much more sense for such customers. The
    objective is to have a strong business logic to either support or disapprove a
    rule identified using the algorithm.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，规则{牛奶，鸡蛋} -> {面包}可能是一个可以多次成立的规则。对于许多客户，当他们一起购买牛奶和鸡蛋时，面包很可能也会在同一交易中购买。因此，对于这样的客户来说，这个规则更有意义。目标是有一个强有力的业务逻辑来支持或否定使用算法识别的规则。
- en: '**Conviction** is an important parameter which is given by the formula below'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**信心**是一个重要的参数，其公式如下'
- en: '![04_01d](images/04_01d.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![04_01d](images/04_01d.png)'
- en: For example, if we are interested in the rule {eggs, bread} -> {cheese}. In
    such a scenario, there is only one transaction in which (cheese) is present. The
    total number of transactions are five. So, it means that the support is 1 / 5
    which is 0.2 and will be used in the numerator. We have already calculated the
    confidence as 0.625\. Putting back in the formula, we can calculate conviction
    as (1-0.2)/(1-0.625) = 2.13
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们对规则 {鸡蛋，面包} -> {奶酪} 感兴趣。在这种情况下，只有一个交易中存在 (奶酪)。总交易数为五。所以，支持度是 1/5，即 0.2，并将用于分子。我们已经计算出置信度为
    0.625。放回公式中，我们可以计算说服力为 (1-0.2)/(1-0.625) = 2.13
- en: We can interpret the conviction as – the rule {eggs, bread} -> {cheese} would
    be incorrect 2.13 times more often if the association between {eggs, bread, cheese}
    was purely chosen at random.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将说服力解释为 - 规则 {鸡蛋，面包} -> {奶酪} 如果 {鸡蛋，面包，奶酪} 之间的关联纯粹是随机选择的，那么它的错误率将是 2.13
    倍。
- en: In most of the business scenarios, lift is the measurement criteria used. There
    are other measurement parameters too like leverage, collective strength etc. But
    most of the time confidence, support and lift are used to measure the effectiveness
    of any rule.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数业务场景中，提升度是使用的测量标准。还有其他测量参数，如杠杆、集体强度等。但是大多数情况下，置信度、支持度和提升度被用来衡量任何规则的有效性。
- en: '![](images/tgt.png) POP QUIZ – answer these question to check your understanding..
    Answers at the end of the book'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![](images/tgt.png) 小测验 - 回答这些问题来检查你的理解.. 答案在书的末尾'
- en: 1.   Support measures how often the rule is present in the dataset. True or
    False
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 1.   支持度测量规则在数据集中出现的频率。是或否。
- en: 2.   If the lift is greater than 1, it means that the two items are independent
    of each other. True or False.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 2.   如果提升度大于 1，则表示两个项目彼此独立。是或否。
- en: 3.   Lower the value of confidence, better is the rule. True or False.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 3.   降低置信度值，规则就越好。是或否。
- en: While we evaluate any rule while analyzing the data set, most of the time we
    set a threshold for the confidence, support, and the lift. It allows us to reduce
    the number of rules and filter out the irrelevant ones. In other words, we are
    interested in only the rules which are very frequent. We will study it in more
    detail when we create a Python solution for a dataset.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析数据集时，我们评估任何规则时，大多数情况下都会为置信度、支持度和提升度设置阈值。这使我们能够减少规则数量并过滤掉不相关的规则。换句话说，我们只关注那些非常频繁的规则。当我们为数据集创建
    Python 解决方案时，我们将更详细地研究它。
- en: We will now study the various algorithms used in association rule. The first
    such algorithm is Apriori algorithm which is the next topic.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将研究关联规则中使用的各种算法。第一个这样的算法是 Apriori 算法，这是下一个主题。
- en: 4.4 Apriori algorithm
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 Apriori 算法
- en: The Apriori algorithm is one of the most popular algorithms used for association
    rules. It was proposed by Agrawal and Shrikant in 1994\. The link to the paper
    is given at the end of the chapter.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 算法是用于关联规则的最流行算法之一。它由 Agrawal 和 Shrikant 在 1994 年提出。本章末尾给出了论文链接。
- en: Apriori is used to understand and analyze the frequent items in a transactional
    database. It utilizes a “bottom-up” approach where first candidates are generated
    based of the frequency of the subsets. Let us understand the entire process by
    means of an example.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 用于理解和分析交易数据库中的频繁项。它利用“自下而上”的方法，首先根据子集的频率生成候选项。让我们通过一个示例来理解整个过程。
- en: We will use the same dataset we have discussed earlier.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们之前讨论过的相同数据集。
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased.
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.3 我们将用来理解支持度、置信度和提升度概念的数据集。第一个发票 1001 有牛奶、鸡蛋和面包，而奶酪没有购买。
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 发票编号 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1 | 1 | 0 |'
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 0 | 1 | 1 | 1 |'
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 1 | 1 | 0 |'
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 0 | 1 | 0 | 1 |'
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 0 | 1 | 1 | 0 |'
- en: The process used in Apriori algorithm it will look like the process below in
    Figure 4.2.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 算法中使用的过程看起来像图 4.2 中下面的过程。
- en: Figure 4.2 Apriori algorithm process can be depicted as shown here.
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.2 Apriori 算法过程可以如下所示。
- en: '![04_02](images/04_02.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![04_02](images/04_02.png)'
- en: Let us say we wish to analyze the relationship of bread with all the other items
    in the dataset. In this case, level 1 is Bread and we find its frequency of occurrence.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要分析面包与数据集中所有其他项目的关系。在这种情况下，级别 1 是面包，我们找到其出现的频率。
- en: Then we move to the next layer which is Layer 2\. Now we find the relationship
    of Bread with each of the other items – Milk, Eggs and Cheese which are at Layer
    2\. Here again we find the respective frequencies of occurrence for all the possible
    combinations which are {Bread, Milk}, {Bread, Eggs}, and {Bread, Cheese}. It can
    be shown in Figure 4.3.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们转移到下一层，即第 2 层。现在我们找到面包与其他每个物品 - 牛奶、鸡蛋和奶酪（在第 2 层）的关系。在这里，我们再次找到所有可能组合的出现频率，即
    {面包，牛奶}，{面包，鸡蛋} 和 {面包，奶酪}。可以在图 4.3 中显示。
- en: Figure 4.3 We have bread at Level 1 while the other items (milk, eggs, and cheese)
    are kept at Level 2\. Bread is kept at level 1 since we wish to analyze the relationship
    of bread with all the other items.
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.3 我们在 1 级有面包，而其他物品（牛奶、鸡蛋和奶酪）都放在 2 级。面包放在 1 级，因为我们希望分析面包与所有其他物品的关系。
- en: '![04_03](images/04_03.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![04_03](images/04_03.png)'
- en: After Layer 2 has been analyzed, we move to the third layer and fourth layer
    and so on. This process continues till we reach the last layer wherein all the
    items have been exhausted.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 分析完第 2 层后，我们转移到第三层、第四层等。这个过程会一直持续，直到我们达到最后一层，其中所有的物品都被用完。
- en: As a result of this process, we can calculate the support for all the possible
    combinations. For example, we would know the support for
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个过程，我们可以计算所有可能组合的支持度。例如，我们可以得到
- en: '{Bread} -> {Milk},'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} -> {牛奶}，'
- en: '{Bread} -> {Eggs} and'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} -> {鸡蛋} 和'
- en: '{Bread} -> {Cheese}.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} -> {奶酪}。'
- en: For the next level, we would also get the support for
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于下一层，我们还会得到支持
- en: '{Bread, Milk} -> {Eggs},'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包，牛奶} -> {鸡蛋}，'
- en: '{Bread, Eggs} -> {Milk},'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包，鸡蛋} -> {牛奶}，'
- en: '{Bread, Milk} -> {Cheese},'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包，牛奶} -> {奶酪}，'
- en: '{Bread, Cheese} -> {Milk},'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包，奶酪} -> {牛奶}，'
- en: '{Bread, Cheese} -> {Eggs} and'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包，奶酪} -> {鸡蛋} 和'
- en: '{Bread, Eggs} -> {Cheese}.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包，鸡蛋} -> {奶酪}。'
- en: Now, using the same process, all the possible combinations for the next level
    are calculated. For example, {Bread, Eggs, Milk} -> {Cheese}, {Bread, Eggs, Cheese}
    -> {Milk} and so on.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用同样的过程，计算下一层的所有可能组合。例如，{面包，鸡蛋，牛奶} -> {奶酪}，{面包，鸡蛋，奶酪} -> {牛奶} 等。
- en: When all the item sets have been exhausted, the process will stop. The complete
    architecture can look like in Figure 4.4.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有的项集都用完时，这个过程将停止。完整的架构可以看起来像图 4.4。
- en: Figure 4.4 The complete architecture for Apriori algorithm. Here, we would have
    calculated support for all the possible combinations. The relationships between
    all the items are explored and because of this entire database scan, the speed
    of Apriori gets hampered.
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.4 Apriori 算法的完整架构。在这里，我们将计算所有可能组合的支持度。探索所有项目之间的关系，由于整个数据库的扫描，Apriori 的速度受到影响。
- en: '![04_04](images/04_04.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![04_04](images/04_04.png)'
- en: Now, we can easily understand that the possible number of combinations is quite
    high, which is one of the challenges with apriori. There are a few other shortcomings
    for Apriori algorithm which we will study later. But right now is the time to
    implement Apriori using Python.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以轻松理解可能的组合数量相当高，这是 Apriori 的挑战之一。Apriori 算法还有一些其他缺点，我们将在后面学习。但现在是用 Python
    实现 Apriori 的时候了。
- en: 4.4.1 Python implementation
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 Python 实现
- en: We will now proceed with Python implementation of Apriori algorithm. The dataset
    and Python Jupyter notebook is checked-in at the GitHub repository.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将继续使用 Python 实现 Apriori 算法。数据集和 Python Jupyter 笔记本已经上传到 GitHub 代码库。
- en: You might have to install apyori.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要安装 apyori。
- en: To install the libraries, simply do the step below
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这些库很简单，只需按照以下步骤进行。
- en: '[PRE0]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Step 1:** Import the necessary libraries for the use case. We are importing
    numpy, pandas. For implementing apriori, we have a library called apyori which
    is also imported.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：** 导入用例所需的库。我们导入了 numpy、pandas。为了实现 Apriori，我们还有一个叫做 apyori 的库也被导入了。'
- en: '[PRE1]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Step 2:** We now import the datset store_data.csv file.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：** 现在，我们导入数据集 store_data.csv 文件。'
- en: '[PRE2]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You are also advised to have a look at the dataset by opening the .csv file.
    It will look like the screenshot below. The first 25 rows are shown in the screenshot.
    Each row represents an invoice.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你还建议查看打开 .csv 文件的数据集。它会像下面的截图一样。截图显示了前 25 行。每一行代表一个发票。
- en: '![04_04a](images/04_04a.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![04_04a](images/04_04a.png)'
- en: '**Step 3:** Let’s perform some basic checks on the data by `.info`, `.head`
    command.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3：** 让我们通过 `.info`，`.head` 命令对数据进行一些基本检查。'
- en: '[PRE3]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![04_04b](images/04_04b.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![04_04b](images/04_04b.png)'
- en: '[PRE4]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![04_04c](images/04_04c.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![04_04c](images/04_04c.png)'
- en: '**Step 4:** Here we can see that the first transaction has been considered
    as the header by the code. Hence, we would import the data again but this time
    he would specify that headers are equal to None.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 4 步：** 在这里我们可以看到，代码已将第一个交易作为标题考虑。因此，我们将重新导入数据，但这次他会指定标题等于 None。'
- en: '[PRE5]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Step 5:** Let’s look at the head again. This time it looks correct.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 5 步：** 让我们再次看一下头部。这次看起来是正确的。'
- en: '[PRE6]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![04_04d](images/04_04d.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![04_04d](images/04_04d.png)'
- en: '**Step 6:** The library we are using for the code accepts the dataset as a
    list of lists. The entire dataset must be a big list while each transaction is
    an inner list in the big list. So, to achieve it, we first convert our store_dataset
    data frame into a list.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 6 步：** 我们用于代码的库接受数据集作为列表的列表。整个数据集必须是一个大列表，而每个交易是大列表中的内部列表。因此，为了实现它，我们首先将我们的
    store_dataset 数据框转换为列表。'
- en: '[PRE7]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Step 7:** Next, we implement the Apriori algorithm.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 7 步：** 接下来，我们实施 Apriori 算法。'
- en: For the algorithm, we are working on `all_records` list we have created in Step
    6\. The minimum support specified is 0.5 or 50%, minimum confidence is 25%, minimum
    lift is 4 and minimum length of the rule is 2.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法，我们正在处理我们在第 6 步创建的 `all_records` 列表。指定的最小支持度为0.5或50%，最小置信度为25%，最小提升为4，规则的最小长度为2。
- en: The output of this step is `apriori_rules` class object. This object is then
    converted into a list which we can understand. And finally, we print this list.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的输出是 `apriori_rules` 类对象。然后将此对象转换为我们可以理解的列表。最后，我们打印此列表。
- en: '[PRE8]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The output of the code will be 0\. It means that no such rules exist which satisfy
    the condition we have set for the rules.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出将为0。这意味着不存在满足我们设置的规则条件的规则。
- en: We again try to execute the same code albeit by reducing the minimum support
    to 25%
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次尝试执行相同的代码，尽管将最小支持度减少到25%。
- en: '[PRE9]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Again, no rules are generated and the output is zero. Even reducing the minimum
    support to 10% does not lead to any rules.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，没有生成任何规则，输出为零。即使将最小支持度降低到10%，也不会产生任何规则。
- en: '[PRE10]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, we reduce the minimum lift to 2\. This time we get 200 as the output. It
    means that there are 200 such rules which fulfil the criteria.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将最小提升减少到2。这次我们得到的输出是200。这意味着有200个满足条件的规则。
- en: '[PRE11]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Step 8:** Let’s look at the first rule.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8 步：** 让我们看一下第一条规则。'
- en: '[PRE12]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![04_04e](images/04_04e.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![04_04e](images/04_04e.png)'
- en: The rule explains the relationship between almonds and burgers. Support is .005
    while the confidence is 0.25\. Lift which is 2.92 indicates that this rule is
    quite strong in itself.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 规则解释了杏仁和汉堡之间的关系。支持率为0.005，置信度为0.25。提升为2.92表明此规则本身相当强大。
- en: '**Step 9:** We will now look at all the rules in detail. For that, loop through
    the rules and extract information from each of the iteration. Each of the rule
    has got the items constituting the rule and respective values for support, confidence
    and lift. We have shown an example in Step 8\. Now in Step 9, we are just extracting
    that information for all of the rules using a for loop.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 9 步：** 我们现在将详细查看所有规则。为此，循环遍历规则并从每次迭代中提取信息。每个规则都有构成规则的项目以及支持、置信度和提升的相应值。我们在第
    8 步中展示了一个示例。现在在第 9 步中，我们只是使用 for 循环从所有规则中提取该信息。'
- en: '[PRE13]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The output for this step is shown below. Here, we can observe the each rule
    in listed along with the respective values of support, confidence and lift.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的输出如下所示。在这里，我们可以观察到每个规则及其支持、置信度和提升的相应值。
- en: '![04_04f](images/04_04f.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![04_04f](images/04_04f.png)'
- en: We can interpret the rules easily. For example, rule almonds-> burgers has a
    lift of 2.92 with a confidence of 25.49% and support of 0.51%. This concludes
    our implementation using Python. This example can be extended to any other real-world
    business dataset.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松解释这些规则。例如，规则杏仁->汉堡包的提升为2.92，置信度为25.49%，支持率为0.51%。这完成了我们使用 Python 的实现。此示例可以扩展到任何其他真实业务数据集。
- en: Not all the rules generated are not good for using. We will examine how to get
    the best rules from all the rules generated when we deal with the case study in
    the last section of the chapter.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有生成的规则都适合使用。在本章的最后一节中，我们将探讨如何从生成的所有规则中获取最佳规则。
- en: Apriori algorithm is a robust and very insightful algorithm. But like any other
    solution, it has a few shortcomings which we are discussing now.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 算法是一种稳健且非常有见地的算法。但像任何其他解决方案一样，它也有一些缺点，我们现在正在讨论。
- en: 4.4.2 Challenges with Apriori algorithm
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 Apriori 算法的挑战
- en: We examined in previous sections how the number of subsets generated in Apriori
    algorithm are quite high.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的部分已经讨论过Apriori算法生成的子集数量相当大。
- en: Figure 4.5 Complete scan of dataset is done multiple times hence the speed is
    decreased significantly.
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.5 数据集的完全扫描被多次进行，因此速度显著下降。
- en: '![04_05](images/04_05.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![04_05](images/04_05.png)'
- en: It is very tedious to generate candidates' item sets and hence it becomes quite
    cumbersome to analyse the dataset. Apriori scans the entire dataset multiple times
    and hence it requires the database to be loaded in the memory. We can safely deduce
    that it requires a lot of time to make the computations. This problem is magnified
    when we are dealing with a very large dataset. In fact, for real-world problems
    where millions of transactions are generated, quite a huge number of candidate
    itemsets are generated and hence it is very time consuming to use Apriori on the
    entire dataset.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 生成候选项集非常繁琐，因此分析数据集变得相当繁重。Apriori多次扫描整个数据集，因此需要将数据库加载到内存中。我们可以肯定地得出结论，它需要大量时间才能进行计算。当处理非常大的数据集时，这个问题就会被放大。事实上，在现实世界的问题中，会产生数百万次交易，会产生相当多的候选项集，因此在整个数据集上使用Apriori是非常耗时的。
- en: Due to this very reason, generally, a minimum value of support is set to reduce
    number of possible rules. In the example given above, we can calculate the support
    for level 1 combinations as shown below in Table 4.4\. Here, if we set the minimum
    value of support as 0.5, only one rule will be shortlisted.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一般情况下，会设定一个最小支持值来减少可能的规则数量。在上面给出的例子中，我们可以根据表4.4中所示计算级别1组合的支持，如果我们将最小支持值设为0.5，只有一个规则会被列入候选名单。
- en: Table 4.4 Support is calculated for each of the combination of the items. For
    example, for milk and bread – the number of transactions is 2 while the total
    number of transactions are 5\. So, the support is 2/5 which is 0.4.
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.4 对每种商品的组合都进行了支持计算。例如，对于牛奶和面包-交易次数为2，而总交易次数为 5。所以，支持率为2/5，即0.4。
- en: '| Combination | Number of txns | Total Txns | Support |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 组合 | 交易次数 | 总交易次数 | 支持率 |'
- en: '| Milk, Eggs | 2 | 5 | 0.4 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋 | 2 | 5 | 0.4 |'
- en: '| Milk, Bread | 2 | 5 | 0.4 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，面包 | 2 | 5 | 0.4 |'
- en: '| Milk, Cheese | 0 | 5 | 0 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，奶酪 | 0 | 5 | 0 |'
- en: '| Eggs, Bread | 4 | 5 | 0.8 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，面包 | 4 | 5 | 0.8 |'
- en: '| Eggs, Cheese | 2 | 5 | 0.4 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，奶酪 | 2 | 5 | 0.4 |'
- en: '| Bread, Cheese | 1 | 5 | 0.2 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 面包，奶酪 | 1 | 5 | 0.2 |'
- en: Setting up a minimum value of support is hence an intelligent tactic to make
    the rules much more manageable. It reduces the time and generates the rules which
    are much more significant. After all, the rules generated from the analysis should
    be generalizable enough so that they can be implemented across the entire data
    base.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 设定一个最小支持值是一个明智的策略，可以使规则更易管理。这样可以减少时间，生成更有意义的规则。毕竟，从分析生成的规则应该足够通用，以至于可以应用于整个数据库。
- en: '![](images/tgt.png) POP QUIZ – answer these question to check your understanding..
    Answers at the end of the book'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![](images/tgt.png) 快速测验 - 回答这些问题来检查你的理解。书末有答案。'
- en: 1.   Apriori algorithm scans the database only once. TRUE or FALSE.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 1.   Apriori算法只扫描数据库一次。是真还是假？
- en: 2.   If bananas are present in 5 transactions out of a total of 12 transactions,
    it means the support for banana is 5/12\. TRUE or FALSE.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 2.   如果香蕉在12次交易中出现了5次，那么香蕉的支持率就是5/12。正确还是错误？
- en: But Apriori algorithm is a path-breaking solution. It is still highly popular
    and generally one of the very first algorithms whenever association rules are
    discussed.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 但Apriori算法是一种开创性的解决方案。它仍然非常受欢迎，通常是讨论关联规则时的第一个算法。
- en: Data preparation is one of the key steps and quite a challenge, we will explore
    this challenge during the case study in the last section of the chapter.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '数据准备是关键步骤之一，也是一个挑战，我们将在本章最后的案例研究中探讨这一挑战。  '
- en: We will now study the next algorithm, which is ECLAT algorithm
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来会学习下一个算法，也就是ECLAT算法。
- en: 4.5 Equivalence class clustering and bottom-up lattice traversal (ECLAT)
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 等价类聚类和自底向上格遍历(ECLAT)
- en: We will now study Equivalence class clustering and bottom-up lattice traversal
    algorithm or ECLAT in this section, which is sometimes said is better than apriori
    in terms of speed and ease of implementation.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们会在这一节学习等价类聚类和自底向上格遍历算法，或者称之为ECLAT，有人认为这个算法在速度和实现的方便性方面比Apriori更好。
- en: ECLAT uses a depth-first search approach. It means that ECLAT performs the search
    in a vertical fashion throughout the dataset. It starts at the root node. Then
    goes one level deep and continues until it reaches the first terminal note. Let’s
    say the terminal node is at level X. Once the terminal node is reached, the algorithm
    then takes a step back and reaches level (X-1) and continues till it finds a terminal
    node again. Let's understand this process by means of a tree diagram as shown
    in Table 4.6.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ECLAT使用深度优先搜索方法。这意味着ECLAT沿着数据集以纵向方式进行搜索。它从根节点开始。然后进入更深的一层，并继续直到达到第一个终端注释。假设终端节点在X级。一旦到达终端节点，算法然后返回一步，并到达级别（X-1），并继续直到再次找到终端节点。让我们通过表4.6中显示的树状图来理解这个过程。
- en: Figure 4.6 Tree diagram to understand the process of ECLAT algorithm. It starts
    with 1 and ends at 16.
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.6 ECLAT算法过程的树状图。 它从1开始，直到16结束。
- en: '![04_06](images/04_06.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![04_06](images/04_06.png)'
- en: 'ECLAT will take the following steps:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ECLAT将采取以下步骤：
- en: The algorithm starts at the root node 1.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法从根节点1开始。
- en: It then goes one level deep to root node 2.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后它向根节点2深入一层。
- en: It will then continue one more level deep till it reaches terminal node 11.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后它会继续向更深的一层，直到达到终端节点11。
- en: Once it reaches the terminal note 11, it then takes a step back and goes to
    node 5.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦它到达终端注释11，然后退回一步，到达节点5。
- en: The algorithm then searches if there is any node available which can be used.
    At node 5 we can see that there is no such node available.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后算法搜索是否有可用的节点。在节点5处，我们可以看到没有可用的节点。
- en: Hence the algorithm again takes a step back and it reaches node 2.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，算法再次退回一步，它达到了节点2。
- en: At node 2, the algorithm explores again. It finds that it is possible to go
    to note 6.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在节点2处，算法再次探索。它发现可以到达注释6。
- en: So, the algorithm goes to node 6 and starts exploring again till it reaches
    the terminal node 12.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，算法进入节点6，并开始探索，直到达到终端节点12。
- en: This process continues till all the combinations have been exhausted.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个过程会一直持续，直到所有组合耗尽。
- en: Obviously, the speed of computation depends on the total number of distinct
    items present in the data set. It is because the number of distinct items define
    the width of the tree. The items purchased in each of the transactions would define
    the relationship between each node.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，计算速度取决于数据集中存在的不同项目的总数。这是因为不同项目的数量定义了树的宽度。每笔交易中购买的商品将定义每个节点之间的关系。
- en: During execution time of ECLAT, each item (either individually or in a pair)
    is analyzed. Let us use the same example we have used for Apriori to understand
    ECLAT better as shown in Table 4.5.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行ECLAT时，将分析每个商品（单独或成对）。让我们使用我们已经用于Apriori的相同示例来更好地理解ECLAT，如表4.5所示。
- en: Table 4.5 Data set we are going to use to understand ECLAT. The first invoice
    1001 has milk, eggs, and bread while cheese is not purchased.
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.5 我们将用来理解ECLAT的数据集。 第一张发票1001有牛奶、鸡蛋和面包，而奶酪没有购买。
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 发票号 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1 | 1 | 0 |'
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 0 | 1 | 1 | 1 |'
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 1 | 1 | 0 |'
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 0 | 1 | 0 | 1 |'
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 0 | 1 | 1 | 0 |'
- en: 'ECLAT will undergo the following steps to analyze the dataset:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ECLAT将经历以下步骤来分析数据集：
- en: In the first run ECLAT will find the invoice numbers for all single items. Or
    in other words, it would find the invoice numbers for all the items individually.
    It can be shown in Table 4.6 below, wherein the milk is present in invoice number
    1001 and 1003 while eggs are present in all the invoices.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次运行中，ECLAT将找到所有单个商品的发票号。换句话说，它会找到所有商品的个别发票号。可以在下面的表4.6中显示，其中牛奶在发票号1001和1003中出现，而鸡蛋出现在所有发票中。
- en: Table 4.6 Respective invoices in which each item is present. Milk is present
    in 1001 and 1003 while eggs is present in five invoices.
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.6 每个商品所在的相应发票。牛奶出现在1001和1003号发票中，而鸡蛋出现在五张发票中。
- en: '| Item | Invoice Numbers |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 商品 | 发票号 |'
- en: '| Milk | 1001,1003 |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| Milk | 1001,1003 |'
- en: '| Eggs | 1001, 1002, 1003, 1004, 1005 |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| Eggs | 1001, 1002, 1003, 1004, 1005 |'
- en: '| Bread | 1001, 1002, 1003, 1005 |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| Bread | 1001, 1002, 1003, 1005 |'
- en: '| Cheese | 1002, 1004 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| Cheese | 1002, 1004 |'
- en: Now in the next step, all the two items dataset are explored as shown below
    in Table 4.7\. For example, milk and eggs are present in invoice number 1001 and
    1003, while milk and cheese are not present in any invoice.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在在下一步中，所有两个项目数据集都将如下所示地进行探索，如表 4.7 所示。例如，牛奶和鸡蛋出现在发票号码 1001 和 1003 中，而牛奶和奶酪没有出现在任何发票中。
- en: Table 4.7 Two item data sets are explored now. Milk and eggs are present in
    invoice number 1001 and 1003 while there is no invoice for milk and cheese.
  id: totrans-257
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.7 现在探索了两个项目数据集。牛奶和鸡蛋出现在发票号码 1001 和 1003 中，而没有牛奶和奶酪的发票。
- en: '| Item | Invoice Numbers |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 发票号码 |'
- en: '| Milk, Eggs | 1001, 1003 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋 | 1001, 1003 |'
- en: '| Milk, Bread | 1001, 1003 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，面包 | 1001, 1003 |'
- en: '| Milk, Cheese | - |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，奶酪 | - |'
- en: '| Eggs, Bread | 1001, 1002, 1003, 1005 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，面包 | 1001, 1002, 1003, 1005 |'
- en: '| Eggs, Cheese | 1002, 1004 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，奶酪 | 1002, 1004 |'
- en: '| Bread, Cheese | 1002 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 面包，奶酪 | 1002 |'
- en: In the next step, all three item datasets are explored as shown in Table 4.8.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，所有三个项目数据集都将如表 4.8 所示进行探索。
- en: Table 4.8 Three item datasets are analyzed in this step. We have two combinations
    only.
  id: totrans-266
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.8 在这一步中分析了三个项目数据集。我们只有两个组合。
- en: '| Item | Invoice Numbers |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 发票号码 |'
- en: '| Milk, Eggs, Bread | 1001, 1003 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋，面包 | 1001, 1003 |'
- en: '| Eggs, Bread, Cheese | 1002 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，面包，奶酪 | 1002 |'
- en: There are no invoices present in our data set which contains four items.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的数据集中没有包含四个项目的发票。
- en: Now depending on the threshold, we set for the value of the support count, we
    can choose the rules. So, if we want that minimum number of transactions in which
    the rule should be true is equal to three then only one rule qualifies which is
    {Eggs, Bread}. If we decide the threshold for the minimum number of transactions
    as two, then rules like {Milk, Eggs, Bread}, {Milk, Eggs}, {Milk, Bread}, {Eggs,
    Bread} and {Eggs, Cheese} qualify as the rules.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在根据我们设置的支持计数值的阈值，我们可以选择规则。因此，如果我们希望使规则为真的最小交易次数等于三，那么只有一个规则符合条件，即{鸡蛋，面包}。如果我们将最小交易次数的阈值设定为两，则诸如{牛奶，鸡蛋，面包}，{牛奶，鸡蛋}，{牛奶，面包}，{鸡蛋，面包}和{鸡蛋，奶酪}等规则都符合条件。
- en: We will now create a Python solution for ECLAT.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将为 ECLAT 创建一个 Python 解决方案。
- en: 4.5.1 Python implementation
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.1 Python 实现
- en: 'We will now work on the execution of ECLAT using Python. We are using pyECLAT
    library here. The dataset looks like this:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用 Python 进行 ECLAT 的执行。我们在这里使用 pyECLAT 库。数据集如下所示：
- en: '![04_06a](images/04_06a.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![04_06a](images/04_06a.png)'
- en: '**Step 1:** We will import the libraries here.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：** 我们将在这里导入库。'
- en: '[PRE14]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Step 2:** Import the dataset now'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：** 现在导入数据集'
- en: '[PRE15]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Step 3:** Here we are generating an ECLAT instance.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3：** 这里我们正在生成一个 ECLAT 实例。'
- en: '[PRE16]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: There are some properties of ECLAT instance `eclat` generated in the last step
    like eclat.df_bin which is a binary dataframe and eclat.uniq_ which is a list
    of all the unique itesms.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步生成的 ECLAT 实例 `eclat` 中有一些属性，如 eclat.df_bin 是一个二进制数据框，eclat.uniq_ 是所有唯一项目的列表。
- en: '**Step 4:** We will now fit the model. We are giving a minimum support of 0.02
    here. After that we are printing the support.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 4：** 现在我们将适配模型。我们在这里给出了最小支持度为 0.02。之后我们将打印支持度。'
- en: '[PRE17]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output is
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '![04_06b](images/04_06b.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![04_06b](images/04_06b.png)'
- en: We can interpret the results here provided based on the support. For each of
    the item and combination of items, we are getting the value of the support. For
    example, for French fries and eggs, the value of support is 3.43%.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据支持度提供的结果进行解释。对于每个项目和项目组合，我们都得到了支持度的值。例如，对于炸薯条和鸡蛋，支持度的值为 3.43%。
- en: ECLAT has some advantages over Apriori algorithm. Since it uses a depth-search
    approach it is faster than Apriori and requires lesser memory to compute. It does
    not scan the dataset iteratively and hence it makes it even faster than Apriori.
    We will compare these algorithms once more after we have studied the last algorithm.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ECLAT 相对于 Apriori 算法具有一些优势。由于它使用深度搜索方法，因此比 Apriori 更快，计算所需的内存更少。它不会迭代地扫描数据集，因此使其比
    Apriori 更快。在我们学习了最后一个算法之后，我们将再次比较这些算法。
- en: 'We will now move to the third algorithm: the F-P growth algorithm.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将转向第三个算法：F-P 生长算法。
- en: 4.6 Frequent-Pattern growth algorithm (F-P algorithm)
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 频繁模式生长算法（F-P 算法）
- en: F-P algorithm or frequent-pattern growth algorithm is the third algorithm we
    will discuss in this chapter. It is an improvement over the Apriori algorithm.
    Recall in Apriori we face challenges of time-consuming and costly computations.
    FP resolves these issues by representing the database in the form of a tree called
    a *frequent pattern tree or FP tree*. Because of this frequent pattern, there
    is no need for generating the candidates as done in the Apriori algorithm. Let’s
    discuss FP in detail now.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: F-P算法或频繁模式增长算法是本章要讨论的第三个算法。它是对Apriori算法的改进。回想一下，在Apriori中，我们面临计算耗时和昂贵的挑战。FP通过将数据库表示为一种名为频繁模式树或FP树的树来解决这些问题。因为这种频繁模式，所以没有必要像Apriori算法那样生成候选项。现在让我们详细讨论一下FP。
- en: FP tree or Frequent Pattern tree is a tree-shaped structure, and it mines the
    most frequent items in the datasets. This is visualized in Figure 4.7.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: FP树或频繁模式树是一个树形结构，它挖掘数据集中最频繁出现的项。见图4.7。
- en: Figure 4.7 FP algorithm can be depicted in a tree-diagram structure. We will
    be creating this tree in a step-by-step fashion. Each node represents a unique
    item. The root node is NULL.
  id: totrans-293
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.7 FP算法可以用树状图结构表示。我们将逐步创建这个树。每个节点代表一个唯一的项。根节点为空。
- en: '![04_07](images/04_07.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![04_07](images/04_07.png)'
- en: Each node represents the unique item in the dataset. The root node of the tree
    is generally kept as NULL. The other nodes in the tree are the items in the dataset.
    The nodes are connected with each other if they are in the same invoice. We will
    study the entire process in a step-by-step fashion.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点表示数据集中的唯一项。树的根节点通常保持为空。树中的其他节点是数据集中的项。如果它们在同一发票中，则节点彼此连接。我们将逐步学习整个过程。
- en: Assume we are using the following dataset as shown in Table 4.9\. So, we have
    unique items as Apple, Milk, Eggs, Cheese and Bread. There are in total 9 transactions
    and the respective items in each of the transaction is shown in Table 4.9.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们使用如表4.9所示的数据集。因此，我们有唯一的项：苹果，牛奶，鸡蛋，奶酪和面包。总共有9个交易，每个交易中的相应项如表4.9所示。
- en: Table 4.9 Data set we are going to use to understand the concept FP algorithm.
    We have nine transactions here, for example in T1 we have apple, milk, and eggs.
  id: totrans-297
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.9我们将使用的数据集，以了解FP算法的概念。这里有九个交易，例如在T1中我们有苹果，牛奶和鸡蛋。
- en: '| Transactions | Item sets |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 交易 | 项集 |'
- en: '| T1 | Apple, Milk, Eggs |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| T1 | 苹果，牛奶，鸡蛋 |'
- en: '| T2 | Milk, Cheese |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| T2 | 牛奶，奶酪 |'
- en: '| T3 | Milk, Bread |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| T3 | 牛奶，面包 |'
- en: '| T4 | Apple, Milk, Cheese |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| T4 | 苹果，牛奶，奶酪 |'
- en: '| T5 | Apple, Bread |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| T5 | 苹果，面包 |'
- en: '| T6 | Milk, Bread |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| T6 | 牛奶，面包 |'
- en: '| T7 | Apple, Bread |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| T7 | 苹果，面包 |'
- en: '| T8 | Apple, Milk, Bread, Eggs |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| T8 | 苹果，牛奶，面包，鸡蛋 |'
- en: '| T9 | Apple, Milk, Bread |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| T9 | 苹果，牛奶，面包 |'
- en: Let’s apply FP algorithm on this dataset now.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将FP算法应用于该数据集。
- en: '**Step 1:** Like Apriori, the entire dataset is scanned first. Occurrences
    for each of the items is counted and a frequency is generated. The results are
    suggested in Table 4.10\. We have arranged the items in descending order of the
    frequency or the respective support count in the entire dataset.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1：** 就像 Apriori 算法一样，我们首先扫描整个数据集。记录每个项出现的次数并生成频率计数。结果如表4.10所示。我们按照整个数据集中各项的频率或对应的支持计数从大到小排列。'
- en: Table 4.10 Respective frequency for each of the item set. For example, apples
    have been purchased in six transactions.
  id: totrans-310
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.10各项集的相应频率。例如，苹果已被购买了六次。
- en: '| Item | Frequency or Support Count |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 项 | 频率或支持计数 |'
- en: '| Milk | 7 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶 | 7 |'
- en: '| Apple | 6 |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 | 6 |'
- en: '| Bread | 6 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 面包 | 6 |'
- en: '| Cheese | 2 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 | 2 |'
- en: '| Eggs | 2 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 | 2 |'
- en: If two items have exactly same frequency, anyone can be ordered first. In the
    example above, we have bread and apple having same frequency. So, we can keep
    either bread or apple as the first one.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个项的频率完全相同，则任何一个都可以排在前面。在上面的例子中，面包和苹果的频率相同。因此，我们可以将面包或苹果作为第一个。
- en: '**Step 2:** Let’s start the construction of the FP tree. We start with creating
    the root node which is generally the NULL node in Figure 4.8.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤2：** 让我们开始构建FP树。我们从根节点开始创建，通常是图4.8中的空节点。'
- en: Figure 4.8 The root node for the tree is generally kept NULL.
  id: totrans-319
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.8 FP树的根节点通常保持为空。
- en: '![04_08](images/04_08.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![04_08](images/04_08.png)'
- en: '**Step 3:** Now analyze the first transaction T1\. Here, we have Apple, Milk
    and Eggs in the first transaction. Out of these three, milk has the highest support
    count which is 7\. So, a connection is extended from root node to Milk and we
    denote it by Milk:1\. We have shown in Figure 4.9.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 3 步：** 现在分析第一个交易 T1。在这里，我们有苹果、牛奶和鸡蛋在第一笔交易中。其中牛奶有最高的支持计数，为 7。因此，从根节点延伸到牛奶的连接，并用
    Milk:1 表示。我们在图 4.9 中展示了。'
- en: Figure 4.9 Connection from the root node to Milk. Milk has the highest support
    hence we have chosen milk.
  id: totrans-322
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.9 从根节点到牛奶的连接。牛奶有最高的支持，因此我们选择了牛奶。
- en: '![04_09](images/04_09.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![04_09](images/04_09.png)'
- en: '**Step 4:** We will now look at the other items in T1\. Apple have a support
    count of 6 and Eggs have a support count of 2\. So, we will extend the connection
    from Milk to Apple and name it Apple:1 and then from Apple to Eggs and call it
    Eggs:1\. We have shown in Figure 4.10.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 4 步：** 现在我们来看看 T1 中的其他项目。苹果的支持计数为 6，鸡蛋的支持计数为 2。所以，我们将从牛奶到苹果延伸连接，并命名为 Apple:1，然后从苹果到鸡蛋并称之为
    Eggs:1。我们在图 4.10 中展示了。  '
- en: Figure 4.10 Step 4 of the process where we have finished all the items in T1\.
    All the items milk, apple and eggs are now connected with each other.
  id: totrans-325
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.10 过程的第 4 步，我们已经完成了 T1 中的所有项目。所有的项目牛奶、苹果和鸡蛋现在都彼此连接。
- en: '![04_10](images/04_10.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![04_10](images/04_10.png)'
- en: '**Step 5:** Let’s look at T2 now. It has Milk and Cheese. Milk is already connected
    to the root node. So, the count for Milk becomes 2 and it becomes Milk:2\. We
    will next create a branch from Milk to cheese and name it Cheese:1\. The addition
    is shown in Figure 4.11.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 5 步：** 现在让我们看看 T2。它有牛奶和奶酪。牛奶已经连接到根节点。所以，牛奶的计数变成 2，变成了 Milk:2。我们接下来会从牛奶到奶酪创建一个分支，并称之为
    Cheese:1。增加的部分显示在图 4.11 中。'
- en: Figure 4.11 Step 5 of the process where we started to analyze T2\. Milk is already
    connected so it’s count increases by 2 while cheese gets added to the tree.
  id: totrans-328
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.11 过程的第 5 步，我们开始分析 T2。牛奶已经连接，所以它的计数增加了 2，同时奶酪被添加到树中。
- en: '![04_11](images/04_11.png)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![04_11](images/04_11.png)'
- en: '**Step 6:** It is the turn of T3 now. T3 has Milk and Bread. So, similar to
    step 5, the count for milk is 3 and it becomes Milk: 3\. And similar to step 5,
    we add another connection from Milk to Bread and call it Bread:1\. The updated
    tree is shown in Figure 4.12.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 6 步：** 现在轮到 T3。T3 有牛奶和面包。所以，类似于第 5 步，牛奶的计数是 3，变成了 Milk: 3。与第 5 步类似，我们从牛奶到面包添加另一个连接，称为
    Bread:1。更新后的树显示在图 4.12 中。'
- en: Figure 4.12 In step 6, T3 is analyzed now. Milk’s count increased by one more
    and becomes 3 while bread is added as a new connection.
  id: totrans-331
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.12 在第 6 步，现在分析 T3。牛奶的计数增加了一个，变成了 3，而面包被添加为一个新的连接。
- en: '![04_12](images/04_12.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![04_12](images/04_12.png)'
- en: '**Step 7:** In T4, we have Apple, Milk and Cheese. The count for milk becomes
    4 now, for apple it is now 2\. Then we create a branch from Apple to Cheese calling
    it Cheese:1\. We are showing in Figure 4.13.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 7 步：** 在 T4 中，我们有苹果、牛奶和奶酪。牛奶的计数现在变成了 4，苹果现在是 2。然后我们创建了一个从苹果到奶酪的分支，称之为 Cheese:1。我们在图
    4.13 中展示。'
- en: Figure 4.13 In the step 7 of the process, T4 is being analyzed. The count of
    milk becomes 4, for apple it increases to 2 and a new branch from apple to cheese
    is added.
  id: totrans-334
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.13 在过程的第 7 步中，正在分析 T4。牛奶的计数变成了 4，苹果的计数增加到了 2，并添加了一个新的从苹果到奶酪的分支。
- en: '![04_13](images/04_13.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![04_13](images/04_13.png)'
- en: '**Step 8:** We can find in T5 that we have Apple and Bread. Both are not directly
    connected to the root node and have an equal frequency of 6\. So, we can take
    either to be connected to the root node. The figure gets updated to Figure 4.14.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8 步：** 我们可以在 T5 中发现，我们有苹果和面包。两者都不直接连接到根节点，频率相等为 6。因此，我们可以任选其一连接到根节点。图更新为图
    4.14。'
- en: Figure 4.14 After analyzing T5, the diagram changes as shown here. We have apple
    and bread which get added to the tree.
  id: totrans-337
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.14 在分析完 T5 之后，图示如下所示发生了变化。我们有苹果和面包被添加到树中。
- en: '![04_14](images/04_14.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![04_14](images/04_14.png)'
- en: '**Step 9:** And this process continues till we exhaust all the transactions
    resulting in the final figure as shown in Figure 4.15.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 9 步：** 这个过程会继续，直到我们耗尽所有的交易，最终的图形如图 4.15 所示。'
- en: Figure 4.15 The final tree once we have exhausted all the possible combinations.
    But there are more steps after this. So far, we have created only the tree. Now
    we need to generate the data set as shown in Table 4.11.
  id: totrans-340
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.15 一旦我们耗尽了所有可能的组合，最终的树就是这样。但是在此之后还有更多的步骤。到目前为止，我们只创建了树。现在我们需要生成数据集，如表 4.11
    所示。
- en: '![04_15](images/04_15.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![04_15](images/04_15.png)'
- en: Great job so far! But the process is not over yet. We have just made the connections
    between the items in the dataset. Now we need to fill a table that looks like
    Table 4.11.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，做得很棒！但是，过程还没有结束。我们刚刚建立了数据集中项目之间的连接。现在我们需要填写一个看起来像表4.11的表。
- en: Table 4.11 Table we are going to complete for FP algorithm. It is the output
    we wish to generate.
  id: totrans-343
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.11 FP算法要完成的表。这是我们希望生成的输出。
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件FP树 | 频繁模式生成 |'
- en: '| Cheese |  |  |  |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 |  |  |  |'
- en: '| Bread |  |  |  |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 面包 |  |  |  |'
- en: '| Eggs |  |  |  |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 |  |  |  |'
- en: '| Apple |  |  |  |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 |  |  |  |'
- en: You might be wondering why there are only 4 items listed. Since Milk has directly
    originated from the root node and there is no other way to reach it, we need not
    have a separate row for milk.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会想为什么只列出了4个项目。由于牛奶直接源自根节点，没有其他到达它的方式，我们不需要为牛奶单独设置一行。
- en: '**Step 10:** Before continuing, we are fixing the minimum support count as
    2 for any rule to be acceptable. We are doing it for simplicity''s sake as the
    dataset is quite small.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '**第10步：** 在继续之前，我们将最小支持计数固定为2，以便接受任何规则。由于数据集相当小，我们这样做是为了简单起见。'
- en: For real-life business problems, you are advised to test with multiple and even
    much higher values for the support counts otherwise the number of rules generated
    can be very high.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 对于现实生活中的业务问题，建议您尝试多个甚至更高的支持计数值，否则生成的规则数量可能会非常多。
- en: Let’s start with Cheese as the first item. We can reach cheese through {NULL-Milk-Cheese}
    and {NULL-Milk-Apple-Cheese}. For both paths, the count of Cheese is 1\. Hence,
    (if we ignore NULL) our conditional pattern base is {Milk-Cheese} or {Milk:1}
    and {Milk-Apple:Cheese} or {Milk-Apple:1}. The complete conditional pattern base
    become {{Milk:1},{Milk-Apple:1}}. This information is added to the second column
    of Table 4.12.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从奶酪作为第一个项目开始。我们可以通过{NULL-牛奶-奶酪}和{NULL-牛奶-苹果-奶酪}到达奶酪。对于这两条路径，奶酪的计数为1。因此，（如果我们忽略NULL）我们的条件模式基为{牛奶-奶酪}或{牛奶:1}和{牛奶-苹果-奶酪}或{牛奶-苹果:1}。完整的条件模式基变为{{牛奶:1},{牛奶-苹果:1}}。这些信息添加到表4.12的第二列。
- en: Table 4.12 Step 10 of the process where we have filled the first cell for cheese.
    We have filled the first cell for cheese.
  id: totrans-353
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.12 过程的第10步，我们已经填写了奶酪的第一个单元格。我们填写了奶酪的第一个单元格。
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件FP树 | 频繁模式生成 |'
- en: '| Cheese | {{Milk:1},{Milk-Apple:1}} |  |  |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 | {{牛奶:1},{牛奶-苹果:1}} |  |  |'
- en: '| Bread |  |  |  |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 面包 |  |  |  |'
- en: '| Eggs |  |  |  |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 |  |  |  |'
- en: '| Apple |  |  |  |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 |  |  |  |'
- en: '**Step 11:** Now if we add the two values in conditional pattern base, we would
    get Milk as 2 and Apple as 1\. Since we have set up a threshold for the frequency
    count of 2, we will ignore the count of Apple. The value for conditional FP tree
    which is the third column in the table become {Milk:2}. Now we simply add the
    original item to this which become frequent patten generated or the column 4\.
    The table now is 4-13'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '**第11步：** 现在，如果我们在条件模式基中添加两个值，我们会得到牛奶为2，苹果为1。由于我们已经为频率计数设置了2的阈值，我们将忽略苹果的计数。条件FP树的值，即表中的第三列，变为{牛奶:2}。现在我们只需将原始项目添加到此项中，变为频繁模式生成或第4列。现在表是4-13。'
- en: Table 4.13 Step 11 of the process where we have finished the details for the
    item cheese. Similarly, all the other items are going to be analyzed and added
    to the table.
  id: totrans-360
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.13 过程的第11步，在这一步中我们完成了奶酪项目的详细信息。同样，所有其他项目都将被分析并添加到表中。
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件FP树 | 频繁模式生成 |'
- en: '| Cheese | {{Milk:1},{Milk-Apple:1}} | {Milk:2} | {Milk-Cheese:2} |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 | {{牛奶:1},{牛奶-苹果:1}} | {牛奶:2} | {牛奶-奶酪:2} |'
- en: '| Bread |  |  |  |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 面包 |  |  |  |'
- en: '| Eggs |  |  |  |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 |  |  |  |'
- en: '| Apple |  |  |  |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 |  |  |  |'
- en: '**Step 12:** In this similar fashion all the other cells are filled in the
    table resulting in the final table as Table 4.14.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '**第12步：** 以类似的方式填写表中的所有其他单元格，最终表为表4.14。'
- en: Table 4.14 Final table after we analyzed all the combinations for the items.
  id: totrans-367
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 我们分析了所有项目的组合后，表4.14是最终表。
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件FP树 | 频繁模式生成 |'
- en: '| Cheese | {{Milk:1},{Milk-Apple:1}} | {Milk:2} | {Milk-Cheese:2} |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 | {{牛奶:1},{牛奶-苹果:1}} | {牛奶:2} | {牛奶-奶酪:2} |'
- en: '| Bread | {{Milk-Apple:2}, {Milk:2}, {Apple:2}} | {{Milk:4, Apple:2}, {Apple:2}}
    | {Milk-Bread:4}, {Apple-Bread:4}, {Milk-Apple-Bread:2} |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 面包 | {{牛奶-苹果:2}, {牛奶:2}, {苹果:2}} | {{牛奶:4, 苹果:2}, {苹果:2}} | {牛奶-面包:4}, {苹果-面包:4},
    {牛奶-苹果-面包:2} |'
- en: '| Eggs | {{Milk-Apple:1},{Milk-Apple-Bread:1}} | {Milk:2, Apple:2} | {Milk-Eggs:2},{Milk-Apple:2},{Milk-Apple:2}
    |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 | {{牛奶-苹果:1},{牛奶-苹果-面包:1}} | {牛奶:2, 苹果:2} | {牛奶-鸡蛋:2},{牛奶-苹果:2},{牛奶-苹果:2}
    |'
- en: '| Apple | {Milk:4} | {Milk:4} | {Milk-Apple:4} |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 | {牛奶:4} | {牛奶:4} | {牛奶-苹果:4} |'
- en: It is a complex process indeed. But once the steps are clear, it is pretty straightforward
    one.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个复杂的过程。但是一旦步骤清晰，就会变得非常简单。
- en: As a result of this exercise, we have received the final set of rules as depicted
    in the final column Frequent Pattern Generated.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个练习，我们已经得到了最终的规则集，如最后一列频繁模式生成所示。
- en: Note that none of the rules are similar to each other.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有的规则都彼此不同。
- en: We will be using the final column “Frequent Pattern Generated” as the rules
    for our dataset.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用最后一列“频繁模式生成”作为我们数据集的规则。
- en: The Python implementation for FP growth algorithm is quite simple and is easy
    to compute using the libraries. In the interest of space, we have uploaded the
    Jupyter Notebook to the GitHub repo of the chapter.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 使用FP增长算法的Python实现非常简单，并且使用库进行计算很容易。出于空间考虑，我们已将Jupyter笔记本上传到了本章的GitHub存储库中。
- en: We will now explore another interesting topic which is sequence rule mining.
    It is very powerful solution that allows the business to tailor their marketing
    strategies and product recommendations to the customers.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将探讨另一个有趣的主题，即序列规则挖掘。这是一个非常强大的解决方案，使企业能够根据客户的需求量身定制他们的营销策略和产品推荐。
- en: 4.7 Sequence rule mining
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 序列规则挖掘
- en: Consider this. Netflix would have a transactional database of all the movies
    ordered by customers over time. If they analyze and find that 65% of customers
    who bought a war movie X also bought a romantic comedy Y in the following month,
    this is very insightful and actionable information. It will allow them to recommend
    their offerings to the customers, and they can customize their marketing strategy.
    Isn’t it?
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下。Netflix会有一个包含顾客随时间订购的所有电影的交易数据库。如果他们分析并发现65%的购买了战争电影X的客户在接下来的一个月也购买了浪漫喜剧Y，这是非常有见地和可操作的信息。这将使他们能够向客户推荐他们的产品，并且他们可以定制他们的营销策略。不是吗？
- en: So far in the chapter, we have covered three algorithms for association rules.
    But all the data points were limited to the same dataset and there was no sequencing
    involved. Sequential pattern mining allows us to analyze a dataset that has a
    sequence of events happening. By analyzing the data set we can find statistically
    relevant patterns, which allows us to decipher the entire sequence of events.
    Obviously, the sequence of events is in a particular order which is a very important
    property to be considered during sequence rule mining.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这一章中，我们已经涵盖了三种关联规则算法。但是所有的数据点都限于相同的数据集，并且没有涉及到序列。序列模式挖掘允许我们分析一组事件发生的数据集。通过分析数据集，我们可以找到统计上相关的模式，这使我们能够解读整个事件序列。显然，事件序列是按照特定顺序排列的，这是序列规则挖掘过程中非常重要的一个属性。
- en: Sequence rule mining is different from time-series analysis. To know more about
    time-series analysis refer to Appendix.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 序列规则挖掘不同于时间序列分析。要了解更多关于时间序列分析的信息，请参阅附录。
- en: Sequence rule mining is utilized across multiple domains and functions. It can
    be used in biology to extract information during DNA sequencing or can be used
    to understand the online search pattern of a user. Sequence rule mining would
    help us understand what the user is going to search next. During the discussion
    of association rules, we used the transactions in which milk, bread, eggs were
    purchased in the same transaction. Sequence rule mining is an extension to that
    wherein we analyze consecutive transactions and try to decipher the sequence present
    if any.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 序列规则挖掘被应用于多个领域和功能。它可以在生物学中用于在DNA测序期间提取信息，也可以用于了解用户的在线搜索模式。序列规则挖掘将帮助我们了解用户接下来要搜索什么。在讨论关联规则时，我们使用了购买牛奶、面包、鸡蛋的同一交易中的交易。序列规则挖掘是对此的扩展，其中我们分析连续的交易，并试图解读是否存在序列。
- en: While studying SPADE algorithm, we will study the mathematical concepts which
    form the base of the algorithm. These concepts are a little tricky to get and
    might require more than one reading to grasp.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究 SPADE 算法时，我们将学习构成该算法基础的数学概念。这些概念有点复杂，可能需要多次阅读才能掌握。
- en: 4.7.1 SPADE
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7.1 SPADE
- en: We are now exploring sequence rule mining using Sequential Pattern Discovery
    using Equivalence classes) or SPADE. It was suggested by Mohammed J. Zaki, the
    link to the paper is at the end of this chapter.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正在使用等价类进行顺序模式挖掘（Sequential Pattern Discovery using Equivalence classes）或
    SPADE 探索序列规则挖掘。这是由穆罕默德·J·扎基（Mohammed J. Zaki）提出的，文章链接在本章末尾。
- en: We understand that we wish to analyze the sequence of events. For example, the
    customer bought a mobile phone and a charger. After a week bought earphones and
    after two weeks bought a mobile cover and mobile screen guard. So, in each of
    the transactions, there are items purchased. And each transaction can be called
    as an event. Let’s understand it in more detail.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到，我们希望分析事件的顺序。例如，顾客购买了手机和充电器。一周后买了耳机，两周后买了手机壳和手机屏幕保护壳。因此，在每次交易中都购买了项目。并且每次交易都可以称为一个事件。让我们更详细地了解一下。
- en: Let us assume we have the complete list of items for the discussion. I will
    contain items like i[1], i[2], i[3], i[4], i[5] and so on. So, we can write
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有讨论所需的所有项目的完整列表。I 将包含像 i[1]、i[2]、i[3]、i[4]、i[5] 等项目。因此，我们可以写成
- en: I = {i[1], i[2], i[3], i[4], i[5]………, i[n]} where we have n distinct items in
    total.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: I = {i[1], i[2], i[3], i[4], i[5]………, i[n]}，其中我们总共有 n 个不同的项目。
- en: Items can be anything. If we consider the same example of a grocery store, items
    can be milk, eggs, cheese, bread and so on.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 项目可以是任何东西。如果我们考虑杂货店的例子，项目可以是牛奶、鸡蛋、奶酪、面包等等。
- en: An event will be a collection of items in the same transaction. An event can
    contain items like (i[1], i[5], i[4], i[8]). For example, an event can contain
    items bought in the same transaction (milk, sugar, cheese, bread). We will denote
    an event by ⍺.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 一个事件将是在同一交易中的项目集合。一个事件可以包含像（i[1], i[5], i[4], i[8）这样的项目。例如，一个事件可以包含在同一交易中购买的项目（牛奶,
    糖, 奶酪, 面包）。我们将用 ⍺ 表示一个事件。
- en: Next let’s understand a sequence. A sequence is nothing but events in an order.
    In other words, ⍺[1] -> ⍺[2] ->⍺[3] ->⍺[4] can be termed as a sequence of event.
    For example, (milk, cheese) -> (bread, eggs)-> (cheese, bread, sugar)-> (milk,
    bread) is a sequence of transactions. It means that in the first transaction milk
    and cheese is bought. In the following transaction, bread and eggs were bought
    and so on.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们了解一下序列。序列只是按顺序的事件。换句话说，⍺[1] -> ⍺[2] ->⍺[3] ->⍺[4] 可以被称为事件序列。例如，（牛奶, 奶酪）->（面包,
    鸡蛋）->（奶酪, 面包, 糖）->（牛奶, 面包）是一系列交易。这意味着在第一次交易中购买了牛奶和奶酪。在接下来的交易中，购买了面包和鸡蛋，依此类推。
- en: A sequence with k items is a k-item sequence. For example, sequence (Milk, Bread)
    -> (Eggs) contains 3 items.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 k 个项目的序列是一个 k 项目序列。例如，序列（牛奶, 面包）->（鸡蛋）包含 3 个项目。
- en: We will now understand SPADE algorithm step-by-step.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将逐步了解 SPADE 算法。
- en: Let’s say we have the following sequences generated. In the first sequence 1001
    of transactions, milk is bought in the very first transaction. In the second one,
    milk, eggs and bread are bought. They are followed by milk and bread. In the fourth
    one only sugar is purchased. In the fifth and final transaction of sequence 1001,
    bread and apples are purchased. And this is applicable to all the respective sequences.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们生成了以下序列。在第一个序列 1001 的交易中，第一个交易中购买了牛奶。第二个交易中购买了牛奶、鸡蛋和面包。紧随其后购买了牛奶和面包。在第四个序列中只购买了糖。在序列
    1001 的第五个和最后一个交易中，购买了面包和苹果。并且这适用于所有相应的序列。
- en: Table 4.15 The dataset for sequence mining. In sequence Id 1001, we have multiple
    events. In the first purchase, milk is bought. Then (milk, eggs, bread) are bought
    and so on.
  id: totrans-396
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.15 序列挖掘的数据集。在序列 ID 1001 中，我们有多个事件。在第一次购买中，购买了牛奶。然后购买了（牛奶, 鸡蛋, 面包）等等。
- en: '| Sequence ID | Sequence |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 序列 |'
- en: '| 1001 | <(Milk) (Milk, Eggs, Bread) (Milk, Bread) (Sugar)(Bread, Apple)> |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | <(牛奶) (牛奶, 鸡蛋, 面包) (牛奶, 面包) (糖)(面包, 苹果)> |'
- en: '| 1002 | <(Milk, Sugar) (Bread) (Eggs, Bread) (Milk, Cheese)> |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | <(牛奶, 糖) (面包) (鸡蛋, 面包) (牛奶, 奶酪)> |'
- en: '| 1003 | <(Cheese, Apple) (Milk, Eggs) (Sugar, Apple) (Bread) (Eggs)> |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | <(奶酪, 苹果) (牛奶, 鸡蛋) (糖, 苹果) (面包) (鸡蛋)> |'
- en: '| 1004 | <(Cheese, Banana)(Milk, Apple)(Bread)(Eggs)(Bread)> |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | <(奶酪, 香蕉)(牛奶, 苹果)(面包)(鸡蛋)(面包)> |'
- en: This (Table 4.15 ) can be converted into a vertical data format as shown in
    Table 4.16\. In this step, we calculate the frequencies for 1-sequence items,
    which are sequence with only one item. For this only a single database scan is
    required.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这个（表 4.15 ）可以转换成垂直数据格式，如表 4.16 所示。在这一步中，我们计算单个项目的频率，即仅包含一个项目的序列。这仅需要进行一次数据库扫描。
- en: Table 4.16 Vertical format for Table 4.15\. We have simply got the sequence
    Id and Item id for each of the item and represented it here.
  id: totrans-403
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.16 表4.15 的垂直格式。我们只是得到了每个项目的序列 ID 和项目 ID，并在此处表示它。
- en: '| Sequence ID | Element ID | Items |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 元素 ID | 项目 |'
- en: '| 1001 | 1 | Milk |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 牛奶 |'
- en: '| 1001 | 2 | Milk, Eggs, Bread |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 2 | 牛奶, 鸡蛋, 面包 |'
- en: '| 1001 | 3 | Milk, Bread |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 3 | 牛奶, 面包 |'
- en: '| 1001 | 4 | Sugar |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 4 | 糖 |'
- en: '| 1001 | 5 | Bread, Apple |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 5 | 面包, 苹果 |'
- en: '| 1002 | 1 | Milk, Sugar |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 1 | 牛奶, 糖 |'
- en: '| 1002 | 2 | Bread |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 2 | 面包 |'
- en: '| 1002 | 3 | Eggs, Bread |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 3 | 鸡蛋, 面包 |'
- en: '| 1002 | 4 | Milk, Cheese |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 4 | 牛奶, 奶酪 |'
- en: '| 1003 | 1 | Cheese, Apple |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 1 | 奶酪, 苹果 |'
- en: '| 1003 | 2 | Milk, Eggs |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 2 | 牛奶, 鸡蛋 |'
- en: '| 1003 | 3 | Sugar, Apple |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 3 | 糖, 苹果 |'
- en: '| 1003 | 4 | Bread |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 4 | 面包 |'
- en: '| 1003 | 5 | Eggs |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 5 | 鸡蛋 |'
- en: '| 1004 | 1 | Cheese, Banana |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 1 | 奶酪, 香蕉 |'
- en: '| 1004 | 2 | Milk, Apple |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 2 | 牛奶, 苹果 |'
- en: '| 1004 | 3 | Bread |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 3 | 面包 |'
- en: '| 1004 | 4 | Eggs |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 4 | 鸡蛋 |'
- en: '| 1004 | 5 | Bread |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 5 | 面包 |'
- en: Table 4.16 is nothing but a vertical tabular representation of Table 4.15\.
    For example, in sequence Id 1001, at the element ID 1 we have Milk. For sequence
    ID 1001, at the element ID 2 we have Milk, Eggs, Bread and so on.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.16 只是表4.15 的垂直制表符号表示。例如，在序列 ID 1001 中，元素 ID 1 是牛奶。对于序列 ID 1001，元素 ID 2 是牛奶，鸡蛋，面包等。
- en: For the purpose of explanation, we are considering only two items 0 milk and
    eggs and the support threshold of 2.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释的目的，我们只考虑两个项目 0 牛奶和鸡蛋以及支持阈值为 2。
- en: Then, in the next step, we will break it down for each of the items. For example,
    milk appears in sequence Id 1001 and element Id 1, sequence Id 1001 and element
    Id 2, sequence Id 1001 and element Id 3, sequence Id 1002 and element Id 1 and
    so on. It results in a table like Table 4.17 where we have shown Milk and Eggs.
    It needs to be applied to all the items in the dataset.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在下一步中，我们将对每个项目进行分解。例如，牛奶出现在序列 ID 1001 和元素 ID 1，序列 ID 1001 和元素 ID 2，序列 ID
    1001 和元素 ID 3，序列 ID 1002 和元素 ID 1 等中。它会产生类似表4.17 的表格，我们在其中显示了牛奶和鸡蛋。它需要应用到数据集中的所有项目。
- en: Table 4.17 Respective sequence Ids for milk and eggs. The same can be done across
    all the items and the sequences.
  id: totrans-427
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.17 中相应的牛奶和鸡蛋序列 ID。同样的方法可以应用到所有项目和序列中。
- en: '| Milk | Eggs |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶 | 鸡蛋 |'
- en: '| Sequence ID | Element ID | Sequence ID | Element ID |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 元素 ID | 序列 ID | 元素 ID |'
- en: '| 1001 | 1 | 1001 | 2 |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 1001 | 2 |'
- en: '| 1001 | 2 | 1002 | 3 |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 2 | 1002 | 3 |'
- en: '| 1001 | 3 | 1003 | 2 |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 3 | 1003 | 2 |'
- en: '| 1002 | 1 | 1003 | 5 |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 1 | 1003 | 5 |'
- en: '| 1002 | 4 | 1004 | 5 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 4 | 1004 | 5 |'
- en: '| 1003 | 2 |  |  |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 2 |  |  |'
- en: '| 1004 | 3 |  |  |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 3 |  |  |'
- en: Now, we wish to count 2-sequences or with 2 item sequences. We can have two
    sequences – either Milk -> Eggs or Eggs -> Milk. Let’s first take Milk-> Eggs.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们希望计算 2-序列或具有 2 项序列。我们可以有两个序列 - 要么是牛奶 -> 鸡蛋，要么是鸡蛋 -> 牛奶。让我们先来看看牛奶-> 鸡蛋。
- en: For Milk -> Eggs we need to have milk in front of eggs. For the same sequence
    Id, if the element Id of milk is less than the element Id of eggs, then it is
    an eligible sequence. In the example above, for sequence Id 1002, the element
    Id of milk is 1 while the element Id of eggs is 2\. So we can add that as the
    first eligible pair as shown in the first row of Table 4.18\. The same is true
    for sequence Id 1002\. In Table 4.17, row 4 we have sequence Id 1002\. Element
    Id of milk is 1 while that of eggs in row 2 is 3\. Again element Id of milk is
    lesser than element Id of eggs, so it becomes the second entry. And the process
    continues.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 对于牛奶 -> 鸡蛋，我们需要在鸡蛋前面放牛奶。对于相同的序列 ID，如果牛奶的元素 ID 小于鸡蛋的元素 ID，则它是一个合格的序列。在上面的示例中，对于序列
    ID 1002，牛奶的元素 ID 是 1，而鸡蛋的元素 ID 是 2。因此，我们可以将其添加为第一个合格对，如下表4.18的第一行所示。对于序列 ID 1002
    也是如此。在表4.17中，第4行我们有序列 ID 1002。牛奶的元素 ID 是 1，而第 2 行的鸡蛋的元素 ID 是 3。同样，牛奶的元素 ID 小于鸡蛋的元素
    ID，因此它变为第二个条目。进程继续。
- en: Table 4.18 Sequence Milk Eggs can be written down here. The key point is to
    have the same sequence Id while comparing the respective element Ids of milk and
    eggs.
  id: totrans-439
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.18 序列牛奶鸡蛋可以写在这里。关键点是在比较牛奶和鸡蛋的相应元素 ID 时具有相同的序列 ID。
- en: '| Milk Eggs |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶 鸡蛋 |'
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 元素 ID（牛奶） | 元素 ID（鸡蛋） |'
- en: '| 1001 | 1 | 2 |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 2 |'
- en: '| 1002 | 1 | 3 |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 1 | 3 |'
- en: '| 1003 | 2 | 5 |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 2 | 5 |'
- en: '| 1004 | 3 | 5 |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 3 | 5 |'
- en: By using the same logic, we can create the table for eggs -> milk which is shown
    in Table 4.19 below.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的逻辑，我们可以创建表格，例如鸡蛋 -> 牛奶，如下所示在下表4.19中显示。
- en: Table 4.19 Sequence Eggs Milk can be written down here. The key point is to
    have the same sequence Id while comparing the respective element Ids of milk and
    eggs.
  id: totrans-447
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.19：序列鸡蛋牛奶可以在此处写下。关键在于比较牛奶和鸡蛋的各自元素ID时保持相同的序列ID。
- en: '| Eggs Milk |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| 美纪牛奶 |'
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| 序列ID | 元素ID（牛奶） | 元素ID（鸡蛋） |'
- en: '| 1001 | 2 | 3 |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 2 | 3 |'
- en: '| 1002 | 3 | 4 |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 3 | 4 |'
- en: This can be done for each of the possible combinations. We will now move to
    creating 3-item sequences and we will create Milk, Eggs -> Milk. For this purpose,
    we have to join the two tables.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 可以对所有可能的组合都进行此操作。现在我们将转向创建3项序列，我们将创建Milk，Eggs -> Milk。为此，我们必须合并这两个表。
- en: Table 4.20 Combining both the sequence i.e., milk-> eggs and eggs-> milk to
    join the tables.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.20：结合序列，即牛奶->鸡蛋和鸡蛋->牛奶，以合并表格。
- en: '![04_T20](images/04_T20.png)'
  id: totrans-454
  prefs: []
  type: TYPE_IMG
  zh: '![04_T20](images/04_T20.png)'
- en: The logic of joining is matching the sequence Id and the element Id. We have
    highlighted the matching ones in red and green color respectively. For sequence
    Id 1001, the element Id of eggs in the left table matches with element Id of eggs
    in the right table and that becomes the first entry of Table 4.21\. Similarly
    for sequence Id 1002, element Id 3 matches. This results in the Table 4.21.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 结合的逻辑是匹配序列ID和元素ID。我们已经用红色和绿色分别突出显示匹配的部分。对于序列ID 1001，左表中鸡蛋的元素ID和右表中鸡蛋的元素ID匹配，这成为表4.21的第一条目。同样对于序列ID
    1002，元素ID 3匹配。这导致了表4.21的生成。
- en: Table 4.21 Final table after we analyzed all the combinations for the items.
  id: totrans-456
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '表4.21：在分析了所有物品的组合后的最终表。 '
- en: '| Milk, Eggs -> Milk |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋 -> 牛奶 |'
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) | Element ID (Milk) |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 序列ID | 元素ID（牛奶） | 元素ID（鸡蛋） | 元素ID（牛奶） |'
- en: '| 1001 | 1 | 2 | 3 |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 1 | 2 | 3 |'
- en: '| 1002 | 1 | 3 | 4 |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 1 | 3 | 4 |'
- en: This process continues. The algorithm stops when no frequent sequences can be
    found.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程将继续进行。当找不到频繁序列时算法停止。
- en: We will now implement SPADE on a dataset using Python. We are using `pyspade`
    library and hence we have to load the dataset and call the function. It generates
    the result for us. The support is kept as 0.6 here and then we are printing the
    results.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Python在数据集上实现SPADE。我们使用`pyspade`库，因此我们必须加载数据集并调用函数。它会为我们生成结果。这里支持率设置为0.6，然后我们打印结果。
- en: '[PRE18]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![04_15a](images/04_15a.png)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
  zh: '![04_15a](images/04_15a.png)'
- en: This concludes our four algorithms which we wish to discuss in this chapter.
    We will now move to the case study to give a real-life experience to you.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们在本章中要讨论的四种算法。现在我们将转向案例研究，为您提供真实的体验。
- en: 4.8 Case study for association rules
  id: totrans-466
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.8关联规则案例研究
- en: Association rule mining is quite a helpful and powerful solution. We are going
    to solve an actual case study using association rules.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '关联规则挖掘是一个非常有用和强大的解决方案。我们将使用关联规则解决一个实际案例研究。 '
- en: Recall that at the start of the chapter, we suggested to study the pattern of
    a grocery store. What is the logic of such arrangements in the store?
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，在本章的开头，我们建议研究杂货店的模式。这种店铺摆设的逻辑是什么呢？
- en: 'Consider this: You are working for a grocery retailer like Walmart or Tesco
    or Spar or Marks & Spencer’s etc. And they have to plan the visual layout of a
    new store. Obviously, it is imperative that retail stores utilize the space in
    the store wisely and to the maximum of its capacity. At the same time, it is vital
    that the movement of the customers is not hindered. Customers should have access
    to all the items at display and can navigate easily. You might have experienced
    some stores where we feel choked and bombarded with displays while others are
    neatly stacked.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：你在像沃尔玛、乐购、Spar或Marks & Spencer等杂货零售商工作。他们必须规划新店的视觉布局。显然，零售商要明智地利用店内空间，充分利用最大的容量。与此同时，至关重要的是不妨碍顾客的活动。顾客应该可以接触到所有展示的物品，并能够轻松地导航。你可能会有一些经历过一些店铺让我们感到窒息和陈列品充斥，而另一些则整齐摆放的情况。
- en: How do we solve this problem?
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何解决这个问题呢？
- en: There can be multiple solutions to this problem. Some retailers might wish to
    group the items based on their categories. They might want to keep all the baking
    products in one shelf or use any other condition. We are studying the machine
    learning example here.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题可能有多种解决方案。一些零售商可能希望根据商品类别对物品进行分组。他们可能希望将所有烘焙产品都放在一个架子上，或者根据任何其他条件使用。我们在这里学习的是机器学习的例子。
- en: Using market basket analysis, we can generate the rules which indicate the respective
    relationships between various items. We can predict which items are frequently
    bought together and they can be kept together in the store. For example, if we
    know that milk and bread are bought together, then bread can be kept near the
    milk counter. The customer purchasing milk can locate bread easily and continue
    with their purchase.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 使用购物篮分析，我们可以生成规则，指示各种商品之间的相关关系。我们可以预测哪些商品经常一起购买，并且可以将它们放在店里的一起。例如，如果我们知道牛奶和面包经常一起购买，那么面包可以放在牛奶柜台附近。购买牛奶的顾客可以轻松找到面包并继续购买。
- en: But it is not as easy as it sounds. Let us solve this case step-by-step.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 但事情并不像听起来那么简单。让我们逐步解决这个案例。
- en: '**Business problem definition**: the very first step is defining the business
    problem which is clear to us. We wish to discover the relationships between various
    items so that the arrangement in the store can be made better. Here *planograms*
    come into the picture. Planograms help the retailer plan the utilization of the
    space in the store in a wise manner so that the customer can also navigate and
    access the products easily. It can be considered as a visual layout of the store.
    An example can be shown as in Figure 4.16.'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**业务问题定义**：第一步是明确定义我们清楚的业务问题。我们希望发现各种商品之间的关系，以便可以更好地安排商店内的布局。在这里，*陈列计划* 变得很重要。陈列计划帮助零售商以明智的方式规划商店内的空间利用，使顾客也可以轻松导航和访问产品。它可以被视为商店的视觉布局。示例如图4.16所示。'
- en: Figure 4.16 An example of planogram is shown here. Planograms are very useful
    for visual merchandising.
  id: totrans-475
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.16 显示了一个陈列计划的示例。陈列计划对于视觉营销非常有用。
- en: '![04_16](images/04_16.png)'
  id: totrans-476
  prefs: []
  type: TYPE_IMG
  zh: '![04_16](images/04_16.png)'
- en: In the figure, we can see that there are specific areas for each and every item
    category. Association rules are quite insightful to help generate directions for
    planograms.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，我们可以看到每个商品类别都有特定的区域。关联规则非常有洞察力，可以帮助生成陈列计划的方向。
- en: '**Data discovery**: the next step is the data discovery wherein the historical
    transactions are scouted and loaded into a database. Typically, a transaction
    can look like the Table 4.22.'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据发现**：下一步是数据发现，其中历史交易被搜索并加载到数据库中。通常，一笔交易看起来像表4.22。'
- en: Table 4.22 Example of invoices generated in real-world retail store. It is quite
    a challenge to convert this data format into the one which can be consumed by
    the association rule algorithms.
  id: totrans-479
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.22 实际零售店生成的发票示例。将这种数据格式转换为可以被关联规则算法消费的格式是相当具有挑战性的。
- en: '| Invoice Number | Date | Items | Amount |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| 发票编号 | 日期 | 商品 | 金额 |'
- en: '| 1001 | 01-Jun-21 | Milk, eggs, cheese, bread | $10 |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 01-Jun-21 | 牛奶，鸡蛋，奶酪，面包 | $10 |'
- en: '| 1002 | 01-Jun-21 | Bread, banana, apples, butter | $15 |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 01-Jun-21 | 面包，香蕉，苹果，黄油 | $15 |'
- en: '| 1003 | 01-Jun-21 | Butter, carrots, cheese, eggs, bread, milk, bananas |
    $19 |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 01-Jun-21 | 黄油，胡萝卜，奶酪，鸡蛋，面包，牛奶，香蕉 | $19 |'
- en: '| 1004 | 01-Jun-21 | Milk | $1 |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| 1004 | 01-Jun-21 | 牛奶 | $1 |'
- en: '| 1005 | 01-Jun-21 | Bread | $0.80 |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| 1005 | 01-Jun-21 | 面包 | $0.80 |'
- en: '**Data preparation**: this step perhaps is the most difficult step. As you
    would have realized that association rules model creation is a very simple task.
    We have libraries that can do the heavy lifting for us. But the data set expected
    by them is in a particular format. This is a tedious task, quite time-consuming
    and requires a lot of data pre-processing skills.'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：这一步也许是最困难的一步。正如你可能意识到的那样，关联规则模型的创建是一项非常简单的任务。我们有可以为我们处理繁重工作的库。但是它们期望的数据集是以特定格式存在的。这是一项繁琐的任务，非常耗时，并且需要大量的数据预处理技能。'
- en: 'There are a few considerations you have to keep in mind while preparing the
    data set, which are:'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在准备数据集时，有几个注意事项你必须记住，它们是：
- en: Sometimes we get **NULL** or **blank values** during the data preparation phase.
    Missing values in the data sets can lead to problems while computing. In other
    machine learning solution, we would advise to treat the missing values. In the
    case of association rules, we would suggest to ignore the respective transactions
    and do not consider it in the final dataset.
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有时在数据准备阶段我们会得到**NULL**或**空值**。数据集中的缺失值可能会导致计算时出现问题。在其他机器学习解决方案中，我们建议处理缺失值。在关联规则的情况下，我们建议忽略相应的交易，并且不在最终数据集中考虑它。
- en: Many times, we get **junk values** in the data. Special characters like !@%^&*()_
    are found in the datasets. It can be attributed to incorrect entries in the system.
    Hence, data cleaning is required.
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 很多时候，我们在数据中会得到**垃圾值**。数据集中会发现像!@%^&*()_这样的特殊字符。这可能是由系统中不正确的输入导致的。因此，需要进行数据清洗。
- en: We are covering the data pre-processing step in great detail in the appendix
    of the book, wherein we deal with NULL values and junk values.
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在书的附录中非常详细地介绍了数据预处理步骤，在这里我们处理NULL值和垃圾值。
- en: Converting Table into a format which can be understood and consumed by the association
    rule learning algorithms is an imperative but arduous step. Go through the concept
    of SQL pivoting to understand the concept better. Else, you might need someone
    (a data engineer) to create the dataset for you.
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将表格转换为关联规则学习算法可以理解和使用的格式是一项必不可少但又艰巨的步骤。深入了解SQL数据透视的概念以更好地理解这个概念。否则，你可能需要某人（一位数据工程师）为你创建数据集。
- en: '**Model preparation:** perhaps the easiest of the steps is modelling. We have
    already solved Python solutions for different algorithms. So, you should be quite
    comfortable with it.'
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型准备：** 或许最容易的步骤之一就是建模。我们已经为不同的算法解决了Python解决方案。所以，你应该对此相当熟悉。'
- en: '**Model interpretation**: creating the model might be easy but interpretation
    of the rules is not. Most of the time, you can rules like:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型解释：** 创建模型可能很容易，但解释规则却不是。大多数时候，你可以得到如下规则：'
- en: '#NA -> (Milk, Cheese) – such a rule is obviously non-usable and does ot make
    any sense. It indicated that the data preparation was not correct and some junk
    values are still present in the dataset.'
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '#NA -> (牛奶，奶酪) - 这样的规则显然是不可用的，也没有任何意义。它表明数据准备不正确，数据集中仍然存在一些垃圾值。'
- en: (Some items) -> (Packaging material) – perhaps the most obvious rule but again
    not usable. This rule indicates that whenever shopping is done, packaging material
    is also purchased, quite obvious right?
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （某些物品）->（包装材料）- 或许是最明显的规则，但同样不可用。这个规则表明，无论何时购物，都会购买包装材料，相当明显对吧？
- en: '(Potatoes, Tomatoes) -> (Onions) : this kind of rule might look correct but
    it a common sense knowledge that the retailer would already know. Obviously, most
    of the customers who are buying vegetables will buy potatoes, tomatoes, and onions
    together. Such rules, might not add much value to the business.'
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （土豆，番茄）->（洋葱）：这种规则看起来可能是正确的，但这是零售商已经知道的常识。显然，大多数购买蔬菜的顾客都会一起购买土豆、番茄和洋葱。这样的规则可能对业务价值增加不多。
- en: Threshold for support, confidence and lift allows to filter out the most important
    rules. We can sort the rules in the descending order of the lift and then remove
    the most obvious ones.
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 支持、置信度和提升阈值允许过滤出最重要的规则。我们可以按提升的降序排序规则，然后移除最明显的规则。
- en: '**Business subject-matter expert**: it is of vital importance that business
    stakeholders and subject matter experts are involved at each and every step. In
    this case study, the operations team, visual merchandising team, product teams
    and marketing teams are the key players which should be closely aligned at each
    and every step.'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**业务主题专家：** 业务利益相关者和主题专家参与每一个步骤是至关重要的。在这个案例研究中，运营团队、视觉营销团队、产品团队和营销团队是关键参与者，他们应该在每一个步骤都密切配合。'
- en: Once the rules are generated and accepted, then we can use them to improve the
    planogram for the retail space. The retailer can use them to improve the marketing
    strategy and improve product promotions. For example, if a rule like (A, B) ->
    (C) is accepted, the retailer might wish to create a bundle of the products and
    sell them as a single entity. It will increase the average number of items purchased
    in the same transaction for the business.
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦规则生成并得到接受，我们就可以使用它们来改善零售空间的陈列方案。零售商可以利用它们来改善营销策略并改进产品促销活动。例如，如果接受了像（A，B）->（C）这样的规则，零售商可能希望将产品捆绑在一起并作为一个单一实体出售。这将增加同一交易中购买的平均物品数量。
- en: This case study can be extended to any other domain or business function. For
    example, the same steps can be used if we wish to examine user’s movement across
    web pages. Web developers can analyze the historical clicks and usages of the
    customers on their websites. By identifying the patterns, they can find out what
    user tends to click and which features will maximize their engagement. Medical
    practitioners can use association rules to better diagnose patients. The doctors
    can compare the probability of the symptoms in relationship with other symptoms
    and provide a more accurate diagnosis.
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个案例研究可以扩展到任何其他领域或业务功能。例如，如果我们希望检查用户在网页上的移动，可以使用相同的步骤。网页开发人员可以分析客户在其网站上的历史点击和使用情况。通过识别模式，他们可以找出用户倾向于点击什么以及哪些功能会最大化他们的参与度。医生可以使用关联规则更好地诊断患者。医生可以比较与其他症状的概率相关的症状，并提供更准确的诊断。
- en: We will now examine the limitations of these algorithms and other solutions
    which are available for association rules and sequence rules.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将研究这些算法的局限性以及关联规则和序列规则的其他可用解决方案。
- en: 4.9 Closing Thoughts
  id: totrans-502
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.9 总结思考
- en: There are some assumptions and limitations in the association rules and sequence
    rules we have studied.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们研究的关联规则和序列规则中，存在一些假设和限制。
- en: The respective significance of an item is ignored while we generate the rules.
    For example, if a customer purchased 5 cans of milk and one kg of apples in a
    transaction, it is treated similarly to an invoice in which one can of milk and
    five kg of apples are purchased. Hence, we have to bear in mind that the respective
    *weight* of an item in not being considered.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成规则时，忽略了物品的各自重要性。例如，如果一个顾客在一次交易中购买了5罐牛奶和一公斤苹果，那么它被类似地对待于一张发票，其中购买了一罐牛奶和五公斤苹果。因此，我们必须记住物品的各自*重要性*没有被考虑。
- en: The cost of an item indicated the perceived value of a product. Some products
    which are costly are more important and hence, if they are purchased by the customer
    more revenue can be generated. While analyzing the invoices, we ignore the cost
    associated with an item.
  id: totrans-505
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商品的成本反映了产品的感知价值。一些昂贵的产品更为重要，因此，如果顾客购买了它们，就可以产生更多的收入。在分析发票时，我们忽略了物品的成本。
- en: While analyzing the sequence, we have not considered the respective time periods
    between the two transactions. For example, if between T1 and T2, there were 10
    days while between T2 and T3 there were 40 days – both are considered as same.
  id: totrans-506
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分析序列时，我们没有考虑两个交易之间的各自时间段。例如，在T1和T2之间有10天，而在T2和T3之间有40天 - 这两个时间段被视为相同。
- en: In all the analyses, we have considered different categories as the same. Perishable
    items and non-perishable items are treated in a similar fashion. For example,
    fresh milk with a shelf life of 2-3 days is treated similarly to washing powder
    which has unlimited shelf life.
  id: totrans-507
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有的分析中，我们将不同类别视为相同。易腐烂商品和不易腐烂商品被以类似方式处理。例如，保质期为2-3天的新鲜牛奶被类似对待于保质期无限的洗衣粉。
- en: Many times we receive non-interesting rules after analysis. These results are
    from common sense (Potatoes, Tomatoes) -> (Onion). Such rules are not of much
    use. We face such an issue a lot of the time.
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多时候，我们在分析后得到了不感兴趣的规则。这些结果来自常识（土豆，西红柿）->（洋葱）。这样的规则并不太有用。我们很多时候都面临这样的问题。
- en: While non-interesting rules are a challenge, a huge number of discovered rules
    are again one of the problems. We get hundreds of rules and it becomes difficult
    to understand and analyze each one of them. Here, the thresholding becomes handy.
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然不感兴趣的规则是一个挑战，但发现的大量规则又是问题之一。我们得到了成百上千的规则，要理解和分析每一个都变得困难。在这里，阈值变得很有用。
- en: The time and memory requirements for computations are huge. The algorithms require
    scanning the data sets many times and hence it is quite a time-consuming exercise.
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算所需的时间和内存需求是巨大的。这些算法需要多次扫描数据集，因此是非常耗时的练习。
- en: The rules generated are dependent on the data set which has been used for analysis.
    For example, if we analyze the data set generated during summers only, we cannot
    use the rules for winters as consumers' preferences change between different weathers.
    Moreover, we have to refresh the algorithms over time since with the passage of
    time, the macro and micro economic factors change and hence, the algorithms should
    be refreshed too.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的规则取决于用于分析的数据集。例如，如果我们仅在夏季生成的数据集上进行分析，我们就不能将规则应用于冬季，因为消费者的偏好会随着不同季节而变化。此外，随着时间的流逝，宏观和微观经济因素也会发生变化，因此算法也应随之更新。
- en: There are some other algorithms which are also of interest. For association
    rules, we can have multi-relation association rules, k-optimal pattern discovery,
    approximate frequent data set, generalized association rules, high order pattern
    discovery etc. For sequence mining, we have Generalized Sequence Pattern, FreeSpan,
    PrefixSpan, Mining associated patterns etc. These algorithms are quite interesting
    and can be studied for knowledge enhancement.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他算法也很有趣。对于关联规则，我们可以有多关系关联规则、k-最佳模式发现、近似频繁数据集、广义关联规则、高阶模式发现等。对于序列挖掘，我们有广义序列模式、FreeSpan、PrefixSpan、挖掘相关模式等。这些算法非常有趣，可以用于增强知识。
- en: Association rules and sequence mining are quite interesting topics. Various
    business domains and functions are increasingly using association rules to understand
    the pattern of events. These insights allow the teams to take sound and scientific
    decisions to improve the customer experience and overall engagement. This chapter
    is the first chapter in the second part of the book. We have explored association
    rules and sequence mining in this chapter. These are studied using Apriori, FP
    and ECLAT algorithms and for sequence mining we used SPADE.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则和序列挖掘是非常有趣的主题。各个商业领域和功能越来越多地使用关联规则来理解事件的模式。这些见解使团队能够做出明智而科学的决策，以改善客户体验和整体参与度。本章是本书第二部分的第一章。我们在本章中探讨了关联规则和序列挖掘。这些是使用Apriori、FP和ECLAT算法进行研究的，而序列挖掘则使用了SPADE。
- en: In the next chapter, we are studying advanced clustering algorithms. So stay
    tuned!
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究高级聚类算法。敬请关注！
- en: You can now progress to question section.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以继续问题部分。
- en: Practical next steps and suggested readings
  id: totrans-516
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实际的下一步和建议的阅读
- en: Go through these research papers for association rules algorithm
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请阅读以下关联规则算法的研究论文
- en: Fast discovery of association rules ([http://www.cs.bme.hu/~marti/adatbanya/apriori_hashtree.pdf](adatbanya.html))
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关联规则的快速发现（[http://www.cs.bme.hu/~marti/adatbanya/apriori_hashtree.pdf](adatbanya.html)）
- en: Fast algorithms for Mining Association Rules ([https://rakesh.agrawal-family.com/papers/vldb94apriori.pdf](papers.html))
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于挖掘关联规则的快速算法（[https://rakesh.agrawal-family.com/papers/vldb94apriori.pdf](papers.html)）
- en: Efficient analysis of Pattern and Association Rule Mining Approaches ([https://arxiv.org/pdf/1402.2892.pdf](pdf.html))
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模式和关联规则挖掘方法的高效分析（[https://arxiv.org/pdf/1402.2892.pdf](pdf.html)）
- en: A review of association rule mining techniques with respect to their privacy
    preserving capabilities ([https://www.ripublication.com/ijaer17/ijaerv12n24_216.pdf](ijaer17.html))
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于其保护隐私能力的关联规则挖掘技术综述（[https://www.ripublication.com/ijaer17/ijaerv12n24_216.pdf](ijaer17.html)）
- en: 'For sequence mining, go through these research papers:'
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于序列挖掘，请阅读以下研究论文：
- en: 'SPADE: An efficient algorithm for mining frequent sequences ([https://link.springer.com/content/pdf/10.1023/A:1007652502315.pdf](10.1023.html))'
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SPADE：用于挖掘频繁序列的高效算法（[https://link.springer.com/content/pdf/10.1023/A:1007652502315.pdf](10.1023.html)）
- en: 'Sequential mining: patterns and algorithm analysis ([https://arxiv.org/pdf/1311.0350.pdf](pdf.html))'
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顺序挖掘：模式与算法分析（[https://arxiv.org/pdf/1311.0350.pdf](pdf.html)）
- en: Sequential pattern mining algorithm based on interestingness ([https://ieeexplore.ieee.org/document/8567170](document.html))
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于趣味性的顺序模式挖掘算法（[https://ieeexplore.ieee.org/document/8567170](document.html)）
- en: A new approach for problem of Sequential Pattern Mining ([https://link.springer.com/chapter/10.1007/978-3-642-34630-9_6](10.1007.html))
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种解决顺序模式挖掘问题的新方法（[https://link.springer.com/chapter/10.1007/978-3-642-34630-9_6](10.1007.html)）
- en: 4.10 Summary
  id: totrans-527
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.10 总结
- en: We studied association rules which can be used to find compelling relationships
    between the variables which are present in the data sets
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们研究了关联规则，这些规则可用于发现数据集中存在的变量之间的引人注目的关系
- en: We covered the concepts of support, confidence, lift, and conviction which are
    used to measure the efficacy of the rules generated.
  id: totrans-529
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们介绍了支持度、置信度、提升度和确信度的概念，用于衡量生成的规则的效果。
- en: We then moved to apriori algorithm which utilizes a “bottom-up” approach where
    the first candidates are generated based of the frequency of the subsets. Apriori
    scans the entire data iteratively and hence takes a lot of time.
  id: totrans-530
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们转向了apriori算法，该算法利用了“自下而上”的方法，首先根据子集的频率生成候选项。Apriori算法会迭代地扫描整个数据，因此需要很长时间。
- en: We discussed ECLAT which is a depth-first search method. It performs the search
    in a vertical fashion throughout the dataset. Since it does not scan the dataset
    iteratively, it is faster than apriori.
  id: totrans-531
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们讨论了ECLAT，这是一种深度优先搜索方法。它在整个数据集上以垂直方式执行搜索。由于它不会迭代地扫描数据集，因此比apriori更快。
- en: We also covered frequent-pattern growth algorithm which works on representing
    the data base in the form of a tree called a frequent pattern tree or FP tree.
    Because of this frequent pattern, there is no need for generating the candidates
    as done in Apriori algorithm and hence it is less time-consuming.
  id: totrans-532
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还介绍了频繁模式增长算法，该算法通过将数据库表示为称为频繁模式树或FP树的树来工作。由于这种频繁模式，无需像Apriori算法中那样生成候选项，因此它所需的时间较少。
- en: We then covered sequence-based learning technique known as SPADE where we also
    take the sequence in which the various events have happened in a particular sequence.
  id: totrans-533
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们接着介绍了一种名为SPADE的基于序列的学习技术，其中我们也考虑了各种事件发生的具体顺序。
- en: We finally had the Python implementation of the techniques using apyori, pyECLAT,
    fpgrowth_py and pyspade.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用apyori、pyECLAT、fpgrowth_py和pyspade实现了Python技术。
