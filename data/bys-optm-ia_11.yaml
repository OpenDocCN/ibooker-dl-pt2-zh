- en: 8 Satisfying extra constraints with constrained optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 满足额外约束的满意条件优化
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括
- en: The problem of black box optimization with constraints
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带约束的黑盒优化问题
- en: Taking constraints into account when making decisions in BayesOpt
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 BayesOpt 中考虑约束时做出决策
- en: Implementing constraint-aware BayesOpt policies
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施考虑约束的 BayesOpt 策略
- en: In previous chapters, we tackled black box optimization problems in which we
    aimed solely to maximize the objective function, without any other considerations.
    This is called an *unconstrained* optimization problem as we are free to explore
    the search space to look for the global optimum of the objective function. Many
    real-life situations do not follow this unconstrained formulation, however, and
    there might be a cost associated with the objective function’s global optimum
    that makes the optimum infeasible to achieve in practice.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们解决了黑盒优化问题，其中我们仅旨在最大化客观函数，没有其他考虑因素。这被称为*无约束*优化问题，因为我们可以自由地探索搜索空间以寻找客观函数的全局最优解。然而，许多现实情况并不遵循这种无约束的制定，客观函数的全局最优解可能存在成本，使实践中无法实现这种最优解。
- en: For example, when tuning the architecture of a neural network, you might find
    that increasing the number of layers in the network usually yields a higher accuracy,
    and a network with millions and billions of layers will perform the best. However,
    unless we have access to expensive, powerful computing resources, running such
    large neural networks isn’t practical. That is, there’s a cost associated with
    running a large neural network, which would otherwise correspond to the global
    optimum of the objective function in this hyperparameter tuning task. We, therefore,
    need to take this computational cost into account while tuning this neural network
    and only look for architectures that are actually feasible to implement in practice.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当调整神经网络的架构时，您可能会发现增加网络层数通常会产生更高的准确性，并且拥有数百万和数十亿层的网络将表现最佳。然而，除非我们有昂贵的、强大的计算资源，否则运行这样的大型神经网络是不切实际的。也就是说，在这种超参数调整任务中，运行大型神经网络会有成本，这在实践中可能对应于客观函数的全局最优解。因此，在调整此神经网络时，我们需要考虑这种计算成本，并且只寻找实际可实现的架构。
- en: Another black-box optimization problem in which we need to consider additional
    constraints is scientific discovery, such as in chemistry and materials science.
    For instance, scientists aim to design chemicals and materials that optimize a
    desirable characteristic, such as drugs that are effective against a disease,
    glass that is resilient against pressure, or metals that are malleable and, thus,
    easy to manipulate. Unfortunately, the drugs that are the most effective against
    a disease might have many side effects that make them dangerous to use, or the
    most resilient type of glass might be too expensive to produce on a large scale.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要考虑额外约束的另一个黑盒优化问题是科学发现，例如在化学和材料科学中。例如，科学家的目标是设计出优化所需特性的化学品和材料，比如对抗疾病有效的药物，抵御压力的玻璃，或者易于操作的可塑金属。不幸的是，对抗疾病最有效的药物可能会有许多副作用，使其使用起来有危险，或者最具韧性的玻璃可能在大规模生产上成本过高。
- en: These are examples of *constrained* optimization problems, where we need to
    optimize an objective function while satisfying other constraints. Seeking to
    optimize the objective function alone might lead us to solutions that violate
    important constraints, rendering the solutions we find useless in practice. Instead,
    we need to identify other regions in the search space that both yield high objective
    values and satisfy these important constraints.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是*受限*优化问题的示例，我们需要在满足其他约束的同时优化客观函数。仅寻求优化客观函数可能会导致我们找到的解决方案违反重要约束，使我们找到的解决方案在实践中无用。相反，我们需要识别搜索空间中的其他区域，这些区域既能产生高客观值，又能满足这些重要约束。
- en: In this chapter, we learn about the constrained optimization problem and see
    examples where having extra constraints may completely change the solution of
    an optimization problem. This need to account for these constraints gives rise
    to constraint-aware optimization policies in BayesOpt. We are introduced to a
    variant of the Expected Improvement (EI) policy that is constraint-aware and learn
    how to implement it in BoTorch. By the end of the chapter, you will understand
    the problem of constrained optimization, learn how it is solved using BayesOpt,
    and see that the constraint-aware policy we use performs much better than constraint-agnostic
    ones. What we learn in this chapter will help us tackle more practical BayesOpt
    problems in real life and, thus, make more effective decisions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解约束优化问题，并看到在某些情况下，额外的约束可能会完全改变优化问题的解。考虑到这些约束的需要引发了 BayesOpt 中的约束感知优化策略。我们介绍了一种考虑约束的预期改进（EI）策略的变体，并学习了如何在
    BoTorch 中实现它。到本章结束时，您将了解约束优化问题，学习如何使用 BayesOpt 解决它，并看到我们使用的约束感知策略要比不考虑约束的策略表现得更好。本章所学将帮助我们在现实生活中解决更多实际的
    BayesOpt 问题，并因此做出更有效的决策。
- en: 8.1 Accounting for constraints in a constrained optimization problem
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 在约束优化问题中考虑约束
- en: 'As mentioned in the introduction, many constrained optimization problems exist
    in the real world: making drugs with high efficacy and minimal side effects, finding
    materials that maximize desirable characteristics and are cheap to produce, or
    hyperparameter tuning while keeping the computational cost low.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正如介绍中提到的，现实世界中存在许多约束优化问题：制造具有高效性和最小副作用的药物，寻找最大化理想特性并且廉价生产的材料，或者在保持计算成本低的同时进行超参数调整。
- en: Note We focus on *inequality constraints*, where we require a result *y* to
    be inside a predetermined numerical range *a* ≤ *y* ≤ *b*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 我们关注*不等式约束*，其中我们要求结果*y*在预定的数值范围*a* ≤ *y* ≤ *b*内。
- en: We first take a closer look at the constrained optimization problem in the next
    section and see why it’s mathematically different from the unconstrained problem
    we see in previous chapters. We then redefine the BayesOpt framework we have been
    working with so far to account for extra constraints.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在接下来的一节中更仔细地看看约束优化问题，并了解为什么它在数学上与我们在前几章中看到的无约束问题不同。然后，我们重新定义了迄今为止一直使用的 BayesOpt
    框架以考虑额外的约束条件。
- en: 8.1.1 Constraints can change the solution of an optimization problem
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 约束条件可能改变优化问题的解
- en: How do constraints complicate the optimization of a black box function? In many
    cases, regions within the search space that give high objective values might violate
    the constraints that come with the optimization problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 约束如何使黑盒函数的优化变得复杂？在许多情况下，搜索空间内部给出高目标值的区域可能会违反随优化问题而来的约束条件。
- en: Note In an optimization problem, we aim to find regions that give high objective
    values since we want to maximize the value of the objective function.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 在优化问题中，我们的目标是找到给出高目标值的区域，因为我们想要最大化目标函数的值。
- en: If it is the case that regions with high objective values violate the given
    constraints, we need to rule out these regions that violate the constraints and
    only conduct our search within other regions that satisfy the constraints.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果高目标值区域违反给定的约束条件，我们需要排除这些违反约束的区域，并仅在满足约束的其他区域内进行搜索。
- en: Definition A data point that violates the predefined constraints in a constrained
    optimization problem is called an *infeasible* point, as it’s infeasible to use
    the point as the solution to the optimization problem. On the other hand, a data
    point that satisfies the constraints is called a *feasible* point. Our goal is
    to find the feasible point that maximizes the value of the objective function.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 违反预定义约束条件的数据点在约束优化问题中被称为*不可行*点，因为将该点作为优化问题的解是不可行的。另一方面，满足约束条件的数据点被称为*可行*点。我们的目标是找到最大化目标函数值的可行点。
- en: Constraints can affect the quality of the optimal solution of the unconstrained
    optimization problem or change the optimal solution altogether. Consider the example
    in figure 8.1, where our objective function (the solid line) is the Forrester
    function we have used in previous chapters. In addition to this objective function,
    we have a cost function, shown as the dashed line. Assume that in this constrained
    optimization problem, the constraint is that the cost needs to be a maximum of
    zero—that is, the cost *c* ≤ 0\. This constraint means only the feasible points
    in the shaded regions in the right panel of figure 8.1 can be used as the optimization
    result.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 约束条件可能会影响无约束优化问题的最优解质量，或者完全改变最优解。考虑图 8.1 中的示例，我们的目标函数（实线）是我们在前几章中使用过的福雷斯特函数。除了这个目标函数之外，我们还有一个成本函数，如虚线所示。假设在这个约束优化问题中，约束是成本需要最大为零——也就是说，成本
    *c* ≤ 0\. 这个约束意味着只有图 8.1 右侧面板中阴影区域内的可行点可以作为优化结果使用。
- en: '![](../../OEBPS/Images/08-01.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-01.png)'
- en: Figure 8.1 An example of a one-dimensional constrained optimization problem.
    The solid line is the objective function we aim to maximize, and the dashed line
    is the cost function that constrains the optimization problem. Only the shaded
    regions (right panel) that yield negative costs are feasible. Here, the constraint
    of nonpositive cost causes the highest objective value to decrease from more than
    8 to 4.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 一维约束优化问题的示例。实线是我们希望最大化的目标函数，虚线是约束优化问题的成本函数。只有产生负成本的阴影区域（右侧面板）是可行的。在这里，非正成本的约束导致最高目标值从超过
    8 减少到 4 左右。
- en: Note We first used the Forrester function as an example objective function in
    BayesOpt in section 2.4.1.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们在 BayesOpt 的 2.4.1 节中首次使用了福雷斯特函数作为示例目标函数。
- en: As a result, the region where *x* > 4, which contains the true global optimum
    of the objective value (denoted as the diamond marker in the right panel), is
    cut off. That is, the global optimum that yields an objective value of more than
    8 is not feasible, and the constrained optimal solution (denoted as the star)
    only achieves an objective value of roughly 4\. An example of this “cutoff” scenario
    is when an effective drug has too severe of a side effect, so the drug company
    decides to use a less effective variant of the same chemical to make the product
    safe.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，包含 *x* > 4 的区域，其中包含目标值的真实全局最优解（在右侧面板中用钻石标记）被切断。也就是说，产生目标值超过 8 的全局最优解是不可行的，而约束最优解（用星号标记）只能达到大约
    4 的目标值。这种“截断”情况的一个例子是当有效药物有太严重的副作用时，药品公司决定使用同一化学成分的效果较差的变体来使产品安全。
- en: Another example of the same objective function and a slightly different cost
    function is shown in figure 8.2, where having this extra cost constraint changes
    the optimal solution of our optimization problem. Without the constraint, the
    global optimum of the objective function is located at *x* = 4.6\. This point,
    however, is an infeasible one that gives a positive cost and, thus, violates our
    constraint. The optimal solution of the constrained problem is at *x* = 1.6\.
    This phenomenon can happen, for example, when the entire family of some highly
    effective drug is dangerous to patients and cannot be produced, so we need to
    look for other solutions that are chemically different from the dangerous drug.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个具有相同目标函数但成本函数略有不同的示例显示在图 8.2 中，这个额外的成本约束改变了我们优化问题的最优解。在没有约束的情况下，目标函数的全局最优解位于
    *x* = 4.6\. 然而，这个点是一个不可行的点，会产生正成本，因此违反了我们的约束。约束问题的最优解在 *x* = 1.6\. 这种现象可能会发生，例如当某种高效药物的整个家族对患者有危险而不能生产时，因此我们需要寻找与危险药物化学成分不同的其他解决方案。
- en: '![](../../OEBPS/Images/08-02.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-02.png)'
- en: Figure 8.2 An example of a one-dimensional constrained optimization problem.
    Here, the optimal solution changes to a different local optimum, as the nonpositive
    cost constraint rules out the region where *x* > 3.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 一维约束优化问题的示例。在这里，由于非正成本约束排除了 *x* > 3 的区域，最优解变为不同的局部最优解。
- en: 'Overall, inequality constraints may impose complex requirements on an optimization
    problem and change its optimal solution. That is, constraints may rule out the
    global optimum of a function as an infeasible point—a common scenario in the real
    world:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，不等式约束可能对优化问题施加复杂的要求，并改变其最优解。也就是说，约束可能排除函数的全局最优解作为不可行点——这在现实世界中是常见的情况：
- en: The prohibitively large neural networks tend to achieve good predictive performance
    but are infeasible to implement in practice.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本过高的神经网络倾向于实现良好的预测性能，但在实践中无法实现。
- en: The most effective drugs are often too aggressive and dangerous to produce.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最有效的药物通常太过激进和危险，无法生产。
- en: The best materials are too expensive to use.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最好的材料价格太高，无法使用。
- en: 'Instead of using the unconstrained optimal point that violates our constraints,
    we need to modify our optimization strategy to account for the constraints and
    find the optimal feasible solution. That is, we need to pursue two goals: optimizing
    the objective function and satisfying the given constraints. Solely optimizing
    the objective function without accounting for the constraints will lead to infeasible
    solutions that are not usable in practice. Instead, we need to find points that
    both yield high objective values and satisfy the constraints.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要修改我们的优化策略来考虑约束并找到最佳可行解，而不是使用违反我们约束的无约束最优点。也就是说，我们需要追求两个目标：优化目标函数并满足给定的约束。单纯优化目标函数而不考虑约束会导致无法使用的不可行解。相反，我们需要找到既产生高目标值又满足约束的点。
- en: '![](../../OEBPS/Images/08-02-unnumb.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-02-unnumb.png)'
- en: 8.1.2 The constraint-aware BayesOpt framework
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 约束感知的贝叶斯优化框架
- en: How should we approach this constrained optimization problem from the BayesOpt
    angle? In this section, we learn how to modify our BayesOpt framework to account
    for the constraints that are given in a constrained optimization problem.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该如何从贝叶斯优化的角度解决这个受约束的优化问题？在本节中，我们学习如何修改我们的贝叶斯优化框架以考虑在受约束优化问题中给定的约束。
- en: Remember in BayesOpt that we use a Gaussian process (GP) to train on the data
    points we have observed from the objective function and make predictions on unseen
    data. In constrained optimization, we have, in addition, one or many functions
    that define the constraints we need to satisfy. For example, in section 8.1.1,
    the cost function shown as the dashed line in figures 8.1 and 8.2 defines the
    constraints that the solution needs to have a nonpositive cost.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯优化中，我们使用高斯过程（GP）来训练我们从目标函数观察到的数据点，并对未见数据进行预测。在受约束优化中，除了我们需要满足的一个或多个定义约束的函数之外，我们还有一个或多个定义约束的函数。例如，在第
    8.1.1 节中，成本函数如图 8.1 和 8.2 中的虚线所示，定义了解决方案需要具有非正成本的约束。
- en: Note You can refer to sections 1.2.3 and 4.1.1 for a refresher on the BayesOpt
    framework.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意你可以参考第 1.2.3 节和第 4.1.1 节来重新了解贝叶斯优化框架。
- en: We assume that, just like the objective function, we don’t know what the true
    cost function looks like. In other words, the cost function is a black box. We
    only get to observe the cost values at the data points we query the objective
    function with, and from there, we determine whether those data points satisfy
    the constraints or not.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设，就像目标函数一样，我们不知道真实的成本函数是什么样的。换句话说，成本函数是一个黑盒。我们只能观察到我们查询目标函数的数据点处的成本值，从那里，我们确定这些数据点是否满足约束。
- en: Note If we did know what the functions that define our constraints look like,
    we could simply identify the feasible regions and restrict our search space to
    be within those feasible regions. In our constrained optimization problem, we
    assume our constraints are also black boxes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意如果我们知道定义约束的函数的样子，我们可以简单地确定可行区域，并将我们的搜索空间限制在这些可行区域内。在我们的受约束优化问题中，我们假设我们的约束也是黑盒。
- en: 'Since we only have black box access to the functions that define our constraints,
    we can also use a GP to model each of these functions. That is, in addition to
    the GP that models our objective function, we use more GPs, one for each function
    that defines a constraint, to inform our decisions about where to query the objective
    function next. We follow the same procedure to train each of these GPs—it’s just
    a matter of using the appropriate training set for each GP:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只能黑盒访问定义约束的函数，我们还可以使用 GP 来模拟每个这些函数。也就是说，除了模拟我们目标函数的 GP 外，我们使用更多的 GP，每个函数定义一个约束，以指导我们下一步在哪里查询目标函数。我们遵循相同的程序来训练每个
    GP——只是使用每个 GP 的适当训练集：
- en: The GP that models the objective function trains on the observed objective values.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟目标函数的 GP 是在观察到的目标数值上进行训练。
- en: A GP that models a constraint-defining function trains on the observed cost
    values.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟定义约束函数的 GP 是在观察到的成本数值上进行训练。
- en: 'Our constrained BayesOpt framework, which is a modified version of figure 1.6,
    is visualized in figure 8.3:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的受限贝叶斯优化框架，是图 1.6 的修改版本，在图 8.3 中进行了可视化：
- en: At step 1, we train a GP on data from the objective function and another GP
    on data from each function that defines a constraint.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在步骤 1 中，我们在来自目标函数的数据和定义约束函数的每个函数的数据上训练一个 GP。
- en: At step 3, we use the point identified by a BayesOpt policy to query both the
    objective function and the constraint-defining functions.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在步骤 3 中，我们使用贝叶斯优化策略确定的点查询目标函数和定义约束函数。
- en: 'Steps 1 and 3 of figure 8.3 are straightforward to implement: we only need
    to maintain multiple GPs at the same time, keep track of the corresponding datasets,
    and keep those datasets updated. The more interesting question comes in step 2:
    decision-making. That is, how should we design a BayesOpt policy that can guide
    us toward feasible regions that yield high objective values? This is the topic
    of our discussion in the next section.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 的步骤 1 和 3 很容易实现：我们只需要同时维护多个 GP，跟踪相应的数据集，并保持这些数据集的更新。更有趣的问题出现在步骤 2 中：决策制定。也就是说，我们应该如何设计一个贝叶斯优化策略，以指导我们朝向产生高客观价值的可行区域？这是我们在下一节讨论的主题。
- en: 8.2 Constraint-aware decision-making in BayesOpt
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 贝叶斯优化中的约束感知决策
- en: An effective constrained BayesOpt policy needs to pursue both optimization and
    satisfying the constraints. One straightforward way to design such a policy is
    to incorporate the constraints into the way an unconstrained BayesOpt policy makes
    its decisions. That is, we wish to modify a policy we already know to take into
    account constraints in a constrained optimization problem and derive a constraint-aware
    decision-making procedure.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有效的受限贝叶斯优化策略需要同时追求优化和满足约束条件。设计这样一个策略的一种简单方法是将约束条件纳入非受限贝叶斯优化策略做出决策的方式中。也就是说，我们希望修改一个我们已经知道的策略，以考虑受限制条件的约束优化问题，并得出一种约束感知的决策程序。
- en: The policy we choose for this modification is EI, which we learned about in
    section 4.3\. (We discuss other BayesOpt policies later in this section.) Remember
    that the EI policy scores each unseen data point with the expected value of how
    much improvement from the current incumbent we observe if we query the objective
    function at this unseen point.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择用于这种修改的策略是 EI，我们在第 4.3 节学到了它。（我们稍后在本节中讨论其他贝叶斯优化策略。）请记住，EI 策略将每个未见过的数据点的预期值得到评分，以表明如果我们在这个未见点查询目标函数，我们会观察到多少改进。
- en: '![](../../OEBPS/Images/08-03.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-03.png)'
- en: Figure 8.3 The constrained BayesOpt loop. A separate GP models either the objective
    function or a function that defines a constraint. A BayesOpt policy recommends
    the next point for us to query both the objective function and the constraint-defining
    functions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 受限贝叶斯优化循环。一个单独的 GP 模型对目标函数或定义约束的函数进行建模。一个贝叶斯优化策略推荐下一个点，我们可以查询目标函数和定义约束的函数。
- en: Definition The term *incumbent* refers to the point having the highest objective
    value within our training set, which is what we need to “beat” to make progress
    with optimization.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *在任职者* 这个术语指的是我们训练集中具有最高客观价值的点，这是我们需要“超越”的点，以便在优化过程中取得进展。
- en: 'The acquisition score EI uses, which, again, computes the average value of
    the improvement of each potential query, ignores the inequality constraints in
    a constrained optimization problem, so we can’t use EI “as is” when optimizing
    a constrained objective function. Fortunately, there’s an easy way to account
    for these constraints: we can scale the EI acquisition score of each unseen point
    by how likely the data point is to satisfy the constraints—that is, the probability
    that the data point is a feasible point:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: EI 使用的收获得分，再次，计算每个潜在查询的改进的平均值，忽略约束优化问题中的不等式约束，因此在优化受约束的目标函数时我们不能直接使用 EI。幸运的是，有一种简单的方法来考虑这些约束：我们可以通过未见点满足约束的概率来缩放每个未见点的
    EI 收购得分，即数据点是可行点的概率：
- en: If the data point is likely to satisfy the constraints, then its EI score will
    be multiplied by a large number (a high probability of feasibility), thus keeping
    the EI score high.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据点可能满足约束条件，则其 EI 分数将乘以一个大数（可行性的高概率），从而保持 EI 分数较高。
- en: If the data point is unlikely to satisfy the constraints, its EI score will
    be multiplied by a small number (a low probability of feasibility), thus de-prioritizing
    that data point.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据点不太可能满足约束条件，那么它的EI得分将乘以一个较小的值（较低的可行性概率），从而降低该数据点的优先级。
- en: Tip The acquisition score of the constrained variant of EI is the product of
    the regular EI score and the probability that a data point satisfies the constraints.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 约束变种的EI获取得分是正常的EI得分和数据点满足约束条件的概率的乘积。
- en: 'The formula for the acquisition score of this constraint-aware variant of EI
    is shown in figure 8.4\. This acquisition score is the product of two terms: the
    EI score encourages optimization of the objective function, and the probability
    of feasibility encourages staying within the feasible regions. This balance between
    optimizing the objective function and satisfying the constraints is exactly what
    we want to achieve, as noted in section 8.1.1.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 约束感知的EI获取得分的公式如图8.4所示。这个获取得分是两个术语的乘积：EI得分鼓励优化目标函数，而可行性概率鼓励停留在可行区域内。正是这种在优化目标函数和满足约束条件之间平衡的方式，正如8.1.1节所述，我们希望实现的。
- en: '![](../../OEBPS/Images/08-04.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-04.png)'
- en: Figure 8.4 Formula for the acquisition score of constrained EI, which is the
    product of the regular EI score and the probability of feasibility. This policy
    aims to optimize the objective value and satisfy the constraints at the same time.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4所示的公式是约束EI获取得分的公式，它是正常的EI得分和可行性概率的乘积。这个策略旨在同时优化目标值并满足约束条件。
- en: We already know how to compute the EI score, but how can we calculate the second
    term—the probability that a given data point is a feasible point? As noted in
    figure 8.4, we do this with the GPs modeling the constraints. Specifically, each
    GP provides a probabilistic belief about the shape of a function defining a constraint.
    From this probabilistic belief, we can calculate the probability that an unseen
    data point will satisfy the corresponding inequality constraint.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道如何计算EI得分，但是如何计算第二个术语-给定数据点是可行点的概率？正如图8.4所述，我们使用对约束进行建模的高斯过程完成此操作。具体而言，每个高斯过程提供有关定义约束函数形状的概率信念。从这种概率信念中，我们可以计算未见过数据点满足相应不等式约束的概率。
- en: As an example, let’s say when solving the constrained optimization problem defined
    in figure 8.2 that we have observed the objective function and the cost function
    at *x* = 0, *x* = 3, and *x* = 4\. From this training set, we train two GPs, one
    for the objective function and the other for the cost function, and obtain the
    predictions visualized in figure 8.5.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当解决图8.2中定义的约束优化问题时，假设我们已经在*x*=0，*x*=3和*x*=4处观察到了目标函数和成本函数。从此培训集中，我们训练了一个用于目标函数和另一个用于成本函数的高斯过程，并获得了图8.5中可视化的预测结果。
- en: '![](../../OEBPS/Images/08-05.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-05.png)'
- en: Figure 8.5 Predictions about the objective function and the cost function made
    by corresponding GPs. Each GP allows us to reason about the shape of the corresponding
    function in a probabilistic manner.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5所示的是相应高斯过程的目标函数和成本函数的预测。每个高斯过程都可以让我们以概率方式推理相应函数的形状。
- en: Now, say we’d like to compute the constrained EI score for *x* = 1\. We already
    have a way to compute the regular EI score for any data point, so all we need
    to do now is calculate the probability that *x* = 1 is a feasible data point.
    To do this, we look at the normal distribution representing our prediction about
    the cost value of *x* = 1, as illustrated in figure 8.6.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想计算*x*=1的约束EI得分。我们已经找到了计算任何数据点的正常EI得分的方法，现在我们需要做的就是计算*x*=1是可行数据点的概率。为了做到这一点，我们查看表示我们对*x*=1成本值的预测的正态分布，如图8.6所示。
- en: '![](../../OEBPS/Images/08-06.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-06.png)'
- en: Figure 8.6 Probability of *x* = 1 being a feasible point, highlighted in a darker
    shade. The left panel shows the entire GP, while the right panel only shows the
    normal distribution corresponding to the prediction at *x* = 1 (the error bars
    are the same across the two panels). Here, feasibility follows a truncated normal
    distribution.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6展示了*x*=1是可行点的概率，用较深的颜色突出显示。左侧显示整个高斯过程，右侧则仅显示与*x*=1（误差条在两个面板中相同）预测相对应的正态分布。在此，可行性遵循一个被截断的正态分布。
- en: The left panel of figure 8.6 contains the same GP as in the bottom panel of
    figure 8.5 that is cut off at the constraint threshold 0, additionally showing
    the CI of the normal distribution prediction at *x* = 1\. Slicing the GP vertically
    at this point *x* = 1, we obtain the right panel of figure 8.6, where the CIs
    in the two panels are the same. In other words, going from the left to the right
    panel of figure 8.6, we have zoomed in on the vertical scale, and instead of showing
    the cost function, we only keep the cost constraint (the dotted line) and the
    GP prediction at *x* = 1, which is a normal distribution. We see that only the
    highlighted portion of the normal distribution in the right panel represents the
    probability that *x* = 1 obeys the cost constraint, which is what we care about.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 的左面板包含与图 8.5 底部面板相同的 GP，它被截断在约束阈值 0，另外还显示了 *x* = 1 处正态分布预测的 CI。在这一点 *x*
    = 1 垂直切割 GP，我们得到图 8.6 的右面板，在这两个面板中的 CI 是相同的。换句话说，从图 8.6 的左面板到右面板，我们已经放大了垂直刻度，而不是显示成本函数，我们只保留了成本约束（虚线）和
    *x* = 1 处的 GP 预测，它是一个正态分布。我们看到右面板中正态分布的突出部分表示 *x* = 1 遵守成本约束的概率，这是我们关心的内容。
- en: 'If figure 8.6 reminds you of figures 4.9 and 4.10, covering the PoI policy,
    that’s because our thought process is the same in the two cases:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图 8.6 让你想起了图 4.9 和 4.10，涵盖了 PoI 策略，那是因为我们在这两种情况下的思考过程是相同的：
- en: With PoI, we compute the probability that a given data point yields an objective
    value *higher* than the incumbent. We, therefore, use the incumbent value as a
    *lower* bound, specifying that we only care about scenarios in which the objective
    value is *higher* than the incumbent.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 PoI，我们计算给定数据点产生的目标值高于现任的概率。因此，我们使用现任值作为下界，指定我们只关心目标值高于现任的情况。
- en: With the probability of feasibility, we compute the probability that a given
    data point yields a cost value *lower* than the cost threshold at 0\. We use 0
    as an *upper* bound to specify that we target scenarios in which the cost value
    is *lower* than the threshold (to obey our cost constraint).
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过可行性概率，我们计算给定数据点产生的成本值低于 0 的概率。我们使用 0 作为上界来指定我们只针对成本值低于阈值的情况（以遵守我们的成本约束）。
- en: Handling different inequality constraints
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 处理不同的不等式约束
- en: The constraint in our current example requires the cost to be less than 0\.
    If we had a constraint requiring a function value to be higher than some threshold,
    then the probability of feasibility would be the probability that a given point
    yields a function value higher than some threshold, and the shaded region in figure
    8.6 would be to the right of the cutoff.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们当前的示例中，约束要求成本低于 0。如果我们有一个要求函数值高于某个阈值的约束条件，那么可行性的概率将是给定点产生函数值高于某个阈值的概率，而图
    8.6 中的阴影区域将位于截止线的右侧。
- en: If there was a constraint requiring the value to be inside a range (*a* ≤ *y*
    ≤ *b*), then the probability of feasibility would be the probability that the
    data point gives a value between the lower and upper bounds of the range.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在一个约束条件，要求数值在一个范围内（*a* ≤ *y* ≤ *b*），那么可行性的概率将是数据点给出一个在范围的下限和上限之间的值的概率。
- en: In our case, we want to compute the probability that the cost value at *x* =
    1 is lower than 0, which is the area of the shaded region under the curve in the
    right panel of figure 8.6\. As we have seen in section 4.2.2 of chapter 4, the
    normal distribution allows us to compute this area under the curve using the cumulative
    density function (CDF). In figure 8.6, the probability that *x* = 1 is feasible
    is roughly 84%—this is the second term in figure 8.4 that we use to compute the
    constrained EI acquisition score.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们想要计算 *x* = 1 处成本值低于 0 的概率，这是图 8.6 中右侧面板下曲线阴影区域的面积。正如我们在第 4.2.2 节的第四章中看到的，正态分布允许我们使用累积密度函数（CDF）计算曲线下面积。在图
    8.6 中，*x* = 1 可行的概率大约为 84% —— 这是我们用于计算受约束 EI 采集分数的图 8.4 中的第二项。
- en: 'Further, we can compute this probability-of-feasibility quantity at any point
    inside our search space. For example, figure 8.7 shows the truncated normal distributions
    for *x* = –1 (center panel) and *x* = 2 (right panel). As we can see, the probability
    that a given point is feasible depends on the predictive normal distribution at
    that point:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以计算搜索空间内任何点的可行性概率。例如，图 8.7 显示了 *x* = –1（中心面板）和 *x* = 2（右侧面板）的截断正态分布。正如我们所见，给定点可行的概率取决于该点的预测正态分布：
- en: At *x* = –1, almost the entire predictive normal distribution lies below the
    cost threshold at 0, so the probability of feasibility here is high, at almost
    98%.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *x* = –1 处，几乎整个预测正态分布都位于成本阈值 0 以下，因此这里的可行性概率很高，几乎为 98%。
- en: At *x* = 2, only a small portion of the normal distribution falls below the
    cost threshold, causing the probability of feasibility to be much lower, roughly
    6%.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *x* = 2 处，只有一小部分正态分布落在成本阈值以下，导致可行性概率较低，大约为 6%。
- en: '![](../../OEBPS/Images/08-07.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-07.png)'
- en: Figure 8.7 Probability of feasibility at *x* = –1 and *x* = 2, highlighted in
    a darker shade. The left panel shows the entire GP, the center panel shows the
    prediction at *x* = –1, and the right panel shows the prediction at *x* = 2\.
    The highlighted portions show the probability of feasibility, which depends on
    the normal distribution at a given point.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 在 *x* = –1 和 *x* = 2 处突出显示的可行性概率，呈深色。左侧面板显示了整个 GP，中间面板显示了 *x* = –1 的预测，右侧面板显示了
    *x* = 2 的预测。突出显示的部分显示了可行性概率，这取决于给定点的正态分布。
- en: With the ability to compute the probability of feasibility for any given point
    in hand, we can now compute the constrained EI acquisition score described in
    figure 8.4\. Again, this score balances between a potentially high objective value,
    quantified by the regular EI score, and satisfying the inequality constraint(s),
    quantified by the probability of feasibility.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有了计算任意给定点可行性概率的能力，我们现在可以计算图 8.4 中描述的受约束 EI 采集分数。再次强调，此分数在潜在的高目标值（由常规 EI 分数量化）和满足不等式约束（由可行性概率量化）之间平衡。
- en: Figure 8.8 shows this score in the bottom right panel, along with the regular
    EI score and the current GPs. We see that constrained EI is aware of the cost
    constraint we need to satisfy and assigns a roughly zero score to the region to
    the right of the space (where *x* > 2). This is because the cost GP (top right
    panel) thinks this is an infeasible region that should be avoided. Ultimately,
    the regular EI policy recommends the objective function with the infeasible point
    *x* = 4 as the next point to query. Constrained EI, on the other hand, recommends
    *x* = –0.8, which, indeed, satisfies our cost constraint.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 在右下面板显示了此分数，以及常规 EI 分数和当前 GPs。我们看到受约束 EI 意识到我们需要满足的成本约束，并且对空间右侧（其中 *x*
    > 2）的区域分配了大约零分。这是因为成本 GP（右上面板）认为这是一个应该避免的不可行区域。最终，常规 EI 策略建议将具有不可行点 *x* = 4 作为下一个要查询的点。受约束
    EI，另一方面，建议 *x* = –0.8，这确实满足了我们的成本约束。
- en: '![](../../OEBPS/Images/08-08.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-08.png)'
- en: Figure 8.8 The acquisition score of EI (bottom left) and that of constrained
    EI (bottom right), along with our current belief about the objective function
    (top left) and about the cost function (top right). By being aware of the cost
    constraint, constrained EI can avoid the infeasible region and recommend an entirely
    different point to query from regular EI.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 EI 的采集分数（左下）和受约束 EI 的采集分数（右下），以及我们对目标函数（左上）和成本函数（右上）的当前信念。通过意识到成本约束，受约束
    EI 可以避免不可行的区域，并建议从常规 EI 完全不同的点进行查询。
- en: 'We have found a good heuristic of deriving a constraint-aware BayesOpt policy
    from a regular one: multiplying the acquisition score of the policy with the probability
    of feasibility to factor in the inequality constraints. Interestingly, adding
    the probability-of-feasibility factor to EI isn’t simply a heuristic—the formula
    in figure 8.4 can be obtained from a heuristic-free, more mathematically rigorous
    procedure. The interested reader can refer to a research paper that defines the
    constrained EI policy for more details ([http://proceedings.mlr.press/v32/gardner14.pdf](http://proceedings.mlr.press/v32/gardner14.pdf)).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经找到了从常规策略中推导出具有约束感知的BayesOpt策略的一个很好的启发式方法：将策略的收购分数与可行性概率相乘以考虑不等式约束。有趣的是，将可行性概率因子添加到EI中并不简单是一种启发式方法——图8.4中的公式可以从一个无启发式、更具数学严谨性的过程中得到。感兴趣的读者可以参考一篇定义了约束EI策略的研究论文以获取更多细节（[http://proceedings.mlr.press/v32/gardner14.pdf](http://proceedings.mlr.press/v32/gardner14.pdf)）。
- en: While we can use the same heuristic on other BayesOpt policies we have learned,
    such as UCB, TS, and Entropy Search, the mathematically rigorous procedure won’t
    apply anymore. Further, at the time of writing, BoTorch only supports constrained
    EI, which is also widely used to solve constrained optimization problems in practice.
    We, therefore, only focus on constrained EI and its optimization results for the
    rest of this chapter.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以将相同的启发式方法应用于我们已学习的其他BayesOpt策略，例如UCB、TS和Entropy Search，但数学上严格的过程将不再适用。此外，在撰写本文时，BoTorch仅支持受约束EI，这也被广泛用于实践中解决受约束优化问题。因此，我们只关注受约束EI及其优化结果在本章的其余部分。
- en: '8.3 Exercise 1: Manual computation of constrained EI'
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 练习1：手动计算受约束的EI
- en: 'We saw in figure 8.4 that the acquisition score of the constrained EI policy
    is the product of the EI score and the probability of feasibility. Although the
    `ConstrainedExpectedImprovement` class from BoTorch provides an implementation
    of the constrained EI score, we can, in fact, perform the computation manually.
    In this exercise, we explore this manual computation and verify our result against
    that of the `ConstrainedExpectedImprovement` class. The solution to this exercise
    is in the CH08/02 - Exercise 1.ipynb notebook:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图8.4中看到，受约束EI策略的收购得分是EI得分和可行性概率的乘积。虽然BoTorch的`ConstrainedExpectedImprovement`类提供了受约束EI得分的实现，但实际上我们可以手动进行计算。在这个练习中，我们将探索这种手动计算，并将我们的结果与`ConstrainedExpectedImprovement`类的结果进行验证。此练习的解决方案在CH08/02
    - Exercise 1.ipynb笔记本中：
- en: Recreate the constrained BayesOpt problem used in CH08/01 - Constrained optimization.ipynb,
    including the objective function, the cost function, the GP implementation, and
    the helper function that trains a GP on some training data `fit_gp_model()`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建在CH08/01 - Constrained optimization.ipynb中使用的约束BayesOpt问题，包括目标函数、成本函数、GP实现以及训练GP的辅助函数`fit_gp_model()`。
- en: Create a PyTorch tensor that is a dense grid between -5 and 5 by using, for
    example, the `torch.linspace()` method. This tensor will act as our test set.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用例如`torch.linspace()`方法创建一个在-5到5之间的密集网格的PyTorch张量。此张量将作为我们的测试集。
- en: Create a toy training data set by randomly sampling 3 data points from our search
    space (between –5 and 5), and evaluate the objective and cost functions at these
    points.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从我们的搜索空间（在-5和5之间）随机抽样3个数据点，创建一个玩具训练数据集，并评估这些点的目标和成本函数。
- en: Train a GP on the data from the objective function and another GP on the data
    from the cost function using the helper function `fit_gp_model()`.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用辅助函数`fit_gp_model()`在目标函数数据和成本函数数据上训练一个GP。
- en: Use the GP trained on the data from the cost function to compute the probability
    of feasibility for each point in the test set. You can use the `torch.distributions`
    `.Normal` class to initialize a normal distribution object and call the `cdf()`
    method of this object on 0 (implemented as `torch.zeros(1)`) to compute the probability
    that each data point yields a cost lower than 0.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用从成本函数数据中训练的GP来计算测试集中每个点的可行性概率。您可以使用`torch.distributions`的`.Normal`类来初始化一个正态分布对象，并在0上调用此对象的`cdf()`方法（实现为`torch.zeros(1)`）来计算每个数据点产生低于0的成本的概率。
- en: 'Initialize a regular EI policy with the `model` argument as the GP trained
    on the data from the objective function and the `best_f` argument as the current
    feasible incumbent:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`model`参数初始化一个常规EI策略，其中GP是由数据从目标函数训练的，并且`best_f`参数是当前可行的候选者：
- en: Compute the EI score for each point in the test set.
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算测试集中每个点的EI得分。
- en: Refer to section 4.3 for more details on implementing the EI policy.
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有关实现EI策略的更多详细信息，请参见4.3节。
- en: Initialize a constrained EI policy, and compute the constrained EI score for
    each point in the test set.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化受约束EI策略，为测试集中的每个点计算受约束EI分数。
- en: Compute the product of the EI scores and the probabilities of feasibility, and
    verify that this manual computation leads to the same results as those from BoTorch’s
    implementation. You can use `torch.isclose(a,` `b,` `atol=1e-3)`, which performs
    element-wise comparisons between two tensors `a` and `b`, specifying `atol=1e-3`
    to account for numerical instability, to verify that all corresponding scores
    match up.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算EI分数和可行性概率的乘积，并验证此手动计算是否导致与BoTorch实现相同的结果。您可以使用`torch.isclose（a，b，atol = 1e-3）`，它在两个张量`a`和`b`之间执行逐元素比较，指定`atol
    = 1e-3`以考虑数值不稳定性，以验证所有相应分数是否匹配。
- en: Plot the EI scores and the constrained EI scores in a graph, and visually verify
    that the former is always greater than or equal to the latter. Prove that this
    is the case using figure 8.4.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在图表中绘制EI分数和受约束EI分数，并通过图8.4视觉验证前者始终大于或等于后者。
- en: 8.4 Implementing constrained EI with BoTorch
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 在 BoTorch 中实现受约束 EI
- en: While we can manually multiply two quantities, the EI score and the probability
    of feasibility, to make a new acquisition score, BoTorch already takes care of
    the low-level bookkeeping. This means we can import the constrained EI policy
    from BoTorch and use it like any other BayesOpt policy, without much overhead.
    We learn how to do so in this section, and the code we use is included in the
    CH08/01 - Constrained optimization.ipynb notebook.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以手动乘以两个量，即EI分数和可行性概率，以生成新的收购分数，但BoTorch已经处理了低级别的簿记。这意味着我们可以从BoTorch中导入受约束EI策略，并像使用任何其他BayesOpt策略一样使用它，而没有太多开销。我们在本节中学习如何这样做，并且我们使用的代码已包含在CH08/01-Constrained
    optimization.ipynb笔记本中。
- en: 'First, we need the objective function and the cost function that defines the
    constraint in figure 8.2\. In the following code, the objective function is implemented
    as `objective()`, and the cost function is `cost()`. Our search space is between
    –5 and 5, and we make the variable `bounds` that contains these numbers, which
    will be passed to BayesOpt policies later:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要实现图8.2中定义约束的目标函数和成本函数。在以下代码中，目标函数实现为`objective（）`，成本函数为`cost（）`。我们的搜索空间介于-5和5之间，并且我们制作包含这些数字的变量`bounds`，将在以后传递给BayesOpt策略：
- en: '[PRE0]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ The objective function to be maximized
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 要最大化的目标函数
- en: ❷ The cost function
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 成本函数
- en: ❸ The bounds on the search space
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 搜索空间的边界
- en: We also need a class implementation of our GP model and a helper function `fit_
    gp_model()` that trains the GP given a training data set. As constrained optimization
    doesn’t require any changes to the GP and how we train it, we can reuse the class
    implementation and the helper function we used in previous chapters. For a more
    in-depth discussion of this implementation, refer to section 4.1.1.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要GP模型的类实现和一个helper函数`fit_ gp_model（）`，该函数训练给定训练数据集的GP。由于受限制的优化不需要对GP以及我们如何训练它进行任何更改，因此我们可以重复使用之前章节中使用的类实现和助手函数。有关此实现的更深入讨论，请参见4.1.1节。
- en: 'To benchmark the optimization performance of the policies we use, we specify
    that each BayesOpt run has 10 queries, and we have 10 runs in total:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了基准测试我们使用的策略的优化性能，我们指定每个BayesOpt运行具有10个查询，并且总共有10个运行：
- en: '[PRE1]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note We run each BayesOpt policy multiple times to have a holistic view of the
    performance of the policy. Refer to exercise 2 of chapter 4 for the discussion
    on repeated experiments.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 我们会多次运行每个BayesOpt策略，以全面了解策略的表现。有关重复实验的讨论，请参见第4章练习2。
- en: 'Finally, we need to modify our BayesOpt loop to account for the changes visualized
    in figure 8.3\. At step 1 of figure 8.3—that is, at the beginning of each step
    in the BayesOpt loop—we need to retrain multiple GPs: one for the objective function
    and the other(s) for the constraint(s).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要修改我们的BayesOpt循环以考虑图8.3中可视化的更改。在图8.3的第1步（即BayesOpt循环中的每个步骤开始时），我们需要重新训练多个GP：一个用于目标函数，另一个（s）用于约束条件。
- en: 'As we already have the helper function `fit_gp_model()` that trains a GP, this
    step comes down to passing appropriate datasets to this helper function. In our
    current example, we only have one cost function defining the constraint, so we
    have, in total, two GPs, which can be retrained with the following code:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经有了训练高斯过程的辅助函数`fit_gp_model()`，这一步只需要将适当的数据集传递给该辅助函数即可。在我们的当前例子中，我们只有一个定义约束的成本函数，所以总共有两个可以用以下代码重新训练的高斯过程：
- en: '[PRE2]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Train a GP on the objective function’s data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在目标函数的数据上训练一个高斯过程（GP）。
- en: ❷ Train a GP on the cost function’s data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在成本函数的数据上训练一个高斯过程（GP）。
- en: Here, the variable `train_x` contains the locations at which we have evaluated
    the objective and cost functions; `train_utility` is the corresponding objective
    values, and `train_cost` is the cost values.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，变量`train_x`包含我们评估目标和成本函数的位置；`train_utility`是相应的目标值，`train_cost`是成本值。
- en: 'Step 2 of figure 8.3 refers to running a BayesOpt policy, which we learn to
    do shortly. For step 3 of figure 8.3, we evaluate the objective and cost functions
    at the data point recommended by the chosen BayesOpt policy, stored in the variable
    `next_x`. We do this by evaluating both the objective and cost functions at `next_x`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3的步骤2是指运行BayesOpt策略，我们很快就会学习到如何运行。图8.3的步骤3中，我们评估由所选BayesOpt策略推荐的数据点处的目标和成本函数，该数据点存储在变量`next_x`中。我们通过在`next_x`处评估目标和成本函数来完成这一点：
- en: '[PRE3]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Evaluates the objective and cost functions at the recommended point
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在推荐点处评估目标和成本函数
- en: ❷ Updates the various datasets
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 更新各种数据集
- en: One more bookkeeping step we need to take is keeping track of our optimization
    progress. Unlike in an unconstrained optimization problem, where we simply record
    the incumbent value (highest objective value seen thus far) at every step, here
    we need to filter out the infeasible observations before taking the maximum. We
    do this by first creating a tensor with `num_repeats` rows (one for each repeated
    run) and `num_queries` columns (one for each time step). This tensor contains
    only one value by default, denoting our utility if no feasible points are found
    throughout BayesOpt.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还需要做一个额外的记账步骤，跟踪我们的优化进展。与无约束优化问题不同，在每个步骤中，我们只需记录最优解（迄今为止见到的最高目标值），而在这里，我们需要在取最大值之前过滤掉不可行的观察结果。我们首先创建一个张量，张量具有`num_repeats`行（每次重复运行一个）和`num_queries`列（每个时间步骤一个）。此张量默认只包含一个值，如果BayesOpt期间未找到可行点，则表示我们的效用:'
- en: 'Inspecting figure 8.2, we see that our objective function is greater than –2
    everywhere within our search space (between –5_ and 5), so we use –2 as this default
    value:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 检查图8.2，我们可以看到在我们的搜索空间内（在-5到5之间），我们的目标函数在任何地方都大于-2，所以我们将-2作为默认值：
- en: '[PRE4]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Checks whether a feasible point has been found
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检查是否找到可行点
- en: 'Then, at each step of the BayesOpt loop, we only record the feasible incumbent
    by taking the maximum of the filtered observations:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在每个BayesOpt循环的步骤中，我们只记录通过取筛选后观测结果的最大值找出的可行的最优解：
- en: '[PRE5]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Checks whether a feasible point has been found
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检查是否找到可行点
- en: 'The preceding code completes our constrained BayesOpt loop. All that’s left
    for us to do is declare the BayesOpt policy we want to use to solve the constrained
    optimization problem. We use the constrained EI policy we discussed in section
    8.2 by using the BoTorch class `ConstrainedExpectedImprovement`. This class takes
    in a number of important arguments:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码完成了我们的约束BayesOpt循环。我们只需要声明我们要用来解决约束优化问题的BayesOpt策略。我们使用在第8.2节中讨论的约束EI策略，使用BoTorch类`ConstrainedExpectedImprovement`。该类需要一些重要参数：
- en: '`model`—A list of GP models for the objective function (`utility_model` in
    our case) and the functions that define the constraints (`cost_model`, in our
    case). We create this list using the `model_list_gp_regression.ModelListGP` class
    from BoTorch’s `models` module: `ModelListGP(utility_model,` `cost_model)`.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` - `ModelListGP(utility_model,` `cost_model)`-目的函数的GP模型列表（在我们的例子中是`utility_model`）和定义约束的函数（在我们的例子中是`cost_model`）。我们使用BoTorch的`models`模块中的`model_list_gp_regression.ModelListGP`类来创建此列表。'
- en: '`objective_index`—The index of the GP modeling the objective function in the
    model list `model`. Since `utility_model` is the first GP we pass to `ModelListGP`,
    this index is 0 in our case.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`objective_index` - model列表`model`中模型目标函数的索引。由于`utility_model`是我们传递给`ModelListGP`的第一个GP，所以在我们的例子中该索引为0。'
- en: '`constraints`—A dictionary mapping the index of each function defining a constraint
    to a two-element list storing the lower and upper bounds for the constraint. If
    a constraint doesn’t have a lower bound or an upper bound, we use `None` in lieu
    of an actual numerical value. Our example requires the cost corresponding to `cost_model`,
    which has an index of 1, to be a maximum of 0, so we set `constraints={1:` `[None,`
    `0]}`.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`constraints` — 将定义约束函数的每个函数的索引映射到存储约束的下限和上限的两元素列表的字典。如果一个约束没有下限或上限，我们使用 `None`
    代替实际数值。我们的示例要求与 `cost_model` 对应的成本最大为 0，因此我们设置 `constraints={1:` `[None,` `0]}`。'
- en: '`best_f`—The current feasible incumbent, which is `train_utility[train_cost`
    <= `0].max()`, if we have found at least one feasible point or the default value,
    –2, otherwise.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`best_f` — 当前可行的最佳解决方案，如果我们找到至少一个可行点，则为 `train_utility[train_cost <= 0].max()`，否则为默认值
    -2。'
- en: 'Overall, we initialize the constrained EI policy as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们如下初始化受约束 EI 策略：
- en: '[PRE6]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ The list of GP models
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ GP 模型列表
- en: ❷ The current feasible incumbent
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 当前可行的最佳解决方案。
- en: ❸ The objective function’s index in the model list
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 目标函数在模型列表中的索引
- en: ❹ A dictionary mapping each constraint’s index to the lower and upper bounds
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将每个约束的索引映射到下限和上限的字典。
- en: With the implementation of constrained EI in hand, let’s now run this policy
    on our one-dimensional constrained optimization problem and observe its performance.
    As a baseline, we can also run the regular version of EI that is constraint agnostic.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们手头有了受约束 EI 的实现，让我们在一维受约束优化问题上运行这个策略并观察其性能。作为基线，我们还可以运行不考虑约束的常规 EI 版本。
- en: Figure 8.9 shows the average feasible incumbent values found by these two policies
    and error bars as a function of time. We see that compared to the regular EI,
    the constrained variant finds a better feasible solution on average and almost
    always converges to the best possible solution. Figure 8.9 highlights the benefit
    of our constraint-aware optimization policy compared to a constraint-agnostic
    approach.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 显示了这两种策略找到的平均可行最优解值以及时间函数的误差条。我们看到，与常规 EI 相比，约束变体平均找到更好的可行解，并且几乎总是收敛到最佳解。图8.9
    强调了我们的受约束优化策略相对于不考虑约束的方法的好处。
- en: '![](../../OEBPS/Images/08-09.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-09.png)'
- en: Figure 8.9 Optimization progress on a one-dimensional constrained optimization
    problem of constrained EI. Compared to the regular EI, the constrained variant
    finds a better feasible solution on average.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 一维约束 EI 优化问题的优化进展。与常规 EI 相比，约束变体平均找到更好的可行解。
- en: 'The EI policy, which is blind to the constraint placed on the optimization
    problem, tends to veer off toward the infeasible optimum. Inspecting the incumbent
    values found by this policy, we notice that in many runs, the policy fails to
    progress from its initial value:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不考虑优化问题的约束的 EI 策略，往往会偏离不可行最优解。检查此策略找到的最佳解值，我们注意到在许多运行中，该策略未能从其初始值中取得进展：
- en: '[PRE7]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this chapter, we have learned about the problem of black box constrained
    optimization and how it is different from the classic black box optimization problem
    discussed in previous chapters. We learned that an effective optimization policy
    needs to pursue both optimizing the objective function and satisfying the constraints.
    We then designed one such policy, a variant of EI, by adding a factor equal to
    the probability of feasibility to the acquisition score. This new acquisition
    score biases our search strategy toward feasible regions, thus better guiding
    us toward the feasible optimum.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们学习了黑盒约束优化问题，并且了解到它与前几章讨论的经典黑盒优化问题有何不同。我们知道一个有效的优化策略需要追求优化目标函数和满足约束条件两者兼顾。然后我们设计了这样一种策略，即将一个等于可行性概率的因子添加到获取分数中的方法的变体。这个新的获取分数会偏向于可行区域，从而更好地引导我们朝着可行最优解前进。
- en: In the next chapter, we discuss a new BayesOpt setting, multifidelity optimization,
    with which there are different costs to querying the objective function. This
    setting requires us to balance finding a high objective value and preserving our
    querying budget.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论一个新的 BayesOpt 设置，即多信任度优化，其中查询目标函数的成本不同。这种设置要求我们平衡寻找高目标值和保留查询预算。
- en: '8.5 Exercise 2: Constrained optimization of airplane design'
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 练习 2：飞机设计的受约束优化
- en: 'In this exercise, we tackle a constrained optimization problem using the airplane-utility
    objective function in exercise 2 of chapter 7\. This process allows us to run
    constrained BayesOpt on a higher-dimensional problem in which it’s not obvious
    where the feasibility optimal solution is. The solution to this exercise is included
    in the CH08/03 - Exercise 2.ipynb notebook:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们使用了第7章练习2中的飞机效用目标函数来解决受约束的优化问题。这个过程允许我们在一个高维问题上运行受约束的BayesOpt，其中不明显的是可行的最优解在哪里。这个练习的解决方案包括在CH08/03
    - Exercise 2.ipynb笔记本中。
- en: Recreate the BayesOpt problem used in the CH07/04 - Exercise 2.ipynb notebook,
    including the airplane-utility objective function named `flight_utility()`, the
    bounds of our search space (the four-dimensional unit hypercube), the GP implementation,
    and the helper function that trains a GP on some training data `fit_gp_model()`.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建在CH07/04 - Exercise 2.ipynb笔记本中使用的BayesOpt问题，包括名为`flight_utility()`的飞机效用目标函数，我们搜索空间的边界（四维单位超立方体），GP实现以及训练一些训练数据的GP的辅助函数`fit_gp_model()`。
- en: 'Implement the following cost function, which simulates the cost of making the
    airplane design specified by a four-dimensional input:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现以下成本函数，模拟通过四维输入指定的飞机设计的成本：
- en: '[PRE8]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Figure 8.10 visualizes this cost function for various pairs of parameters we
    can tune, showing a complex nonlinear trend across these two-dimensional spaces.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8.10可视化了我们可以调整的各个参数对应的成本函数，显示了跨越这些二维空间的复杂非线性趋势。
- en: '![](../../OEBPS/Images/08-10.png)'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/08-10.png)'
- en: Figure 8.10 The cost function of the simulated airplane design optimization
    problem in various two-dimensional subspaces, corresponding to pairs of tunable
    parameters, shown as axis labels.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8.10 在各种二维子空间中模拟飞机设计优化问题的成本函数，对应于可调参数的成对显示为坐标轴标签。
- en: 'Our goal is to maximize the objective function `flight_utility()`, while following
    the constraint that the cost, as computed by `flight_cost()`, is less than or
    equal to 0:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的目标是在遵循`flight_cost()`计算出的成本小于或等于0的约束条件的情况下，最大化目标函数`flight_utility()`：
- en: To this end, we set the number of queries a BayesOpt policy can make in each
    experiment as 50 and designate that each policy needs to run 10 repeated experiments.
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此，我们将每次实验中BayesOpt策略可以进行的查询次数设置为50，并指定每个策略需要运行10次重复实验。
- en: The default value quantifying optimization progress if no feasible solution
    is found should be set to –2.
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果找不到可行解决方案，刻画优化进展的默认值应该设置为-2。
- en: Run the constrained EI policy as well as the regular EI policy on this problem,
    and then visualize and compare their average progress (along with error bars).
    The plot should look similar to figure 8.9.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此问题上运行受约束的EI策略以及常规EI策略，然后可视化并比较它们的平均进展（以及误差条）。绘图应该类似于图8.9。
- en: Summary
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Constrained optimization is an optimization problem in which, in addition to
    optimizing the objective function, we need to satisfy other constraints to have
    practical solutions to the optimization problem. Constrained optimization is common
    in materials and drug discovery as well as hyperparameter tuning, where the objective
    function’s optimum is too difficult or dangerous to be used in practice.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约束优化是一种优化问题，除了优化目标函数外，我们需要满足其他约束条件以获得实际解决方案。约束优化在材料和药物发现以及超参数调整中很常见，其中目标函数的最优解在实践中太难或太危险而无法使用。
- en: A data point that satisfies the constraints in a constrained optimization problem
    is called a feasible point, while a data point that violates the constraints is
    called infeasible. We aim to find the point that maximizes the objective function
    among the feasible points.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在受约束的优化问题中满足约束的数据点称为可行点，而违反约束的数据点称为不可行点。我们的目标是在可行点中找到最大化目标函数的点。
- en: Constraints can vastly change the solution to an optimization problem, cutting
    off or even excluding a region with high objective values. We, therefore, need
    to actively account for the constraints when optimizing the objective function.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约束条件可以极大地改变优化问题的解，切断或者排除具有高目标值的区域。因此，在优化目标函数时，我们需要积极考虑约束条件。
- en: In the framework of constrained BayesOpt, we train a GP on each of the functions
    that define the constraints. These GPs allow us to reason about whether a data
    point will satisfy the constraints in a probabilistic manner. Specifically, the
    probability that a given data point is feasible is easy to compute thanks to the
    fact that the predictive distributions from a GP are normal distributions.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在约束 BayesOpt 框架中，我们对定义约束的每个函数训练一个 GP。这些 GP 允许我们以概率方式推理出数据点是否满足约束。具体来说，由于 GP
    的预测分布是正态分布，因此很容易计算给定数据点可行性的概率。
- en: We can modify the EI policy to account for the constraints by adding the probability
    of feasibility to its acquisition score. The constrained EI policy can balance
    optimizing the objective function and satisfying the constraints.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过将可行性的概率添加到 EI 策略的获取得分中来修改 EI 策略以考虑约束。约束 EI 策略可以平衡优化目标函数和满足约束条件。
- en: BoTorch provides a class implementation of the constrained EI policy. When implementing
    constrained EI, we need to pass in the GPs modeling the objective and constraint
    functions as well as declare the constraint lower and upper bounds.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BoTorch 提供了一个约束 EI 策略的类实现。在实现约束 EI 时，我们需要传入建模目标和约束函数的 GP，以及声明约束的下界和上界。
