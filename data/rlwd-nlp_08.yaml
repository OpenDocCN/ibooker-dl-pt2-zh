- en: Part 2 Advanced models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 2 部分 高级模型
- en: The field of NLP has seen rapid progress in the past few years. Specifically,
    the advent of the Transformer and pretrained language models such as BERT have
    completely changed the landscape of the field and how practitioners build NLP
    applications. This part of the book will help you catch up with these latest developments.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年，自然语言处理领域取得了迅猛的进步。具体来说，Transformer 和预训练语言模型（如BERT）的出现彻底改变了该领域的格局以及从业者构建自然语言处理应用的方式。本书的这部分内容将帮助你跟上这些最新进展。
- en: Chapter 6 introduces sequence-to-sequence models, an important class of models
    that will enable you to build more complex applications such as machine translation
    systems and chatbots. Chapter 7 discusses another type of popular neural network
    architecture, *convolutional neural networks* (CNNs).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 第 6 章介绍了序列到序列模型，这是一类重要的模型，它将使你能够构建更复杂的应用，比如机器翻译系统和聊天机器人。第 7 章讨论了另一种流行的神经网络架构，*卷积神经网络*（CNNs）。
- en: Chapters 8 and 9 are arguably the most important and exciting chapters of this
    book. They cover the Transformer and transfer learning methods (such as BERT)
    respectively. We’ll demonstrate how to build advanced NLP applications such as
    high-quality machine translation and spell-checkers, using those technologies.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 第 8 章和第 9 章可以说是本书最重要和最令人兴奋的章节。它们分别涵盖了Transformer 和迁移学习方法（如BERT）。我们将演示如何利用这些技术构建高质量的机器翻译和拼写检查器等高级自然语言处理应用。
- en: By the time you finish reading this part, you’ll feel confident that you can
    now solve a wide range of NLP tasks with what you have learned so far.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成阅读这一部分时，你会自信地感觉到，通过你目前所学，你现在能够解决各种各样的自然语言处理任务。
