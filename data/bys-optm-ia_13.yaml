- en: 10 Learning from pairwise comparisons with preference optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过偏好优化进行成对比较学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The problem of learning about and optimizing preferences using only pairwise
    comparison data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅使用成对比较数据学习和优化偏好的问题
- en: Training a GP on pairwise comparisons
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在成对比较上训练 GP
- en: Optimization policies for pairwise comparisons
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成对比较的优化策略
- en: Have you ever found it difficult to rate something (food, a product, or an experience)
    on an exact scale? Asking for the customer’s numerical score for a product is
    a common task in A/B testing and product recommendation workflows.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经发现难以为某物（食物、产品或体验）打分？在 A/B 测试和产品推荐工作流程中，询问客户对产品的数值评分是一个常见任务。
- en: Definition The term *A/B testing* refers to the method of measuring a user’s
    experience in two environments (referred to as *A* and *B*) via randomized experiments
    and determining which environment is more desirable. A/B testing is commonly conducted
    by technology companies.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 定义术语 *A/B 测试* 指的是通过随机实验在两个环境（称为 *A* 和 *B*）中测量用户体验，并确定哪个环境更理想的方法。 A/B 测试通常由技术公司进行。
- en: A/B testers and product recommendation engineers often have to deal with a high
    level of noise in the feedback collected from their customers. By *noise*, we
    mean any type of corruption that the feedback collected from customers is subject
    to. Example sources of noise in product rating include the number of advertisements
    served on an online streaming service, the quality of the delivery service for
    a package, or the general mood of the customer when they consume a product. These
    factors affect how the customer rates their product, potentially corrupting the
    signal that is the customer’s true evaluation of the product.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试人员和产品推荐工程师经常需要处理从客户收集的反馈中的高水平噪音。通过*噪音*，我们指的是客户反馈所受到的任何类型的损坏。产品评分中的噪音示例包括在线流媒体服务上提供的广告数量，包裹的送货服务质量，或客户在消费产品时的一般心情。这些因素影响客户对产品的评分方式，可能会破坏客户对产品的真实评价。
- en: Uncontrollable external factors make it hard for the customer to report their
    true evaluation of a product. Customers, therefore, often find it hard to choose
    a numerical score as their evaluation of a product when rating on a scale. The
    prevalence of feedback noise in A/B testing and product recommendation means a
    service platform cannot rely on a few data points collected from their users to
    learn about their preferences. Instead, the platform needs to collect more data
    from the customers to become more certain about what the customers truly want.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 不可控的外部因素使客户难以报告他们对产品的真实评价。因此，当在评分时难以选择数值评分作为对产品的评价时，客户通常会发现这很困难。在 A/B 测试和产品推荐中的反馈噪音的普遍存在意味着服务平台不能仅依靠从用户那里收集到的少量数据来了解其偏好。相反，平台需要从客户那里收集更多数据，以更加确定客户真正想要的是什么。
- en: However, just as in other settings of black box optimization, such as hyperparameter
    tuning and drug discovery, querying the objective function is expensive. In product
    recommendation, every time we query a customer asking for their rating of a product,
    we run the risk of intruding on the customer’s experience and discouraging them
    from continuing to use the platform. Hence, there’s a natural tension between
    the need for a large amount of data to better learn customers' preferences and
    being intrusive, potentially leading to a loss of customers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如在其他黑盒优化设置中一样，比如超参数调整和药物发现，查询目标函数是昂贵的。在产品推荐中，每当我们询问客户对产品的评分时，我们都面临着侵入客户体验和阻止他们继续使用平台的风险。因此，需要大量数据来更好地了解客户的偏好和具有侵入性之间存在自然紧张关系，可能导致客户流失。
- en: Luckily, there’s a way around this problem. Research in the field of psychology
    ([http://mng.bz/0KOl](http://mng.bz/0KOl)) has found the intuitive result that
    we humans are much better at giving preference-based responses in the form of
    pairwise comparisons (e.g., “product A is better than product B”) than rating
    products on a scale (e.g., “product A is an 8 out of 10”).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一种方法可以解决这个问题。心理学领域的研究（[http://mng.bz/0KOl](http://mng.bz/0KOl)）发现了一个直观的结果，即我们人类在进行成对比较的偏好反应方面要比在评分产品时更擅长（例如，“产品A比产品B更好”）。
- en: Definition A *pairwise comparison* is a method of collecting preference data.
    Each time we want to elicit information about a customer’s preference, we ask
    the customer to pick (from two items) the item they prefer. Pairwise comparisons
    are different from numerical ratings, where we ask the customer to rate an item
    on a scale.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 成对比较是一种收集偏好数据的方法。每次我们想要获取有关客户偏好的信息时，我们都会要求客户从两个项目中选择他们更喜欢的项目。成对比较不同于数值评分，其中我们要求客户在一定比例上对项目进行评分。
- en: 'The reason for the difference in difficulty between pairwise comparisons and
    ratings is that comparing two items is a less cognitively demanding task, and
    we, therefore, can compare two objects while being consistent with our true preference
    better than we can provide numerical ratings. In figure 10.1, consider two example
    interfaces of an online shopping site that is trying to learn about your preference
    for Hawaiian shirts:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 成对比较和评分之间难度差异的原因在于，比较两个项目是一项认知要求较低的任务，因此，我们可以在比较两个对象时更好地与我们的真实偏好保持一致，而不是提供数值评分。在图10.1中，考虑一个在线购物网站的两个示例界面，该网站正在尝试了解您对夏威夷衬衫的偏好：
- en: The first interface asks you to rate the shirt on the scale from 1 to 10\. This
    can be difficult to do, especially if you don’t have a frame of reference.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个界面要求您按照从1到10的比例为衬衫评分。这可能很难做到，特别是如果您没有一个参考框架的话。
- en: The second interface asks you to instead pick the shirt that you like better.
    This task is easier to complete.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个界面要求您选择您更喜欢的衬衫。这个任务更容易完成。
- en: '![](../../OEBPS/Images/10-01.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-01.png)'
- en: Figure 10.1 Examples of user’s preference elicitation in production recommendation.
    On the left, the user is asked to rate a recommended product. On the right, the
    user is asked to pick the product they like better. The latter situation helps
    better elicit the user’s preference.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 生产推荐中用户偏好引导的示例。左侧，用户被要求对推荐产品进行评分。右侧，用户被要求选择他们更喜欢的产品。后者有助于更好地引导用户的偏好。
- en: Given the potential of high-quality data we can collect using pairwise comparisons,
    we’d like to apply this preference elicitation technique to BayesOpt of a user’s
    preference. The question becomes, “How can we train a ML model on pairwise comparison
    data, and afterwards, how should we present new comparisons to the user to best
    learn and optimize their preference?” We answer these questions in this chapter,
    first by using a GP model that can effectively learn from pairwise comparisons.
    We then develop strategies that pit the best data point (representing a product)
    we have found so far against a promising rival, allowing us to optimize the user’s
    preference as quickly as possible. In other words, we assume the user’s preference
    is the objective function defined over a search space, and we’d like to optimize
    this objective function.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们可以使用成对比较收集高质量数据的潜力，我们希望将这种偏好引导技术应用于用户偏好的BayesOpt。问题是，“我们如何在成对比较数据上训练ML模型，然后，如何向用户呈现新的比较以最好地学习和优化他们的偏好？”我们在本章中回答了这些问题，首先使用一个能够有效地从成对比较中学习的GP模型。然后，我们开发了策略，将迄今为止我们找到的最佳数据点（代表一个产品）与一个有希望的竞争对手相比较，从而使我们能够尽快优化用户的偏好。换句话说，我们假设用户的偏好是定义在搜索空间上的目标函数，我们希望优化这个目标函数。
- en: This setting of learning and optimizing a user’s preference from pairwise comparisons
    is a unique task that lies at the intersection of black box optimization and product
    recommendation and has been gaining interest in both communities. By the end of
    this chapter, we learn how to approach this problem from the BayesOpt, trading
    off exploitation and exploration as we collect data from the user.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从成对比较中学习和优化用户偏好的这种设置是一个独特的任务，位于黑盒优化和产品推荐的交集处，两个社区都对此产生了兴趣。通过本章末尾，我们了解了如何从BayesOpt的角度解决这个问题，通过从用户那里收集数据来权衡开发和探索。
- en: 10.1 Black-box optimization with pairwise comparisons
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 使用成对比较进行黑盒优化
- en: In this section, we further discuss the usefulness of pairwise comparisons in
    the task of eliciting preference. We then examine the BayesOpt loop that is modified
    for this preference-based optimization setting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们进一步讨论了成对比较在引导偏好任务中的有用性。然后，我们研究了为这种基于偏好的优化设置修改过的BayesOpt循环。
- en: In addition to exact numerical evaluations as ratings, pairwise comparisons
    offer a method of collecting information about a customer in a production recommendation
    application. Compared to numerical ratings, pairwise comparisons pose less of
    a cognitive burden on the user and are, therefore, likely to result in higher-quality
    data (feedback that is consistent with the user’s true preference).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将精确的数字评估作为评级外，成对比较还提供了一种在生产推荐应用中收集有关客户信息的方法。与数字评级相比，成对比较对用户的认知负担较小，因此可能会产生更高质量的数据（即与用户真实偏好一致的反馈）。
- en: Pairwise comparisons in multiobjective optimization
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 多目标优化中的成对比较
- en: 'A setting where pairwise comparisons are particularly useful is decision-making
    when multiple criteria need to be considered. For example, say you are looking
    to buy a car and are choosing between car A and car B. To make your decision,
    you list out the different characteristics you care about in a car: appearance,
    practicality, energy efficiency, cost, and so on. You then score both cars on
    each of these criteria, hoping to find a clear winner. Unfortunately, car A scores
    higher than car B on some of the criteria but not all, and car B scores higher
    than car A on the rest of the criteria.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 成对比较特别有用的一个场景是在需要考虑多个标准的决策中。例如，假设你想买一辆车，正在选择 A 车和 B 车。为了做出决定，你列出了你在一辆车上关心的不同特征：外观、实用性、能效、成本等。然后你为两辆车在每个标准上评分，希望找到一个明显的赢家。不幸的是，A
    车在某些标准上得分比 B 车高，但并不是所有标准都是如此，而 B 车在其余标准上的得分高于 A 车。
- en: So, there’s no clear winner between the two cars, and combining the scores for
    the different criteria into a single score could be difficult. You care about
    some criteria more than others, so those criteria that you care about more need
    to be weighted more heavily when being combined with the other criteria to produce
    a single number. However, working out the exact values for these weights could
    pose an even greater challenge than choosing between the two cars themselves!
    It can be much easier to ignore the specifics, view each car as a whole, and compare
    the two cars “head-to-head.”
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在这两辆车之间没有明显的赢家，将不同标准的分数合并成一个单一分数可能会很困难。你关心某些标准胜过其他标准，所以在将这些标准与其他标准相结合以产生单一数字时，需要更加重视这些标准的权重。然而，确定这些权重的确切值可能比选择这两辆车本身更具挑战性！忽视具体细节，将每辆车作为一个整体，并将两辆车进行“头对头”比较可能更容易一些。
- en: The ease of using pairwise comparisons has, therefore, been exploited in optimization
    situations where there are multiple criteria to be considered. For example, a
    research project by Edward Abel, Ludmil Mikhailov, and John Keane ([http://mng.bz/KenZ](http://mng.bz/KenZ))
    used pairwise comparisons to tackle group decision-making.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在需要考虑多个标准的优化情况下，利用成对比较的便利性已经被利用起来。例如，Edward Abel、Ludmil Mikhailov 和 John
    Keane 的一个研究项目 ([http://mng.bz/KenZ](http://mng.bz/KenZ)) 使用成对比较来解决群体决策问题。
- en: Of course, pairwise comparisons are not objectively better than numerical evaluations.
    While the former are easier to elicit from users, they contain considerably less
    information than the latter. The response that you like the orange shirt better
    than the red shirt in figure 10.1 contains exactly one bit of information (the
    outcome of the comparison is binary; either orange is better than red or red is
    better than orange, so observing the outcome information theoretically constitutes
    gaining one bit of information). Meanwhile, if you were to report that you rate
    the orange shirt 8 out of 10 and the red 6 out of 10, we would have much more
    information than simply knowing that orange is valued more highly than red.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，成对比较并不一定比数字评估更好。虽然前者更容易从用户那里获取，但它们所包含的信息明显比后者少得多。比如，在图 10.1 中，你喜欢橙色衬衫胜过红色衬衫的回答正好包含一位信息（比较的结果是二元的；要么橙色比红色好，要么红色比橙色好，所以观察结果信息理论上构成了一位信息）。而如果你报告说你给橙色衬衫评了
    8 分，红色衬衫评了 6 分，那么我们获得的信息就比仅仅知道橙色被高估要多得多。
- en: In other words, there’s always a tradeoff in choosing the method of eliciting
    feedback from users. Numerical evaluations contain more information, but they
    are prone to noise and can place a larger cognitive burden on the user. Pairwise
    comparisons, on the other hand, offer less information but are easier for the
    user to report. These pros and cons are summarized in figure 10.2.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在选择从用户那里引出反馈的方法时总是存在权衡。数值评估包含更多信息，但容易受到噪声影响，并且可能给用户带来更大的认知负担。另一方面，两两比较提供的信息较少，但用户报告起来更容易。这些优缺点在图
    10.2 中总结。
- en: '![](../../OEBPS/Images/10-02.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-02.png)'
- en: Figure 10.2 Differences between numerical ratings and pairwise comparisons in
    terms of informativeness and difficulty in reporting. Each method of preference
    elicitation offers its own advantages and disadvantages.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 数值评分和两两比较在信息量和报告难度方面的差异。每种偏好引出方法都有其优缺点。
- en: Keeping the tradeoff between information and difficulty of reporting in mind,
    we should stick to numerical evaluations if we are willing to ask users to complete
    a more cognitively demanding task to gain more information and if we can account
    for noise. On the other hand, if we place more importance on having customers
    accurately express their true preferences and are willing to gain less information,
    pairwise comparisons should be our method of choice to elicit customers' feedback.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑信息和报告难度之间的权衡时，如果我们愿意让用户完成更具认知要求的任务以获取更多信息，并且可以考虑到噪声，那么我们应该坚持使用数值评估。另一方面，如果我们更注重客户准确表达他们真实的偏好，并且愿意获取更少的信息，那么两两比较应该是我们引出客户反馈的首选方法。
- en: Other ways of eliciting customers' preferences
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其他引出客户偏好的方法
- en: 'Pairwise comparisons are not the only form of relieving the cognitive burden
    of numerical evaluations. For example, the online streaming service Netflix collects
    viewers'' ratings by asking them to choose between three options: “thumbs down”
    to indicate they dislike something, “thumbs up” to indicate they like something,
    and “double thumbs up” to indicate they *love* something ([http://mng.bz/XNgl](http://mng.bz/XNgl)).
    This setting constitutes an ordinal classification problem in which items are
    classified into different categories and there’s an inherent order among the categories.
    The production recommendation problem in this setting is just as interesting to
    consider, but we keep our focus on pairwise comparisons in this chapter.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 两两比较并不是减轻数值评估认知负担的唯一形式。例如，在线流媒体服务 Netflix 通过要求观众在三个选项中进行选择来收集观众的评分：“向下拇指”表示他们不喜欢某物，“向上拇指”表示他们喜欢某物，“双向上拇指”表示他们*喜欢*某物
    ([http://mng.bz/XNgl](http://mng.bz/XNgl))。这种设置构成了一种有序分类问题，其中项目被分类到不同的类别中，并且类别之间存在固有的顺序。在这种情况下，产品推荐问题同样值得考虑，但在本章中我们将重点放在两两比较上。
- en: 'In this chapter, we learn how to facilitate the task of using pairwise comparisons
    to learn and optimize a customer’s preference using BayesOpt. First, we examine
    a modified version of the BayesOpt loop we saw in figure 1.6, as shown in figure
    10.3:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习如何利用 BayesOpt 来促进使用两两比较来学习和优化客户偏好的任务。首先，我们研究了一个修改过的 BayesOpt 循环版本，如图
    1.6 所示，如图 10.3 所示：
- en: In step 1, the GP is trained on pairwise comparison data instead of numerical
    evaluations. The key challenge is to ensure that the GP belief about the objective
    function (the user’s true preference function) reflects information in the observed
    comparisons.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，GP 是根据两两比较数据而不是数值评估进行训练的。关键挑战在于确保 GP 对于目标函数（用户真实偏好函数）的信念反映了观察到的比较中的信息。
- en: In step 2, the BayesOpt policy computes acquisition scores to quantify how useful
    each potential new query to the user is. A query to the user needs to come in
    the form of a pair of products for the user to compare. Just as in other settings,
    the policy needs to balance exploiting a region where we know the user’s preference
    is high and exploring other regions where we don’t know a lot about the user’s
    preference.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二步中，BayesOpt 策略计算获取分数，以量化对用户每个潜在新查询的有用程度。用户的查询需要以一对产品的形式提供给用户进行比较。就像在其他情况下一样，策略需要平衡利用我们知道用户偏好高的区域和探索我们对用户偏好了解不多的其他区域。
- en: In step 3, the user compares the two products presented to them by the BayesOpt
    policy and reports the product they prefer. This new information is then added
    to our training set.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第 3 步中，用户比较了由贝叶斯优化策略呈现给他们的两种产品，并报告他们更喜欢的产品。然后，将此新信息添加到我们的训练集中。
- en: '![](../../OEBPS/Images/10-03.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-03.png)'
- en: Figure 10.3 The BayesOpt loop with pairwise comparisons for preference optimization.
    The GP trains on pairwise comparison data, and the BayesOpt policy decides which
    pair of data points it should ask the user to compare.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 使用成对比较进行偏好优化的贝叶斯优化循环。高斯过程根据成对比较数据进行训练，而贝叶斯优化策略决定应该要求用户比较哪一对数据点。
- en: 'We seek to address two main questions in the remainder of this chapter:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的剩余部分试图解决两个主要问题：
- en: How can we train a GP only on pairwise comparisons? A GP, when trained on numerical
    responses, produces probabilistic predictions with quantified uncertainty, which
    is crucial in decision-making. Can we use the same model here with pairwise comparison
    responses?
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何仅根据成对比较训练高斯过程？高斯过程在数值响应上进行训练时，会产生具有量化不确定性的概率预测，这在决策中至关重要。我们能否在这里使用相同的模型来处理成对比较响应？
- en: How should we generate new product pairs for the user to compare so as to identify
    the maximizer of the user’s preference as quickly as possible? That is, how do
    we best elicit the user’s feedback using pairwise comparisons to optimize their
    preference?
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该如何生成新的产品对供用户比较，以便尽快确定用户偏好的最大化者？也就是说，我们如何通过成对比较最好地引出用户的反馈以优化他们的偏好？
- en: 10.2 Formulating a preference optimization problem and formatting pairwise comparison
    data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 制定偏好优化问题和格式化成对比数据
- en: Before we start tackling these questions, this section introduces the product
    recommendation problem we’ll be solving throughout the chapter and how we simulate
    the problem in Python. Setting up the problem properly will help us more easily
    integrate the BayesOpt tools we will learn about in subsequent sections. The code
    we use here is included in the first portion of the CH10/01 - Learning from pairwise
    comparisons.ipynb Jupyter notebook.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始解决这些问题之前，本节介绍了我们将在整章中解决的产品推荐问题以及我们如何在 Python 中模拟这个问题。正确设置问题将帮助我们更轻松地整合我们将在随后章节学习到的贝叶斯优化工具。我们在此处使用的代码包含在
    CH10/01 - 从成对比较中学习.ipynb Jupyter 笔记本的第一部分中。
- en: As hinted at in figures 10.1 and 10.3, the scenario we’re in is a product recommendation
    problem for Hawaiian shirts. That is, imagine we run an online shopping site for
    Hawaiian shirts, and we are trying to determine the product that maximizes the
    preference of a specific customer who is currently shopping for a shirt.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如图 10.1 和 10.3 所示的，我们现在面临的情景是夏威夷衬衫的产品推荐问题。也就是说，想象我们经营一家夏威夷衬衫的在线购物网站，我们试图确定一款特定客户在购物时最大化偏好的产品。
- en: For simplicity’s sake, let’s assume that after a brief survey, we learn that
    the factor that matters the most to the customer is the number of flowers printed
    on the shirt. Other factors, such as style and color, matter too, but the most
    important thing about a Hawaiian shirt to this customer is how floral the shirt
    is. Further, assume we have many Hawaiian shirts in our stock with varying numbers
    of flowers, so we can roughly find a shirt with any given specified degree of
    “floral-ness.” So our goal is to find the shirt with the optimal number of flowers,
    which is unknown to us, with respect to the customer’s preference. We conduct
    this search in a one-dimensional search space, where the lower bound of the space
    corresponds to shirts without floral patterns and the upper bound of the space
    contains shirts covered in flowers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，让我们假设在简要调查之后，我们得知对客户最重要的因素是衬衫上印花的数量。其他因素，如款式和颜色，也很重要，但对于这个客户来说，夏威夷衬衫最重要的是衬衫上的花朵有多少。此外，假设我们库存中有许多夏威夷衬衫，花朵数量各异，因此我们大致可以找到任何指定“花朵程度”的衬衫。因此，我们的目标是找到符合客户偏好的衬衫，这对我们来说是未知的。我们在一维搜索空间中进行这一搜索，其中空间的下限对应于没有花纹的衬衫，空间的上限包含覆盖着花朵的衬衫。
- en: 'Figure 10.4 visualizes our setup in more detail. In the top portion, the figure
    shows the customer’s true preference and how it changes with respect to how floral
    a shirt is:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 更详细地展示了我们的设置。在图的顶部部分，显示了客户的真实偏好以及随着衬衫花朵程度的变化而变化的情况：
- en: The *x*-axis indicates the number of flowers a shirt has. On one end of the
    spectrum, we have shirts without any flowers; on the other are shirts covered
    in flowers.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x*轴表示衬衫的花朵数量。在光谱的一端，我们有没有花朵的衬衫；另一端是满是花朵的衬衫。'
- en: The *y*-axis is the customer’s preference for each shirt. The higher the customer’s
    preference for a shirt, the more the customer likes the shirt.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*轴是每个衬衫的客户偏好度。客户对衬衫的偏好度越高，表示客户越喜欢这件衬衫。'
- en: '![](../../OEBPS/Images/10-04.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-04.png)'
- en: Figure 10.4 Searching for the shirt with the optimal number of flowers in a
    product recommendation problem. Our search space is one-dimensional since we only
    search for the number of flowers on a shirt. A shirt that’s more than half covered
    in flowers is a local optimum, while a shirt that’s almost fully covered maximizes
    the user’s preference.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 在一个产品推荐问题中搜索具有最佳花朵数量的衬衫。我们的搜索空间是一维的，因为我们只搜索衬衫上花朵的数量。一件半面覆盖花朵的衬衫是一个局部最优点，而几乎完全覆盖的衬衫最大化了用户的偏好。
- en: 'We see that this customer likes floral shirts: there’s a local optimum in preference
    past the middle point of the shirt, and the global optimum of the preference function
    is located near the upper bound of the search space. This means that a shirt that
    has a lot of flowers but is not completely covered in them maximizes the customer’s
    preference.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这个客户喜欢花纹衬衫：在衬衫的中间点过后有一个局部最优点，而偏好函数的全局最优点位于搜索空间的上界附近。这意味着一件有很多花朵但不完全覆盖的衬衫最大化了客户的偏好。
- en: Since what we have is a black box optimization problem, the customer’s preference
    curve in figure 10.4 is actually inaccessible to us in the real world, and we
    need to learn about this preference function using pairwise comparisons and optimize
    it as quickly as possible. Now, let’s see how we can set up this optimization
    problem in Python.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们处理的是一个黑盒优化问题，在实际世界中我们实际上无法获得图10.4中客户的偏好曲线，我们需要使用成对比较来学习这个偏好函数，并尽快对其进行优化。现在，让我们看看如何在Python中设置这个优化问题。
- en: 'You might have already noticed that we are using the Forrester function used
    in previous chapters to simulate the objective function, the customer’s true preference,
    in figure 10.4\. As a result, the code for this function doesn’t change from what
    we had in other chapters, which is the following formula, defined as between –5
    and 5, the lower and upper bounds of our search space:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在图10.4中我们使用了前几章中使用的Forrester函数来模拟客户的目标函数，也就是客户的真实偏好。因此，这个函数的代码与前几章没有任何区别，其定义如下（定义范围是我们搜索空间的下界-5和上界5之间）：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ The objective function
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 目标函数
- en: ❷ The bounds of the search space
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 搜索空间的边界
- en: Remember from previous chapters that where the labels of our data have numerical
    values, each data point in the training set, stored in variable `train_x`, has
    a corresponding label in `train_y`. Our current setting is a little different.
    As our data is in the form of pairwise comparisons, each observation results from
    comparing two data points in `train_x`, and the label of the observation indicates
    which data point is valued more by the customer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从前几章可以记得，当我们的数据标签具有数值值时，在变量`train_x`中的每个数据点都有对应的`train_y`标签。我们当前的设置有点不同。由于我们的数据以成对比较的形式存在，每个观察结果都来自于对`train_x`中的两个数据点进行比较，并且观察的标签指示了客户更看重哪个数据点。
- en: 'Note We follow BoTorch’s convention to encode the result of each pairwise comparison
    between two data points in `train_x` as a PyTorch tensor of two elements: the
    first is the index of the data point that is preferred within `train_x`, and the
    second is the index of the data point not preferred.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们遵循 BoTorch 的规定，用一个包含两个元素的 PyTorch 张量来编码在 `train_x` 中每对数据点之间的每个配对比较的结果：第一个元素是在
    `train_x` 中被偏好的数据点的索引，第二个元素是未被偏好的数据点的索引。
- en: 'For example, say that based on two queries to the user, we know that the user
    prefers *x* = 0 to *x* = 3 (that is, *f*(0) > *f*(3), where *f*(*x*) is the objective
    function), and the user also prefers *x* = 0 to *x* = –4 (so *f*(0) > *f*(–4)).
    A way for us to represent these two pieces of information expressed as a training
    data set is with `train_x` having the following values:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '举个例子，假设根据两次用户查询，我们知道用户更喜欢*x* = 0而不是*x* = 3（也就是说，*f*（0）>*f*（3），其中*f*（*x*）是目标函数），用户也更喜欢*x*
    = 0而不是*x* = -4（所以*f*（0）>*f*（-4））。我们可以用`train_x`来表示这两个信息作为训练数据集，`train_x`的取值如下:'
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Represents x = 0
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 表示 x = 0
- en: ❷ Represents x = 3
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 表示 x = 3
- en: ❸ Represents x = −4
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 表示 x = −4
- en: These values are the three *x* values we have used to query the user. The training
    labels `train_comp`, on the other hand, should be
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是我们用来查询用户的三个*x*值。而训练标签`train_comp`则应该
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Represents f(0) > f(3)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 表示 f(0) > f(3)
- en: ❷ Represents f(0) > f(−4)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 表示 f(0) > f(−4)
- en: Each row in `train_comp` is a two-element tensor representing the result of
    a pairwise comparison. In the first row, `[0,` `1]` says that the data point with
    index `0` in `train_x`, which is *x* = 0, is preferred to the point with index
    `1`, which is *x* = 3\. Similarly, the second row `[0,` `2]` encodes the comparison
    that *f*(0) > *f*(–4).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_comp`中的每一行都是表示成对比较结果的两个元素张量。在第一行中，`[0,``1]`表示`train_x`中索引为`0`的数据点（即*x*
    = 0）优先于索引为`1`的点（即*x* = 3）。同样，第二行`[0,``2]`编码了比较*f*(0) > *f*(-4)。'
- en: 'To help streamline the process of comparing any pair of data points within
    our search space, we write a helper function that takes in the objective values
    of any two data points and returns `[0,` `1]` if the first objective value is
    the greater of the two and `[1,` `0]` otherwise:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化在我们的搜索空间内比较任意一对数据点的过程，我们编写了一个辅助函数，该函数接受任意两个数据点的目标值，并在第一个目标值大于第二个值时返回`[0,``1]`，否则返回`[1,``0]`：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Makes sure we only have two objective values to compare
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保我们只有两个目标值进行比较
- en: ❷ If the first value is greater
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果第一个值较大
- en: ❸ If the second value is greater
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果第二个值较大
- en: 'Let’s use this function to generate a sample training set. We first randomly
    draw two data points within our search space:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个函数来生成一个样本训练集。我们首先在我们的搜索空间内随机绘制两个数据点：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Fixes the random seed for reproducibility
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为了可重现性，修正随机种子
- en: ❷ Draws two numbers between 0 and 1 and scales them to our search space
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在0和1之间绘制两个数字，并将它们缩放到我们的搜索空间
- en: 'The variable `train_x` here contains the following two points:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此处的变量`train_x`包含以下两个点：
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we obtain the result of the comparison between these two points by evaluating
    the user’s true preference function and calling `compare()`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们通过评估用户的真实偏好函数并调用`compare()`来获得这两个点之间的比较结果：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Computes the actual objective values, which are hidden from us
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算实际的目标值，这些值对我们是隐藏的
- en: ❷ Obtains the result of the comparison
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取比较结果
- en: The result of the comparison between the objective values of the data points
    in `train_x` is stored in `train_comp`, which is
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将`train_x`中数据点的目标值的比较结果存储在`train_comp`中，即
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This result means the first data point in `train_x` is valued by the customer
    more than the second point.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果意味着`train_x`中的第一个数据点比第二个点受到客户的更高评价。
- en: 'We also write another helper function named `observe_and_append_data()` whose
    role is to take in a pair of data points, compare them, and add the result of
    the comparison to a running training set:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还编写了另一个名为`observe_and_append_data()`的辅助函数，其作用是接受一对数据点，比较它们，并将比较结果添加到运行的训练集中：
- en: 'The function first calls the helper function `compare()` to obtain either `[0,`
    `1]` or `[1,` `0]` and then adjusts the values of the indices stored in the two-element
    tensor so that the indices point to the correct locations of the data points in
    the training set:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该函数首先调用辅助函数`compare()`来获得`[0,``1]`或`[1,``0]`，然后调整存储在两个元素张量中的索引值，以便这些索引指向训练集中数据点的正确位置：
- en: '[PRE8]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Evaluates the comparison according to the user’s preference
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 根据用户的偏好评估比较
- en: ❷ Keeps track of the indices
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 跟踪索引
- en: 'The function also checks for data points within the training set that are close
    enough to each other to be considered the same point (e.g., *x* = 1 and *x* =
    1.001). These very similar data points can cause the training of the preference-based
    GP we learn in the next section to become numerically unstable. Our solution is
    to flag these similar data points, treat them as duplicates, and remove one of
    them:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该函数还检查训练集中彼此接近到可以视为相同点的数据点（例如，*x* = 1 和 *x* = 1.001）。这些非常相似的数据点可能会导致我们在下一节学习的基于偏好的高斯过程的训练变得数值不稳定。我们的解决方案是标记这些相似的数据点，将它们视为重复项，并删除其中一个：
- en: '[PRE9]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Checks for duplicates of the first data point in the new pair
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 检查新对中第一个数据点的重复项
- en: ❷ If there are no duplicates, adds the data point to train_x
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 如果没有重复，则将数据点添加到train_x中
- en: ❸ If there’s at least one duplicate, keeps track of the index of the duplicate
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 如果至少有一个重复项，则跟踪重复项的索引
- en: ❹ Checks for duplicates of the second data point in the new pair
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 检查新对中第二个数据点的重复项
- en: ❺ If there’s at least one duplicate, keeps track of the index of the duplicate
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❺ 如果至少有一个重复项，请跟踪重复项的索引
- en: ❻ Returns the updated training set
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❻ 返回更新后的训练集
- en: We make use of these two helper functions in our downstream tasks of training
    GPs and optimizing the user’s preference function, the first of which we explore
    in the next section.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练 GP 和优化用户偏好函数的下游任务中利用这两个辅助函数，我们将在下一节中探讨第一个辅助函数。
- en: 10.3 Training a preference-based GP
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 训练基于偏好的高斯过程
- en: We continue to use the code in the CH10/01 - Learning from pairwise comparisons.ipynb
    notebook to implement our GP model in this section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用 CH10/01 - 从成对比较中学习.ipynb 笔记本中的代码，在本节中实现我们的 GP 模型。
- en: We learned in section 2.2.2 that under the Bayesian update rule (which allows
    us to update our belief in light of data), we can obtain the exact posterior form
    of an MVN distribution, given that we have observed the values of some of the
    variables. This ability to compute a posterior MVN distribution exactly is the
    basis for updating a GP in light of new observations. Unfortunately, this exact
    update is only applicable under numerical observations. That is, we can only exactly
    update a GP with observations in the form of *y* = *f*(*x*), where *x* and *y*
    are real-valued numbers.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第 2.2.2 节中学到，在贝叶斯更新规则下（这使我们能够根据数据更新我们对数据的信念），我们可以在观察到一些变量的值的情况下获得 MVN 分布的精确后验形式。准确计算后验
    MVN 分布的能力是根据新观测更新 GP 的基础。不幸的是，这种精确更新仅适用于数值观测。也就是说，我们只能使用形式为 *y* = *f*(*x*) 的观测精确更新
    GP，其中 *x* 和 *y* 是实数。
- en: Under our current setting, observations come in the form of pairwise comparisons,
    and the posterior form of a GP when conditioned on this type of preference-based
    data is *not* a GP anymore, which rules out most of the methods we have developed
    in this book that rely on the fact that our predictive model is a GP. However,
    this doesn’t mean we have to abandon the entire project.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们当前的设置下，观测结果以成对比较的形式出现，当以这种类型的基于偏好的数据为条件时，GP 的后验形式再也不是 GP，这排除了我们在本书中开发的大部分依赖于我们的预测模型是
    GP 这一事实的方法。然而，这并不意味着我们必须放弃整个项目。
- en: Approximating the posterior GP under pairwise comparisons
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在成对比较下近似后验 GP
- en: 'A common theme in ML (and computer science, in general) is trying to approximately
    solve a task when we can’t accomplish it exactly. Within our context, this approximation
    equates to finding a posterior form for our GP that gives the highest likelihood
    for the observed pairwise comparisons. The interested reader can find more details
    about this approach in the research paper by Wei Chu and Zoubin Ghahramani that
    proposed it: [http://mng.bz/9Dmo](http://mng.bz/9Dmo).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（以及计算机科学一般）中的一个共同主题是在无法准确完成任务时尝试近似解决任务。在我们的上下文中，这种近似等同于为我们的 GP 找到一个后验形式，该后验形式为我们观察到的成对比较提供了最高的可能性。对此方法感兴趣的读者可以在
    Wei Chu 和 Zoubin Ghahramani 提出的研究论文中找到更多细节：[http://mng.bz/9Dmo](http://mng.bz/9Dmo)。
- en: 'Of course, the distribution that truly maximizes the likelihood of the data
    is a non-GP posterior distribution. But as we’d like to have a GP as our predictive
    model, enabling the BayesOpt policies we have learned, our goal is to find the
    GP with the highest data likelihood. Note that finding the GP maximizing the likelihood
    of the data is also what we do when we train a GP: we find the best hyperparameters
    for the GP (e.g., length scale and output scale) that maximize the data likelihood.
    (See section 3.3.2, where we first discuss this method.)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，真正最大化数据可能性的分布是非 GP 后验分布。但是由于我们希望将 GP 作为我们的预测模型，从而实现我们已学到的贝叶斯优化策略，我们的目标是找到具有最高数据可能性的
    GP。请注意，找到最大化数据可能性的 GP 也是我们训练 GP 时所做的事情：我们找到最佳的 GP 超参数（例如，长度尺度和输出尺度），以最大化数据可能性。（请参见第
    3.3.2 节，我们首先讨论了这种方法。）
- en: 'In terms of implementation, we can initialize and train a GP on pairwise comparisons
    using the following code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现方面，我们可以使用以下代码对成对比较进行初始化和训练 GP：
- en: BoTorch provides a special class implementation for this GP model named `PairwiseGP`,
    which can be imported from the `botorch.models.pairwise_gp` module.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BoTorch 为这个 GP 模型提供了一个特殊的类实现，命名为 `PairwiseGP`，可以从 `botorch.models.pairwise_gp`
    模块中导入。
- en: The likelihood of pairwise comparison data requires a different computation
    from that of the likelihood of real-valued data. For this computation, we use
    `PairwiseLaplaceMarginalLogLikelihood`, imported from the same module as the class
    implementation.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两两比较数据的可能性需要与实值数据的可能性不同的计算。对于这种计算，我们使用从同一模块导入的 `PairwiseLaplaceMarginalLogLikelihood`。
- en: To be able to visualize and inspect the predictions made by the GP, we fix its
    output scale so that it retains its default value of 1 during training. We do
    this by disabling its gradient with `model.covar_module.raw_outputscale.requires_`
    `grad_(False)`. This step is only for visualization purposes and is, therefore,
    optional; we won’t do this when running our optimization policies later in the
    chapter.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了能够可视化和检查 GP 进行的预测，我们固定其输出比例，使其在训练期间保持其默认值 1。我们通过使用 `model.covar_module.raw_outputscale.requires_grad_(False)`
    来禁用其梯度来实现这一点。这一步仅用于可视化目的，因此是可选的；在本章后面运行优化策略时我们不会这样做。
- en: 'Finally, we use the helper function `fit_gpytorch_mll` from `botorch.fit` to
    obtain the posterior GP that maximizes the likelihood of our training data:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用 `botorch.fit` 中的辅助函数 `fit_gpytorch_mll` 来获得最大化我们训练数据可能性的后验 GP：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Imports the necessary classes and helper function
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入必要的类和辅助函数
- en: ❷ Initializes the GP model
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 初始化 GP 模型
- en: ❸ Fixes the output scale for more readable output (optional)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 固定输出比例以获得更易读的输出（可选）
- en: ❹ Initializes the (log) likelihood object
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 初始化（对数）可能性对象
- en: ❺ Trains the model by maximizing the likelihood
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 通过最大化可能性训练模型
- en: 'Using this trained GP model, we can now make and visualize predictions across
    our search space in figure 10.5\. We note a few interesting points about these
    predictions:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个训练好的 GP 模型，我们现在可以在图 10.5 中跨我们的搜索空间进行预测并可视化。关于这些预测，我们注意到一些有趣的点：
- en: The mean predictions obey the relationship expressed in the training data that
    *f*(–0.0374) > *f*(2.6822), in that the mean prediction at *x* = –0.0374 is greater
    than 0, while at *x* = 2.6822, it is less than 0.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值预测遵循训练数据中表示 *f*(-0.0374) > *f*(2.6822) 的关系，在这个关系中，在 *x* = –0.0374 处的均值预测大于0，而在
    *x* = 2.6822 处小于0。
- en: The uncertainty in our predictions at –0.0374 and 2.6822 is also lower than
    in the rest of the predictions. This difference in uncertainty reflects the fact
    that upon observing *f*(–0.0374) > f(2.6822), we have gained some information
    about *f*(–0.0374) and *f*(2.6822), and our knowledge about these two objective
    values should increase.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在–0.0374和2.6822处的预测不确定性也比其余预测低。这种不确定性的差异反映了观察到 *f*(-0.0374) > *f*(2.6822) 后，我们对
    *f*(-0.0374) 和 *f*(2.6822) 有了一些信息，我们对这两个目标值的了解应该增加。
- en: However, the uncertainty at these points doesn’t significantly decrease to zero,
    as we see in settings where we train on numerical observations (e.g., in figure
    2.14). This is because, as we remarked in section 10.1, pairwise comparisons don’t
    offer as much information as numerical evaluations, so a significant level of
    uncertainty remains. Figure 10.5 shows that the GP we trained can effectively
    learn from a pairwise comparison where the mean function obeys the observed comparison
    and the uncertainty is well calibrated.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，在这些点上的不确定性并没有显著减少到零，正如我们在训练数值观测时看到的情况（例如，图 2.14 中）。这是因为，正如我们在第 10.1 节中所述，两两比较没有提供与数值评估相同数量的信息，因此仍然存在显著水平的不确定性。图
    10.5 显示了我们训练的 GP 可以有效地从两两比较中学习，其中均值函数遵循观察到的比较，并且不确定性是良好校准的。
- en: BoTorch warning when making predictions
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行预测时的 BoTorch 警告
- en: 'You might encounter a warning from BoTorch similar to the following when making
    predictions with the GP we just trained:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用我们刚刚训练的 GP 进行预测时，您可能会遇到 BoTorch 类似以下的警告：
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This warning indicates that the covariance matrix produced by the GP is not
    positive definite, causing numerical stability-related problems, and BoTorch has
    automatically added a “jitter” to the diagonal of the matrix as a fix, so we,
    the users, don’t need to do anything further. Refer to section 5.3.2 for the instance
    in which we encounter this warning.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个警告表示 GP 生成的协方差矩阵不是正定的，导致数值稳定性相关的问题，BoTorch 已经自动向矩阵的对角线添加了“抖动”作为修复措施，所以我们用户不需要再做进一步的操作。有关我们遇到此警告的示例，请参阅第
    5.3.2 节。
- en: '![](../../OEBPS/Images/10-05.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-05.png)'
- en: Figure 10.5 Predictions made by the GP trained on a pairwise comparison *f*(–0.0374)
    > *f*(2.6822). The posterior mean reflects the result of this comparison, while
    the posterior standard deviation around the two data points slightly decreased
    from the prior.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 展示了由 GP 训练出的对比 *f*(–0.0374) > *f*(2.6822) 的预测。后验均值反映了这个比较的结果，而围绕两个数据点的后验标准偏差从先验中略微减小。
- en: 'To play around with this model further and see how it can learn from more complicated
    data, let’s create a slightly larger training set. Specifically, say we’d like
    to train the GP on three individual comparisons: *f*(0) > *f*(3), *f*(0) > *f*(–4),
    and *f*(4) > *f*(–0), all of which are true for the objective function we have
    in figure 10.5\. To this end, we set our training data points stored in `train_x`
    as'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要进一步玩弄这个模型，并看看它如何从更复杂的数据中学习，让我们创建一个稍大一点的训练集。具体来说，假设我们想要训练 GP 在三个单独的比较上：*f*(0)
    > *f*(3)，*f*(0) > *f*(–4)，和 *f*(4) > *f*(–0)，所有这些对于我们在图 10.5 中有的目标函数都是正确的。为此，我们将我们的训练数据点存储在
    `train_x` 中
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This set contains all the data points involved in the preceding observed comparisons.
    Now, as for `train_comp`, we encode the three comparisons using two-element tensors
    in the way we discussed in section 10.2:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个集合包含了前面观察到的所有比较中涉及的所有数据点。至于 `train_comp`，我们使用我们在第 10.2 节中讨论过的方式，使用两元张量来编码这三个比较：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ [0, 1] means f(train_x[0]) > f(train_x[1]), or f(0) > f(3).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ [0, 1] 表示 f(train_x[0]) > f(train_x[1])，或者 f(0) > f(3)。
- en: ❷ [0, 2] means f(train_x[0]) > f(train_x[2]), or f(0) > f(−4).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ [0, 2] 表示 f(train_x[0]) > f(train_x[2])，或者 f(0) > f(−4)。
- en: ❸ [3, 0] means f(train_x[3]) > f(train_x[0]), or f(4) > f(0).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ [3, 0] 表示 f(train_x[3]) > f(train_x[0])，或者 f(4) > f(0)。
- en: 'Now, we simply redeclare the GP and refit it on this new training data:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们简单地重新声明 GP 并在这个新的训练数据上重新拟合它：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Initializes the GP model
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化 GP 模型
- en: ❷ Initializes the (log) likelihood object
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 初始化（对数）似然对象
- en: ❸ Trains the model by maximizing the likelihood
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 通过最大化似然来训练模型
- en: The GP model produces the predictions shown in figure 10.6, where we see that
    all three comparison results in the training data are reflected in the mean predictions,
    and uncertainty, once again, decreases around the training data points.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: GP 模型产生了图 10.6 中显示的预测，在这里我们看到训练数据中的所有三个比较结果都反映在平均预测中，并且不确定性再次在训练数据点周围减小。
- en: '![](../../OEBPS/Images/10-06.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-06.png)'
- en: Figure 10.6 Predictions made by the GP trained on the pairwise comparisons are
    shown on the right. The posterior mean reflects the result of this comparison,
    while the posterior standard deviation around the data points in the training
    set decreased from the prior.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 展示了由对比训练的 GP 进行的预测，右侧显示了后验均值反映了这个比较的结果，而在训练集中数据点周围的后验标准偏差从先验中减小了。
- en: 'Figure 10.6 shows that our GP model can effectively train on pairwise comparison
    data. We now have a means to learn from preference-based data and make probabilistic
    predictions about the user’s preference function. This leads us to the final topic
    of this chapter: decision-making in preference optimization. That is, how should
    we select data pairs to have the user compare them to find the most preferred
    data point as quickly as possible?'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 显示了我们的 GP 模型可以有效地在对比数据上进行训练。我们现在有了一种方法来从基于偏好的数据中学习，并对用户的偏好函数进行概率预测。这引导我们来到本章的最后一个话题：偏好优化中的决策制定。也就是说，我们应该如何选择数据对让用户将它们进行比较以尽快找到最受欢迎的数据点？
- en: The range of the objective function in preference learning
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 优先学习中目标函数的范围
- en: An interesting advantage of training a GP on pairwise comparisons compared to
    doing so with numerical evaluations is that the range of the objective function
    doesn’t need to be accounted for during training. This is because all we care
    about are the *relative comparisons* between objective values. In other words,
    learning about *f*(*x*) is equivalent to learning about *f*(*x*) + 5, or 2 *f*(*x*),
    or *f*(*x*) / 10.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 GP 训练成对比较的方式与使用数值评估进行比较时，一个有趣的优势是，在训练过程中不需要考虑目标函数的范围。这是因为我们只关心目标值之间的*相对比较*。换句话说，了解
    *f*(*x*) 等同于了解 *f*(*x*) + 5，或者 2 *f*(*x*)，或者 *f*(*x*) / 10。
- en: Meanwhile, when training a traditional GP with numerical evaluations, it’s crucial
    to account for the range of the objective function because only by doing so can
    we have a model with a well-calibrated uncertainty quantification. (For example,
    to model an objective function that ranges from –1 to 1, an output scale that’s
    equal to 1 is appropriate, while for an objective function that ranges from –10
    to 10, we need a larger output scale.)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，当训练传统的GP时，使用数值评估是至关重要的，因为只有这样我们才能拥有一个具有良好校准的不确定性量化的模型。 （例如，要对范围从-1到1的目标函数建模，适当的输出尺度为1，而对于范围从-10到10的目标函数，我们需要更大的输出尺度。）
- en: 10.4 Preference optimization by playing king of the hill
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 通过玩“山顶之王”进行偏好优化
- en: In this section, we learn to apply BayesOpt to preference learning. The code
    we use is included in the CH10/02 - Optimizing preferences.ipynb notebook.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习将BayesOpt应用于偏好学习。 我们使用的代码包含在CH10/02 - 优化偏好.ipynb笔记本中。
- en: The question we need to address is how to select the best pair of data points,
    present them to the user, and ask for their preference to find the data point
    the user prefers the most. As with any BayesOpt optimization policy, our strategy
    needs to achieve a balance between exploitation (zeroing in on a region in the
    search space where we know the user’s value is high) and exploration (inspecting
    the regions we don’t know much about).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要解决的问题是如何选择最佳的一对数据点，呈现给用户，并询问他们的偏好，以找到用户最喜欢的数据点。 与任何BayesOpt优化策略一样，我们的策略需要在利用（将搜索空间中用户价值高的区域归零）和探索（检查我们不太了解的区域）之间取得平衡。
- en: The BayesOpt policies we learned in chapters 4 through 6 effectively address
    this exploitation–exploration tradeoff using various heuristics. We will, therefore,
    develop a strategy to repurpose these policies for our preference-based setting.
    Remember that in previous chapters, a BayesOpt policy computes an acquisition
    score for each data point within the search space, quantifying the data point’s
    value in helping us optimize the objective function. By finding the data point
    maximizing this acquisition score, we obtain the next point to evaluate the objective
    function with.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第4章到第6章学到的BayesOpt策略有效地使用各种启发式方法来解决利用-探索的权衡。 因此，我们将开发一种策略来重新利用这些策略，以适应我们基于偏好的设置。
    请记住，在前几章中，BayesOpt策略为搜索空间中的每个数据点计算一个收获分数，量化帮助我们优化目标函数的数据点的价值。 通过找到最大化此收获分数的数据点，我们获得下一个要评估目标函数的点。
- en: Using a BayesOpt policy to suggest pairwise comparisons
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用BayesOpt策略建议成对比较
- en: In our current preference-based setting, we need to present a pair of data points
    to the user for them to compare. At each iteration of the optimization loop, we
    assemble this pair with, first, the data point that maximizes the acquisition
    score of a given BayesOpt policy and, second, the best point we have seen so far.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们当前的基于偏好的设置中，我们需要向用户展示一对数据点以供他们比较。 在优化循环的每次迭代中，我们首先组装这一对数据点，第一个是最大化给定BayesOpt策略的收获分数的数据点，第二个是我们迄今为止看到的最佳点。
- en: The strategy we use resembles the popular children’s game king of the hill,
    where at each iteration, we attempt to “beat” the best data point we have collected
    so far (the current “king of the hill”), using a challenger chosen by a BayesOpt
    policy, as illustrated in figure 10.7.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的策略类似于流行的儿童游戏“山顶之王”，在每次迭代中，我们试图“击败”迄今为止收集到的最佳数据点（当前的“山顶之王”），使用一个由BayesOpt策略选择的挑战者，如图10.7所示。
- en: '![](../../OEBPS/Images/10-07.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-07.png)'
- en: Figure 10.7 Illustration of the “king of the hill” strategy in Bayesian preference
    optimization. We compare the best point we have seen so far against a promising
    candidate identified by a BayesOpt policy.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 在贝叶斯偏好优化中“山顶之王”策略的示意图。我们将迄今为止看到的最佳点与由BayesOpt策略确定的一个有希望的候选点进行比较。
- en: By using this “king of the hill” strategy, we are outsourcing the task of constructing
    a pair of data points for the user to compare to a regular BayesOpt policy that
    can balance the exploitation–exploration tradeoff well and that we already know
    how to work with.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这种“山顶之王”策略，我们将构造一对数据点的任务外包给了一个常规的BayesOpt策略，该策略能够很好地平衡利用-探索的权衡，并且我们已经知道如何使用它了。
- en: 'Code-wise, this strategy is straightforward to implement. We simply declare
    a BayesOpt policy object and optimize its acquisition score using the helper function
    `optimize_acqf()`. For example, the following code uses the Upper Confidence Bound
    (UCB) policy, which we learned about in section 5.2\. The UCB policy uses upper
    bounds of the predictive normal distributions made by the GP as acquisition scores
    to quantify the value of inspecting a data point:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码的角度来看，这个策略实现起来很简单。我们只需声明一个BayesOpt策略对象，并使用辅助函数`optimize_acqf()`优化其收获分数。例如，以下代码使用了我们在5.2节中学到的上置信度界（UCB）策略。UCB策略使用由GP生成的预测正态分布的上界作为收获分数，以量化检查数据点的价值：
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Initializes the BayesOpt policy
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化BayesOpt策略
- en: ❷ Finds the data point maximizing the acquisition score
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 找到最大化收获分数的数据点
- en: Another policy we use is Expected Improvement (EI), which we learned about in
    section 4.3\. An attribute of EI that makes it suitable for our setting is that
    the motivation of the policy matches exactly with the “king of the hill” strategy
    we employ. That is, EI aims to search for data points that, on average, lead to
    the biggest improvement (in terms of the value of the objective function, our
    optimization goal) from the best point seen so far. Exceeding the best value found
    so far is exactly what the “king of the hill” strategy is all about. To implement
    EI in our setting, we use a different class implementation that can handle noisy
    observations, named `qNoisyExpectedImprovement`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们使用的策略是期望改善（EI），我们在4.3节中学到了这个策略。EI的一个特点使得它适用于我们的环境，就是该策略的动机与我们采用的“山顶之王”策略完全匹配。也就是说，EI旨在搜索数据点，这些数据点平均而言可以从迄今为止看到的最佳点导致最大的改进（就目标函数的值而言，我们的优化目标）。超过迄今为止找到的最佳值恰恰是“山顶之王”策略的全部内容。为了在我们的环境中实现EI，我们使用了一种不同的类实现，它可以处理嘈杂的观测值，命名为`qNoisyExpectedImprovement`。
- en: Noisy observations in BayesOpt
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: BayesOpt中的嘈杂观测
- en: The term *noisy observations* in BayesOpt refers to the situation in which we
    suspect the labels we observe are corrupted by noise in the same way described
    in the beginning of this chapter.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: BayesOpt中的*嘈杂观测*一词指的是我们怀疑观察到的标签可能受到与本章开头描述的方式相同的噪声的污染。
- en: 'As shown in figures 10.5 and 10.6, we still have substantial uncertainty in
    our GP predictions, even at locations included in our training data `train_x`.
    The noisy version of EI should be used here because this policy handles this type
    of uncertain prediction better than the regular EI policy. We implement noisy
    EI as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 正如图10.5和10.6所示，在包括在我们的训练数据`train_x`中的位置上，我们的GP预测仍然存在相当大的不确定性。在这里应该使用嘈杂的EI版本，因为这个策略处理这种类型的不确定预测比常规EI策略更好。我们实现嘈杂的EI如下：
- en: '[PRE16]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Initializes the BayesOpt policy
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化BayesOpt策略
- en: ❷ Finds the data point maximizing the acquisition score
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 找到最大化收获分数的数据点
- en: 'As a point of comparison, let’s also include a naïve strategy of picking the
    challenger for the best point seen so far uniformly at random within the search
    space:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 作为比较的一点，让我们还包括一个简单的策略，即在搜索空间内均匀随机选择挑战者来挑选到目前为止看到的最佳点：
- en: '[PRE17]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Picks a random point between 0 and 1 and scales the point to our search space
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在0和1之间随机选择一个点，并将该点缩放到我们的搜索空间
- en: 'This random strategy serves as a benchmark to determine whether the BayesOpt
    policies we have can work better than random selection. With these policies in
    hand, we are now ready to run our BayesOpt loop to optimize a user’s preference
    in our example problem. The code for this loop resembles what we used in previous
    chapters, except for the step where we present the pair of data points to the
    user for their feedback to append the result to our training set. This is done
    with the `observe_and_ append_data()` helper function we wrote in section 10.2:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这个随机策略作为一个基准，用来确定我们手头的BayesOpt策略是否比随机选择更好。有了这些策略，我们现在准备好运行我们的BayesOpt循环，以优化我们示例问题中用户的偏好。这个循环的代码类似于我们在之前章节中使用的，除了将数据点对呈现给用户以获取他们的反馈并将结果附加到我们的训练集的步骤。这是通过我们在10.2节中编写的`observe_and_
    append_data()`辅助函数完成的：
- en: '[PRE18]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Finds the best point seen so far
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 找到迄今为止看到的最佳点
- en: ❷ Assembles the batch with the best point and the point suggested by a policy
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 组装最佳点和策略建议的点的批次
- en: ❸ Updates our training data
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 更新我们的训练数据
- en: In the code in the CH10/02 - Optimizing preferences.ipynb notebook, each BayesOpt
    run starts out with a randomly generated pair of data points and the feedback
    from the objective function comparing those two points. Each run then proceeds
    with 20 pairwise comparisons (that is, 20 queries to the user). We also repeat
    the experiment 10 times for each policy so that we can observe the aggregated
    performance of each strategy.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在CH10 / 02-Optimizing preferences.ipynb笔记本中的代码中，每个BayesOpt运行都始于随机生成的一对数据点，以及比较这两个点的目标函数的反馈。然后，每个运行都进行20个成对比较（即，向用户查询20个问题）。我们还为每个策略重复实验10次，以便观察每种策略的汇总表现。
- en: Figure 10.8 shows the average best value (and error bars) found by the optimization
    strategies we have. EI performs the best, consistently discovering the global
    optimum. Perhaps a large part of EI’s success can be attributed to the agreement
    between our “king of the hill” method and the algorithmic motivation behind EI.
    More surprisingly, UCB fails to outperform the random strategy; perhaps a different
    value for the tradeoff parameter β can improve UCB’s performance.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8显示了我们使用的优化策略找到的平均最佳值（和误差条）。EI性能最佳，不断发现全局最优解。也许EI的成功很大程度上归功于我们的“国王山”方法与EI背后的算法动机之间的一致性。更令人惊讶的是，UCB未能优于随机策略；也许对于权衡参数β的不同值可以改善UCB的性能。
- en: '![](../../OEBPS/Images/10-08.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/10-08.png)'
- en: Figure 10.8 Optimization performance of various BayesOpt policies, aggregated
    across 10 experiments. EI performs the best, consistently discovering the global
    optimum. Surprisingly, UCB fails to outperform the random strategy.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8汇总了10个实验的各种BayesOpt策略的优化性能。EI性能最佳，不断发现全局最优解。令人惊讶的是，UCB未能优于随机策略。
- en: Note UCB’s tradeoff parameter β directly controls how the policy balances between
    exploration and exploitation. Refer to section 5.2.2 for more discussion on this
    parameter.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，UCB的权衡参数β直接控制策略在探索和利用之间的平衡。有关此参数的更多讨论，请参见第5.2.2节。
- en: In this chapter, we covered the problem of preference learning and optimization
    using pairwise comparisons. We learned about the motivation behind this particular
    method of data collection and the advantages it has over requiring users to report
    numerical evaluations. We then tackled the optimization problem using BayesOpt,
    first training a GP on pairwise comparisons using an approximate method. This
    GP model can effectively learn about the relations between data points expressed
    in the training set, while still offering a well-calibrated quantification of
    uncertainty. Finally, we learned to apply BayesOpt policies to this problem by
    pitting the best data point we have seen against the point recommended by a given
    BayesOpt policy. In the next chapter, we learn about a multiobjective variant
    of the black box optimization problem where there are multiple competing objective
    functions we need to balance during optimization.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了使用成对比较进行偏好学习和优化的问题。我们了解了数据收集的这种特定方法背后的动机以及它优于要求用户报告数字评估的优点。然后，我们使用BayesOpt解决了优化问题，首先使用近似方法在成对比较上训练GP。该GP模型可以有效地了解在训练集中表达的数据点之间的关系，同时仍然提供良好校准的不确定性量化。最后，我们学习将BayesOpt策略应用于该问题，进行最佳数据点与给定BayesOpt策略推荐的点之间的竞争。在下一章中，我们将了解一个黑盒优化问题的多目标变体，其中我们在优化过程中需要平衡多个竞争目标函数。
- en: Summary
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In production recommendation applications, comparing two items can help us obtain
    feedback that is more consistent with the user’s true preference than ratings
    on a numerical scale. This is because the former poses a less cognitively demanding
    task.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产推荐应用中，比较两个物品可以帮助我们获得比数字评级更符合用户真实偏好的反馈。这是因为前者提出的任务量较小。
- en: Pairwise comparisons contain less information than numerical evaluations, so
    there’s a tradeoff between relieving the user’s cognitive burden and obtaining
    information when choosing between the two methods of eliciting preference.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成对比较包含较少的信息，因此在选择两种引出偏好的方法时，存在减轻用户认知负担和获得信息之间的权衡。
- en: A GP can be trained to maximize the likelihood of a dataset of pairwise comparisons.
    This model approximates the true posterior non-GP model when conditioned on pairwise
    comparison data.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以训练GP，使其最大化成对比较数据集的似然。当在成对比较数据上进行条件化时，此模型近似为真实的后验非GP模型。
- en: A GP trained on pairwise comparisons produces mean predictions consistent with
    the comparison results in the training set. In particular, the mean predictions
    at preferred locations are greater than the mean predictions at locations not
    preferred.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在成对比较上训练的高斯过程产生的均值预测与训练集中的比较结果一致。特别是在首选位置的均值预测大于非首选位置的均值预测。
- en: The uncertainty of the GP trained on pairwise comparisons slightly decreases
    from the prior GP but doesn’t collapse to zero, which appropriately reflects our
    uncertainty about the user’s preference function because pairwise comparisons
    offer less information than numerical evaluations.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于在成对比较上训练的高斯过程，其不确定性略微减小于先验高斯过程，但并未降至零，这恰如其分地反映了我们对用户偏好函数的不确定性，因为成对比较比数值评估提供的信息较少。
- en: A strategy for optimizing the user’s preference using BayesOpt involves pitting
    the best data point found against the candidate recommended by a BayesOpt policy.
    The motivation of this strategy is to constantly try to improve from the best
    point we have found so far.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用贝叶斯优化优化用户偏好的策略涉及将找到的最佳数据点与由贝叶斯优化策略推荐的候选数据点进行比较。这一策略的动机是不断尝试从迄今为止找到的最佳点进行改进。
- en: The result of a pairwise comparison is represented as a two-element tensor in
    BoTorch where the first element is the index of the data point that is preferred
    within the training set, and the second element is the index of the data point
    not preferred.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成对比较的结果在 BoTorch 中表示为一个两元张量，其中第一个元素是首选的数据点在训练集中的索引，第二个元素是不被偏好的数据点的索引。
- en: To use the EI policy in the optimization setting with pairwise comparisons,
    we use the noisy version of the policy that can handle high levels of uncertainty
    in the trained GP better than regular EI.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用成对比较的优化设置中使用 EI 策略时，我们使用可以更好处理训练的高斯过程中高不确定性的噪声版本的策略，而不是常规的 EI。
