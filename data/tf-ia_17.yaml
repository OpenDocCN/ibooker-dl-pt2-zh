- en: '14 TensorBoard: Big brother of TensorFlow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14 TensorBoard：TensorFlow 的大兄弟
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容包括
- en: Running and visualizing image data in TensorBoard
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 TensorBoard 上运行和可视化图像数据
- en: Monitoring model performance and behaviors in real time
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时监测模型性能和行为
- en: Performance profiling models using TensorBoard
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 进行性能分析模型建模
- en: Using tf.summary to log custom metrics during customized model training
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 tf.summary 在自定义模型训练过程中记录自定义指标
- en: Visualizing and analyzing word vectors on TensorBoard
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 TensorBoard 上可视化和分析词向量
- en: Thus far we have focused on various models. We have talked about fully connected
    models (e.g., autoencoders), convolutional neural networks, and recurrent neural
    networks (e.g., LSTMs, GRUs). In chapter 13, we talked about Transformers, a powerful
    family of deep learning models that have paved the way to a new state-of-the-art
    performance in language understanding. Furthermore, inspired by the achievements
    in the field of natural language processing, Transformers are making waves in
    the computer vision field. We are past the modeling step, but we still have to
    plough through several more steps to reap the final harvest. One such step is
    making sure the data/features to the model are correct and the models are working
    as expected.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经重点关注了各种模型。我们讨论了全连接模型（例如自动编码器）、卷积神经网络和循环神经网络（例如 LSTM、GRU）。在第 13 章，我们谈到了
    Transformer，这是一类强大的深度学习模型，为语言理解领域的最新最优性能打下了基础。此外，受到自然语言处理领域的成就启发，Transformer 在计算机视觉领域也引起了轰动。我们已经完成了建模步骤，但还需要通过其他几个步骤来最终收获成果。其中一个步骤是确保向模型提供的数据/特征是正确的，并且模型按预期工作。
- en: 'In this chapter, we will explore a new facet of machine learning: leveraging
    a visualization tool kit to visualize high-dimensional data (e.g., images, word
    vectors, etc.) as well as track and monitor model performance. Let’s understand
    why this is a crucial need. Due to the success demonstrated by using machine learning
    in many different fields, machine learning has become deeply rooted in many industries
    and fields of research. Consequently, this means that we need more rapid cycles
    in training new models and less friction when performing various steps in the
    data science workflow (e.g., understanding data, model training, model evaluation,
    etc.). TensorBoard is a step in that direction. It allows you to easily track
    and visualize data, model performance, and even profile models to understand where
    data spends the most time.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索机器学习的一个新方面：利用可视化工具包来可视化高维数据（例如图像、词向量等），以及跟踪和监控模型性能。让我们了解为什么这是一个关键需求。由于机器学习在许多不同领域的成功示范，机器学习已经深深扎根于许多行业和研究领域。因此，这意味着我们需要更快速地训练新模型，并在数据科学工作流程的各个步骤中减少摩擦（例如了解数据、模型训练、模型评估等）。TensorBoard
    是迈出这一步的方向。它可以轻松跟踪和可视化数据、模型性能，甚至对模型进行性能分析，了解数据在哪里花费了最多的时间。
- en: You typically write data and model metrics or other things you want to visualize
    to a logging directory. What is written to the logging directory is typically
    organized into subfolders, which are named to have information like the date,
    time, and a brief description of the experiment. This will help to identify an
    experiment quickly in TensorBoard. TensorBoard will constantly search the designated
    logging directory for changes and visualize them on the dashboard. You will learn
    the specifics of these steps in the coming sections.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您会将数据和模型度量值以及其他要可视化的内容写入日志目录。写入日志目录的内容通常被组织成子文件夹，文件夹的命名包含了日期、时间以及对实验的简要描述。这将有助于在
    TensorBoard 中快速识别一个实验。TensorBoard 会不断搜索指定的日志目录以查找更改，并在仪表板上进行可视化。您将在接下来的章节中了解到这些步骤的具体细节。
- en: 14.1 Visualize data with TensorBoard
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 使用 TensorBoard 可视化数据
- en: Imagine you are working for a fashion company as a data scientist. They have
    asked you to assess the feasibility of building a model that can identify clothing
    items in a given photo. For this, you pick the Fashion-MNIST data set, which has
    images of clothes in black and white belonging to one of 10 categories. Some categories
    are T-shirt, trouser, and dress. You will first load the data and analyze it through
    TensorBoard, a visualization tool for visualizing data and models. Here, you will
    visualize a few images and make sure they have the correct class label assigned
    after loading to memory.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您是一家时尚公司的数据科学家。他们要求您评估构建一个可以在给定照片中识别服装的模型的可行性。为此，您选择了Fashion-MNIST数据集，该数据集包含黑白服装图像，属于10个类别之一。一些类别包括T恤、裤子和连衣裙。您将首先加载数据并通过TensorBoard进行分析，TensorBoard是一种可视化工具，用于可视化数据和模型。在这里，您将可视化一些图像，并确保在加载到内存后正确分配了类标签。
- en: The first thing we will do is download the Fashion-MNIST data set. Fashion-MNIST
    is a labeled data set that contains images of various garments and corresponding
    labels/categories. Fashion-MNIST is primarily inspired by the MNIST data set.
    To refresh our memories, the MNIST data set consists of 28 × 28-sized images of
    digits 0-9, and the corresponding digit is the label. Fashion-MNIST emerged as
    a solution as many were recommending moving away from MNIST as a performance benchmarking
    data set due to the easiness of the task. Fashion-MNIST is considered a more challenging
    task compared to MNIST.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将下载Fashion-MNIST数据集。Fashion-MNIST是一个带有各种服装图片和相应标签/类别的标记数据集。Fashion-MNIST主要受到了MNIST数据集的启发。为了恢复我们的记忆，MNIST数据集由28×28大小的0-9数字图像和相应的数字标签构成。由于任务的容易性，许多人建议不再将MNIST作为性能基准数据集，因此Fashion-MNIST应运而生。与MNIST相比，Fashion-MNIST被认为是一项更具挑战性的任务。
- en: 'Downloading the Fashion-MNIST data set is a very easy step, as it is available
    through the tensorflow_datasets library:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 下载Fashion-MNIST数据集非常容易，因为它可通过tensorflow_datasets库获取：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let’s print to see the format of the data:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们打印来查看数据的格式：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will return
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The data set has two components, a training data set and a testing data set.
    The training set has two items: images, each of which is 28 × 28 × 1, and an integer
    label. The same items are available for the test set. Next, we are going to create
    three tf.data data sets: training, validation, and testing. We will split the
    original training data set into two, a training and a validation set, and then
    keep the test set as it is (see the next listing).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含两个部分，一个训练数据集和一个测试数据集。训练集有两个项：图像（每个图像尺寸为28×28×1）和一个整数标签。测试集上也有同样的项。接下来，我们将创建三个tf.data数据集：训练集、验证集和测试集。我们将原始训练数据集分为两部分，一个训练集和一个验证集，然后将测试集保持不变（参见下一个代码清单）。
- en: Listing 14.1 Generating training, validation, and test data sets
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单14.1 生成训练、验证和测试数据集
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Get the training data set, shuffle it, and output a tuple of (image, label).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取训练数据集，对其进行洗牌，并输出一个(image, label)元组。
- en: ❷ Get the testing data set and output a tuple of (image, label).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取测试数据集，并输出一个(image, label)元组。
- en: ❸ Flatten the images to a 1D vector for fully connected networks.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将图像扁平化为1D向量，用于全连接网络。
- en: ❹ Make the validation data set the first 10,000 data points.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将验证数据集设置为前10,000个数据点。
- en: ❺ Make training data set the rest.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将训练数据集设置为其余数据。
- en: 'This is a simple data pipeline. Each record in the original data set is provided
    as a dictionary with two keys: image and label. First, we convert dictionary-based
    records to a tuple of (<image>, <label>) using the tf.data.Dataset.map() function.
    Then, we have an optional step of flattening the 2D images to a 1D vector if the
    data set is to be used for fully connected networks. In other words, the 28 ×
    28 image will become a 784-sized vector. Finally, we create the valid set as the
    first 10,000 data points in the train_ds (after shuffling) and keep the rest as
    the training set.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的数据流程。原始数据集中的每个记录都以字典形式提供，包含两个键：image和label。首先，我们使用tf.data.Dataset.map()函数将基于字典的记录转换为(image,
    label)的元组。然后，如果数据集要用于全连接网络，则可选择性地将2D图像扁平化为1D向量。换句话说，28 × 28的图像将变为784大小的向量。最后，我们将前10,000个数据点（经过洗牌）作为验证集，其余数据作为训练集。
- en: 'The way to visualize data on TensorBoard is by logging information to a predefined
    log directory through a tf.summary.SummaryWriter(). This writer will write the
    data we’re interested in, in a special format the TensorBoard understands. Next,
    you spin up an instance of TensorBoard, pointing it to the log directory. Using
    this approach, let’s visualize some of the training data using the TensorBoard.
    First, we define a mapping from the label ID to the string label:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorBoard上可视化数据的方式是通过将信息记录到预定义的日志目录中，通过 tf.summary.SummaryWriter()。这个写入器将以TensorBoard理解的特殊格式写入我们感兴趣的数据。接下来，您启动一个TensorBoard的实例，将其指向日志目录。使用这种方法，让我们使用TensorBoard可视化一些训练数据。首先，我们定义一个从标签ID到字符串标签的映射：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'These mappings are obtained from [http://mng.bz/DgdR](http://mng.bz/DgdR).
    Then we will define the logging directory. We are going to use date-timestamps
    to generate a unique identifier for different runs, as shown:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些映射是从 [http://mng.bz/DgdR](http://mng.bz/DgdR) 中获得的。然后我们将定义日志目录。我们将使用日期时间戳来生成不同运行的唯一标识符，如下所示：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you’re wondering about the strange-looking format found in the log_datetimestamp_format
    variable, it is a standard format used by Python’s datetime library to define
    the format of dates and times ([http://mng.bz/lxM2](http://mng.bz/lxM2)), should
    you use them in your code. Specifically, we are going to the time of running (given
    by datetime .now()) as a string of digits with no separators in between. We will
    get the year (%Y), month (%m), day (%d), hour in 24-hour format (%H), minutes
    (%M), and seconds (%S) of a given time of the day. Then we append the string of
    digits to the logging directory to create a unique identifier based on the time
    of running. Next, we define a tf.summary.SummaryWriter() by calling the following
    function, with the logging directory as an argument. With that, any write we do
    with this summary writer will be logged in the defined directory:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对 log_datetimestamp_format 变量中的奇怪格式感到困惑，那么它是Python的datetime库使用的标准格式，用于定义日期和时间的格式（[http://mng.bz/lxM2](http://mng.bz/lxM2)），如果你在你的代码中使用它们。具体来说，我们将会得到运行时间（由
    datetime.now() 给出）作为一个没有分隔符的数字字符串。我们将得到一天中给定时间的年份（%Y）、月份（%m）、日期（%d）、24小时制的小时（%H）、分钟（%M）和秒（%S）。然后，我们将数字字符串附加到日志目录中，以根据运行时间创建一个唯一标识符。接下来，我们通过调用以下函数定义一个
    tf.summary.SummaryWriter()，并将日志目录作为参数传递。有了这个，我们使用这个摘要写入器所做的任何写入都将被记录在定义的目录中：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we open the defined summary writer as the default writer, using a with
    clause. Once the summary writer is open, any tf.summary.<data type> object will
    log that information to the log directory. Here, we use a tf.summary.image object.
    There are several different objects you can use to log ([https://www.tensorflow.org/api_docs/python/tf/summary](https://www.tensorflow.org/api_docs/python/tf/summary)):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们打开已定义的摘要写入器作为默认写入器，使用一个 with 子句。一旦摘要写入器打开，任何 tf.summary.<数据类型> 对象都将将该信息记录到日志目录中。在这里，我们使用了一个
    tf.summary.image 对象。你可以使用几种不同的对象来记录（[https://www.tensorflow.org/api_docs/python/tf/summary](https://www.tensorflow.org/api_docs/python/tf/summary)）：
- en: tf.summary.audio—A type of object used to log audio files and listen to them
    on TensorBoard
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tf.summary.audio—用于记录音频文件并在TensorBoard上听取的对象类型
- en: tf.summary.histogram—A type of object used to log histograms and view them on
    TensorBoard
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tf.summary.histogram—用于记录直方图并在TensorBoard上查看的对象类型
- en: tf.summary.image—A type of object used to log images and view them on TensorBoard
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tf.summary.image—用于记录图像并在TensorBoard上查看的对象类型
- en: tf.summary.scalar—A type of object used to log scalar values (e.g., model losses
    computed over several epochs) and show them on TensorBoard
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tf.summary.scalar—用于记录标量值（例如，在几个周期内计算的模型损失）并在TensorBoard上显示的对象类型
- en: tf.summary.text—A type of object used to log raw textual data and show it on
    TensorBoard
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tf.summary.text—用于记录原始文本数据并在TensorBoard上显示的对象类型
- en: '*Here, we will use* tf.summary.image() *to write and display images on TensorBoard.*
    tf.summary.image() takes in several arguments:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这里，我们将使用* tf.summary.image() *来编写并在TensorBoard上显示图像。* tf.summary.image()
    接受几个参数：'
- en: name—A description of the summary. This will be used as a tag when displaying
    images on TensorBoard.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: name—摘要的描述。这将在在TensorBoard上显示图像时用作标签。
- en: data—A batch of images of size [b, h, w, c], where b is the batch size, h is
    the image height, w is the image width, and c is the number of channels (e.g.,
    RGB).
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: data—大小为[b, h, w, c]的图像批次，其中b是批次大小，h是图像高度，w是图像宽度，c是通道数（例如，RGB）。
- en: step—An integer that can be used to show images belonging to different batches/iterations
    (defaults to None).
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: step—一个整数，可用于显示属于不同批次/迭代的图像（默认为None）。
- en: max_outputs—The maximum number of outputs to display at a given time. If there
    are more images than max_outputs in the data, the first max_outputs images will
    be shown, and the rest will be silently discarded (defaults to three).
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: max_outputs—在给定时间内显示的最大输出数量。如果数据中的图片数量超过max_outputs，则将显示前max_outputs个图片，其余图片将被静默丢弃（默认为三）。
- en: description—A detailed description of the summary (defaults to None)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: description—摘要的详细描述（默认为 None）
- en: 'We will write two sets of image data in two ways:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以两种方式编写两组图像数据：
- en: First, we will take 10 images, one by one, from the training data set and write
    them with their class label tagged. Then, images with the same class label (i.e.,
    category) are nested under the same section on TensorBoard.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们将从训练数据集中逐个取出 10 张图像，并带有其类标签标记地写入它们。然后，具有相同类标签（即，类别）的图像将被嵌套在 TensorBoard
    上的同一部分中。
- en: Finally, we will write a batch of 20 images at once.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们将一次写入一批 20 张图像。
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then we are all set to visualize the TensorBoard. Initializing and loading
    the TensorBoard can be done simply by running the following commands in a Jupyter
    notebook code cell. As you know by now, a Jupyter notebook is made of cells, where
    you can enter text/code. Cells can be code cells, Markdown cells, and so on:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们就可以开始可视化 TensorBoard 了。在 Jupyter 笔记本代码单元格中只需运行以下命令即可简单地初始化和加载 TensorBoard。您现在已经知道，Jupyter
    笔记本由单元格组成，您可以在其中输入文本/代码。单元格可以是代码单元格、Markdown 单元格等：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Figure 14.1 shows how the code will look in a notebook cell.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 显示了代码在笔记本单元格中的外观。
- en: '![14-01](../../OEBPS/Images/14-01.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![14-01](../../OEBPS/Images/14-01.png)'
- en: Figure 14.1 Jupyter magic commands in a notebook cell
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 在笔记本单元格中的 Jupyter 魔术命令
- en: You might notice that this is not typical Python syntax. Commands such as these
    that start with a % sign are known as Jupyter magic commands. Remember that Jupyter
    is the name of the Python library that is producing notebooks that we have our
    code in. You can see a list of such commands at [http://mng.bz/BMd1](http://mng.bz/BMd1).
    The first command loads the TensorBoard Jupyter notebook extension. The second
    command instantiates a TensorBoard with the provided logging directory (--logdir)
    argument and a port (--port) argument. If you don’t specify a port, TensorBoard
    will run on 6006 (or the first unused port greater than 6006) by default. Figure
    14.2 shows how the TensorBoard looks with visualized images.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到，这不是典型的 Python 语法。以 % 符号开头的命令被称为 Jupyter 魔术命令。请记住，Jupyter 是生成笔记本的 Python
    库的名称。您可以在 [http://mng.bz/BMd1](http://mng.bz/BMd1) 查看此类命令的列表。第一个命令加载 TensorBoard
    Jupyter 笔记本扩展程序。第二个命令使用提供的日志目录（--logdir）参数和端口（--port）参数实例化 TensorBoard。如果不指定端口，则
    TensorBoard 默认在 6006（或大于 6006 的第一个未使用的端口）上运行。图 14.2 显示了可视化图像的 TensorBoard 的外观。
- en: '![14-02](../../OEBPS/Images/14-02.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![14-02](../../OEBPS/Images/14-02.png)'
- en: Figure 14.2 The TensorBoard visualizing logged images, displayed inline in the
    Jupyter notebook. You can perform various operations on images, such as adjusting
    brightness or contrast. Furthermore, the subdirectories to which the data is logged
    are shown on the left-hand panel, allowing you to easily show/hide different subdirectories
    for easier comparison.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 TensorBoard 可视化记录的图像，以内联方式在 Jupyter 笔记本中显示。您可以对图像执行各种操作，例如调整亮度或对比度。此外，数据被记录到的子目录显示在左侧面板上，让您可以轻松地显示/隐藏不同的子目录以便进行更容易的比较。
- en: Alternatively, you can also visualize the TensorBoard on a browser tab independent
    of the Jupyter notebook. After you run the two commands in your browser, open
    http://localhost:6006, which will display the TensorBoard as shown in figure 14.2\.
    In the next section, we will see how TensorBoard can be used to track and monitor
    model performance as models are trained.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您还可以将 TensorBoard 可视化为 Jupyter 笔记本之外的浏览器选项卡。在浏览器中运行这两个命令后，打开 http://localhost:6006，将显示
    TensorBoard，如图 14.2 所示。在下一节中，我们将看到在模型训练过程中如何使用 TensorBoard 来跟踪和监视模型性能。
- en: Exercise 1
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 1
- en: You have a list of five batches of images in a variable called step_image_batches.
    Each item in the list corresponds to the first five steps of the training. You
    want to have these batches shown in the TensorBoard, each with the correct step
    value. You can name each batch as batch_0, batch_1, and so on. How would you do
    this?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您有一个名为 step_image_batches 的变量中包含五批图像的列表。列表中的每个项目对应于训练的前五个步骤。您希望在 TensorBoard
    中显示这些批次，每个批次都具有正确的步骤值。您可以将每个批次命名为 batch_0、batch_1 等等。您该如何做？
- en: 14.2 Tracking and monitoring models with TensorBoard
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 使用 TensorBoard 跟踪和监视模型
- en: With a good understanding of the data in the Fashion-MNIST data set, you will
    use a neural network to train a model on this data to gauge how accurately you
    can classify different types of apparel. You are planning to use a dense network
    and a convolutional neural network. You will train both these models under the
    same conditions (e.g., data sets) and visualize the model’s accuracy and loss
    on the TensorBoard.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对 Fashion-MNIST 数据集中的数据有很好的理解，您将使用神经网络在此数据上训练模型，以衡量您能够对不同类型的服装进行多么准确的分类。您计划使用密集网络和卷积神经网络。您将在相同的条件下训练这两个模型（例如，数据集），并在
    TensorBoard 上可视化模型的准确性和损失。
- en: The primary purpose served by the TensorBoard is the ability to visualize a
    model’s performance as it is trained. Deep neural networks are notoriously known
    for their long training times. There is no doubt that identifying problems with
    a model as early as possible pays off well. The TensorBoard plays a vital role
    in that. You can pipe model performance (through evaluation metrics) to be displayed
    in real time on TensorBoard. Therefore, you can spot any abnormal behaviors in
    the model before spending too much time and take necessary actions quickly.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 的主要作用是能够在模型训练时可视化模型的性能。深度神经网络以其长时间的训练时间而闻名。毫无疑问，尽早识别模型中的问题是非常值得的。TensorBoard
    在其中发挥着至关重要的作用。您可以将模型性能（通过评估指标）导入到 TensorBoard 中实时显示。因此，您可以在花费过多时间之前快速发现模型中的任何异常行为并采取必要的行动。
- en: 'In this section, we will compare the performance of a fully connected network
    and a convolutional neural network on the Fashion-MNIST data set. Let’s define
    a small fully connected model as the first model we want to test with this data
    set. It will have three layers:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将比较全连接网络和卷积神经网络在 Fashion-MNIST 数据集上的性能。让我们将一个小型全连接模型定义为我们想要使用该数据集测试的第一个模型。它将有三层：
- en: A layer with 512 neurons and ReLU activation that takes a flattened image from
    the Fashion-MNIST data set
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有 512 个神经元和 ReLU 激活的层，该层接收来自 Fashion-MNIST 数据集的平坦图像
- en: A layer with 256 neurons and ReLU activation that takes the previous layer’s
    output
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有 256 个神经元和 ReLU 激活的层，该层接收前一层的输出
- en: A layer with 10 outputs (representing the categories) that has a softmax activation
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有 softmax 激活的具有 10 个输出的层（表示类别）
- en: 'The model is compiled with sparse categorical cross-entropy loss and the Adam
    optimizer. Since we’re interested in the model accuracy, we add that to the list
    of metrics that are tracked:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型使用稀疏分类交叉熵损失和 Adam 优化器进行编译。由于我们对模型准确性感兴趣，因此我们将其添加到要跟踪的指标列表中：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With the model fully defined, we train it on the training data and evaluate
    it on the validation data set. First, let’s define the logging directory for the
    fully connected model:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 模型完全定义后，我们对训练数据进行训练，并在验证数据集上进行评估。首先，让我们定义全连接模型的日志目录：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As before, you can see that we are not only writing to subdirectories instead
    of the plain flat directory, but we are also using a unique identifier that is
    based on the time of running. Each of these subdirectories represents what is
    called a *run* in TensorBoard terminology.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 与以往一样，您可以看到我们不仅将写入子目录而不是普通的平面目录，而且还使用了基于运行时间的唯一标识符。这些子目录中的每一个代表了 TensorBoard
    术语中所谓的一个 *run*。
- en: Organizing runs in TensorBoard
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorBoard 中组织运行
- en: Typically, users leverage some kind of run organization when visualizing them
    via the TensorBoard. Other than having multiple runs for multiple algorithms,
    a standard thing to do is add a date-time stamp to the runs to discriminate between
    different runs of the same algorithm running at different occasions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，用户在通过 TensorBoard 可视化时利用某种运行组织。除了为多个算法创建多个运行之外，常见的做法是向运行添加日期时间戳，以区分同一算法在不同场合运行的不同运行。
- en: 'For example, you might test the same algorithm with different hyperparameters
    (e.g., number of layers, learning rate, optimizer, etc.) and may want to see them
    all in one place. Let’s say you want to test a fully connected layer with different
    learning rates (0.01, 0.001, and 0.0005). You would have the following directory
    structure in your main logging directory:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可能会测试相同的算法与不同的超参数（例如，层数、学习率、优化器等），并且可能希望将它们都放在一个地方查看。假设您想测试具有不同学习率（0.01、0.001
    和 0.0005）的全连接层。您将在主日志目录中具有以下目录结构：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Or you could even use a more nested directory structure:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您甚至可以使用更嵌套的目录结构：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'I would like to stress that it is important to time stamp your runs, as explained
    in the sidebar. This way you will have a unique folder for each run and can always
    go back to previous runs to compare if needed. Next, let’s generate training/validation/testing
    data sets using the get_train_valid_test() function. Make sure to set the flatten_
    images=True:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我想强调时间戳您的运行很重要，如侧边栏中所述。这样，您将为每次运行都有一个唯一的文件夹，并且可以随时返回到以前的运行以进行比较。接下来，让我们使用get_train_valid_test（）函数生成训练/验证/测试数据集。请确保设置flatten_images=True：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Modeling metrics to the TensorBoard is very easy. There is a special callback
    for the TensorBoard that you can pass during the model training/evaluation:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型指标传递给TensorBoard非常简单。在模型训练/评估期间，可以传递一个特殊的TensorBoard回调函数：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s discuss some of the key arguments you can pass to the TensorBoard callback.
    The default TensorBoard callback looks as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一些您可以传递给TensorBoard回调函数的关键参数。默认的TensorBoard回调函数如下所示：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we will look at the arguments provided:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将查看所提供的参数：
- en: log_dir—The directory to log information to. Once the TensorBoard is spun up
    using the log dir as this (or a parent of this) directory, the information can
    be visualized on the TensorBoard (defaults to 'logs').
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: log_dir—用于日志记录的目录。一旦使用该目录（或该目录的父目录）启动了TensorBoard，可以在TensorBoard上可视化信息（默认为“logs”）。
- en: histogram_freq—Creates histograms of activation distribution in layers (discussed
    in detail later). This specifies how frequently (in epochs) these histograms need
    to be recorded (defaults to 0, meaning it’s disabled).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: histogram_freq—在各个层中创建激活分布的直方图（稍后详细讨论）。此选项指定要多频繁（以epochs为单位）记录这些直方图（默认值为0，即禁用）。
- en: write_graph—Determines whether to write the model as a graph to visualize on
    the TensorBoard (defaults to True).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: write_graph—确定是否将模型以图形的形式写入TensorBoard以进行可视化（默认为True）。
- en: write_image—Determines whether to write model weights as an image (i.e., a heat
    map) to visualize the weights on the TensorBoard (defaults to False).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: write_image—确定是否将模型权重写为图像（即热图）以在TensorBoard上可视化权重（默认为False）。
- en: write_steps_per_second—Determines whether to write the number of steps performed
    in a second to the TensorBoard (defaults to False).
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: write_steps_per_second—确定是否将每秒执行的步骤数写入TensorBoard（默认为False）。
- en: update_freq ('batch', 'epoch' or an integer)—Determines whether to write updates
    to the TensorBoard every batch (if the value is set to batch) or epoch (if value
    is set to epoch). Passing an integer, TensorFlow will interpret it as “write to
    the TensorBoard every x batches.” By default, updates will be written every epoch.
    Writing to the disk is expensive; therefore, writing too frequently will slow
    your training down.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: update_freq（'batch'、'epoch'或整数）—确定是否每个批次（如果值设置为batch）或每个epoch（如果值设置为epoch）向TensorBoard写入更新。传递一个整数，TensorFlow将解释为“每x个批次写入TensorBoard”。默认情况下，将每个epoch写入更新。写入磁盘很昂贵，因此过于频繁地写入将会降低训练速度。
- en: profile_batch (an integer or a list of two numbers)—Determines which batches
    to use for profiling the model. Profiling computes computational and memory profiles
    of the model (discussed in detail later). If an integer is passed, it will profile
    a single batch. If a range (i.e., a list of two numbers) is passed, it will profile
    batches in that range. If set to zero, profiling will not happen (defaults to
    2).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: profile_batch（整数或两个数字的列表）—确定要用于对模型进行分析的批次。分析计算模型的计算和内存使用情况（稍后详细讨论）。如果传递一个整数，它将分析一个批次。如果传递一个范围（即一个包含两个数字的列表），它将分析该范围内的批次。如果设置为零，则不进行分析（默认为2）。
- en: embedding_freq—If the model has an embedding layer, this parameter specifies
    the interval (in epochs) to visualize the embedding layer. If set to zero, this
    is disabled (defaults to 0).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: embedding_freq—如果模型具有嵌入层，则此参数指定可视化嵌入层的间隔（以epochs为单位）。如果设置为零，则禁用此功能（默认为0）。
- en: embedding_metadata—A dictionary that maps the embedding layer name to a file
    name. The file should consist of the tokens corresponding to each row in the embedding
    matrix (in that order; defaults to None).
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: embedding_metadata—一个将嵌入层名称映射到文件名的字典。该文件应包含与嵌入矩阵中每行对应的标记（按顺序排列；默认为None）。
- en: 'Finally, we will train the model as we have done before. The only difference
    is that we pass tb_callback as a callback to the model:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将像以前一样训练模型。唯一的区别是将tb_callback作为回调参数传递给模型：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The model should reach a validation accuracy of around 85%. Now open the TensorBoard
    by visiting http:/ /localhost:6006\. It will display a dashboard similar to figure
    14.3\. The dashboard will be refreshed automatically as new data appears in the
    log directory.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 模型应该达到约85%的验证准确率。现在打开TensorBoard，访问http:/ /localhost:6006。它将显示类似于图14.3的仪表板。随着日志目录中出现新数据，仪表板将自动刷新。
- en: '![14-03](../../OEBPS/Images/14-03.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![14-03](../../OEBPS/Images/14-03.png)'
- en: Figure 14.3 How tracked metrics are displayed on the TensorBoard. You can see
    the training and validation accuracy and the loss are plotted as line graphs.
    Furthermore, you have various controls, such as maximizing the graph, switching
    to a log-scale y-axis, and so on.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3显示了TensorBoard上如何显示跟踪的指标。您可以看到训练和验证准确率以及损失值被绘制为折线图。此外，还有各种控件，例如最大化图形，切换到对数刻度y轴等等。
- en: The TensorBoard dashboard has many controls that help users understand their
    models in great depth with the help of logged metrics. You can turn different
    runs on or off depending on what you want to analyze. For example, if you only
    want to look at validation metrics, you can switch off dense/train run, and vice
    versa. Data/train run does not affect this panel as it contains images we logged
    from the training data. To view them, you can click on the IMAGES panel.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard仪表板具有许多控件，可以帮助用户通过记录的指标深入了解他们的模型。您可以打开或关闭不同的运行，具体取决于您要分析的内容。例如，如果您只想查看验证指标，则可以关闭dense/train运行，并反之亦然。Data/train运行不会影响此面板，因为它包含我们从训练数据中记录的图像。要查看它们，可以单击IMAGES面板。
- en: Next, you can change the smoothing parameter to control the smoothness of the
    line. It helps to remove localized small changes in metrics and focus on global
    trends by having a smoother version of the line. Figure 14.4 depicts the effect
    of the smoothing parameter on line plots.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以更改平滑参数以控制曲线的平滑程度。通过使用曲线的平滑版本，有助于消除指标中的局部小变化，聚焦于整体趋势。图14.4描述了平滑参数对折线图的影响。
- en: '![14-04](../../OEBPS/Images/14-04.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![14-04](../../OEBPS/Images/14-04.png)'
- en: Figure 14.4 How the smoothing parameter changes the line plot. Here, we are
    showing the same line plot under different smoothing parameters. You can see how
    the line gets smoother as the smoothing parameter increases. The original line
    is shown in faded colors.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4展示了平滑参数如何改变折线图。在这里，我们显示了使用不同平滑参数的相同折线图。您可以看到，随着平滑参数的增加，线条变得更平滑。原始线条以淡色显示。
- en: Additionally, you have other controls such as switching to a log-scale y-axis
    instead of a linear one. This is useful if metrics observe large changes over
    time. In log scale, such large changes will become smaller. You can also toggle
    between standard-sized plots and full-sized plots if you need to examine the graphs
    in more detail. Figure 14.3 highlights these controls.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以进行其他控制，例如切换到对数刻度y轴而不是线性。如果指标随时间观察到大幅变化，则这非常有用。在对数刻度下，这些大变化将变得更小。如果您需要更详细地检查图表，还可以在标准大小和全尺寸图之间切换。图14.3突出显示了这些控件。
- en: After that, we will define a simple convolutional neural network and do the
    same. That is, we will define the network first, and then train the model while
    using a callback to the TensorBoard.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将定义一个简单的卷积神经网络，并执行相同的操作。也就是说，我们将首先定义网络，然后在使用回调函数到TensorBoard的同时训练模型。
- en: 'Let’s define the next model we will compare our fully connected network to:
    a convolutional neural network (CNN). Again, we are defining a very simple CNN
    that encompasses'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义下一个我们将与全连接网络进行比较的模型：卷积神经网络（CNN）。同样，我们正在定义一个非常简单的CNN，它包括
- en: A 2D convolution layer with 32 filters with a 5 × 5 kernel, 2 × 2 strides, and
    ReLU activation that takes a 2D 28 × 28-sized image from the Fashion-MNIST data
    set
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个2D卷积层，具有32个过滤器，5×5内核，2×2步幅和ReLU激活，该层接受来自Fashion-MNIST数据集的2D 28×28大小的图像
- en: A 2D convolution layer with 16 filters with a 3 × 3 kernel, 1 × 1 strides, and
    ReLU activation that takes the previous layer’s output
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有16个过滤器的2D卷积层，具有3×3内核，1×1步幅和ReLU激活，该层接受先前层的输出
- en: A Flatten layer that will flatten the convolutional output to a 1D vector suitable
    for a Dense layer
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个扁平化层，将卷积输出压成适用于密集层的1D向量
- en: A layer with 10 outputs (representing the categories) that has a softmax activation
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有10个输出（表示类别）并具有softmax激活的层
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Moving onto the model training, we will log the CNN-related metrics to a separate
    directory called ./logs/conv_{datetimestamp}. This way, we can plot the evaluation
    metrics of the fully connected network and the CNN under two separate runs. We
    will generate training and validation data sets and a TensorBoard callback, as
    we did earlier. These are then passed to the model when calling the fit() method
    to train the model:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将CNN相关的指标记录到一个名为./logs/conv_{datetimestamp}的单独目录中。这样，我们可以分别绘制完全连接的网络和CNN的评估指标。我们将生成训练和验证数据集以及一个TensorBoard回调，就像之前做的那样。然后，在调用fit()方法训练模型时将它们传递给模型：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Notice the changes we have made when training the CNN. First, we do not flatten
    the images like we did when training the fully connected network (i.e., we set
    flatten_ images=False in the get_train_valid_test_datasets() function). Next,
    we introduce a new argument to the TensorBoard callback. We will use the histogram_freq
    argument to log layer activation histograms of the model during the training process.
    We will discuss layer activation histograms in more depth shortly. This will display
    the accuracy and loss metrics of both models (i.e., dense model and convolutional
    model) in the same graph, so they can be easily compared (figure 14.5).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们在训练CNN时所做的更改。首先，我们不像训练完全连接的网络时那样将图像展平（即，在get_train_valid_test_datasets()函数中设置flatten_
    images=False）。接下来，我们向TensorBoard回调引入了一个新参数。我们将使用histogram_freq参数来记录模型在训练过程中的层激活直方图。我们将很快更深入地讨论层激活直方图。这将在同一张图中显示两个模型（即密集模型和卷积模型）的准确度和损失指标，以便它们可以轻松比较（图14.5）。
- en: '![14-05](../../OEBPS/Images/14-05.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![14-05](../../OEBPS/Images/14-05.png)'
- en: Figure 14.5 Viewing metrics of both the dense model and the convolutional model.
    You can switch different runs off/on depending on what you want to compare.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5查看密集模型和卷积模型的指标。你可以根据需要比较不同的运行状态。
- en: Let’s come back to activation histograms again. Activation histograms let us
    visualize the neuron activation distribution of different layers as the training
    progresses. This is an important check that allows you to see whether or not the
    model is converging during the optimization, giving insights into problems in
    model training or data quality.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次回到激活直方图。激活直方图让我们可以可视化不同层的神经元激活分布随着训练的进行而变化的情况。这是一个重要的检查，它可以让你看到模型在优化过程中是否正在收敛，从而提供关于模型训练或数据质量的问题的见解。
- en: Let’s look at what these histograms show in more depth. Figure 14.6 illustrates
    the histograms generated for the CNN we have trained. We have plotted histograms
    every two epochs. Weights represented as histograms are stacked behind each other
    so we can easily understand how they evolved over time. Each slice in the histogram
    shows the weight distribution in a given layer and a given epoch. In other words,
    it will provide information such as “there were x number of outputs, having a
    value of y, approximately.”
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地看一下这些直方图显示了什么。图14.6说明了我们训练的CNN生成的直方图。我们每两个时代绘制一次直方图。以直方图表示的权重堆叠在一起，这样我们就可以很容易地了解它们随时间的变化情况。直方图中的每个切片显示了给定层和给定时代中的权重分布。换句话说，它将提供诸如“有x个输出，其值为y，大约为z”的信息。
- en: '![14-06](../../OEBPS/Images/14-06.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![14-06](../../OEBPS/Images/14-06.png)'
- en: Figure 14.6 Activation histograms displayed by the TensorBoard. These graphs
    indicate how the distribution of activations in a given layer changed over time
    (lighter ones represent more recent epochs).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6由TensorBoard显示的激活直方图。这些图表显示了给定层的激活分布随时间的变化情况（较浅的图表表示更近期的时代）。
- en: 'Typically, if you have a vector of values, it is quite straightforward to create
    the histogram. For example, assume the values are [0.1, 0.3, 0.35, 0.5, 0.6, 0.61,
    0.63], and say that you have four bins: [0.0, 0.2), [0.2, 0.4), [0.4, 0.6), and
    [0.6, 0.8). You’d get the histogram shown in figure 14.7\. If you look at the
    line connecting the midpoints of the bars, it’s similar to what you see in the
    dashboard.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，如果你有一个值的向量，创建直方图就相当简单。例如，假设值为[0.1, 0.3, 0.35, 0.5, 0.6, 0.61, 0.63]，并且假设你有四个箱子：[0.0,
    0.2)，[0.2, 0.4)，[0.4, 0.6)，和[0.6, 0.8)。你将得到图14.7所示的直方图。如果你看一下连接各条的中点的线，它类似于你在仪表板中看到的内容。
- en: '![14-07](../../OEBPS/Images/14-07.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![14-07](../../OEBPS/Images/14-07.png)'
- en: Figure 14.7 A histogram generated for the sequence [0.1, 0.3, 0.35, 0.5, 0.6,
    0.61, 0.63]
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7生成的序列[0.1, 0.3, 0.35, 0.5, 0.6, 0.61, 0.63]的直方图
- en: However, computing histograms involves more complex data manipulations when
    data is large and sparse, like in a weight matrix. For example, computing histograms
    in TensorBoard involves using exponential bin sizes (as opposed to uniform bin
    sizes, as in the example), which gives more fine-grained bins near zero and wider
    bins as you move away from zero. Then it resamples these uneven-sized bins to
    uniformly sized bins for easier and more meaningful visualizations. The specific
    details of these computations are beyond the scope of this book. If you want more
    details, refer to [http://mng.bz/d26o](http://mng.bz/d26o).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当数据很大且稀疏（例如在权重矩阵中）时，计算直方图涉及更复杂的数据操作。例如，在TensorBoard中计算直方图涉及使用指数bin大小（与示例中的均匀bin大小相反），这在接近零时提供了更细粒度的bin和远离零时提供了更宽的bin。然后，它将这些不均匀大小的bin重新采样为统一大小的bin，以便更容易、更有意义地进行可视化。这些计算的具体细节超出了本书的范围。如果您想了解更多细节，请参考[http://mng.bz/d26o](http://mng.bz/d26o)。
- en: We can see in the graphs that the weights are converging to an approximate normal
    distribution as the training progresses. But the bias converges to a multi-modal
    distribution, with spikes appearing in many different places.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在训练过程中，权重正在收敛于一个近似的正态分布。但是偏差收敛于一个多峰分布，并在许多不同的地方出现峰值。
- en: This section elucidated how you can use the TensorBoard for some of the primary
    data visualization and model performance tracking. These are vital parts of the
    core checkpoints you have to set up in your data science project. Visualizing
    data needs to be done early in your project to help you understand the data and
    its structure. Model performance tracking is important as deep learning models
    take longer to train, and you need to complete that training within a limited
    budget (of both time and cost). In the next section, we will discuss how we can
    log custom metrics to the TensorBoard and visualize them.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本节阐述了如何使用TensorBoard进行一些主要数据可视化和模型性能跟踪。这些是您在数据科学项目中必须设置的核心检查点的重要组成部分。数据可视化需要在项目早期完成，以帮助您理解数据及其结构。模型性能跟踪非常重要，因为深度学习模型需要更长的训练时间，而您需要在有限的预算（时间和成本）内完成培训。在下一节中，我们将讨论如何记录自定义指标到TensorBoard并可视化它们。
- en: Exercise 2
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 练习2
- en: You have a binary classification model represented by classif_model. You’d like
    to track precision and recall for this model in the TensorBoard. Furthermore,
    you’d like to visualize the activation histograms every epoch. How would you compile
    the model and fit it with data using the TensorBoard callback to achieve this?
    TensorFlow provides tf.keras.metrics.Precision() and tf.keras.metrics.Recall()
    to compute precision and recall, respectively. You can assume that you are logging
    directly to the ./logs directory. Assume that you have been provided training
    data (tr_ds) and validation data (v_ds) as tf.data.Dataset objects.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 您有一个由classif_model表示的二元分类模型。您想在TensorBoard中跟踪此模型的精度和召回率。此外，您想在每个时期可视化激活直方图。您将如何使用TensorBoard回调编译模型，并使用TensorBoard回调拟合数据以实现此目的？TensorFlow提供了tf.keras.metrics.Precision()和tf.keras.metrics.Recall()来分别计算精度和召回率。您可以假设您直接记录到./logs目录。假设您已经提供了tf.data.Dataset对象的训练数据（tr_ds）和验证数据（v_ds）。
- en: 14.3 Using tf.summary to write custom metrics during model training
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3使用tf.summary在模型训练期间编写自定义度量
- en: Imagine you are a PhD student researching the effects of batch normalization.
    Particularly, you need to analyze how the weights’ mean and standard deviation
    in a given layer change over time, with and without batch normalization. For this,
    you will use a fully connected network and log the weights’ mean and standard
    deviation at every step on the TensorBoard. As this is not a typical metric that
    you can produce using the Keras model, you will log it (for every step) during
    model training in a custom training loop.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，您是一名博士研究批量归一化的影响。特别是，您需要分析给定层中的权重均值和标准偏差如何随时间变化，以及有无批量归一化。为此，您将使用一个全连接网络，并在TensorBoard上记录每个步骤的权重均值和标准偏差。由于这不是您可以使用Keras模型生成的典型指标，因此您将在自定义培训循环中记录每个步骤的模型训练期间的指标。
- en: 'In order to compare the effects of batch normalization, we need to define two
    different models: one without batch normalization and one with batch normalization.
    Both these models will have the same specifications, apart from using batch normalization.
    First, let’s define a model without batch normalization:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较批量归一化的效果，我们需要定义两个不同的模型：一个没有批量归一化，一个有批量归一化。这两个模型将具有相同的规格，除了使用批量归一化。首先，让我们定义一个没有批量归一化的模型：
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The model is quite straightforward and identical to the fully connected model
    we defined earlier. It has three layers, with 512, 256, and 10 nodes, respectively.
    The first two layers use ReLU activation, whereas the last layer uses softmax
    activation. Note that we name the second Dense layer log_layer. We will use this
    layer to compute the metrics we’re interested in. Finally, the model is compiled
    with sparse categorical cross-entropy loss, the Adam optimizer, and accuracy as
    metrics. Next, we define the same model with batch normalization:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型非常简单，与我们之前定义的完全连接模型相同。它有三个层，分别有512、256和10个节点。前两层使用ReLU激活函数，而最后一层使用softmax激活函数。请注意，我们将第二个Dense层命名为log_layer。我们将使用该层来计算我们感兴趣的指标。最后，该模型使用稀疏分类交叉熵损失、Adam优化器和准确度作为指标进行编译。接下来，我们使用批量归一化定义相同的模型：
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Introducing batch normalization means adding tf.keras.layers.BatchNormalization()
    layers between the Dense layers. We name the layer of interest in the second model
    as log_layer_bn, as we cannot have two layers with the same name at once.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 引入批量归一化意味着在Dense层之间添加tf.keras.layers.BatchNormalization()层。我们将第二个模型中感兴趣的层命名为log_layer_bn，因为我们不能同时使用相同名称的两个层。
- en: With the models defined, our task is to compute the mean and standard deviation
    of weights at every step. To do that, we will observe the mean and standard deviation
    of the weights in the second layer of both networks (log_layer and log_layer_bn).
    As we have already discussed, we cannot simply pass a TensorBoard callback and
    expect these metrics to be available. Since the metrics we’re interested in are
    not commonly used, we have to do the heavy lifting and make sure the metrics are
    logged every step.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有了定义好的模型，我们的任务是在每一步计算权重的均值和标准差。为此，我们将观察两个网络的第二层的权重的均值和标准差（log_layer和log_layer_bn）。正如我们已经讨论过的，我们不能简单地传递一个TensorBoard回调并期望这些指标可用。由于我们感兴趣的指标不常用，我们必须费力确保这些指标在每一步都被记录。
- en: We will define a train_model() function, to which we can pass the defined model
    and train it on the data. While training, we will compute the mean and the standard
    deviation of the weights in every step and log that to the TensorBoard (see the
    next listing).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义一个train_model()函数，可以将定义的模型传递给它，并在数据上进行训练。在训练过程中，我们将计算每一步权重的均值和标准差，并将其记录到TensorBoard中（见下一个清单）。
- en: Listing 14.2 Writing a tf.summary object while training the model in a custom
    loop
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 清单14.2 在自定义循环中训练模型时编写tf.summary对象
- en: '[PRE21]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Define the writer.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义写入器。
- en: ❷ Open the writer.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 打开写入器。
- en: ❸ Train with one batch.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用一个批次进行训练。
- en: ❹ Get the weights of the layer. It’s a list of arrays [weights, bias] in that
    order. Therefore, we’re only taking the weights (index 0).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 获取层的权重。它是一个数组列表[权重，偏差]，顺序是这样的。因此，我们只取权重（索引0）。
- en: ❺ Log mean and std of absolute weights (which are two scalars for a given epoch).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 记录权重的均值和标准差（对于给定epoch是两个标量）。
- en: ❻ Flush to the disk from the buffer.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 从缓冲区刷新到磁盘。
- en: 'Note how we open a tf.summary.writer() and then log the metrics in every step
    using the tf.summary.scalar() call. We are giving the metrics meaningful names
    to make sure we know which is which when visualizing them on the TensorBoard.
    With the function defined, we call it for the two different models we have compiled:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何打开一个tf.summary.writer()，然后使用tf.summary.scalar()调用在每一步记录指标。我们给指标起了有意义的名称，以确保在TensorBoard上可视化时知道哪个是哪个。有了函数定义，我们为我们编译的两个不同模型调用它：
- en: '[PRE22]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note that we are specifying different logging subdirectories to make sure the
    two models that appear are different runs. After running this, you will see two
    new additional sections called mean_weights and std_weights (figure 14.8). It
    seems that the mean and variance of weights change more drastically when batch
    normalization is used. This could be because, as batch normalization introduces
    explicit normalization between layers, weights of layers have more freedom to
    move around.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们指定不同的日志子目录，以确保出现的两个模型是不同的运行。运行后，您将看到两个新的附加部分，名为mean_weights和std_weights（图14.8）。似乎当使用批量归一化时，权重的均值和方差更加剧烈地变化。这可能是因为批量归一化在层之间引入了显式归一化，使得层的权重更自由地移动。
- en: '![14-08](../../OEBPS/Images/14-08.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![14-08](../../OEBPS/Images/14-08.png)'
- en: Figure 14.8 The mean and standard deviation of weights plotted in the TensorBoard
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.8 权重的均值和标准差在TensorBoard中绘制
- en: The next section expands on how the TensorBoard can be used to profile models
    and provides in-depth analysis of how time spent and memory are consumed when
    models are executed.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分详细介绍了如何使用TensorBoard来分析模型并深入分析模型执行时时间和内存消耗情况。
- en: Exercise 3
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 练习3
- en: You are planning to compute Fibonacci numbers (i.e., 0, 1, 1, 2, 3, 5, 8, 13,
    21, 34, 55, etc.), where the n^(th) number x_n is given by x_n = x_{n - 1} + x_{n
    - 2}. Write a code to compute the Fibonacci series for 100 steps and plot it as
    a line graph in TensorBoard. You can use the name “fibonacci” as the name for
    the metric.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 你计划计算斐波那契数列（即0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55等），其中第n个数字 x_n 由 x_n = x_{n
    - 1} + x_{n - 2} 给出。编写一个代码，计算100步的斐波那契数列并在TensorBoard中将其绘制为折线图。你可以将名字“fibonacci”作为指标名称。
- en: 14.4 Profiling models to detect performance bottlenecks
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.4 对模型进行性能瓶颈检测
- en: You are starting off as a data scientist at a bio-tech company that is identifying
    endangered flower species. One of the previous data scientists developed a model,
    and you are continuing that work. First, you want to determine if there are any
    performance bottlenecks. To analyze such issues, you plan to use the TensorBoard
    profiler. You will be using a smaller flower data set for the purpose of training
    the model so that the profiler can capture various computational profiles.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在作为一位数据科学家加入了一家正在识别濒临灭绝的花卉物种的生物技术公司。之前的一位数据科学家开发了一个模型，而你将继续这项工作。首先，你想确定是否存在任何性能瓶颈。为了分析这些问题，你计划使用TensorBoard分析器。你将使用一个较小的花卉数据集来训练模型，以便分析器可以捕获各种计算配置文件。
- en: We start with the model in listing 14.3\. It is a CNN model that has four convolutional
    layers, with pooling layers in between and three fully connected layers, including
    a final softmax layer with 17 output classes.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从列表14.3中的模型开始。这是一个具有四个卷积层的CNN模型，中间有池化层，包括三个完全连接的层，最后一个是具有17个输出类别的softmax层。
- en: Listing 14.3 The CNN model available to you
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.3 你可用的CNN模型
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Define a Keras model using the sequential API.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用顺序API定义一个Keras模型。
- en: ❷ Define the first convolutional layer that takes a 64 × 64 × 3-sized input.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义一个接受大小为64 × 64 × 3的输入的第一个卷积层。
- en: ❸ A batch normalization layer
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 一个批量归一化层
- en: ❹ A max pooling layer
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 一个最大池化层
- en: ❺ A series of alternating convolution and batch normalization layers
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 一系列交替的卷积和批量归一化层
- en: ❻ An average pooling layer that marks the end of convolutional/pooling layers
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 一个平均池化层，标志着卷积/池化层的结束
- en: ❼ Flatten the output of the last pooling layer.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 将最后一个池化层的输出展平。
- en: ❽ A set of Dense layers (with leaky ReLU activation), followed by a layer with
    softmax activation
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 一组稠密层（带有渗漏线性整流激活），接着是一个具有softmax激活的层
- en: 'The data set we’re going to use is a flower data set found at [https://www.robots.ox.ac.uk/~vgg/data/flowers](https://www.robots.ox.ac.uk/~vgg/data/flowers),
    specifically, the 17-category data set. It has a single folder with images of
    flowers, and each image filename has a number. The images are numbered in such
    a way that, when sorted by the filename, the first 80 images belong to class 0,
    the next 80 images belong to class 1, and so on. You have been provided the code
    to download the data set in the notebook Ch14/14.1_Tensorboard.ipynb, which we
    will not discuss here. Next, we will write a simple tf.data pipeline to create
    batches of data by reading these images in:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集是在[https://www.robots.ox.ac.uk/~vgg/data/flowers](https://www.robots.ox.ac.uk/~vgg/data/flowers)找到的花卉数据集，具体来说，是17类别数据集。它有一个包含花朵图像的单独文件夹，每个图像文件名上都有一个数字。这些图像按照文件名排序时，前80个图像属于类别0，接下来的80个图像属于类别1，依此类推。你已经提供了下载数据集的代码，位于笔记本Ch14/14.1_Tensorboard.ipynb中，我们这里不会讨论。接下来，我们将编写一个简单的tf.data流水线，通过读取这些图像来创建数据批次：
- en: '[PRE24]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Let’s analyze what we’re doing here. First, we read the files which have a .jpg
    extension from a given folder. Then we have a nested function called get_image_and_label(),
    which takes a file path of an image and produces the image by reading it from
    the disk and the label. The label can be computed by
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下我们在这里所做的事情。首先，我们从给定文件夹中读取具有.jpg扩展名的文件。然后我们有一个名为get_image_and_label()的嵌套函数，它接受一个图像的文件路径，并通过从磁盘中读取该图像产生图像和标签。标签可以通过计算得到
- en: Extracting the image ID
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取图像ID
- en: Subtracting 1 (i.e., to make IDs zero-based indices) and dividing by 80
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减去1（即将ID减1，以使其成为从零开始的索引）并除以80
- en: 'After that, we shuffle the data and take the first 250 as validation data and
    the rest as training data. Next, we use these functions defined and train the
    CNN model while creating various computational profiles of the model. In order
    for the profiling to work, you need two main prerequisites:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们对数据进行洗牌，并将前250个数据作为验证数据，其余的作为训练数据。接下来，我们使用定义的这些函数并训练CNN模型，同时创建模型的各种计算性能分析。为了使性能分析工作，你需要两个主要的先决条件：
- en: Install the Python package tensorboard_plugin_profile.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Python包`tensorboard_plugin_profile`。
- en: Install libcupti, the CUDA Profiling Toolkit Interface.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装libcupti，CUDA性能分析工具包接口。
- en: Installing the CUDA Profiling Toolkit Interface (libcupti)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 安装CUDA性能分析工具包接口（libcupti）
- en: TensorBoard requires the libcupti CUDA library in order for model profiling
    to work. Installing this library requires different steps depending on which operating
    system is used. This assumes that your computer is equipped with an NVIDIA GPU.
    Unfortunately, you will not be able to perform this on a Mac, as the profiling
    API for data collection is not available on Mac. (Look at the Requirements section
    in [https://developer.nvidia.com/cupti-ctk10_1u1](https://developer.nvidia.com/cupti-ctk10_1u1).)
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard需要libcupti CUDA库才能进行模型性能分析。安装此库需要根据所使用的操作系统的不同步骤。这假设您的计算机配备了NVIDIA
    GPU。不幸的是，你将无法在Mac上执行此操作，因为Mac上没有可用于数据收集的性能分析API。（查看[https://developer.nvidia.com/cupti-ctk10_1u1](https://developer.nvidia.com/cupti-ctk10_1u1)中的需求部分。）
- en: '**Installing libcupti on Ubuntu**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**在Ubuntu上安装libcupti**'
- en: To install libcupti on Linux, simply run sudo apt-get install libcupti-dev.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Linux上安装libcupti，只需运行`sudo apt-get install libcupti-dev`。
- en: '**Installing libcupti on Windows**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**在Windows上安装libcupti**'
- en: 'Installing libcupti on Windows requires more work:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上安装libcupti需要更多工作：
- en: Make sure you have installed the recommended CUDA installation (e.g., CUDA 11
    [>= TensorFlow 2.4.0]). For more information on the CUDA version, visit [https://www.tensorflow.org/install/source#gpu](https://www.tensorflow.org/install/source#gpu).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保你已经安装了推荐的CUDA版本（例如CUDA 11 [>= TensorFlow 2.4.0]）。有关CUDA版本的更多信息，请访问[https://www.tensorflow.org/install/source#gpu](https://www.tensorflow.org/install/source#gpu)。
- en: 'Next, open the NVIDIA control panel (by right-clicking on the desktop and selecting
    the menu item) to make several changes ([http://mng.bz/rJVJ](http://mng.bz/rJVJ)):'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，打开NVIDIA控制面板（通过右键单击桌面并选择菜单项）进行几项更改（[http://mng.bz/rJVJ](http://mng.bz/rJVJ)）：
- en: Make sure you set the developer mode by clicking Desktop > Set Developer Mode.
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保你点击桌面 > 设置开发者模式，设置开发者模式。
- en: Make sure you enabled GRU profiling to all users and not just the administrator
    (figure 14.9).
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保你为所有用户启用了GRU性能分析，而不仅仅是管理员（图14.9）。
- en: For more errors that you might face, refer to [http://mng.bz/VMxy](http://mng.bz/VMxy)
    from the official NVIDIA website.
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多可能遇到的错误，请参考来自官方NVIDIA网站的[http://mng.bz/VMxy](http://mng.bz/VMxy)。
- en: To install libcupti ([http://mng.bz/xn2d](http://mng.bz/xn2d))
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要安装libcupti，请访问[http://mng.bz/xn2d](http://mng.bz/xn2d)
- en: Copy libcupti_<version>.dll, nvperf_host.dll, and nvperf_target .dll from extras\CUPTI\lib64
    to the bin folder. Make sure the libcupti file has the name libcupti_110.dll.
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`extras\CUPTI\lib64`中的`libcupti_<version>.dll`、`nvperf_host.dll`和`nvperf_target
    .dll`文件复制到`bin`文件夹中。确保libcupti文件的名称为`libcupti_110.dll`。
- en: Copy all files in extras\CUPTI\lib64 *to* lib\x64
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`extras\CUPTI\lib64`中的所有文件复制到`lib\x64`中。
- en: Copy all files in extras\CUPTI\include to include.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`extras\CUPTI\include`中的所有文件复制到`include`中。
- en: '![14-09](../../OEBPS/Images/14-09.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![14-09](../../OEBPS/Images/14-09.png)'
- en: Figure 14.9 Enabling GPU profiling for all users
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.9 为所有用户启用GPU性能分析
- en: 'Make sure you have libcupti installed properly in the environment you are using
    (e.g., Ubuntu or Windows). Otherwise, you will not see the expected results. Then,
    to enable profiling, all you need to do is pass the argument profile_batch to
    the TensorBoard callback. The value is a list of two numbers: the starting step
    and the ending step. Profiling is typically done across a span of several batches
    and therefore requires a range as the value. However, profiling can be done for
    a single batch too:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经在你所使用的环境中正确安装了libcupti（例如Ubuntu或Windows）。否则，你将看不到预期的结果。然后，要启用性能分析，你只需要将参数`profile_batch`传递给TensorBoard回调函数。该值是两个数字的列表：起始步骤和结束步骤。通常情况下，性能分析是跨越几个批次进行的，因此值需要一个范围。但是，也可以对单个批次进行性能分析：
- en: '[PRE25]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Once the training finishes, you can view the results on the TensorBoard. TensorBoard
    provides a large collection of valuable information and insights on model performance.
    It breaks down the computation into smaller subtasks and provides fine-grained
    computational time decomposition based on those subtasks. Furthermore, TensorBoard
    provides recommendations on where there is room for improvement (figure 14.10).
    Let’s now delve into more details about the information provided on this page.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，您可以在TensorBoard上查看结果。TensorBoard提供了大量有价值的信息和对模型性能的洞察。它将计算分解为更小的子任务，并根据这些子任务提供细粒度的计算时间分解。此外，TensorBoard提供了关于改进空间的建议（图14.10）。现在让我们更深入地了解该页面提供的信息。
- en: '![14-10](../../OEBPS/Images/14-10.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![14-10](../../OEBPS/Images/14-10.png)'
- en: Figure 14.10 TensorBoard profiling interface. It gives a valuable collection
    of information on various subtasks involved in running models on the GPU. In addition,
    it provides recommendations on how to improve the performance of the models.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10 TensorBoard性能分析界面。它提供了有关在GPU上运行模型涉及的各种子任务的宝贵信息。此外，它还提供了改进模型性能的建议。
- en: 'The average step time is a summation of several smaller tasks:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 平均步骤时间是几个较小任务的总和：
- en: '*Input time*—Time spent on reading data-related operations (e.g., tf.data.Dataset
    operations).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输入时间*—用于读取与数据相关的操作（例如，tf.data.Dataset操作）的时间。'
- en: '*Host compute time*—Model-related computations done on the host (e.g., CPU).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主机计算时间*—在主机上执行的与模型相关的计算（例如，CPU）。'
- en: '*Device-to-device time*—To run things on the GPU, data first needs to be transferred
    to the GPU. This subtask measures the time taken for such transfers.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设备到设备时间*—要在GPU上运行东西，首先需要将数据传输到GPU。这个子任务测量了这种传输所花费的时间。'
- en: '*Kernel launch time*—For the GPU to execute operations on the transferred data,
    the CPU needs to launch the kernels for the GPU. A kernel encapsulates a primitive
    computation performed on data (e.g., matrix multiplication). This measures the
    time taken for launching kernels.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内核启动时间*—为了使GPU执行传输的数据上的操作，CPU需要为GPU启动内核。内核封装了对数据执行的原始计算（例如，矩阵乘法）。这测量了启动内核所需的时间。'
- en: '*Device compute time*—Model-related computations that happen on the device
    (e.g., GPU).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设备计算时间*—发生在设备上的与模型相关的计算（例如，GPU）。'
- en: '*Device collective communication time*—Relates to time spent on communicating
    in multi-device (e.g., multiple GPUs) or multi-node environments.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设备集体通信时间*—与在多设备（例如，多个GPU）或多节点环境中通信所花费的时间相关。'
- en: All the other times (e.g., compilation time, output time, all other remaining
    time).
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有其他时间（例如，编译时间、输出时间、所有其他剩余时间）。
- en: Here we can see that the most time is spent on device computations. This is,
    in a way, good, as it means that most computations happen on the GPU. The next-biggest
    time consumer is the input time. This makes sense as we are not using any optimizations
    for our tf.data pipeline and it is a highly disk-bound pipeline as images are
    read from the disk.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到大部分时间都花在了设备计算上。从某种意义上说，这是好的，因为它意味着大多数计算发生在GPU上。下一个最大的时间消耗者是输入时间。这是有道理的，因为我们没有对我们的tf.data流水线进行任何优化，并且它是一个高度依赖磁盘的流水线，因为图像是从磁盘中读取的。
- en: Then, right below that, you can see some more information. Close to 80% of the
    TensorFlow ops were placed on this host, whereas only 20% ran on the GPU. Furthermore,
    all the operations were 32-bit operations, and none were 16-bit; 16-bit (half-precision
    floating point) operations run faster and save a lot of memory compared to 32-bit
    (single-precision floating point) data types. GPUs and Tensor Processing Units
    (TPUs) are optimized hardware that can run 16-bit operations much faster than
    32-bit operations. Therefore, they must be incorporated whenever possible. Having
    said that, we must be careful how we use 16-bit operations, as incorrect usage
    can hurt model performance (e.g., model accuracy) significantly. Incorporating
    16-bit operations along with 32-bit operations to train the model is known as
    *mixed precision training*.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在下面，您可以看到更多信息。接近80%的TensorFlow操作被放置在此主机上，而仅有20%在GPU上运行。此外，所有操作都是32位操作，没有16位操作；16位（半精度浮点）操作比32位（单精度浮点）数据类型运行得更快，节省了大量内存。GPU和Tensor处理单元（TPU）是经过优化的硬件，可以比32位操作更快地运行16位操作。因此，必须尽可能地将它们纳入其中。话虽如此，我们必须小心如何使用16位操作，因为不正确的使用可能会严重影响模型性能（例如，模型准确性）。将16位操作与32位操作一起用于训练模型称为*混合精度训练*。
- en: 'If you look at the recommendation section, you can see two main recommendations:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看推荐部分，你会看到两个主要的建议：
- en: Optimize the input data pipeline.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化输入数据管道。
- en: Utilize more 16-bit operations in model training.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型训练中利用更多的 16 位操作。
- en: Brain Floating Point data type (bfloat16)
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Brain Floating Point 数据类型（bfloat16）
- en: Brain Floating Point values, or bfloat16 values, are a data type proposed by
    Google. It has the same number of bits as float16 (i.e., 16 bits) but is able
    to represent the dynamic range of float32 values with some loss in precision.
    This change is implemented by having more exponent bits (left side of the decimal
    point) and less fraction bits (right side of the decimal point). This data type
    can give significant advantages on optimized hardware like TPUs and GPUs (given
    they have Tensor Cores; [https://developer.nvidia.com/tensor-cores)](https://developer.nvidia.com/tensor-cores).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Brain Floating Point 值，或称 bfloat16 值，是 Google 提出的一种数据类型。它与 float16（即，16 位）具有相同的位数，但能够表示
    float32 值的动态范围，但在精度上会有一定损失。这种变化是通过增加更多的指数位（小数点左侧）和减少小数位（小数点右侧）来实现的。这种数据类型可以在优化的硬件上获得显著的优势，比如
    TPU 和 GPU（假设它们有 Tensor 核心；[https://developer.nvidia.com/tensor-cores)](https://developer.nvidia.com/tensor-cores)）。
- en: Let’s see how we can use these recommendations to reduce model training time.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何利用这些建议来减少模型训练时间。
- en: 14.4.1 Optimizing the input pipeline
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.4.1 优化输入管道
- en: 'To optimize the data pipeline, we will introduce two changes to our get_flower_
    datasets() function:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化数据管道，我们将对 get_flower_datasets() 函数进行两项更改：
- en: Use data prefetching to avoid the model having to wait for the data to become
    available.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据预取以避免模型等待数据可用。
- en: Use the parallelized map function when calling the get_image_and_label() function.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用 get_image_and_label() 函数时使用并行化的 map 函数。
- en: In terms of how these changes are reflected in the code, they are minor changes.
    In the following listing, the changes are in bold.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些变化在代码中的体现来说，它们是小变化。在下面的列表中，这些变化用粗体表示。
- en: Listing 14.4 The function generating training/validation data sets from flower
    data set
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.4 从花数据集生成训练/验证数据集的函数
- en: '[PRE26]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Get the training data set, shuffle it, and output a tuple of (image, label).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取训练数据集，对其进行洗牌，并输出（图像，标签）元组。
- en: ❷ Define a function to get the image and the label given a file name.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义一个函数，根据文件名获取图像和标签。
- en: ❸ Get the tokens in the file path and compute the label from the image ID.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 获取文件路径中的标记并从图像 ID 计算标签。
- en: ❹ Read the image and convert to a tensor.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 读取图像并转换为张量。
- en: ❺ Parallelize the map function.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 并行化 map 函数。
- en: ❻ Incorporate prefetching.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 结合预取。
- en: To parallelize the dataset.map() function, we add the num_parallel_calls=tf.data
    .AUTOTUNE argument, which will cause TensorFlow to execute the map function in
    parallel, where the number of threads will be determined by the workload carried
    out by the host at the time. Next, we invoke the prefetch() function on the data
    after batching to make sure the model training is not hindered by waiting for
    the data to become available.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了并行化 dataset.map() 函数，我们在其后添加了 num_parallel_calls=tf.data .AUTOTUNE 参数，这将导致
    TensorFlow 在并行执行 map 函数，其中线程数将由主机在执行时承载的工作量确定。接下来，在批处理后我们调用 prefetch() 函数，以确保模型训练不会因为等待数据可用而受阻。
- en: 'Next, we will set a special environment variable called TF_GPU_THREAD_MODE.
    To understand the effects of this variable, you first need to grok how GPUs execute
    instructions at a high level. When you run deep learning models on a machine with
    a GPU, most of the data-parallel operations (i.e., operations that can be parallelly
    executed on data) get executed on the GPU. But how do data and instructions get
    to the GPU? Assume use of a GPU to execute an element-wise multiplication between
    two matrices. Since individual elements can be multiplied in parallel, this is
    a data-parallel operation. To execute this operation (defined as a set of instructions
    and referred to as a *kernel*) on the GPU, the host (CPU) first needs to launch
    the kernel in order for the GPU to use that function on data. Particularly, a
    thread in the CPU (a modern Intel CPU has around two threads per core) will need
    to trigger this. Think about what will happen if all the threads in the CPU are
    very busy. In other words, if there are a lot of CPU-bound operations happening
    (e.g., doing lot of reads from the disk), it can create CPU contention, causing
    these GPU kernel launches to be delayed. This, in turn, delays code getting executed
    on the GPU. With the TF_GPU_THREAD_MODE *variable, you can alleviate the delays
    on the GPU caused by CPU contention*. More concretely, this variable controls
    how CPU threads are allocated to launch kernels on the GPU. It can take three
    different values:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将设置一个特殊的环境变量，称为TF_GPU_THREAD_MODE。要理解这个变量的影响，你首先需要弄清楚 GPU 如何高效执行指令。当你在一台带有
    GPU 的机器上运行深度学习模型时，大多数数据并行操作（即可以并行执行的数据操作）都会在 GPU 上执行。但数据和指令是如何传输到 GPU 的呢？假设使用
    GPU 执行两个矩阵之间的逐元素乘法。由于可以并行地对个别元素进行乘法，这是一个数据并行操作。为了在 GPU 上执行此操作（定义为一组指令并称为*内核*），主机（CPU）首先需要启动内核，以便
    GPU 使用该函数对数据进行操作。特别地，CPU 中的一个线程（现代 Intel CPU 每个核心大约有两个线程）将需要触发此操作。想象一下如果 CPU 中的所有线程都非常忙碌会发生什么。换句话说，如果有很多
    CPU 绑定的操作正在进行（例如，从磁盘读取大量数据），它可能会导致 CPU 竞争，从而延迟 GPU 内核的启动。这反过来又延迟了在 GPU 上执行的代码。有了TF_GPU_THREAD_MODE
    *变量，你可以缓解 CPU 竞争引起的 GPU 延迟*。更具体地说，这个变量控制着 CPU 线程如何分配到 GPU 上启动内核。它可以有三个不同的值：
- en: Global—There is no special preference as to how threads are allocated for the
    different processes (default).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局—对于为不同的进程分配线程没有特殊的偏好（默认）。
- en: gpu_private—A number of dedicated threads are allocated to launch kernels for
    the GPU. This way, kernel launch will not be delayed, even when a CPU is executing
    a significant load. If there are multiple GPUs, they will have their own private
    threads. The number of threads defaults to two and can be changed by setting the
    TF_GPU_THREAD_COUNT variable.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpu_private—分配了一些专用线程来为 GPU 启动内核。这样，即使 CPU 正在执行大量负载，内核启动也不会延迟。如果有多个 GPU，则它们将拥有自己的私有线程。线程的数量默认为两个，并可以通过设置TF_GPU_THREAD_COUNT变量进行更改。
- en: shared—Same as gpu_private, except in multi-GPU environments, a pool of threads
    will be shared between the GPUs.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: shared—与gpu_private相同，但在多 GPU 环境中，一组线程将在 GPU 之间共享。
- en: We will set this variable to gpu_private. We will keep the number of dedicate
    threads to two, so it will not create the TF_GPU_THREAD_COUNT variable.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将此变量设置为gpu_private。我们将保持专用线程的数量为两个，因此不会创建TF_GPU_THREAD_COUNT变量。
- en: Setting environment variables
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 设置环境变量
- en: 'To set the TF_GPU_THREAD_MODE environment variable, you can do the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置TF_GPU_THREAD_MODE环境变量，你可以执行以下操作：
- en: '**Linux operating systems (e.g., Ubuntu)**'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**Linux 操作系统（例如 Ubuntu）**'
- en: To set the environment variable
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 设置环境变量
- en: Open a terminal.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开一个终端。
- en: Run export TF_GPU_THREAD_MODE=gpu_private.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 export TF_GPU_THREAD_MODE=gpu_private。
- en: Verify the environment variable is set by calling echo $TF_GPU_THREAD_MODE.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过调用 echo $TF_GPU_THREAD_MODE 来验证环境变量是否设置。
- en: Open a new shell and start the Jupyter notebook server.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开一个新的 shell 并启动 Jupyter 笔记本服务器。
- en: '**Windows operating system**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**Windows 操作系统**'
- en: To the environment variable
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量
- en: From the start menu, select Edit the system environment variables.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从开始菜单中，选择编辑系统环境变量。
- en: Click the button called environment variables.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单击名为环境变量的按钮。
- en: Add a new environment variable, TF_GPU_THREAD_MODE=gpu_private, in the opened
    dialog.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在打开的对话框中添加一个新的环境变量TF_GPU_THREAD_MODE=gpu_private。
- en: Open a new command prompt and start the Jupyter notebook server.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开一个新的命令提示符并启动 Jupyter 笔记本服务器。
- en: '**conda environment (Anaconda)**'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**conda 环境（Anaconda）**'
- en: To set environment variables in a conda environment
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在 conda 环境中设置环境变量
- en: Activate the conda environment with conda activate manning.tf2.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 conda activate manning.tf2 激活 conda 环境。
- en: Run conda env config vars set TF_GPU_THREAD_MODE=gpu_private.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 conda env config vars set TF_GPU_THREAD_MODE=gpu_private。
- en: Deactivate and reactivate the environment for the variable to take effect.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停用并重新启用环境以使变量生效。
- en: Start the Jupyter notebook server.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动 Jupyter 笔记本服务器。
- en: It is important to restart the notebook server after changing environment variables
    in your operating system or the conda environment. Refer to the following sidebar
    for more details.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在更改操作系统或 conda 环境中的环境变量后，重启笔记本服务器非常重要。有关更多详细信息，请参阅以下边栏。
- en: 'Important: Restart the notebook server after setting the environment variable'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 重要：设置环境变量后重新启动笔记本服务器。
- en: When you create the notebook server from a shell (e.g., Command prompt on Windows
    or Terminal on Linux), the notebook server is created as a child process of the
    shell. The changes you do to the environment (e.g., adding an environment variable)
    after starting the notebook server will not be reflected in that child process.
    Therefore, you have to kill any existing notebook servers, change the environment
    variables, and then restart the notebook server to see the effects.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从 shell（例如，Windows 上的命令提示符或 Linux 上的终端）创建笔记本服务器时，笔记本服务器将作为 shell 的子进程创建。在启动笔记本服务器后对环境进行的更改（例如，添加环境变量）将不会反映在该子进程中。因此，您必须关闭任何现有的笔记本服务器，更改环境变量，然后重新启动笔记本服务器以查看效果。
- en: 'We introduced three optimizations to our tf.data pipeline:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对我们的 tf.data 流水线进行了三项优化：
- en: Prefetching batches of data
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预取数据批次
- en: Using the parallelized map() function instead of the standard map() function
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用并行化的 map() 函数而不是标准的 map() 函数
- en: Using dedicated kernel launch threads by setting TF_GPU_THREAD_MODE=gpu_ private
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过设置 TF_GPU_THREAD_MODE=gpu_private 使用专用的内核启动线程。
- en: 14.4.2 Mixed precision training
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.4.2 混合精度训练
- en: As explained earlier, mixed precision training refers to employing a combination
    of 16-bit and 32-bit operations in model training. For example, the trainable
    parameters (i.e., variables) are kept as 32-bit floating point values and operations
    (e.g., matrix multiplication) and produce 16-bit floating point outputs.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面所解释的，混合精度训练是指在模型训练中采用 16 位和 32 位操作的组合。例如，可训练参数（即变量）保持为 32 位浮点值，而操作（例如，矩阵乘法）产生
    16 位浮点输出。
- en: 'In Keras, it’s very easy to enable mixed precision training. You simply import
    the mixed_precision namespace from Keras and create a policy that uses mixed precision
    data types by passing mixed_float16. Finally, you set it as a global policy. Then,
    whenever you define a new model, it will use this policy to determine the data
    types for the model:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Keras 中，启用混合精度训练非常简单。您只需从 Keras 中导入 mixed_precision 命名空间，并创建一个使用 mixed precision
    数据类型的策略，通过传递 mixed_float16。最后，将其设置为全局策略。然后，每当您定义一个新模型时，它都会使用此策略来确定模型的数据类型：
- en: '[PRE27]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let’s redefine the CNN model we defined and do a quick check on data types
    to understand how this new policy has changed the model data types:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新定义我们定义的 CNN 模型并快速检查数据类型，以了解此新策略如何更改模型数据类型：
- en: '[PRE28]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now we will pick a layer and check the data types of the inputs/internal parameters
    (e.g., trainable weights) and outputs:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将选择一个层并检查输入/内部参数（例如，可训练权重）和输出的数据类型：
- en: '[PRE29]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This will print
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印。
- en: '[PRE30]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As you can see, the inputs and outputs have the float16 data type, whereas the
    variables have the float32 type. This is a design principle incorporated by mixed
    precision training. The variables are kept as type float32 to make sure the precision
    is preserved as the weights are updated.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，输入和输出的数据类型为 float16，而变量的数据类型为 float32。这是混合精度训练所采用的设计原则。为了确保在更新权重时保留精度，变量保持为
    float32 类型。
- en: Loss scaling to avoid numerical underflow
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 损失缩放以避免数值下溢。
- en: When mixed precision training is used, the loss needs to be treated with care.
    Half precision floating point (float16) values have a smaller dynamic range than
    single precision floating point values (float32). Dynamic range refers to the
    range of values each data type can represent. For example, the maximum value that
    can be represented by float16 is 65,504 (minimum positive 0.000000059604645),
    whereas float32 can go up to 3.4 × 10^38 (minimum positive 1.4012984643 × 10 −
    45). Due to this small dynamic range of the float16 data type, the loss value
    can easily underflow (or overflow), causing numerical issues during back propagation.
    To avoid this, the loss needs to be scaled by an appropriate value, such that
    the gradients stay within the dynamic range of float16 values. Fortunately, Keras
    automatically takes care of this.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 使用混合精度训练时，必须小心处理损失。半精度浮点数（float16）值的动态范围比单精度浮点数（float32）值更小。动态范围是指每种数据类型可以表示的值的范围。例如，float16
    可以表示的最大值为 65,504 （最小正数为 0.000000059604645），而 float32 可以达到 3.4 × 10^38 （最小正数为 1.4012984643
    × 10 − 45）。由于 float16 数据类型的动态范围较小，损失值很容易下溢或溢出，导致反向传播时出现数值问题。为了避免这种情况，损失值需要乘以适当的值进行缩放，以使梯度保持在
    float16 值的动态范围之内。幸运的是，Keras 会自动处理此问题。
- en: When the policy is set to mixed_float16 and you call model.compile(), the optimizer
    is automatically wrapped in a tf.keras.mixed_precision.LossScaleOptimizer() *(*[http://mng.bz/Aydo](http://mng.bz/Aydo)*)*.
    The LossScaleOptimizer() will automatically scale the loss dynamically during
    model optimization to avoid numerical issues. If you did not using Keras to build
    the model, then you have to manually take care of this.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 当策略设置为 mixed_float16 且调用 model.compile() 时，优化器会自动包装为 tf.keras.mixed_precision.LossScaleOptimizer()
    *(*[http://mng.bz/Aydo](http://mng.bz/Aydo)*)*。LossScaleOptimizer() 会在模型优化期间动态缩放损失，以避免数值上的问题。如果您没有使用
    Keras 构建模型，则必须手动处理此问题。
- en: 'With that, rerun the model training:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在重新运行模型训练：
- en: '[PRE31]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: After running the model training with the various optimization steps that we
    introduced, we can compare the results by changing the run on the TensorBoard.
    For example, we show a side-by-side comparison of the elements on the overview
    page with and without optimizations. We can see that the time has reduced significantly
    after introducing the tf.data pipeline-related optimizations (figure 14.11).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在加入我们介绍的各种优化步骤后运行模型训练。通过改变 TensorBoard 上的运行来进行比较。例如，我们在概览页面上显示了使用和不使用优化技巧的元素的并排比较。我们可以看到，在引入
    tf.data pipeline 相关的优化后，时间大大减少（图 14.11）。
- en: '![14-11](../../OEBPS/Images/14-11.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![14-11](../../OEBPS/Images/14-11.png)'
- en: Figure 14.11 Side-by-side comparison of the profiling overview with and without
    data- and model-related optimizations. We can see a significant reduction of the
    input time after introducing the optimizations.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.11 显示了使用和不使用数据和模型相关优化的分析概览的并排比较。引入优化后，输入时间大大减少。
- en: You might be thinking that the device compute time has not gone down much after
    incorporating the 16-bit operations. The largest benefit of using 16-bit operations
    is in the memory consumption of the GPU. The TensorBoard provides a separate view
    called the *memory profile* to analyze the memory profile of the model (figure
    14.12). You can use this view to analyze memory bottlenecks or memory leaks of
    the model.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为，使用 16 位操作后设备的计算时间并没有显著降低。使用 16 位操作最大的优势在于减少了 GPU 的内存消耗。TensorBoard 提供了一个称为
    *memory profile* 的单独视图，用于分析模型的内存占用情况（图 14.12）。您可以使用此视图来分析模型的内存瓶颈或内存泄漏。
- en: '![14-12](../../OEBPS/Images/14-12.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![14-12](../../OEBPS/Images/14-12.png)'
- en: Figure 14.12 Memory profile with and without the optimizations. The difference
    from using 16-bit operations is very clear, as it has reduced the memory consumption
    of the model significantly.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.12 显示了经过优化前后的内存占用情况差异。使用 16 位操作减少了模型的内存消耗。差异非常明显。
- en: You can clearly see how the memory requirements have taken a plunge after incorporating
    mixed precision training. The model’s appetite for memory has gone down by approximately
    76% when mixed precision training is used (from 5.48 GB to 1.25 GB).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 可以清楚地看出，在使用混合精度训练后，内存需求显著下降。当使用混合精度训练时（从 5.48 GB 至 1.25 GB），模型对内存的需求降低了约 76%。
- en: 'The graph specifically refers to two types of memory: *heap* and *stack*. These
    are fundamental memory spaces used by programs to keep track of variables a function
    calls when a program is executed. From these, the heap will help us to learn about
    memory usage patterns or memory-related issues, as that’s where various objects
    and variables created during program execution are kept. For example, if memory
    leaks are present, you will see an increasing amount of memory used by the heap.
    Here, we can see that the memory usage is quite linear and can assume that there
    are no significant memory leaks. You can read more about heaps and stacks in the
    sidebar on the next page.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图表明了两种类型的内存：*堆*和*栈*。这些是程序用于在执行程序时跟踪变量和函数调用的基本内存空间。从这些中，堆将帮助我们了解内存使用模式或与内存相关的问题，因为在程序执行期间创建的各种对象和变量都保存在其中。例如，如果存在内存泄漏，您将看到堆使用的内存量正在增加。在这里，我们可以看到内存使用情况相当线性，并且可以假设没有重大的内存泄漏。您可以在下一页的侧边栏中阅读有关堆和栈的更多信息。
- en: Stack vs. heap
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 堆 vs. 栈
- en: Memory of a running program is kept either in the stack or in the heap. For
    example, function calls are kept in a stack, where the last call is on top of
    the stack and the oldest is at the bottom. When these function calls create objects,
    for example, they are written to the heap (the term “heap” comes from a collection
    of objects that has nothing to do with the heap data structure). You can imagine
    that the heap contains many objects and attributes, without a particular order
    (thus the term “heap”). Items are automatically popped out from the stack as function
    calls end. But it is up to the programmer to free up the heap when objects are
    no longer used, as they persist even after the function call has ended. However,
    in modern programming languages, the garbage collector automatically takes care
    of this. (See [http://mng.bz/VMZ5](http://mng.bz/VMZ5) and [http://mng.bz/ZAER](http://mng.bz/ZAER).)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 程序运行时的内存保持在堆栈或堆中。例如，函数调用保持在堆栈中，其中最后一次调用位于堆栈顶部，最早的调用位于底部。当这些函数调用创建对象时，例如，它们被写入堆中（术语“堆”来自与堆数据结构无关的对象集合）。您可以想象堆中包含许多对象和属性，没有特定顺序（因此术语“堆”）。随着函数调用结束，项目将自动从堆栈中弹出。但是，当对象不再使用时，由程序员释放堆的责任，因为它们在函数调用结束后仍然存在。然而，在现代编程语言中，垃圾收集器会自动处理这个问题。
    （请参阅[http://mng.bz/VMZ5](http://mng.bz/VMZ5)和[http://mng.bz/ZAER](http://mng.bz/ZAER)。）
- en: 'You probably have heard the term “stack overflow,” which happens when recursive
    function calls in the code do not meet termination conditions in a reasonable
    manner, leading the large number of function calls to spill the stack. On a different
    note, we cannot ignore how the name of a popular website among developers came
    to be ([stackoverflow.com](http://stackoverflow.com)). I can’t think of a better
    resource than Stack Overflow itself to explain this: [http://mng.bz/R4ZZ](http://mng.bz/R4ZZ).'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能听说过“堆栈溢出”的术语，当代码中的递归函数调用没有合理满足终止条件时，大量的函数调用会溢出堆栈。另外，我们不能忽视一个受开发者欢迎的网站的名称是如何产生的（[stackoverflow.com](http://stackoverflow.com)）。我认为没有比
    Stack Overflow 本身更好的资源来解释这个问题了：[http://mng.bz/R4ZZ](http://mng.bz/R4ZZ)。
- en: We also can see fine-grained details about which operations used how much memory.
    For example, we know that the main bottleneck of a CNN is the first Dense layer
    after a series of convolutional/pooling layers. Table 14.1 confirms that. That
    is, it shows that the Dense layer, with a shape of [115200, 512] (i.e., first
    Dense layer), uses the most memory.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到有关哪些操作使用了多少内存的细节。例如，我们知道 CNN 的主要瓶颈是在一系列卷积/池化层之后的第一个 Dense 层。表 14.1 证实了这一点。也就是说，它显示了
    Dense 层，其形状为 [115200, 512]（即第一个 Dense 层），使用了最多的内存。
- en: Table 14.1 Memory breakdown table. The table shows the memory usage of various
    TensorFlow operations along with their data shape.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 表 14.1 内存分解表。该表显示了各种 TensorFlow 操作的内存使用情况以及它们的数据形状。
- en: '| **Op name** | **Allocation size (GiBs)** | **Requested size (GiBs)** | **Occurrences**
    | **Region type** | **Data type** | **Shape** |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| **操作名称** | **分配大小（GiBs）** | **请求大小（GiBs）** | **发生次数** | **区域类型** | **数据类型**
    | **形状** |'
- en: '| preallocated/unknown | 0.743 | 0.743 | 1 | persist/dynamic | INVALID | unknown
    |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 预分配/未知 | 0.743 | 0.743 | 1 | 持久/动态 | 无效 | 未知 |'
- en: '| gradient_tape/sequential/dense/MatMul/Cast/Cast | 0.220 | 0.220 | 1 | output
    | float | [115200,512] |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| gradient_tape/sequential/dense/MatMul/Cast/Cast | 0.220 | 0.220 | 1 | 输出
    | 浮点 | [115200,512] |'
- en: '| gradient_tape/sequential/batch_normalisation_3/FusedBatchNormGradV3 | 0.051
    | 0.029 | 1 | temp | half | [32,512,31,31] |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| gradient_tape/sequential/batch_normalisation_3/FusedBatchNormGradV3 | 0.051
    | 0.029 | 1 | temp | half | [32,512,31,31] |'
- en: '| gradient_tape/sequential/average_pooling2d/AvgPool/AvgPoolGrad | 0.036 |
    0.029 | 1 | output | half | [32,31,31,512] |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| gradient_tape/sequential/average_pooling2d/AvgPool/AvgPoolGrad | 0.036 |
    0.029 | 1 | output | half | [32,31,31,512] |'
- en: '| gradient_tape/sequential/batch_normalisation_3/FusedBatchNormGradV3 | 0.029
    | 0.029 | 1 | output | half | [32,31,31,512] |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| gradient_tape/sequential/batch_normalisation_3/FusedBatchNormGradV3 | 0.029
    | 0.029 | 1 | output | half | [32,31,31,512] |'
- en: '| gradient_tape/sequential/batch_normalisation_3/FusedBatchNormGradV3 | 0.029
    | 0.029 | 2 | temp | half | [32,512,31,31] |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| gradient_tape/sequential/batch_normalisation_3/FusedBatchNormGradV3 | 0.029
    | 0.029 | 2 | temp | half | [32,512,31,31] |'
- en: Finally, you have the *trace viewer*. This gives a longitudinal view of how
    various operations were executed on the CPU or GPU and how much time it took.
    This gives a very detailed view of when and how various operations were scheduled
    and executed.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以查看*trace viewer*。这个工具提供了各种操作在 CPU 或 GPU 上是如何执行的纵向视图以及所花费的时间。这提供了关于各种操作何时以及如何被安排和执行的非常详细的视图。
- en: On your left, you can see what was executed on your CPU versus on the GPU. For
    example, you can see that most model-related operations (e.g., convolution) were
    executed on the GPU, whereas tf.data operations (e.g., decoding images) were executed
    on the GPU. You can also note that the trace viewer shows GPU private threads
    separately.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，您可以看到在 CPU 上执行了什么操作，而在 GPU 上执行了什么操作。例如，您可以看到大多数与模型相关的操作（例如，卷积）在 GPU 上执行，而
    tf.data 操作（例如，解码图像）在 GPU 上执行。您还可以注意到，跟踪查看器单独显示了 GPU 私有线程。
- en: TensorBoard has far more uses than what we have listed here. To know more about
    these, please refer the following sidebar.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 的用途远不止我们在这里列出的。要了解更多，请参考以下侧边栏。
- en: Other views on the TensorBoard
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 的其他视图
- en: 'There are many different views available for the TensorBoard. We have discussed
    the most used view, and I will leave it to the readers to explore the views we
    haven’t discussed. However, out of the ones left out, there are views that are
    worth noting:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 有许多不同的视图可用。我们已经讨论了最常用的视图，我将让读者探索我们没有讨论的视图。然而，剩下的视图中有一些值得注意的视图：
- en: '**Debugger v2**'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '**Debugger v2**'
- en: Debugger v2 is a tool introduced since TensorFlow 2.3\. The primary purpose
    of it is to debug numerical issues in models. For example, NaN values creeping
    in during model training are a very common issue for deep networks. Debugger v2
    will provide a comprehensive step-by-step breakdown of various elements in your
    model (e.g. ,input and output tensors) and which ones produced numerical errors.
    For more information, visit [https://www.tensorflow.org/tensorboard/debugger_v2](https://www.tensorflow.org/tensorboard/debugger_v2).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Debugger v2 是 TensorFlow 2.3 以后引入的工具。它的主要目的是调试模型中的数值问题。例如，在模型训练过程中出现 NaN 值是深度网络的一个非常常见的问题。Debugger
    v2 将提供模型中各种元素（例如，输入和输出张量）的全面逐步分解，以及哪些元素产生了数值错误。有关更多信息，请访问[https://www.tensorflow.org/tensorboard/debugger_v2](https://www.tensorflow.org/tensorboard/debugger_v2)。
- en: '**HParams**'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '**HParams**'
- en: Hparams is a view that helps hyperparameter optimization and allows you to dive
    into individual runs to understand which parameters help improve model performance.
    The tensorboard.plugins.hparams.api provides various useful functions and callbacks
    to hyperparameter-optimize Keras models easily. Then, the trials that happened
    during the hyperparameter optimization can be viewed in the HParams view. For
    more information, visit [http://mng.bz/2nKg](http://mng.bz/2nKg).
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Hparams 是一个视图，帮助超参数优化，并允许您深入研究个别运行，以了解哪些参数有助于改善模型性能。tensorboard.plugins.hparams.api
    提供了各种有用的功能和回调，以轻松优化 Keras 模型的超参数。然后，可以在 HParams 视图中查看超参数优化期间发生的试验。有关更多信息，请访问[http://mng.bz/2nKg](http://mng.bz/2nKg)。
- en: '**What-If Tool**'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '**What-If 工具**'
- en: What-If is a tool that can give valuable insights into black-box models, helping
    with the interpretability of such models. For example, you can run a model inference
    with some data. Then you can modify the data and see how the output changes through
    the What-If tool. Furthermore, it provides various tools for analyzing the performance
    and fairness of models. For more information, visit [http://mng.bz/AyjW](http://mng.bz/AyjW).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: What-If 是一个工具，可以为黑盒模型提供有价值的见解，有助于解释这些模型。例如，您可以使用一些数据运行模型推理。然后，您可以修改数据，并通过 What-If
    工具查看输出如何变化。此外，它提供了各种工具，用于分析模型的性能和公平性。有关更多信息，请访问[http://mng.bz/AyjW](http://mng.bz/AyjW)。
- en: In the next section, we will discuss how we can visualize and interact with
    word vectors on the TensorBoard.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何在 TensorBoard 上可视化和与词向量交互。
- en: Exercise 4
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 4
- en: 'You have a model that you have already profiled. You have seen the following
    overview of times:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经进行了模型性能分析。你已经看到了以下时间概述：
- en: 'Input time: 1.5 ms'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入时间：1.5 毫秒
- en: 'Device compute time: 6.7 ms'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备计算时间：6.7 毫秒
- en: 'Kernel launch time: 9.8 ms'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核启动时间：9.8 毫秒
- en: 'Output time: 10.1 ms'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出时间：10.1 毫秒
- en: 'Host compute time: 21.2 ms'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机计算时间：21.2 毫秒
- en: For this scenario, assume a time recorded more than 5 ms is an opportunity for
    improvement. List three code/environment change recommendations to improve the
    model performance.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种情况，假设超过 5 毫秒的时间是有改进空间的机会。列出三个代码/环境更改建议以提高模型性能。
- en: 14.5 Visualizing word vectors with the TensorBoard
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.5 使用 TensorBoard 可视化词向量
- en: You are working as an NLP engineer for a movie recommendation company and have
    been tasked with developing a movie recommendation model that can be trained on
    small devices. To reduce the training overhead, one of the techniques used is
    using pretrained word vectors and freezing them (i.e., not training them). You
    think GloVe word vectors will give a good initial point and plan to use them.
    But before that, you have to make sure the vectors capture the semantics/relationships
    in the movie-specific terminology/words adequately. For that, you need to visualize
    word vectors for these words on TensorBoard and analyze whether GloVe vectors
    represent sensible relationships between words.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在一家电影推荐公司担任 NLP 工程师，负责开发一种可以在小设备上训练的电影推荐模型。为了减少训练开销，使用了一种技术：使用预训练的词向量并将其冻结（即不进行训练）。你认为
    GloVe 词向量将是一个很好的起点，并计划使用它们。但在此之前，你必须确保这些向量充分捕捉到电影特定术语/单词中的语义/关系。为此，你需要在 TensorBoard
    上可视化这些单词的词向量，并分析 GloVe 向量是否表示了单词之间的合理关系。
- en: 'The first thing we need to do is download the GloVe word vectors. You have
    been provided the code to download GloVe vectors in the notebook, and it is very
    similar to how we have downloaded datasets in the past. Therefore, we will not
    discuss the download in detail. The GloVe word vectors are obtained from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/).
    There are several different versions of GloVe vectors; they have different dimensionalities
    and vocabulary sizes:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是下载 GloVe 词向量。你已经在笔记本中提供了下载 GloVe 向量的代码，它与我们过去下载数据集的方式非常相似。因此，我们不会详细讨论下载过程。GloVe
    词向量可从[https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)获取。GloVe
    向量有几个不同的版本；它们具有不同的维度和词汇量：
- en: Trained on Wikipedia 2014 + Gigaword 5 data sets with 6 billion tokens; 400,000
    vocabulary; uncased tokens; and 50D, 100D, 200D, and 300D vectors
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Wikipedia 2014 + Gigaword 5 数据集进行训练，共有 60 亿个标记；词汇量为 400,000 个；大小写不敏感的标记；词向量维度为
    50D、100D、200D 和 300D
- en: Trained on the Common Crawl data set with 42 billion tokens, 1,900,000 vocabulary,
    uncased tokens, and 300D vectors
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Common Crawl 数据集训练，共有 420 亿个标记；词汇量为 1,900,000 个；大小写不敏感的标记；词向量维度为 300D
- en: Trained on the Common Crawl data set with 840 billion tokens, 2,200,000 vocabulary,
    cased tokens, and 300D vectors
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Common Crawl 数据集训练，共有 8400 亿个标记；词汇量为 2,200,000 个；大小写敏感的标记；词向量维度为 300D
- en: Trained on the Twitter data set with 2 billion tweets; 27 billion tokens; 1,200,000
    vocabulary; uncased tokens; and 25D, 50D, 100D, and 200D vectors
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Twitter 数据集进行训练，共有 20 亿个推文；总标记数为 270 亿个；词汇量为 1,200,000 个；大小写不敏感的标记；词向量维度为
    25D、50D、100D 和 200D
- en: GloVe word vectors
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: GloVe 词向量
- en: GloVe (standing for *Glo*bal *Ve*ctors) is a word vector algorithm that generates
    word vectors by looking at both global and local statistics of a corpus. For example,
    word vector algorithms such as Skip-gram or Continuous Bag-of-Words rely only
    on the local context of a given word to learn the word vector for that word. The
    lack of attention to global information about how the word is used in a larger
    corpus leads to suboptimal word vectors. GloVe incorporates the global statistics
    by computing a large co-occurrence matrix to indicate the co-occurrence frequency
    (i.e., if a given word appears in the context of another word) between all words.
    For more information about GloVe vectors, see [http://mng.bz/1oGX](http://mng.bz/1oGX).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: GloVe（代表 *Glo*bal *Ve*ctors）是一种单词向量算法，通过查看语料库的全局和局部统计信息生成单词向量。例如，像 Skip-gram
    或 Continuous Bag-of-Words 这样的单词向量算法仅依赖于给定单词的局部上下文来学习该单词的单词向量。对单词在较大语料库中的使用情况缺乏全局信息的关注会导致次优的单词向量。GloVe
    通过计算一个大型共现矩阵来表示所有单词之间的共现频率（即，如果一个给定单词出现在另一个单词的上下文中）来融合全局统计信息。有关 GloVe 向量的更多信息，请参见
    [http://mng.bz/1oGX](http://mng.bz/1oGX)。
- en: 'We will use the 50-dimensional word vectors from the first category (which
    is the smallest). A 50-dimensional word vector will have 50 values in each word
    vector designated for each token in the corpus. Once the data is extracted by
    running the code in the notebook, you will see a file with the name glove.6B.50d.txt
    in the data folder. Let’s load that as a pandas DataFrame using the pd.read_csv()
    function:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用第一类别（最小的）中的 50 维词向量。一个 50 维词向量将对语料库中的每个标记有 50 个值的向量。一旦在笔记本中运行代码提取数据，你将看到一个名为
    glove.6B.50d.txt 的文件出现在数据文件夹中。让我们使用 pd.read_csv() 函数将其加载为 pandas DataFrame：
- en: '[PRE32]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This will return table 14.2\. Now we will download the IMDB movie reviews data
    set ([https://ai.stanford.edu/~amaas/data/sentiment/](https://ai.stanford.edu/~amaas/data/sentiment/)).
    Since this data set is readily available as a TensorFlow data set (through the
    tensorflow_datasets library), we can use that:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回表格 14.2\. 现在我们将下载 IMDB 电影评论数据集（[https://ai.stanford.edu/~amaas/data/sentiment/](https://ai.stanford.edu/~amaas/data/sentiment/)）。由于这个数据集可以轻松地作为
    TensorFlow 数据集（通过 tensorflow_datasets 库）获得，我们可以使用它：
- en: '[PRE33]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Once we download the data, we will create a corpus that contains all the reviews
    (text) in the training set as a list of strings:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们下载了数据，我们将创建一个包含训练集中所有评论（文本）的语料库，以字符串列表的形式：
- en: '[PRE34]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we want to get the most common 5,000 words in this corpus so that we
    can compare the GloVe vectors of these common words to see if they contain sensible
    relationships. To get the most common words, we will use the built-in Counter
    object. The Counter object counts the frequencies of the words in the vocabulary:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想要获取此语料库中最常见的 5,000 个单词，以便我们可以比较这些常见单词的 GloVe 向量，以查看它们是否包含合理的关系。为了获得最常见的单词，我们将使用内置的
    Counter 对象。Counter 对象计算词汇表中单词的频率：
- en: '[PRE35]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This will print
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印
- en: '[PRE36]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![14-12_table_14-2](../../OEBPS/Images/14-12_table_14-2.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![14-12_table_14-2](../../OEBPS/Images/14-12_table_14-2.png)'
- en: 'With both the GloVe vectors and the corpus containing the most common 5,000
    words in the IMDB movie reviews data set, we find the common tokens between the
    two sets for visualization:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 使用了 IMDB 电影评论数据集中最常见的 5,000 个单词的语料库以及 GloVe 向量，我们找到了这两个集合之间的常见标记以进行可视化：
- en: '[PRE37]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This will give a list of roughly 3,600 tokens that appear in both sets.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出大约 3,600 个在两个集合中都出现的标记列表。
- en: Next, we can visualize these vectors on the TensorBoard. To reiterate, word
    vectors are numerical representations of tokens in a given corpus. The specialty
    of these word vectors (as opposed to one-hot encoding words) is that they capture
    the semantics of words. For example, if you compute the distance between the word
    vector of “cat” and “dog,” they will be a lot closer than “cat” and “volcano.”
    But when analyzing relationships between a larger set of tokens, we prefer a visual
    aid. It would be great if there was a way to visualize these word vectors on a
    2D or 3D plane, which is much easier to visualize and understand. There are dimensionality-reduction
    algorithms such as Principal Component Analysis (PCA) ([http://mng.bz/PnZw](http://mng.bz/PnZw))
    or t-SNE ([https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/))
    that can achieve this. The specific algorithms used for this are out of scope
    for this book. The good news is that with TensorBoard, you can do this. TensorBoard
    can map these high-dimensional vectors to a smaller projection space. To do that,
    we have to first load these weights as a TensorFlow variable and then save it
    to the disk as a TensorFlow checkpoint. Then we also save the words or tokens
    as a new file, with one token per line, corresponding to each vector in the set
    of word vectors we just saved. With that, you can visualize the word vectors on
    the TensorBoard (see the next listing).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以在TensorBoard上可视化这些向量。再次强调，单词向量是给定语料库中标记的数值表示。这些单词向量的特点（与独热编码单词相反）是它们捕捉了单词的语义。例如，如果计算“cat”和“dog”的单词向量之间的距离，它们会比“cat”和“volcano”更接近。但是在分析更大的一组标记之间的关系时，我们喜欢有一个可视化辅助工具。如果有一种方法可以在二维或三维平面上可视化这些单词向量，那将更容易可视化和理解。有降维算法，如主成分分析（PCA）([http://mng.bz/PnZw](http://mng.bz/PnZw))或t-SNE([https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/))可以实现这一点。本书不涉及这些特定算法的使用。好消息是，使用TensorBoard，你可以做到这一点。TensorBoard可以将这些高维向量映射到一个更小的投影空间。要做到这一点，我们首先要将这些权重加载为一个TensorFlow变量，然后将其保存为TensorFlow检查点。然后我们还要将单词或标记保存为一个新文件，每行一个标记，对应于我们刚刚保存的一组单词向量中的每个向量。有了这个，你就可以在TensorBoard上可视化单词向量（见下一个列表）。
- en: Listing 14.5 Visualizing word vectors on TensorBoard
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.5 在TensorBoard上可视化单词向量
- en: '[PRE38]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: ❶ Create a tf.Variable with the embeddings we captured.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 用我们捕获的嵌入创建一个tf.Variable。
- en: ❷ Save the embeddings as a TensorFlow checkpoint.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: ❷将嵌入保存为TensorFlow检查点。
- en: ❸ Save the metadata (a TSV file), where each word corresponding to the embeddings
    is appended as a new line.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 保存元数据（一个TSV文件），其中每个与嵌入对应的单词被附加为新行。
- en: ❹ Create a configuration specific to the projector and embeddings (details are
    discussed in the text).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: ❹创建一个特定于投影仪和嵌入的配置（有关详细信息，请参阅文本）。
- en: ❺ Set the metadata path so that TensorBoard can incorporate that in the visualization.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: ❺设置元数据路径，以便TensorBoard可以在可视化中包含它。
- en: 'To visualize the word vectors from the saved TensorFlow checkpoint and the
    metadata (i.e., tokens corresponding to the word vectors saved), we use the tensorboard.plugins
    .projector object. We then define a ProjectorConfig object and an embedding config.
    We will keep them with the default configurations, which suit our problem. When
    config.embeddings.add() is invoked, it will generate an embedding config (of type
    EmbeddingInfo object) with default configuration. The ProjectorConfig contains
    information such as the following:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 要可视化来自保存的TensorFlow检查点和元数据（即，保存的单词向量对应的标记），我们使用tensorboard.plugins.projector对象。然后我们定义一个ProjectorConfig对象和一个嵌入配置。我们将保留它们的默认配置，这适合我们的问题。当调用config.embeddings.add()时，它将生成一个使用默认配置的嵌入配置（类型为EmbeddingInfo对象）。ProjectorConfig包含诸如以下信息：
- en: model_checkpoint_directory—The directory to which the checkpoint containing
    embeddings was saved
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: model_checkpoint_directory —— 包含嵌入的检查点的目录
- en: The EmbeddingInfo contains
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: EmbeddingInfo包含
- en: tensor_name—If a special tensor name was used for embeddings
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tensor_name —— 如果嵌入使用了特殊的张量名称
- en: metadata_path—The path to a TSV file that contains the labels of the embeddings
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: metadata_path —— 包含嵌入标签的TSV文件的路径
- en: To see a full list of available configurations, refer to the file at [http://mng.bz/J2Zo](http://mng.bz/J2Zo).
    In its current state, the projector’s config does not support a lot of customizations.
    For this reason, we will keep them as default. One config we will set in the EmbeddingInfo
    config is the metadata_path. We will set the metadata_path to the file containing
    the tokens and finally pass it to the projecter.visualize_embeddings() function.
    We give it a logging directory, and the projector will automatically detect the
    TensorFlow checkpoint and load it.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看可用配置的完整列表，请参考 [http://mng.bz/J2Zo](http://mng.bz/J2Zo) 上的文件。在其当前状态下，投影仪的配置不支持太多的定制。因此，我们将保持默认设置。我们将在
    EmbeddingInfo 配置中设置一个配置，即 metadata_path。我们将 metadata_path 设置为包含令牌的文件，最后将其传递给 projecter.visualize_embeddings()
    函数。我们给它一个日志目录，投影仪将自动检测 TensorFlow 检查点并加载它。
- en: 'We’re all good to go. On your notebook, execute the following line to bring
    up the TensorBoard:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一切都准备就绪。在您的笔记本上，执行以下行以打开 TensorBoard：
- en: '[PRE39]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: To visualize word vectors, they need to be in the exact directory the --logdir
    is pointing to (i.e., not in a nested folder). Therefore, we need a new TensorBoard
    server. This line will open a new TensorBoard server on port 6007\. Figure 14.13
    depicts what is displayed in the TensorBoard.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 要可视化词向量，它们需要在 --logdir 指向的确切目录中（即不在嵌套文件夹中）。因此，我们需要一个新的 TensorBoard 服务器。这行代码将在端口
    6007 上打开一个新的 TensorBoard 服务器。图 14.13 描述了在 TensorBoard 中显示的内容。
- en: Interesting facts about the %tensorboard magic command
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 %tensorboard 魔术命令的有趣事实
- en: The %tensorboard magic command is smart enough to know when to open a new TensorBoard
    server and when not to. If you are executing the same command over and over again,
    it will reuse the existing TensorBoard. However, if you execute a command with
    a different --logdir or a --port, it will open a new TensorBoard server.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '%tensorboard 魔术命令足够智能，能够知道何时打开新的 TensorBoard 服务器以及何时不需要。如果您一遍又一遍地执行相同的命令，它将重用现有的
    TensorBoard。但是，如果您执行带有不同 --logdir 或 --port 的命令，它将打开一个新的 TensorBoard 服务器。'
- en: '![14-13](../../OEBPS/Images/14-13.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![14-13](../../OEBPS/Images/14-13.png)'
- en: Figure 14.13 The word vector view on the TensorBoard. You have the ability to
    pick which dimensionality-reduction algorithm (along with parameters) to use in
    order to get a 2D or 3D representation of the word vectors. Hovering over the
    dots in the visualization will show the word represented by the dot.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.13 在 TensorBoard 上的词向量视图。您可以选择使用哪种降维算法（以及参数）来获取词向量的二维或三维表示。在可视化中悬停在点上将显示由该点表示的单词。
- en: You can hover over the dots shown in the visualization, and they will show which
    word in the corpus they represent. You have the ability to visualize the word
    vectors in a 2D or a 3D space by toggling the dimensionality controller. You might
    be wondering about the word vectors that we chose. They initially had 50 dimensions—how
    can we visualize such high-dimensional data in a 2D or 3D space? There’s a suite
    of dimensionality-reduction algorithms that can do this for us. A few examples
    are t-SNE ([http://mng.bz/woxO](http://mng.bz/woxO)), PCA (principal component
    analysis; [http://mng.bz/ZAmZ](http://mng.bz/ZAmZ)), and UMAP (Uniform Manifold
    Approximation and Projection; [https://arxiv.org/pdf/1802.03426.pdf](https://arxiv.org/pdf/1802.03426.pdf)).
    Refer to the accompanied links to learn more about these algorithms.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在可视化中悬停在显示的点上，它们将显示它们代表的语料库中的哪个单词。您可以通过切换维度控制器来可视化二维或三维空间中的词向量。您可能想知道我们选择的词向量。它们最初有
    50 个维度 —— 我们如何在二维或三维空间中可视化这样高维度的数据呢？有一套降维算法可以为我们做到这一点。一些示例是 t-SNE ([http://mng.bz/woxO](http://mng.bz/woxO))，PCA（主成分分析;
    [http://mng.bz/ZAmZ](http://mng.bz/ZAmZ))，以及 UMAP（Uniform Manifold Approximation
    and Projection; [https://arxiv.org/pdf/1802.03426.pdf](https://arxiv.org/pdf/1802.03426.pdf))。参考附带的链接以了解更多关于这些算法的信息。
- en: You can do more than a plain visualization of word vectors on the TensorBoard.
    You can do more detailed analysis by highlighting specific words in the visualization.
    For that, you can employ regular expressions. For example, the visualization shown
    in figure 14.14 is generated using the regular expression (?:fred|larry|mrs\.|mr\
    .|michelle|sea|denzel|beach|comedy|theater|idiotic|sadistic|marvelous| loving|gorg|bus|truck|lugosi).
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 TensorBoard 上做的不仅仅是词向量的简单可视化。您可以通过突出显示可视化中的特定单词进行更详细的分析。为此，您可以使用正则表达式。例如，图
    14.14 中显示的可视化是使用正则表达式(?:fred|larry|mrs\.|mr\.|michelle|sea|denzel|beach|comedy|theater|idiotic|sadistic|marvelous|loving|gorg|bus|truck|lugosi)生成的。
- en: '![14-14](../../OEBPS/Images/14-14.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![14-14](../../OEBPS/Images/14-14.png)'
- en: Figure 14.14 Searching words in the visualizations. You can use regular expressions
    to search combinations of words.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.14 在可视化中搜索单词。您可以使用正则表达式来搜索单词的组合。
- en: This concludes our discussion about the TensorBoard. In the next chapter, we
    will discuss how TensorFlow can help us to create machine learning pipelines and
    deploy models with ease.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们关于 TensorBoard 的讨论。在下一章中，我们将讨论 TensorFlow 如何帮助我们轻松创建机器学习流水线并部署模型。
- en: Exercise 5
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 5
- en: Instead of just the word, say you want to include a unique ID when displaying
    word vectors in the TensorBoard. For example, instead of the word “loving” you
    want to see “loving; 218,” where 218 is the unique ID given to the word. To do
    this, you need to change what’s written to the metadata.tsv file. Instead of just
    the word, write an incrementing ID separated by a semicolon on each line. For
    example, if the words are [“a”, “b”, “c”], in that order, then the new lines should
    be [“a;1”, “b;2”, “c;3”]. How would you make changes?
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在 TensorBoard 中显示单词向量时包含唯一标识符，而不仅仅是单词本身，例如，您想要看到“loving; 218”而不是“loving”，其中
    218 是给予该单词的唯一标识符。为此，您需要更改写入 metadata.tsv 文件的内容。不仅仅是单词，每行上都写一个用分号分隔的递增 ID。例如，如果单词是[“a”,
    “b”, “c”]，那么新行应该是[“a;1”, “b;2”, “c;3”]。您如何进行更改？
- en: Summary
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: TensorBoard is a great visualization aid for visualizing data (e.g., images)
    and tracking model performance in real time.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard 是一个用于可视化数据（例如图像）和实时跟踪模型性能的优秀工具。
- en: When building models with Keras, you can use the convenient tf.keras.callbacks.TensorBoard()
    callback to log model performance, layer activation histograms, and much more.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用 Keras 构建模型时，您可以使用方便的 tf.keras.callbacks.TensorBoard() 回调来记录模型性能、层激活直方图等。
- en: If you have custom metrics that you want to log to the TensorBoard, you can
    use the corresponding data type in the tf.summary namespace (e.g., use tf.summary.scalar()
    if you want to log a scalar value, like model accuracy over time).
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您有自定义指标想要记录到 TensorBoard 中，您可以在 tf.summary 命名空间中使用相应的数据类型（例如，如果您想要记录随时间变化的模型精度等，可以使用
    tf.summary.scalar()）。
- en: Each session where you log information to the TensorBoard is called a run. You
    should incorporate a readable and robust naming convention for the different runs.
    A good naming convention should capture major changes you did and the date/time
    the run was executed.
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次将信息记录到 TensorBoard 中的会话称为一次运行。您应该为不同的运行制定一个可读且健壮的命名约定。一个好的命名约定应该捕捉您所做的主要更改以及运行执行的日期/时间。
- en: TensorBoard Profile provides a diverse collection of profiling (using libcupti
    library by NVIDIA) results such as time taken by various subtasks during model
    training (e.g., device compute time, host compute time, input time, etc.), memory
    used by the model, and a sequential view of when and how various operations are
    carried out.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard Profile 提供了各种各样的性能分析结果（使用 NVIDIA 的 libcupti 库），例如模型训练过程中各个子任务所花费的时间（例如，设备计算时间、主机计算时间、输入时间等）、模型使用的内存以及各种操作是如何进行的顺序视图。
- en: TensorBoard is a great tool for visualizing high-dimensional data like images
    and word vectors.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard 是一个用于可视化高维数据（如图像和单词向量）的强大工具。
- en: Answers to exercises
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习答案
- en: '**Exercise 1**'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 1**'
- en: '[PRE40]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '**Exercise 2**'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 2**'
- en: '[PRE41]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '**Exercise 3**'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 3**'
- en: '[PRE42]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '**Exercise 4**'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 4**'
- en: There are a lot of computations happening on the host. This could be because
    the device (e.g., GPU) does not have enough memory. Using mixed precision training
    will help to alleviate the issue. Furthermore, there might be too much non-TensorFlow
    code that cannot run on the GPU. For that, using more TensorFlow operations and
    converting such code to TensorFlow will gain speed-ups.
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主机上正在进行大量的计算。这可能是因为设备（例如，GPU）的内存不足。使用混合精度训练将有助于缓解这个问题。此外，可能有太多无法在 GPU 上运行的非
    TensorFlow 代码。为此，使用更多的 TensorFlow 操作并将这样的代码转换为 TensorFlow 将获得加速。
- en: The Kernel launch time has increased. This could be because the workload is
    heavily CPU-bound. In this case, we can incorporate the TF_GPU_THREAD_MODE environment
    variable and set it to gpu_private. This will make sure there will be several
    dedicated threads to launch kernels for the GPU.
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内核启动时间增加了。这可能是因为工作负载严重受限于 CPU。在这种情况下，我们可以合并 TF_GPU_THREAD_MODE 环境变量，并将其设置为 gpu_private。这将确保有几个专用线程用于为
    GPU 启动内核。
- en: Output time is significantly high. This could be because of writing too many
    outputs too frequently to the disk. To solve that, we can incorporate keeping
    data in memory for longer and flushing it to the disk only a few times.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出时间显著偏高。这可能是因为频繁向磁盘写入过多输出。为解决此问题，我们可以考虑将数据在内存中保存更长时间，并仅在少数时刻将其刷新到磁盘上。
- en: '**Exercise 5**'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习5**'
- en: '[PRE43]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
