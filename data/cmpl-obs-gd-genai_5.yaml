- en: 5 Feeding Data to Your Generative AI Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 将数据提供给您的生成式 AI 模型
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Building and then querying an index based on a local data archive.
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于本地数据存档构建索引，然后进行查询。
- en: Uploading a PDF document to the ChatPDF service to query it the way you’d use
    ChatGPT.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 PDF 文档上传到 ChatPDF 服务以像使用 ChatGPT 一样查询它。
- en: Scripting the PDF-querying process using the ChatPDF API.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 ChatPDF API 对 PDF 查询过程进行脚本编制。
- en: Using the AutoGPT tool to give a GPT-fueled agent access to the full and open
    internet.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AutoGPT 工具让 GPT 引擎代理访问完整和开放的互联网。
- en: There’s only so long you’ll keep at it before the novelty of torturing secrets
    out of an always friendly (and occasionally outrageous) AI gets a bit stale. After
    all, how many versions of the perfect resume do you actually need? And do you
    really *want* to hear how John Lennon would have sounded singing Shakespearian
    sonnets?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在你不断试图从一直友好（偶尔令人震惊）的 AI 中挖掘秘密的新鲜感消失之前，只能持续那么长时间。毕竟，你实际上需要多少个完美简历的版本呢？你真的*想*听到约翰·列侬唱着莎士比亚十四行诗会是什么样子吗？
- en: 'The real power of an LLM is in how quickly it’s able to process - and "understand"
    - insane volumes of data. It would be a shame to have to limit its scope to just
    the stuff it was shown during its training period. And in any case, you stand
    to gain more from the way that your AI processes *your* data than someone else’s.
    Just imagine how much value can be unleashed by identifying:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 LLM 的真正力量在于它能够多快地处理 - 并且“理解” - 庞大的数据量。将其范围限制在训练期间显示的内容上将是一种遗憾。而且无论如何，你从你的
    AI 处理*你的*数据的方式中所获得的价值要比从别人那里获得的更多。想象一下通过识别以下内容可以释放多少价值：
- en: Patterns and trends in health records
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康记录中的模式和趋势
- en: Threats and attacks in digital network access logs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字网络访问日志中的威胁和攻击
- en: Potential financial opportunities or risks in banking records
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 银行记录中的潜在金融机会或风险
- en: Opportunities for introducing efficiencies in supply chain, infrastructure,
    and governance operations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在供应链、基础设施和治理运营中引入效率的机会
- en: Insurance, tax, or program fraud
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保险、税收或程序欺诈
- en: Government corruption (and opportunities for operational improvements)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 政府腐败（以及运营改进的机会）
- en: So is it possible to expose GPT to stuff on your computer or, even better, to
    stuff that’s out there on the live internet? The short answer is "yes." And that’ll
    have to do for the long answer, too. In fact, as of a few hours before I sat down
    to write this chapter at any rate, there are a handful of ways to get this done.
    In this chapter I’ll show you how to send LLMs deep into your data-rich documents,
    and out across the live internet.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，将 GPT 暴露给计算机上的东西，甚至更好的是暴露给互联网上的东西，是可能的吗？简短的答案是“是的”。对于长答案，也是如此。事实上，至少在我坐下来写这一章的几个小时前，有几种方法可以完成这项工作。在本章中，我将向您展示如何将
    LLMs 深入到您的数据丰富的文档中，并将其传播到互联网上。
- en: 5.1 Indexing local data archives
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 索引本地数据存档
- en: The full power of even currently available AI systems can hardly be imagined.
    Not a single day has passed over the last year or so when I didn’t hear about
    the discovery of some new and madly creative way of using the tools. But from
    my perspective - at this point in history at least - the greatest potential lies
    in a generative AI’s ability to instantly read, digest, organize, and then explain
    vast volumes of raw data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是当前可用的 AI 系统的全部力量也很难想象。过去一年左右的时间里，我每天都听说有一些新的、疯狂创造性的使用方式的发现。但从我的角度来看 - 至少在历史的这一时刻
    - 生成式 AI 的最大潜力在于其即时阅读、消化、组织然后解释大量原始数据的能力。
- en: Large organizations spend millions of dollars building and maintaining systems
    for managing, parsing, and monitoring the terabytes of data their operations regularly
    spit out at them. Database managers and security analysts don’t come cheap. But
    what choice do those organizations have? Why generate all that data in the first
    place if there’s no way to properly understand it?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大型组织花费数百万美元建立和维护用于管理、解析和监视其运营定期产生的数百万字节数据的系统。数据库管理员和安全分析师不是便宜货。但是这些组织有什么选择呢？如果没有正确理解数据的方法，为什么一开始要生成所有这些数据呢？
- en: But what about those of us who work for organizations that aren’t named "Google",
    "Amazon", or "Government of…​"? Our devices and digital activities are probably
    producing their own data that would love to be read. Well, we may not be able
    to afford our own teams of DB managers, security analysts, or data analytics,
    but we do have plenty of data. And the age of LLMs is officially upon us.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们这些为不是“谷歌”、“亚马逊”或“xxxx政府”命名的组织工作的人怎么办呢？我们的设备和数字活动可能产生它们自己的数据，这些数据可能会被读取。嗯，我们可能负担不起我们自己的DB管理员、安全分析师或数据分析师团队，但我们确实拥有大量的数据。LLMs时代官方已经到来。
- en: The trick is to to connect our data to a friendly AI. How will we do that? That
    would be the [LlamaIndex project](latest.html) (which we’ve already seen back
    in chapter 3). LlamaIndex maintains the open source GPTSimpleVectorIndex module
    along with a full ecosystem of resources for exposing your own data to GPT.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代的关键是将我们的数据连接到一个友好的AI。我们将如何做到这一点呢？这将是[LlamaIndex项目](latest.html)（我们在第3章已经见过了）。LlamaIndex维护了开源的GPTSimpleVectorIndex模块以及一整套用于暴露您自己的数据给GPT的资源。
- en: You can read the full documentation guide on LlamaIndex’s [Read the Docs site](getting_started.html).
    But here’s the quick and dirty version that’ll demonstrate how it works on a Python
    environment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[LlamaIndex的Read the Docs网站](getting_started.html)上阅读完整的文档指南。但是这里是一个简明的版本，将演示它在Python环境中的工作方式。
- en: 'The odds are good that you already have the Python programming language installed
    along with the Python package manager, `pip`. You can confirm that’s the case
    by running these two commands from your command line. Here’s how those looked
    when I ran them:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 很有可能您已经安装了Python编程语言以及Python包管理器`pip`。您可以通过从命令行运行以下两个命令来确认这一点。以下是我运行它们时的样子：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If your system isn’t ready yet, you should head over to the Installing Python
    Appendix at the end of this book.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的系统还没有准备好，您应该转到本书末尾的安装Python附录。
- en: 'Once everything’s in place, we’ll install the two modules (`os` and `llama-index`)
    we’ll need for this particular project:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有准备就绪，我们将为这个特定项目安装两个模块（`os` 和 `llama-index`）：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Pro tip!
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 专业提示！
- en: 'The first troubleshooting step if a llama-index operation ever fails is to
    make sure you’ve got the latest version installed. You can do that with this command:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果llama-index操作失败，首先要解决的故障排除步骤是确保您安装了最新版本。您可以使用以下命令来执行这个步骤：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we’ll start writing our Python code. You’ll begin by setting up your GPT-enabled
    environment by importing the `os` module and adding your OpenAI key. Since LlamaIndex
    uses the public OpenAI API, nothing will happen without this.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将开始编写我们的Python代码。您可以通过导入`os`模块并添加您的OpenAI密钥来搭建您的启用了GPT的环境。由于LlamaIndex使用公共OpenAI
    API，没有这个就什么都不会发生。
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you don’t yet have a valid OpenAI API key, head over to [the API reference
    page](docs.html) and click the Sign up button.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有有效的OpenAI API密钥，请转到[API参考页面](docs.html)并单击注册按钮。
- en: This next code will import the modules that’ll do all the heavy lifting. `pathlib`
    will make it easy for our code to find the location on our local file system where
    we’ve saved our data, `GPTVectorStoreIndex` handles the embeddings representing
    our data that will be generated by `llama_index`, and `download_loader` handles
    the loader file we’ll be working with.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码将导入所有的重活儿都交给的模块。`pathlib`将使我们的代码能够轻松找到我们在本地文件系统中保存数据的位置，`GPTVectorStoreIndex`处理由`llama_index`生成的表示我们数据的嵌入，`download_loader`处理我们将要使用的加载器文件。
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To keep things simple, you should copy all the documents you want GPT to analyze
    to a directory beneath the directory where your Python code is running. I chose
    to call my directory `data`, but you can use whatever you’d prefer. For this example,
    I downloaded a CSV file from the [Kaggle site](www.kaggle.com.html) containing
    population numbers for each of the world’s nations. ([this was the dataset I used](thabresh.html),
    although I renamed it `population.csv`.)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化操作，您应该将想要进行GPT分析的所有文档都复制到Python代码运行的目录下的一个目录中。我选择将我的目录称为`data`，但您也可以使用任何您喜欢的名称。在本示例中，我从[Kaggle网站](www.kaggle.com.html)下载了一个包含世界各国人口数量的CSV文件。
    ([这是我使用的数据集](thabresh.html)，尽管我将其重命名为`population.csv`。)
- en: This code will read the `population.csv` file a variable called `documents`
    and then use that data to build a GPT-friendly index that’ll take the name `index`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码将从`population.csv`文件中读取一个名为`documents`的变量，然后使用该数据构建一个适用于GPT的索引，该索引的名称将为`index`。
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: I’ll then submit my query as an argument for the `query_engine.query` method.
    Just to demonstrate that GPT understands both the CSV ("comma separated values")
    data and the question I’m asking, I’ll ask it for the population of Canada as
    of 2010\. Note how my prompt includes instructions for the LLM on what kind of
    data the `pop2010` column contains. This will greatly increase the chances that
    it’ll understand how to answer my questions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我将我的查询作为`query_engine.query`方法的参数提交。只是为了演示GPT理解CSV（“逗号分隔值”）数据和我提出的问题，我将询问2010年加拿大的人口。请注意，我的提示包含对LLM的说明，说明`pop2010`列包含何种类型的数据。这将大大增加它理解如何回答我的问题的可能性。
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The response was correct - although the commas were a bit weird:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 反应是正确的 - 尽管逗号有点奇怪：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let’s run one more request. Sticking with the `pop2010` column, I want to know
    which country’s population was, in 2010, the closest to the median population
    for all countries.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再进行一次请求。继续使用`pop2010`列，我想知道在2010年，哪个国家的人口最接近所有国家的人口的中位数。
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here’s what came back: *Poland had the population closest to the median of
    all countries in 2010, with 38,597,353 people.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是反馈的内容：*波兰在2010年的人口最接近所有国家的中位数，有38,597,353人。*
- en: Well, Poland’s 2010 population *was* 38,597,353\. But the actual median population
    of all countries was actually over 49 million, which meant that Myanmar was the
    closest. To be fair, Myanmar was only eights spots off from Poland. And GPT’s
    preference for text analysis over simple math operations is well known. I’d say
    that things will only improve with time.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，波兰2010年的人口确实是38,597,353。但所有国家的实际中位数人口实际上超过4900万，这意味着缅甸是最接近的国家。公平地说，缅甸距离波兰只有八个位置。而GPT更倾向于文本分析而不是简单的数学运算是众所周知的。我想随着时间的推移，情况只会变得更好。
- en: Nevertheless, here’s another example of an LLM that does *seem* to understand
    what we’re after, but doesn’t get the job done quite right. And, of course, it’s
    a healthy reminder to always manually confirm that what you’re getting from your
    AI actually makes real-world sense.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这是另一个看起来*似乎*理解我们意图的LLM的例子，但没有完全正确地完成任务。当然，这也是一个健康的提醒，始终手动确认您从人工智能获取的内容是否真实可信。
- en: Dig around and you’ll find much more to the LllamaIndex project. For instance,
    [Llama Hub](llamahub.ai.html) is an archive of "loaders" containing code snippets
    you can use to connect Llama to your own data that’s maintained within any one
    of hundreds of popular frameworks, including Wikipedia, Trello, Reddit, and Jira.
    Those loaders simplify the process of giving GPT access to real-world data in
    a wide range of environments.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 深入挖掘，你会发现LllamaIndex项目的更多内容。例如，[Llama Hub](llamahub.ai.html)是一个包含代码片段的“加载器”存档，您可以使用这些代码片段将Llama连接到您自己维护在数百个流行框架中的数据，包括维基百科、Trello、Reddit和Jira。这些加载器简化了在广泛环境中为GPT提供对真实世界数据的访问的过程。
- en: This is about way more than just summarizing stand alone spreadsheets. Bearing
    in mind the use-case scenarios I listed at the start of this chpater, just imagine
    how tools like this can be put to work aggregating data in multiple formats and
    then mining the data for deep insights.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅仅是对独立电子表格进行摘要。记住我在本章开头列出的用例场景，想象一下这种工具如何用于聚合多种格式的数据，然后对数据进行深度洞察。
- en: 5.2 Seeding a chat session with private data (ChatPDF)
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 使用私人数据启动聊天会话（ChatPDF）
- en: Let me give you an example of just how much better GPT is when working with
    text than with numbers - at least so far. We’re going to take advantage of one
    of the countless businesses that are rushing to offer value-added GPT-based services.
    ChatPDF provides a browser-based interface to which you can upload and "chat with"
    any PDF document.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我给你举个例子，说明GPT在处理文本时比处理数字要好得多 - 至少目前是这样。我们将利用数不尽的企业之一，他们正在争相提供增值的基于GPT的服务。ChatPDF提供了一个基于浏览器的界面，您可以上传并“与之交谈”任何PDF文档。
- en: Just point your browser to [chatpdf.com](www.chatpdf.com.html), drag your PDF
    document to the box labeled "Drop PDF here" that’s visible in the image below,
    and start asking questions. It works just like a ChatGPT session.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 只需将浏览器指向[chatpdf.com](www.chatpdf.com.html)，将PDF文档拖到下图中可见的标有“将PDF文件拖到此处”的框中，然后开始提问。它的工作原理就像ChatGPT会话一样。
- en: Figure 5.1 The ChatPDF webpage
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 ChatPDF网页
- en: '![gai 5 1](images/gai-5-1.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 ChatPDF网页](images/gai-5-1.png)'
- en: But where’s the fun of that? Instead, there’s no reason why you shouldn’t automate
    and integrate your prompts into sophisticated and efficient scripts. To do that,
    you’ll need to request an API key from ChatPDF using the dialog box that appears
    when you click the `API` link at the bottom of the page. If you get access, you’ll
    be all set for some serious scripting.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但是那样有什么乐趣呢？相反，你完全可以将提示自动化并集成到复杂而高效的脚本中。为此，你需要通过单击页面底部的`API`链接时出现的对话框向ChatPDF请求API密钥。如果你获得了访问权限，你就可以准备好进行一些严肃的脚本编写了。
- en: The [ChatPDF API documentation](api.html) - at least in its current iteration
    - provides code snippets for Node.js, Python, and curl requests. For this example,
    I’m going to use the `curl` command line data transfer tool that we saw back in
    chapter two.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[ChatPDF API文档](api.html) - 至少在当前版本中 - 提供了Node.js、Python和curl请求的代码片段。对于本例，我将使用我们在第二章中看到的`curl`命令行数据传输工具。'
- en: 'In our case, sending API requests using `curl` will take two steps, which means
    you’ll run two variations of the `curl` command. The figure illustrates the process:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，使用`curl`发送API请求将需要两个步骤，这意味着你将运行两种`curl`命令的变体。以下是该过程的示意图：
- en: Figure 5.2 The request/response process using the ChatPDF API
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 使用ChatPDF API的请求/响应过程
- en: '![gai 5 2](images/gai-5-2.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![gai 5 2](images/gai-5-2.png)'
- en: 'Here’s how that first step will work:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第一步的工作原理：
- en: Authenticate with the ChatPDF API server using the POST method that points to
    the ChatPDF API address
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用指向ChatPDF API地址的POST方法进行ChatPDF API服务器的身份验证
- en: Include the `-H` argument containing your API key (insert in place of the `sec_xxxxxx`
    dummy code)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含包含你的API密钥的`-H`参数（替换为`sec_xxxxxx`虚拟代码）
- en: Include the `-d` argument to pass the URL where ChatPDF can find the PDF document
    you want to query
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加`-d`参数以传递ChatPDF可以找到你想查询的PDF文档的URL
- en: 'And here’s the actual code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是实际的代码：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: That URL in my sample code points to a real PDF document, by the way. It’s just
    some slides from a video course on [the LPI Security Essentials certification](complete-lpi-security-essentials-exam-study-guide.html)
    that I recently published. Since, however, that document doesn’t have all that
    much text in it, you might want to substitute it for your own PDF.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在我示例代码中的那个URL指向一个真实的PDF文档。顺便说一下，这只是我最近发布的关于[LPI安全基础认证](complete-lpi-security-essentials-exam-study-guide.html)的视频课程的一些幻灯片。但是，由于那个文档里面并没有太多的文本，你可能想用你自己的PDF替换它。
- en: You could also have run that command as a single line, but formatting it over
    multiple lines makes it much easier to read. In Bash shell sessions, make sure
    that the `\` backslash at the end of each line (which tells the interpreter that
    the command continues on to the next line) is the last character on that line.
    Even an invisible space character will mess everything up.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以将该命令作为单行运行，但是将其格式化为多行使其更易读。在Bash shell会话中，请确保每行末尾的`\`反斜杠（告诉解释器命令将继续到下一行）是该行的最后一个字符。即使是一个不可见的空格字符也会搞乱一切。
- en: If that command is successful, it’ll return a `sourceID` value, which is the
    session identifier you’ll use going forward when you want to query your PDF. You’ll
    paste that identifier into the second `curl` command. In this example, we use
    the `-d` argument to send a question ("What is the main topic of this document?")
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果该命令成功，它将返回一个`sourceID`值，这是你在以后查询PDF时将要使用的会话标识符。你将把该标识符粘贴到第二个`curl`命令中。在这个例子中，我们使用`-d`参数发送一个问题（"这个文档的主要话题是什么？"）
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here’s the response I got back:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我收到的响应：
- en: Response
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 响应
- en: '{"content":"The main topic of this document is not specified on the given pages.
    However, based on the topics listed on page 50, it appears to be related to networking
    protocols, routing, risk categories, and best practices."}'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '{"content":"这个文档的主要话题没有在给定的页面上指定。但是，根据第50页列出的主题，似乎与网络协议、路由、风险类别和最佳实践有关。"}'
- en: Here’s a more complex example based on something I myself did recently.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个更复杂的例子，基于我最近自己做的事情。
- en: It was all about solving a long-standing personal problem that’s caused me suffering
    for three decades now. You see, I’ve always hated having to come up with assessment
    questions. This was true during those years when I taught high school, and it’s
    even more true now.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都是为了解决一个长期存在的个人问题，这个问题让我受苦已经三十年了。你知道，我一直讨厌想出评估问题。这在我教高中的那些年里是真的，在现在更是如此。
- en: AI to the rescue! Why not convert the transcript for the new video course I’m
    creating to a single PDF document and see what ChatPDF has to say about it?
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: AI 来拯救！为什么不将我正在创建的新视频课程的文字记录转换为一个 PDF 文档，看看 ChatPDF 的反馈是什么？
- en: Consider it done. I seeded ChatPDF with that new PDF document exactly the way
    I showed you earlier. But the request will be a bit more complicated. You see,
    I need to make sure that I get assessment questions that address all the course
    topics, and that they comply with some basic formatting needs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 没问题，我按照之前展示的方法，精确地为 ChatPDF 添加了那个新的 PDF 文档。但这次请求有点复杂。你看，我需要确保获得的评估问题涵盖所有课题，并符合一些基本的格式要求。
- en: 'I’ll have to create a Bash script that will send the ChatPDF API individual
    prompts for *each* set of course topics and then append the output to a file.
    This diagram should help you visualize what we’re doing here:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要创建一个 Bash 脚本，用来逐个为*每组*课题发送 ChatPDF API 提示，然后将输出追加到一个文件中。这个图示可以帮助你理解我们这里正在做什么：
- en: Figure 5.3 Process for feeding the ChatPDF API with unique, topic-informed requests
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.3 是使用具有独特、针对课题的请求来提供输入给 ChatPDF API 的流程。
- en: '![gai 5 3](images/gai-5-3.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![gai 5 3](images/gai-5-3.png)'
- en: 'To solve the first problem, I created a single text file containing a list
    of all the course topics with about four or five topics per line. I then created
    a Bash script that would expect to be run with the name of that text file as the
    single argument. Running the script from the command line would look something
    like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决第一个问题，我创建了一个包含所有课题的单个文本文件，每行大约有四到五个课题。然后我创建了一个 Bash 脚本，该脚本希望以该文本文件的名称作为单个参数来运行。从命令行运行脚本会像这样：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now here’s the script itself:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是脚本本身：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let’s break that down into steps. Since the `curl` command is so complicated,
    the script will iterate through all the lines of the text file as part of a `while`
    loop.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其分解为几个步骤。由于 `curl` 命令非常复杂，脚本将在 `while` 循环的一部分中遍历文本文件的所有行。
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For each iteration, it will execute our `curl` command within a `heredoc` format
    (`$(cat <<EOF…​`).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每次迭代，脚本会在 `heredoc` 格式的内部执行我们的 `curl` 命令。
- en: The `content` argument within the `curl` command lays out how I’d like the assessments
    formatted by ChatPDF.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`curl` 命令中的 `content` 参数定义了我希望 ChatPDF 格式化评估问题的方式。'
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By the way, I didn’t include the actual URL for the PDF - you’ll just have to
    pay for the course yourself!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，我没有包含 PDF 的实际 URL - 你只能自己为这门课程付费！
- en: Finally, the script will append (`>> multi_select_raw`) the assessments that
    come back with each iteration to a file called `multi_select_raw`. The output
    came in JSON format which required a bit of manipulation to get it into the shape
    I wanted. But I guess that’s why they pay me the big bucks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个脚本将把每次迭代返回的评估问题追加到一个名为 `multi_select_raw` 的文件中（`>> multi_select_raw`）。输出是以
    JSON 格式返回的，我需要对其进行一些处理才能使其达到我想要的格式。但我想这就是为什么他们付给我高额薪酬的原因吧。
- en: Come to think of it, I could probably have used GPT in one form or another to
    do the formatting for me. See if you can figure that out for yourself
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细想想，我可能可以以一种形式或另一种形式使用 GPT 来为我进行格式设置。看看你能否自己弄清楚。
- en: Takeaway
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 要点
- en: 'You’re not limited to the context provided within short chat prompts: use tools
    like llama_index and ChatPDF (including its API) to train LLMs on as much source
    material as you need to get informed responses to your requests.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在短聊天提示提供的上下文之外，你不必受限于使用 llama_index 和 ChatPDF（包括其 API）工具的使用。你可以使用尽可能多的源材料来训练
    LLMs，以便获得对请求的知情回复。
- en: 5.3 Connecting your AI to the internet (Auto-GPT)
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 连接你的 AI 到互联网（Auto-GPT）
- en: Our final stop in this chapter will be the big, bad internet itself. That’s
    right. We’re going to find out whether GPT is better at wasting valuable time
    watching cute kitten videos than we are. Also, we’ll see whether giving a very
    smart GAI access to all the world’s knowledge can deliver something valuable in
    return.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章的最后一站将是大互联网本身。没错，我们要看看 GPT 在浪费宝贵时间观看可爱小猫视频方面是否比我们更擅长。此外，我们将看到是否让一台非常智能的 GAI访问全球所有的知识能够带来一些有价值的回报。
- en: We’re going to use the madly popular Auto-GPT project’s Python code - provided
    through a [GitHub account](Significant-Gravitas.html) called `Significant-Gravitas`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用非常流行的 Auto-GPT 项目的 Python 代码 - 这些代码可以通过名为 `Significant-Gravitas` 的[GitHub
    账户](Significant-Gravitas.html)获得。
- en: 'NOTE:'
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意：
- en: '**Git**, in case you haven’t yet been formally introduced, is a decentralized
    version control system that tracks changes to files in software projects. It allows
    multiple developers to collaborate, work on different features simultaneously,
    and merge their changes seamlessly. It provides a complete history of the project,
    facilitates code reviews, and enables efficient collaboration in both small and
    large-scale software development projects. **GitHub** is a web-based platform
    for version control and collaboration, built on top of Git. It provides a centralized
    hub for hosting repositories, managing code, and facilitating collaboration among
    developers.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**Git**，如果您还没有正式介绍过，是一种去中心化的版本控制系统，用于跟踪软件项目中的文件更改。它允许多个开发人员协作，同时处理不同的功能，并无缝合并其更改。它提供了项目的完整历史记录，促进了代码审查，并在小型和大型软件开发项目中实现了高效的协作。**GitHub**是建立在Git之上的用于版本控制和协作的基于Web的平台。它为托管存储库、管理代码和促进开发人员之间的协作提供了一个集中的枢纽。'
- en: In the unlikely event you don’t yet have Git installed, you can find [excellent
    guides](install-git.html) in many places.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尚未安装Git，您可以在许多地方找到[优秀的指南](install-git.html)。
- en: 'Once that’s behind you, run this `git clone` command to download and unpack
    the Auto-GPT software:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这一切都完成了，运行以下`git clone`命令以下载和解压Auto-GPT软件：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: For a minimal configuration that’ll be good enough for many operations, you’ll
    move into the `Auto-GPT` directory that the `git clone` command created and edit
    a hidden file called `.env.template`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多操作而言，最少的配置就足够了，您将进入由`git clone`命令创建的`Auto-GPT`目录并编辑名为`.env.template`的隐藏文件。
- en: Look for a line in that file containing the text `OPENAI_API_KEY=`. Make sure
    that line is uncommented (i.e., that there’s no `#` at the start) and then add
    your OpenAI API key. Finally, change the name of the saved `.env.template` file
    to just `.env` (i.e., remove the `.template` extension).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在该文件中查找包含文本`OPENAI_API_KEY=`的行。确保该行已取消注释（即，在开头没有`#`），然后添加您的OpenAI API密钥。最后，将保存的`.env.template`文件的名称更改为`.env`（即，删除`.template`扩展名）。
- en: With that, you’re all ready to go. Although there are many configuration settings
    you can play with to tweak performance. You’ll find configuration files in the
    root (`Auto-GPT`) directory and in the `autogpt` directory that’s below it. Keep
    in mind the details about settings like, for instance, `Temperature` that you
    already learned about in Chapter two (How We Control Generative Artificial Intelligence).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，您就可以准备好了。虽然有许多配置设置可供您调整性能。您会在根目录（`Auto-GPT`）和其下的`autogpt`目录中找到配置文件。请记住有关诸如您在第二章（我们如何控制生成人工智能）中已经了解的`Temperature`等设置的详细信息。
- en: 'Launching AutoGPT can be as simple as this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 启动AutoGPT可能就像这样简单：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: But you might want to consult the `run.sh` or `run.bat` files in the `Auto-GPT`
    directory for alternatives. And, as always, the [official documentation](docs.agpt.co.html)
    is going to be helpful.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，您可能想要查看`Auto-GPT`目录中的`run.sh`或`run.bat`文件以查看备选方案。而且，和往常一样，[官方文档](docs.agpt.co.html)将会很有帮助。
- en: When AutoGPT launches, you’ll be asked whether you want to reload a previous
    session’s settings (which, if this is your first time using the program, would
    be the pre-set default), or whether you’d prefer to start something new. If you
    go with "new", you’ll be asked for an "AI Name", a description of the role you
    want this AI to play, and then up to five Goals. Sorry. That *was* true a few
    days ago. But stability and predictability aren’t attributes that get along well
    with AI, are they? Instead, just enter a single (detailed) prompt and you’re good
    to go.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当AutoGPT启动时，您将被询问是否要重新加载先前会话的设置（如果这是您第一次使用该程序，则为预设默认值），还是您是否更喜欢开始新的。如果选择“new”，则将要求您提供“AI名称”，您希望此AI扮演的角色的描述，然后是最多五个目标。抱歉。这在几天前确实是真的。但是，稳定性和可预测性并不与AI相容，不是吗？相反，只需输入一个（详细的）提示，您就可以开始了。
- en: Once you’ve entered your goals, AutoGPT will head off to figure out how it should
    solve the problem and come back with its thinking and recommendations. AutoGPT
    is verbose. It’ll tell you what it thinks about the task you’ve given it, what
    potential problems it might face, and how it might be able to solve those problems.
    It’ll also present a multi-step plan of action. All those discussions will, by
    default, be saved to a JSON-formatted file in the `AutoGPT` directory called `auto-gpt.json`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您输入了您的目标，AutoGPT将开始思考如何解决问题，并带着它的思考和建议回来。AutoGPT很啰嗦。它会告诉您它对您给予它的任务的看法，它可能面临的潜在问题以及如何解决这些问题的方法。它还会呈现一个多步计划。所有这些讨论，默认情况下，都会保存到名为`auto-gpt.json`的JSON格式文件中的`AutoGPT`目录中。
- en: 'By default, it’ll wait for you to approve each new next step of its plan. Alternatively,
    although there is some risk involved, you can give it permission to perform, say,
    the next ten steps without asking permission by responding with something like
    this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，它会等待您批准其计划的每个新步骤。或者，虽然存在一些风险，但您可以允许它执行，比如，下一个十个步骤而不需要询问许可，只需回复类似以下的内容：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: I should note that the process I’m going to describe did end up costing me around
    $3.00 in OpenAI API costs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该指出，我即将描述的过程最终花费了我大约3.00美元的OpenAI API费用。
- en: So let’s see what we can do here. I recently used the tool for some serious
    research for my business. I’ve been debating whether I should create a book and
    course covering the objectives for a relatively new technology certification.
    My doubts center around the question of whether there will be enough demand from
    students planning to earn the certification to make my new content useful.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们看看我们能做些什么。我最近为我的业务进行了一些严肃的研究。我一直在考虑是否应该创建一本书和一门课程，涵盖相对较新的技术认证的目标。我的疑虑集中在这样一个问题上，即是否会有足够的学生需求来使我的新内容有用。
- en: 'I asked AutoGPT to use the internet to rank the popularity of this particular
    certification against a couple of other older certs (whose value I’m in a better
    position to gauge). Here - in slightly modified form - is how I framed my request:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我要求AutoGPT使用互联网对这个特定认证的受欢迎程度进行排名，与其他几个较老的认证进行对比（我更有能力评估其价值）。以下是我提出请求的稍作修改的方式：
- en: '*AI Name: Assess popularity of […​] certifications Description: Assess the
    relative popularity of the […​] certifications to know which one might be the
    most profitable for a new certification study guide course Goal 1: Compare the
    popularity of following certification programs: […​]. Goal 2: Estimate the likely
    future demand for each of the certification programs among potential students.
    Goal 3: Estimate the likely demand for training programs (like Udemy courses,
    books) for each certification programs. Goal 4: Estimate each certification’s
    popularity using a scale of 0 - 100 and save the results to a local file. Goal
    5: Shut down.*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*AI 名称：评估[...] 认证的受欢迎程度描述：评估[...] 认证的相对受欢迎程度，以了解哪一个可能对新认证学习指南课程最有利目标 1：比较以下认证计划的受欢迎程度：[...]
    目标 2：估计潜在学生对每个认证计划的未来需求。 目标 3：估计每个认证计划的培训计划（如Udemy课程、图书）的潜在需求。 目标 4：使用0-100的比例估计每个认证的受欢迎程度，并将结果保存到本地文件中。
    目标 5：关闭。*'
- en: After around four hours(!) of independently thinking, browsing, and searching,
    AutoGPT gave me a file that ranked three certifications - including the new one
    I’m considering - by scores between 0 and 100\. For context, I copied the enormous
    raw output it generated (there was nearly 200k of it) and converted it to a PDF.
    I then uploaded that PDF to ChatPDF to try to discover more about the methodology.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 经过大约四个小时的独立思考、浏览和搜索后，AutoGPT给了我一个文件，其中排名了三个认证（包括我正在考虑的新认证），得分介于0到100之间。为了了解背景，我复制了它生成的庞大原始输出（接近20万字节）并将其转换为PDF格式。然后我将PDF上传到ChatPDF以尝试了解更多关于方法论的内容。
- en: After all the dust had settled, I was actually impressed with the results. Based
    on AutoGPT’s in-process output, it seems to have leveraged a wide range of online
    resources, including social media discussions, Amazon reviews, and content nested
    deeply within the web sites of various related organizations. Those four hours
    did seem to stretch on, but I’m happy with what that bought me.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有尘埃落定之后，我实际上对结果印象深刻。根据AutoGPT的过程中输出，它似乎利用了广泛的在线资源，包括社交媒体讨论、亚马逊评论以及深藏在各种相关组织网站中的内容。那四个小时似乎过得很慢，但我对所获得的内容很满意。
- en: Having said that, AutoGPT can sometimes lose its way. The most common (and frustrating)
    problem I’ve faced is its tendency to fail with the same futile operation over
    and over again. At this point, if the agent is just going round and round in circles,
    your best bet is to simply shut it down.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，AutoGPT有时会迷失方向。我面临的最常见（也是最令人沮丧）的问题是它倾向于一遍又一遍地失败于同样无益的操作。此时，如果代理程序只是在原地打转，那么最好的办法就是简单地关闭它。
- en: And while we’re on the subject of giving LLMs internet access, ChatGPT (using
    GPT-4) can, from time to time, be convinced to access live internet URLs. Although
    it’s been known to get cranky when it’s just not in the mood.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到让LLMs访问互联网，ChatGPT（使用GPT-4）偶尔可以被说服访问实时互联网URL。尽管它有时候会在心情不好时变得暴躁。
- en: 5.4 Summary
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 总结
- en: We used the `GPTVectorStoreIndex` from LlamaIndex to get GPT to read amd analyze
    locally-hosted data - which can include CSV and PDF files (among others).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用LlamaIndex的`GPTVectorStoreIndex`来让GPT读取和分析本地托管的数据 - 这些数据可以包括CSV和PDF文件（等等）。
- en: We used ChatPDF to assess and query our own PDF documents, both through the
    web interface and, programmatically, through the ChatPDF API.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用ChatPDF来评估和查询我们自己的PDF文档，无论是通过网络界面还是通过ChatPDF API进行编程。
- en: We used AutoGPT to created a GPT-fueled agent capable of searching the live
    internet for data of all kinds in order to answer complex sequences of questions.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用AutoGPT创建了一个以GPT为引擎的代理，能够搜索互联网上的各种数据，以回答复杂的问题序列。
- en: 5.5 Try this for yourself
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 亲自尝试
- en: Identify a PDF file containing, say, the many objectives for an IT-related certification
    program (something like the [AWS Certified Cloud Practitioner](docs-cloud-practitioner.html),
    perhaps).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 确定一个包含IT相关认证计划的多个目标的PDF文件（也许是类似于[AWS认证云从业者](docs-cloud-practitioner.html)的东西）。
- en: Feed the PDF to both ChatPDF and LlamaIndex and ask for a detailed summary of
    the exam objectives.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将PDF文件提供给ChatPDF和LlamaIndex，并要求详细总结考试目标。
- en: Compare the results you get.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较您得到的结果。
- en: Ask AutoGPT for a summary of that certification’s objectives.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求AutoGPT总结该认证的目标。
