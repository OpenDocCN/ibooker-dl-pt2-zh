- en: 4 Association rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Association rule learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different types of association rules algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of different association rules algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence learning using SPADE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “The power of association is stronger than the power of beauty; therefore the
    power of association is the power of beauty– John Ruskin”
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations on finishing the first part of the book! You explored the basics
    of unsupervised learning and algorithms like k-means clustering, hierarchical
    clustering, DBSCAN, principal component analysis, and others. It is expected that
    you have covered the mathematical concepts in the first part and created the Python
    codes to solve the exercise given at the end of each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the second part of the book wherein we leverage the concepts learned
    in the first part and explore slightly more complex topics. We are starting with
    association rules in chapter 4 of this book. All the very best!
  prefs: []
  type: TYPE_NORMAL
- en: Next time you visit a nearby grocery store, look around inside the store and
    the arrangements of various items. You would find shelves with items like milk,
    eggs, bread, sugar, washing powder, soaps, fruits, vegetables, cookies and various
    other items neatly stacked. Have you ever wondered what is the logic of this arrangement
    and how these items are laid out? Why certain products are kept near each other
    while others are quite far from each other? Obviously, the arrangement cannot
    be done in a random manner and there has to be scientific reasoning behind it.
    Or do you wonder, how does Netflix recommend movies to you based on your movie
    history like a sequence? We are going to find the answers to these questions in
    this chapter. Like always, we will study the concepts first. We will go through
    the mathematical logic for different algorithms, the pros and cons of each, and
    practical implementations using Python. A business case study is provided at the
    end of the chapter to complement the knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the fourth chapter and all the very best!
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Technical toolkit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will continue to use the same version of Python and Jupyter notebook as we
    have used so far. The codes and datasets used in this chapter have been checked-in
    at this location.
  prefs: []
  type: TYPE_NORMAL
- en: You would need to install a few Python libraries in this chapter which are –
    apyori, pyECLAT, fpgrowth_py and pyspade. Along with this we will need numpy and
    pandas. Using libraries, we can implement the algorithms very quickly. Otherwise,
    coding these algorithms is quite a time-consuming and painstaking task.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with association rules.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Association rule learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might have heard the famous “*beer and diaper story*”. As per this anecdote,
    customers (mostly young men) of a supermarket who buy diapers also buy beer in
    the same invoice. In other words, young men who are buying diapers for their babies
    have quite a high probability to buy beers in the same transaction. We will not
    comment on the authenticity of the story, but *association rule learning* can
    be attributed as the logic derived from this story.
  prefs: []
  type: TYPE_NORMAL
- en: Formally put - association rules can be used to find compelling relationships
    between the variables which are present in the data sets. We can use association
    rules for measuring the correlations and co-occurrences between the variables
    in a dataset. In the example given above (assuming the story is true), one could
    analyse the daily customer transactions. And if a relationship emerges between
    beer and diapers, it is a very strong insight for the supermarket, which can allow
    them to customize their placements of beer and diapers or tailor the marketing
    strategy or even alter the prices.
  prefs: []
  type: TYPE_NORMAL
- en: We can understand by a different example in a supermarket. Consider the example
    below. Assume that by analyzing five invoices generated in a supermarket, we get
    the data below as shown in Table 4.1\. In this example, in invoice number 1001
    milk is purchased hence it has a value of 1, whereas cheese is not purchased,
    hence it is 0.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.1 Examples of invoices generated in a supermarket. The first invoice
    number is 1001 and, in that invoice, milk is bought. Hence, there is 1 in front
    of milk. While cheese is not bought in 1001 and hence, there is 0 in front of
    cheese.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 1 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: So, in invoice number 1001, milk, eggs, and bread are purchased while in invoice
    number 1002 only cheese is purchased. Here, we can see that whenever milk and
    eggs are purchased together, bread is always purchased in the same invoice. It
    is an important discovery indeed.
  prefs: []
  type: TYPE_NORMAL
- en: Now scale up this understanding to thousands of transactions made in a day.
    It will lead to very strong relationships which human eyes are generally oblivious
    to, but association rule algorithms can uncover them for us. It can lead to better
    product placements, better prices of the products and much more optimized marketing
    spending. Such patterns will enhance the customer experience and prove quite handy
    to improve overall customer satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize association rules as shown in Figure 4.1\. Here, there are
    some incoming variables represented as nodes 1,2,3,4 etc. These nodes are related
    to each other as shown by the arrows. This relationship between them gives rise
    to rules A and B. If we relate back to the beer/diaper story we mentioned at the
    start of this section, rule A can be that when a young male customer buys diapers
    they also often buy beer; while a rule B can be that when milk and eggs are purchased,
    often bread is bought too.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 Association rule can be visualized as the relationships between various
    variables in the dataset. These variables are linked to each other, and significant
    relationships are established between them.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_01](images/04_01.png)'
  prefs: []
  type: TYPE_IMG
- en: The example of the supermarket discussed above is sometimes referred to as *Market
    Basket Analysis.* But association rules are applicable not only in grocery retail.
    Their utility has been proven in other sectors like bioinformatics and the medical
    industry, intrusion detection etc. They can be utilized by Netflix or Spotify
    to analyze historical user behavior and then recommend the content which the user
    most likely is going to like. Web developers can analyze the historical clicks
    and usages of the customers on their websites. By identifying the patterns, they
    can find out what user tends to click and which features will maximize their engagements.
    Medical practitioners can use association rules to better diagnose patients. The
    doctors can compare the probability of the symptoms in relationships with other
    symptoms and provide more accurate diagnoses. The use cases are across multiple
    business domains and business functions.
  prefs: []
  type: TYPE_NORMAL
- en: We will now understand the building blocks for association rules.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Building blocks of association rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We covered the definition of the association rule in the last section.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's understand the mathematical concept behind association rules. Assume
    that we have the following datasets in a retail store-
  prefs: []
  type: TYPE_NORMAL
- en: Let X = {x[, x[2], x[3], x[4], x[5] …., x[n]} are the *n* items available in
    the retail store. For example, they can be milk, eggs, bread, cheese, apples and
    so on.]
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let Y = {y[, y[2], y[3], y[4], y[5] …., y[m]} are the *m* transactions generated
    in that retail store. Each transaction could have all or some items from the retail
    store.]
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obviously, each item in the transactions will be bought from the retail store
    only. Or, in other words, every item in transactions in set Y will be a subset
    of items in set X. At the same time, each item would have a unique identifier
    attached to it and each transaction would have a unique invoice number attached
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are interested to analyze the patterns and discover the relationships.
    This will be used to generate any rule or insight. So, let’s define the meaning
    of the rule first.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assume that we find a rule that whenever items in list P are bought, items
    in list Q are also bought. This rule can be written as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The rule is **P -> Q**. It means that whenever items defined in P are bought
    it leads to the purchase of Q too.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Items in P will be a subset of X or **P** **Í** X.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similarly, items in Q will be a subset of X or **Q** **Í** X.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: P and Q cannot have any common element or **P** **Ç** Q = 0
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let’s understand these mathematical concepts with a real-world example.
  prefs: []
  type: TYPE_NORMAL
- en: Assume that X = {milk, bananas, eggs, cheese, apples, bread, salt, sugar, cookies,
    butter, cold drinks, water}. These are the total items available in the retail
    shop.
  prefs: []
  type: TYPE_NORMAL
- en: Y = {1001, 1002, 1003, 1004, 1005}. These are the five invoices generated in
    that retail store. The respective items purchased in each of these invoices are
    given in Table 4.2.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.2 Example of five invoices generated in a retail store. Note how for
    each invoice, we have 0 and 1 associated for each of the items. These invoices
    are just for illustration purposes. In the actual invoices, the number of items
    can be much more.
  prefs: []
  type: TYPE_NORMAL
- en: '![04_T02](images/04_T02.png)'
  prefs: []
  type: TYPE_IMG
- en: Using this dataset, let’s assume we create two rules that {milk, bananas} ->
    {eggs} and {milk, bananas} -> {bread}.
  prefs: []
  type: TYPE_NORMAL
- en: First rule means that whenever milk and bananas are bought together, eggs are
    also purchased in the same transaction. And second rule means that whenever milk
    and bananas are bought together, bread is also bought in the same transaction.
    By analyzing the dataset above, we can clearly see that rule 1 is always true
    whereas rule 2 is not.
  prefs: []
  type: TYPE_NORMAL
- en: The items on the left side are called the *antecedent* or the LHS and the ones
    on the right side are called the *consequents* or the RHS.
  prefs: []
  type: TYPE_NORMAL
- en: In the real-world, for any such rule to have significance, the same pattern
    must repeat itself across several hundreds and thousands of transactions. Then
    only we would conclude that the rule is indeed true and can be generalized across
    the entire database.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, there can be many such rules. In a retail shop where daily
    thousands of invoices are generated, there can be hundreds of such rules. How
    can be find out which rules are significant, and which are not? This can be understood
    using the concept of *support, confidence, and lift* which we will study in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1 Support, confidence, lift, and conviction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We identified the meaning of a rule in association rule in the last sections.
    We also understand that there can be hundreds of rules based on the transactional
    data set. In this section, we will explore, how we can measure the effectiveness
    of such rules and can shortlist the most interesting ones. This can be achieved
    using the concepts of support, confidence, lift, and conviction.
  prefs: []
  type: TYPE_NORMAL
- en: Recall in the last section we discussed the generalization of a rule. Support,
    confidence, lift, and conviction allow us to measure the level of generalization.
    In simple words, using these four parameters we can determine how useful the rule
    can be in our pragmatic real-world business. After all, if a rule is not useful
    or is not powerful enough, it is not required to be implemented. Support, confidence,
    lift, and conviction are the parameters to check the efficacy of the rule. We
    will look at these concepts in detail now.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the below data set in Table 4.3 to understand the concept of support,
    confidence, and lift.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased. Again, for the sake of this example, we have taken only 4 items
    in total.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: Here, for an invoice, 1 represents if an item is present in that invoice while
    0 shows that the item was not purchased in that particular invoice. For example,
    invoice number 1001 has milk, eggs and bread while 1002 has eggs, bread and cheese.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s study support now.
  prefs: []
  type: TYPE_NORMAL
- en: Support
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Support measures the frequency percentage of the items in the datasets. In other
    words, it measures the percentage of transactions in which the items are occurring
    in the data set.
  prefs: []
  type: TYPE_NORMAL
- en: Support can be denoted as shown below
  prefs: []
  type: TYPE_NORMAL
- en: '![04_01a](images/04_01a.png)'
  prefs: []
  type: TYPE_IMG
- en: Refer to Table 4.3, if we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which all three items (milk,
    eggs, and bread) are present. The total number of transactions is five. So, it
    means that the support for the rule is 2 / 5 which is 0.4 or 40%.
  prefs: []
  type: TYPE_NORMAL
- en: If we are interested in the rule {bread, eggs} -> {cheese}. In such a scenario,
    there is only one transaction in which all three items are present. The total
    number of transactions is five. So, it means that the support for the rule is
    1 / 5 which is 0.2 or 20%.
  prefs: []
  type: TYPE_NORMAL
- en: Higher the support for a rule, better it is. Generally, we put a minimum threshold
    to get support. Minimum threshold is generally determined in consultation with
    the business stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: We will now study confidence for a rule.
  prefs: []
  type: TYPE_NORMAL
- en: Confidence
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Confidence measures how often the rule is true. In other words, it measures
    the percentage of transactions which if contain antecedents also contain consequents.
  prefs: []
  type: TYPE_NORMAL
- en: So, if we wish to measure the confidence of the rule A->B
  prefs: []
  type: TYPE_NORMAL
- en: '![04_01b](images/04_01b.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the numerator is supported when both A and B are present in the transaction,
    while the denominator refers to the support only for A.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased. Again, for the sake of this example, we have taken only 4 items
    in total.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: Refer to Table 4.3, if we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which both milk and eggs are
    present. Hence, the support is 2/5 = 0.4\. It is the denominator. There are two
    transactions in which all three (milk, eggs, bread) are present. Hence, support
    is 2/5 = 0.4, which is the numerator. Putting in the equation above, the confidence
    for the rule {milk, eggs} -> {bread} is 0.4/0.4 = 1.
  prefs: []
  type: TYPE_NORMAL
- en: If we are interested in the rule {eggs, bread} -> {cheese}. In such a scenario,
    there are three transactions in which (eggs, bread) are present. The total number
    of transactions are five. So, it means that the support is 3 / 5 which is 0.6\.
    There is only one transaction in which all the three items (eggs, bread, cheese)
    are present. So, the support is 1/5 = 0.2\. Hence the confidence for the rule
    {eggs, bread} -> {cheese}is 0.2/0.6 = 0.33.
  prefs: []
  type: TYPE_NORMAL
- en: The higher the confidence in the rule, the better it is. Like support, we put
    a minimum threshold on confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is also referred to as the *conditional probability* of A on B.
    It can be understood as the probability of B occurring provided A has already
    occurred and can be written as P(A|B). So, in the examples quoted above, the probability
    of cheese to be bought provided eggs, bread is already bought is 33% while the
    probability of bread to be purchased, provided milk, eggs are already purchased
    is 100%
  prefs: []
  type: TYPE_NORMAL
- en: We have covered confidence and support so far. We will now study lift and conviction
    for a rule which are real criteria to evaluate a rule.
  prefs: []
  type: TYPE_NORMAL
- en: Lift and conviction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lift is a very important measurement criteria for a rule. Lift for a rule A->
    B can be defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![04_01c](images/04_01c.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the numerator is supported when both A and B are present in the transaction,
    while the denominator refers to the support for A multiplied by the support for
    B.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased. Again, for the sake of this example, we have taken only 4 items
    in total.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: Refer to Table 4.3, if we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which all three (milk, eggs,
    bread) are present. Hence, support is again 2/5 = 0.4, which is the numerator.
    There are two transactions in which only (milk, eggs) are present, so the support
    is 2/5 = 0.4\. There are four transactions in which bread is present, hence the
    support is 4/5 = 0.8\. Putting in the equation above, the lift for the rule {milk,
    eggs} -> {bread} is 0.4/(0.4x0.8) = 1.25.
  prefs: []
  type: TYPE_NORMAL
- en: If we are interested in the rule {eggs, bread} -> {cheese}. In such a scenario,
    there is only one transaction in which (eggs, bread, cheese) are present. The
    total number of transactions is five. So, it means that the support is 1 / 5 which
    is 0.2\. There are two transactions in which (cheese) is present. So, the support
    is 2/5 = 0.4\. There are four transactions in which (eggs, bread) are present,
    so the support is 4/5 = 0.8\. Putting in the equation above, the lift for the
    rule {eggs, bread} -> {cheese} is 0.2/(0.4x0.8) = 0.625.
  prefs: []
  type: TYPE_NORMAL
- en: If the value of the lift is *equal to 1*, it means that the antecedent and precedent
    are independent of each other, and no rule can be drawn from it.
  prefs: []
  type: TYPE_NORMAL
- en: If the value of lift is *greater than one*, it means that the antecedent and
    precedent are dependent on each other. This rule can be used for predicting the
    antecedent in future transactions. This is the insight we want to draw from the
    data set.
  prefs: []
  type: TYPE_NORMAL
- en: The value of lift is *lesser than one*, it means that the antecedent and precedent
    are substitutes of each other. The presence of one can have a negative impact
    on the other. It is also an important insightthath can be used by the business
    teams for strategic planning.
  prefs: []
  type: TYPE_NORMAL
- en: While we evaluate any rule using the lift, it is imperative that we apply domain
    knowledge to it. For example, if we evaluate the rule {eggs, bread} -> {cheese},
    it suggests that eggs, bread can be a substitute for cheese. We know that it is
    not true in the real life. Hence, in such a scenario we cannot make any decision
    for this role. We must take help of domain knowledge to draw any conclusions for
    this rule.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, rule {milk, eggs} -> {bread} might be a rule which can be
    true for a large number of times. For many customers, when they purchase milk
    and eggs together it is highly likely that bread will be purchased too in the
    same transaction. Hence this rule makes much more sense for such customers. The
    objective is to have a strong business logic to either support or disapprove a
    rule identified using the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conviction** is an important parameter which is given by the formula below'
  prefs: []
  type: TYPE_NORMAL
- en: '![04_01d](images/04_01d.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, if we are interested in the rule {eggs, bread} -> {cheese}. In
    such a scenario, there is only one transaction in which (cheese) is present. The
    total number of transactions are five. So, it means that the support is 1 / 5
    which is 0.2 and will be used in the numerator. We have already calculated the
    confidence as 0.625\. Putting back in the formula, we can calculate conviction
    as (1-0.2)/(1-0.625) = 2.13
  prefs: []
  type: TYPE_NORMAL
- en: We can interpret the conviction as – the rule {eggs, bread} -> {cheese} would
    be incorrect 2.13 times more often if the association between {eggs, bread, cheese}
    was purely chosen at random.
  prefs: []
  type: TYPE_NORMAL
- en: In most of the business scenarios, lift is the measurement criteria used. There
    are other measurement parameters too like leverage, collective strength etc. But
    most of the time confidence, support and lift are used to measure the effectiveness
    of any rule.
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/tgt.png) POP QUIZ – answer these question to check your understanding..
    Answers at the end of the book'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Support measures how often the rule is present in the dataset. True or
    False
  prefs: []
  type: TYPE_NORMAL
- en: 2.   If the lift is greater than 1, it means that the two items are independent
    of each other. True or False.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Lower the value of confidence, better is the rule. True or False.
  prefs: []
  type: TYPE_NORMAL
- en: While we evaluate any rule while analyzing the data set, most of the time we
    set a threshold for the confidence, support, and the lift. It allows us to reduce
    the number of rules and filter out the irrelevant ones. In other words, we are
    interested in only the rules which are very frequent. We will study it in more
    detail when we create a Python solution for a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We will now study the various algorithms used in association rule. The first
    such algorithm is Apriori algorithm which is the next topic.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Apriori algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Apriori algorithm is one of the most popular algorithms used for association
    rules. It was proposed by Agrawal and Shrikant in 1994\. The link to the paper
    is given at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Apriori is used to understand and analyze the frequent items in a transactional
    database. It utilizes a “bottom-up” approach where first candidates are generated
    based of the frequency of the subsets. Let us understand the entire process by
    means of an example.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the same dataset we have discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.3 Data set we are going to use to understand the concept of support,
    confidence, and lift. The first invoice 1001 has milk, eggs, and bread while cheese
    is not purchased.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: The process used in Apriori algorithm it will look like the process below in
    Figure 4.2.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 Apriori algorithm process can be depicted as shown here.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_02](images/04_02.png)'
  prefs: []
  type: TYPE_IMG
- en: Let us say we wish to analyze the relationship of bread with all the other items
    in the dataset. In this case, level 1 is Bread and we find its frequency of occurrence.
  prefs: []
  type: TYPE_NORMAL
- en: Then we move to the next layer which is Layer 2\. Now we find the relationship
    of Bread with each of the other items – Milk, Eggs and Cheese which are at Layer
    2\. Here again we find the respective frequencies of occurrence for all the possible
    combinations which are {Bread, Milk}, {Bread, Eggs}, and {Bread, Cheese}. It can
    be shown in Figure 4.3.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 We have bread at Level 1 while the other items (milk, eggs, and cheese)
    are kept at Level 2\. Bread is kept at level 1 since we wish to analyze the relationship
    of bread with all the other items.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_03](images/04_03.png)'
  prefs: []
  type: TYPE_IMG
- en: After Layer 2 has been analyzed, we move to the third layer and fourth layer
    and so on. This process continues till we reach the last layer wherein all the
    items have been exhausted.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of this process, we can calculate the support for all the possible
    combinations. For example, we would know the support for
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread} -> {Milk},'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread} -> {Eggs} and'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread} -> {Cheese}.'
  prefs: []
  type: TYPE_NORMAL
- en: For the next level, we would also get the support for
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread, Milk} -> {Eggs},'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread, Eggs} -> {Milk},'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread, Milk} -> {Cheese},'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread, Cheese} -> {Milk},'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread, Cheese} -> {Eggs} and'
  prefs: []
  type: TYPE_NORMAL
- en: '{Bread, Eggs} -> {Cheese}.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, using the same process, all the possible combinations for the next level
    are calculated. For example, {Bread, Eggs, Milk} -> {Cheese}, {Bread, Eggs, Cheese}
    -> {Milk} and so on.
  prefs: []
  type: TYPE_NORMAL
- en: When all the item sets have been exhausted, the process will stop. The complete
    architecture can look like in Figure 4.4.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 The complete architecture for Apriori algorithm. Here, we would have
    calculated support for all the possible combinations. The relationships between
    all the items are explored and because of this entire database scan, the speed
    of Apriori gets hampered.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_04](images/04_04.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we can easily understand that the possible number of combinations is quite
    high, which is one of the challenges with apriori. There are a few other shortcomings
    for Apriori algorithm which we will study later. But right now is the time to
    implement Apriori using Python.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.1 Python implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will now proceed with Python implementation of Apriori algorithm. The dataset
    and Python Jupyter notebook is checked-in at the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: You might have to install apyori.
  prefs: []
  type: TYPE_NORMAL
- en: To install the libraries, simply do the step below
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 1:** Import the necessary libraries for the use case. We are importing
    numpy, pandas. For implementing apriori, we have a library called apyori which
    is also imported.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2:** We now import the datset store_data.csv file.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You are also advised to have a look at the dataset by opening the .csv file.
    It will look like the screenshot below. The first 25 rows are shown in the screenshot.
    Each row represents an invoice.
  prefs: []
  type: TYPE_NORMAL
- en: '![04_04a](images/04_04a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 3:** Let’s perform some basic checks on the data by `.info`, `.head`
    command.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![04_04b](images/04_04b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![04_04c](images/04_04c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 4:** Here we can see that the first transaction has been considered
    as the header by the code. Hence, we would import the data again but this time
    he would specify that headers are equal to None.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 5:** Let’s look at the head again. This time it looks correct.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![04_04d](images/04_04d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 6:** The library we are using for the code accepts the dataset as a
    list of lists. The entire dataset must be a big list while each transaction is
    an inner list in the big list. So, to achieve it, we first convert our store_dataset
    data frame into a list.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 7:** Next, we implement the Apriori algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: For the algorithm, we are working on `all_records` list we have created in Step
    6\. The minimum support specified is 0.5 or 50%, minimum confidence is 25%, minimum
    lift is 4 and minimum length of the rule is 2.
  prefs: []
  type: TYPE_NORMAL
- en: The output of this step is `apriori_rules` class object. This object is then
    converted into a list which we can understand. And finally, we print this list.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The output of the code will be 0\. It means that no such rules exist which satisfy
    the condition we have set for the rules.
  prefs: []
  type: TYPE_NORMAL
- en: We again try to execute the same code albeit by reducing the minimum support
    to 25%
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Again, no rules are generated and the output is zero. Even reducing the minimum
    support to 10% does not lead to any rules.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, we reduce the minimum lift to 2\. This time we get 200 as the output. It
    means that there are 200 such rules which fulfil the criteria.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 8:** Let’s look at the first rule.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![04_04e](images/04_04e.png)'
  prefs: []
  type: TYPE_IMG
- en: The rule explains the relationship between almonds and burgers. Support is .005
    while the confidence is 0.25\. Lift which is 2.92 indicates that this rule is
    quite strong in itself.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 9:** We will now look at all the rules in detail. For that, loop through
    the rules and extract information from each of the iteration. Each of the rule
    has got the items constituting the rule and respective values for support, confidence
    and lift. We have shown an example in Step 8\. Now in Step 9, we are just extracting
    that information for all of the rules using a for loop.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The output for this step is shown below. Here, we can observe the each rule
    in listed along with the respective values of support, confidence and lift.
  prefs: []
  type: TYPE_NORMAL
- en: '![04_04f](images/04_04f.png)'
  prefs: []
  type: TYPE_IMG
- en: We can interpret the rules easily. For example, rule almonds-> burgers has a
    lift of 2.92 with a confidence of 25.49% and support of 0.51%. This concludes
    our implementation using Python. This example can be extended to any other real-world
    business dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Not all the rules generated are not good for using. We will examine how to get
    the best rules from all the rules generated when we deal with the case study in
    the last section of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Apriori algorithm is a robust and very insightful algorithm. But like any other
    solution, it has a few shortcomings which we are discussing now.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.2 Challenges with Apriori algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We examined in previous sections how the number of subsets generated in Apriori
    algorithm are quite high.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 Complete scan of dataset is done multiple times hence the speed is
    decreased significantly.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_05](images/04_05.png)'
  prefs: []
  type: TYPE_IMG
- en: It is very tedious to generate candidates' item sets and hence it becomes quite
    cumbersome to analyse the dataset. Apriori scans the entire dataset multiple times
    and hence it requires the database to be loaded in the memory. We can safely deduce
    that it requires a lot of time to make the computations. This problem is magnified
    when we are dealing with a very large dataset. In fact, for real-world problems
    where millions of transactions are generated, quite a huge number of candidate
    itemsets are generated and hence it is very time consuming to use Apriori on the
    entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Due to this very reason, generally, a minimum value of support is set to reduce
    number of possible rules. In the example given above, we can calculate the support
    for level 1 combinations as shown below in Table 4.4\. Here, if we set the minimum
    value of support as 0.5, only one rule will be shortlisted.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.4 Support is calculated for each of the combination of the items. For
    example, for milk and bread – the number of transactions is 2 while the total
    number of transactions are 5\. So, the support is 2/5 which is 0.4.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Combination | Number of txns | Total Txns | Support |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Eggs | 2 | 5 | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Bread | 2 | 5 | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Cheese | 0 | 5 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Bread | 4 | 5 | 0.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Cheese | 2 | 5 | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Bread, Cheese | 1 | 5 | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: Setting up a minimum value of support is hence an intelligent tactic to make
    the rules much more manageable. It reduces the time and generates the rules which
    are much more significant. After all, the rules generated from the analysis should
    be generalizable enough so that they can be implemented across the entire data
    base.
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/tgt.png) POP QUIZ – answer these question to check your understanding..
    Answers at the end of the book'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Apriori algorithm scans the database only once. TRUE or FALSE.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   If bananas are present in 5 transactions out of a total of 12 transactions,
    it means the support for banana is 5/12\. TRUE or FALSE.
  prefs: []
  type: TYPE_NORMAL
- en: But Apriori algorithm is a path-breaking solution. It is still highly popular
    and generally one of the very first algorithms whenever association rules are
    discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation is one of the key steps and quite a challenge, we will explore
    this challenge during the case study in the last section of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We will now study the next algorithm, which is ECLAT algorithm
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Equivalence class clustering and bottom-up lattice traversal (ECLAT)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now study Equivalence class clustering and bottom-up lattice traversal
    algorithm or ECLAT in this section, which is sometimes said is better than apriori
    in terms of speed and ease of implementation.
  prefs: []
  type: TYPE_NORMAL
- en: ECLAT uses a depth-first search approach. It means that ECLAT performs the search
    in a vertical fashion throughout the dataset. It starts at the root node. Then
    goes one level deep and continues until it reaches the first terminal note. Let’s
    say the terminal node is at level X. Once the terminal node is reached, the algorithm
    then takes a step back and reaches level (X-1) and continues till it finds a terminal
    node again. Let's understand this process by means of a tree diagram as shown
    in Table 4.6.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 Tree diagram to understand the process of ECLAT algorithm. It starts
    with 1 and ends at 16.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_06](images/04_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ECLAT will take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm starts at the root node 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It then goes one level deep to root node 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It will then continue one more level deep till it reaches terminal node 11.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once it reaches the terminal note 11, it then takes a step back and goes to
    node 5.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The algorithm then searches if there is any node available which can be used.
    At node 5 we can see that there is no such node available.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hence the algorithm again takes a step back and it reaches node 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At node 2, the algorithm explores again. It finds that it is possible to go
    to note 6.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So, the algorithm goes to node 6 and starts exploring again till it reaches
    the terminal node 12.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process continues till all the combinations have been exhausted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obviously, the speed of computation depends on the total number of distinct
    items present in the data set. It is because the number of distinct items define
    the width of the tree. The items purchased in each of the transactions would define
    the relationship between each node.
  prefs: []
  type: TYPE_NORMAL
- en: During execution time of ECLAT, each item (either individually or in a pair)
    is analyzed. Let us use the same example we have used for Apriori to understand
    ECLAT better as shown in Table 4.5.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.5 Data set we are going to use to understand ECLAT. The first invoice
    1001 has milk, eggs, and bread while cheese is not purchased.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'ECLAT will undergo the following steps to analyze the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: In the first run ECLAT will find the invoice numbers for all single items. Or
    in other words, it would find the invoice numbers for all the items individually.
    It can be shown in Table 4.6 below, wherein the milk is present in invoice number
    1001 and 1003 while eggs are present in all the invoices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.6 Respective invoices in which each item is present. Milk is present
    in 1001 and 1003 while eggs is present in five invoices.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Invoice Numbers |'
  prefs: []
  type: TYPE_TB
- en: '| Milk | 1001,1003 |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs | 1001, 1002, 1003, 1004, 1005 |'
  prefs: []
  type: TYPE_TB
- en: '| Bread | 1001, 1002, 1003, 1005 |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese | 1002, 1004 |'
  prefs: []
  type: TYPE_TB
- en: Now in the next step, all the two items dataset are explored as shown below
    in Table 4.7\. For example, milk and eggs are present in invoice number 1001 and
    1003, while milk and cheese are not present in any invoice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.7 Two item data sets are explored now. Milk and eggs are present in
    invoice number 1001 and 1003 while there is no invoice for milk and cheese.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Invoice Numbers |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Eggs | 1001, 1003 |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Bread | 1001, 1003 |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Cheese | - |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Bread | 1001, 1002, 1003, 1005 |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Cheese | 1002, 1004 |'
  prefs: []
  type: TYPE_TB
- en: '| Bread, Cheese | 1002 |'
  prefs: []
  type: TYPE_TB
- en: In the next step, all three item datasets are explored as shown in Table 4.8.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.8 Three item datasets are analyzed in this step. We have two combinations
    only.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Invoice Numbers |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Eggs, Bread | 1001, 1003 |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Bread, Cheese | 1002 |'
  prefs: []
  type: TYPE_TB
- en: There are no invoices present in our data set which contains four items.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now depending on the threshold, we set for the value of the support count, we
    can choose the rules. So, if we want that minimum number of transactions in which
    the rule should be true is equal to three then only one rule qualifies which is
    {Eggs, Bread}. If we decide the threshold for the minimum number of transactions
    as two, then rules like {Milk, Eggs, Bread}, {Milk, Eggs}, {Milk, Bread}, {Eggs,
    Bread} and {Eggs, Cheese} qualify as the rules.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now create a Python solution for ECLAT.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5.1 Python implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will now work on the execution of ECLAT using Python. We are using pyECLAT
    library here. The dataset looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![04_06a](images/04_06a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 1:** We will import the libraries here.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2:** Import the dataset now'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3:** Here we are generating an ECLAT instance.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: There are some properties of ECLAT instance `eclat` generated in the last step
    like eclat.df_bin which is a binary dataframe and eclat.uniq_ which is a list
    of all the unique itesms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4:** We will now fit the model. We are giving a minimum support of 0.02
    here. After that we are printing the support.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The output is
  prefs: []
  type: TYPE_NORMAL
- en: '![04_06b](images/04_06b.png)'
  prefs: []
  type: TYPE_IMG
- en: We can interpret the results here provided based on the support. For each of
    the item and combination of items, we are getting the value of the support. For
    example, for French fries and eggs, the value of support is 3.43%.
  prefs: []
  type: TYPE_NORMAL
- en: ECLAT has some advantages over Apriori algorithm. Since it uses a depth-search
    approach it is faster than Apriori and requires lesser memory to compute. It does
    not scan the dataset iteratively and hence it makes it even faster than Apriori.
    We will compare these algorithms once more after we have studied the last algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now move to the third algorithm: the F-P growth algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 Frequent-Pattern growth algorithm (F-P algorithm)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: F-P algorithm or frequent-pattern growth algorithm is the third algorithm we
    will discuss in this chapter. It is an improvement over the Apriori algorithm.
    Recall in Apriori we face challenges of time-consuming and costly computations.
    FP resolves these issues by representing the database in the form of a tree called
    a *frequent pattern tree or FP tree*. Because of this frequent pattern, there
    is no need for generating the candidates as done in the Apriori algorithm. Let’s
    discuss FP in detail now.
  prefs: []
  type: TYPE_NORMAL
- en: FP tree or Frequent Pattern tree is a tree-shaped structure, and it mines the
    most frequent items in the datasets. This is visualized in Figure 4.7.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.7 FP algorithm can be depicted in a tree-diagram structure. We will
    be creating this tree in a step-by-step fashion. Each node represents a unique
    item. The root node is NULL.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_07](images/04_07.png)'
  prefs: []
  type: TYPE_IMG
- en: Each node represents the unique item in the dataset. The root node of the tree
    is generally kept as NULL. The other nodes in the tree are the items in the dataset.
    The nodes are connected with each other if they are in the same invoice. We will
    study the entire process in a step-by-step fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Assume we are using the following dataset as shown in Table 4.9\. So, we have
    unique items as Apple, Milk, Eggs, Cheese and Bread. There are in total 9 transactions
    and the respective items in each of the transaction is shown in Table 4.9.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.9 Data set we are going to use to understand the concept FP algorithm.
    We have nine transactions here, for example in T1 we have apple, milk, and eggs.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Transactions | Item sets |'
  prefs: []
  type: TYPE_TB
- en: '| T1 | Apple, Milk, Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | Milk, Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | Milk, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| T4 | Apple, Milk, Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| T5 | Apple, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| T6 | Milk, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| T7 | Apple, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| T8 | Apple, Milk, Bread, Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| T9 | Apple, Milk, Bread |'
  prefs: []
  type: TYPE_TB
- en: Let’s apply FP algorithm on this dataset now.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** Like Apriori, the entire dataset is scanned first. Occurrences
    for each of the items is counted and a frequency is generated. The results are
    suggested in Table 4.10\. We have arranged the items in descending order of the
    frequency or the respective support count in the entire dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.10 Respective frequency for each of the item set. For example, apples
    have been purchased in six transactions.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Frequency or Support Count |'
  prefs: []
  type: TYPE_TB
- en: '| Milk | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| Apple | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Bread | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs | 2 |'
  prefs: []
  type: TYPE_TB
- en: If two items have exactly same frequency, anyone can be ordered first. In the
    example above, we have bread and apple having same frequency. So, we can keep
    either bread or apple as the first one.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2:** Let’s start the construction of the FP tree. We start with creating
    the root node which is generally the NULL node in Figure 4.8.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 The root node for the tree is generally kept NULL.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_08](images/04_08.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 3:** Now analyze the first transaction T1\. Here, we have Apple, Milk
    and Eggs in the first transaction. Out of these three, milk has the highest support
    count which is 7\. So, a connection is extended from root node to Milk and we
    denote it by Milk:1\. We have shown in Figure 4.9.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.9 Connection from the root node to Milk. Milk has the highest support
    hence we have chosen milk.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_09](images/04_09.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 4:** We will now look at the other items in T1\. Apple have a support
    count of 6 and Eggs have a support count of 2\. So, we will extend the connection
    from Milk to Apple and name it Apple:1 and then from Apple to Eggs and call it
    Eggs:1\. We have shown in Figure 4.10.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.10 Step 4 of the process where we have finished all the items in T1\.
    All the items milk, apple and eggs are now connected with each other.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_10](images/04_10.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 5:** Let’s look at T2 now. It has Milk and Cheese. Milk is already connected
    to the root node. So, the count for Milk becomes 2 and it becomes Milk:2\. We
    will next create a branch from Milk to cheese and name it Cheese:1\. The addition
    is shown in Figure 4.11.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.11 Step 5 of the process where we started to analyze T2\. Milk is already
    connected so it’s count increases by 2 while cheese gets added to the tree.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_11](images/04_11.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 6:** It is the turn of T3 now. T3 has Milk and Bread. So, similar to
    step 5, the count for milk is 3 and it becomes Milk: 3\. And similar to step 5,
    we add another connection from Milk to Bread and call it Bread:1\. The updated
    tree is shown in Figure 4.12.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.12 In step 6, T3 is analyzed now. Milk’s count increased by one more
    and becomes 3 while bread is added as a new connection.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_12](images/04_12.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 7:** In T4, we have Apple, Milk and Cheese. The count for milk becomes
    4 now, for apple it is now 2\. Then we create a branch from Apple to Cheese calling
    it Cheese:1\. We are showing in Figure 4.13.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.13 In the step 7 of the process, T4 is being analyzed. The count of
    milk becomes 4, for apple it increases to 2 and a new branch from apple to cheese
    is added.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_13](images/04_13.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 8:** We can find in T5 that we have Apple and Bread. Both are not directly
    connected to the root node and have an equal frequency of 6\. So, we can take
    either to be connected to the root node. The figure gets updated to Figure 4.14.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.14 After analyzing T5, the diagram changes as shown here. We have apple
    and bread which get added to the tree.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_14](images/04_14.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 9:** And this process continues till we exhaust all the transactions
    resulting in the final figure as shown in Figure 4.15.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.15 The final tree once we have exhausted all the possible combinations.
    But there are more steps after this. So far, we have created only the tree. Now
    we need to generate the data set as shown in Table 4.11.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_15](images/04_15.png)'
  prefs: []
  type: TYPE_IMG
- en: Great job so far! But the process is not over yet. We have just made the connections
    between the items in the dataset. Now we need to fill a table that looks like
    Table 4.11.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.11 Table we are going to complete for FP algorithm. It is the output
    we wish to generate.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Apple |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: You might be wondering why there are only 4 items listed. Since Milk has directly
    originated from the root node and there is no other way to reach it, we need not
    have a separate row for milk.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 10:** Before continuing, we are fixing the minimum support count as
    2 for any rule to be acceptable. We are doing it for simplicity''s sake as the
    dataset is quite small.'
  prefs: []
  type: TYPE_NORMAL
- en: For real-life business problems, you are advised to test with multiple and even
    much higher values for the support counts otherwise the number of rules generated
    can be very high.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with Cheese as the first item. We can reach cheese through {NULL-Milk-Cheese}
    and {NULL-Milk-Apple-Cheese}. For both paths, the count of Cheese is 1\. Hence,
    (if we ignore NULL) our conditional pattern base is {Milk-Cheese} or {Milk:1}
    and {Milk-Apple:Cheese} or {Milk-Apple:1}. The complete conditional pattern base
    become {{Milk:1},{Milk-Apple:1}}. This information is added to the second column
    of Table 4.12.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.12 Step 10 of the process where we have filled the first cell for cheese.
    We have filled the first cell for cheese.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese | {{Milk:1},{Milk-Apple:1}} |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Apple |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '**Step 11:** Now if we add the two values in conditional pattern base, we would
    get Milk as 2 and Apple as 1\. Since we have set up a threshold for the frequency
    count of 2, we will ignore the count of Apple. The value for conditional FP tree
    which is the third column in the table become {Milk:2}. Now we simply add the
    original item to this which become frequent patten generated or the column 4\.
    The table now is 4-13'
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.13 Step 11 of the process where we have finished the details for the
    item cheese. Similarly, all the other items are going to be analyzed and added
    to the table.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese | {{Milk:1},{Milk-Apple:1}} | {Milk:2} | {Milk-Cheese:2} |'
  prefs: []
  type: TYPE_TB
- en: '| Bread |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Apple |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '**Step 12:** In this similar fashion all the other cells are filled in the
    table resulting in the final table as Table 4.14.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.14 Final table after we analyzed all the combinations for the items.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional Pattern Base | Conditional FP Tree | Frequent Pattern
    Generated |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese | {{Milk:1},{Milk-Apple:1}} | {Milk:2} | {Milk-Cheese:2} |'
  prefs: []
  type: TYPE_TB
- en: '| Bread | {{Milk-Apple:2}, {Milk:2}, {Apple:2}} | {{Milk:4, Apple:2}, {Apple:2}}
    | {Milk-Bread:4}, {Apple-Bread:4}, {Milk-Apple-Bread:2} |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs | {{Milk-Apple:1},{Milk-Apple-Bread:1}} | {Milk:2, Apple:2} | {Milk-Eggs:2},{Milk-Apple:2},{Milk-Apple:2}
    |'
  prefs: []
  type: TYPE_TB
- en: '| Apple | {Milk:4} | {Milk:4} | {Milk-Apple:4} |'
  prefs: []
  type: TYPE_TB
- en: It is a complex process indeed. But once the steps are clear, it is pretty straightforward
    one.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of this exercise, we have received the final set of rules as depicted
    in the final column Frequent Pattern Generated.
  prefs: []
  type: TYPE_NORMAL
- en: Note that none of the rules are similar to each other.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using the final column “Frequent Pattern Generated” as the rules
    for our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The Python implementation for FP growth algorithm is quite simple and is easy
    to compute using the libraries. In the interest of space, we have uploaded the
    Jupyter Notebook to the GitHub repo of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We will now explore another interesting topic which is sequence rule mining.
    It is very powerful solution that allows the business to tailor their marketing
    strategies and product recommendations to the customers.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Sequence rule mining
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider this. Netflix would have a transactional database of all the movies
    ordered by customers over time. If they analyze and find that 65% of customers
    who bought a war movie X also bought a romantic comedy Y in the following month,
    this is very insightful and actionable information. It will allow them to recommend
    their offerings to the customers, and they can customize their marketing strategy.
    Isn’t it?
  prefs: []
  type: TYPE_NORMAL
- en: So far in the chapter, we have covered three algorithms for association rules.
    But all the data points were limited to the same dataset and there was no sequencing
    involved. Sequential pattern mining allows us to analyze a dataset that has a
    sequence of events happening. By analyzing the data set we can find statistically
    relevant patterns, which allows us to decipher the entire sequence of events.
    Obviously, the sequence of events is in a particular order which is a very important
    property to be considered during sequence rule mining.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence rule mining is different from time-series analysis. To know more about
    time-series analysis refer to Appendix.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence rule mining is utilized across multiple domains and functions. It can
    be used in biology to extract information during DNA sequencing or can be used
    to understand the online search pattern of a user. Sequence rule mining would
    help us understand what the user is going to search next. During the discussion
    of association rules, we used the transactions in which milk, bread, eggs were
    purchased in the same transaction. Sequence rule mining is an extension to that
    wherein we analyze consecutive transactions and try to decipher the sequence present
    if any.
  prefs: []
  type: TYPE_NORMAL
- en: While studying SPADE algorithm, we will study the mathematical concepts which
    form the base of the algorithm. These concepts are a little tricky to get and
    might require more than one reading to grasp.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7.1 SPADE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We are now exploring sequence rule mining using Sequential Pattern Discovery
    using Equivalence classes) or SPADE. It was suggested by Mohammed J. Zaki, the
    link to the paper is at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We understand that we wish to analyze the sequence of events. For example, the
    customer bought a mobile phone and a charger. After a week bought earphones and
    after two weeks bought a mobile cover and mobile screen guard. So, in each of
    the transactions, there are items purchased. And each transaction can be called
    as an event. Let’s understand it in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Let us assume we have the complete list of items for the discussion. I will
    contain items like i[1], i[2], i[3], i[4], i[5] and so on. So, we can write
  prefs: []
  type: TYPE_NORMAL
- en: I = {i[1], i[2], i[3], i[4], i[5]………, i[n]} where we have n distinct items in
    total.
  prefs: []
  type: TYPE_NORMAL
- en: Items can be anything. If we consider the same example of a grocery store, items
    can be milk, eggs, cheese, bread and so on.
  prefs: []
  type: TYPE_NORMAL
- en: An event will be a collection of items in the same transaction. An event can
    contain items like (i[1], i[5], i[4], i[8]). For example, an event can contain
    items bought in the same transaction (milk, sugar, cheese, bread). We will denote
    an event by ⍺.
  prefs: []
  type: TYPE_NORMAL
- en: Next let’s understand a sequence. A sequence is nothing but events in an order.
    In other words, ⍺[1] -> ⍺[2] ->⍺[3] ->⍺[4] can be termed as a sequence of event.
    For example, (milk, cheese) -> (bread, eggs)-> (cheese, bread, sugar)-> (milk,
    bread) is a sequence of transactions. It means that in the first transaction milk
    and cheese is bought. In the following transaction, bread and eggs were bought
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: A sequence with k items is a k-item sequence. For example, sequence (Milk, Bread)
    -> (Eggs) contains 3 items.
  prefs: []
  type: TYPE_NORMAL
- en: We will now understand SPADE algorithm step-by-step.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we have the following sequences generated. In the first sequence 1001
    of transactions, milk is bought in the very first transaction. In the second one,
    milk, eggs and bread are bought. They are followed by milk and bread. In the fourth
    one only sugar is purchased. In the fifth and final transaction of sequence 1001,
    bread and apples are purchased. And this is applicable to all the respective sequences.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.15 The dataset for sequence mining. In sequence Id 1001, we have multiple
    events. In the first purchase, milk is bought. Then (milk, eggs, bread) are bought
    and so on.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sequence ID | Sequence |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | <(Milk) (Milk, Eggs, Bread) (Milk, Bread) (Sugar)(Bread, Apple)> |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | <(Milk, Sugar) (Bread) (Eggs, Bread) (Milk, Cheese)> |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | <(Cheese, Apple) (Milk, Eggs) (Sugar, Apple) (Bread) (Eggs)> |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | <(Cheese, Banana)(Milk, Apple)(Bread)(Eggs)(Bread)> |'
  prefs: []
  type: TYPE_TB
- en: This (Table 4.15 ) can be converted into a vertical data format as shown in
    Table 4.16\. In this step, we calculate the frequencies for 1-sequence items,
    which are sequence with only one item. For this only a single database scan is
    required.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.16 Vertical format for Table 4.15\. We have simply got the sequence
    Id and Item id for each of the item and represented it here.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sequence ID | Element ID | Items |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | Milk |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 2 | Milk, Eggs, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 3 | Milk, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 4 | Sugar |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 5 | Bread, Apple |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 1 | Milk, Sugar |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 2 | Bread |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 3 | Eggs, Bread |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 4 | Milk, Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 1 | Cheese, Apple |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 2 | Milk, Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 3 | Sugar, Apple |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 4 | Bread |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 5 | Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 1 | Cheese, Banana |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 2 | Milk, Apple |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 3 | Bread |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 4 | Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 5 | Bread |'
  prefs: []
  type: TYPE_TB
- en: Table 4.16 is nothing but a vertical tabular representation of Table 4.15\.
    For example, in sequence Id 1001, at the element ID 1 we have Milk. For sequence
    ID 1001, at the element ID 2 we have Milk, Eggs, Bread and so on.
  prefs: []
  type: TYPE_NORMAL
- en: For the purpose of explanation, we are considering only two items 0 milk and
    eggs and the support threshold of 2.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in the next step, we will break it down for each of the items. For example,
    milk appears in sequence Id 1001 and element Id 1, sequence Id 1001 and element
    Id 2, sequence Id 1001 and element Id 3, sequence Id 1002 and element Id 1 and
    so on. It results in a table like Table 4.17 where we have shown Milk and Eggs.
    It needs to be applied to all the items in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.17 Respective sequence Ids for milk and eggs. The same can be done across
    all the items and the sequences.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk | Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID | Sequence ID | Element ID |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 1001 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 2 | 1002 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 3 | 1003 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 1 | 1003 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 4 | 1004 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 2 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 3 |  |  |'
  prefs: []
  type: TYPE_TB
- en: Now, we wish to count 2-sequences or with 2 item sequences. We can have two
    sequences – either Milk -> Eggs or Eggs -> Milk. Let’s first take Milk-> Eggs.
  prefs: []
  type: TYPE_NORMAL
- en: For Milk -> Eggs we need to have milk in front of eggs. For the same sequence
    Id, if the element Id of milk is less than the element Id of eggs, then it is
    an eligible sequence. In the example above, for sequence Id 1002, the element
    Id of milk is 1 while the element Id of eggs is 2\. So we can add that as the
    first eligible pair as shown in the first row of Table 4.18\. The same is true
    for sequence Id 1002\. In Table 4.17, row 4 we have sequence Id 1002\. Element
    Id of milk is 1 while that of eggs in row 2 is 3\. Again element Id of milk is
    lesser than element Id of eggs, so it becomes the second entry. And the process
    continues.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.18 Sequence Milk Eggs can be written down here. The key point is to
    have the same sequence Id while comparing the respective element Ids of milk and
    eggs.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 1 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 2 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 3 | 5 |'
  prefs: []
  type: TYPE_TB
- en: By using the same logic, we can create the table for eggs -> milk which is shown
    in Table 4.19 below.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.19 Sequence Eggs Milk can be written down here. The key point is to
    have the same sequence Id while comparing the respective element Ids of milk and
    eggs.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Eggs Milk |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 2 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 3 | 4 |'
  prefs: []
  type: TYPE_TB
- en: This can be done for each of the possible combinations. We will now move to
    creating 3-item sequences and we will create Milk, Eggs -> Milk. For this purpose,
    we have to join the two tables.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.20 Combining both the sequence i.e., milk-> eggs and eggs-> milk to
    join the tables.
  prefs: []
  type: TYPE_NORMAL
- en: '![04_T20](images/04_T20.png)'
  prefs: []
  type: TYPE_IMG
- en: The logic of joining is matching the sequence Id and the element Id. We have
    highlighted the matching ones in red and green color respectively. For sequence
    Id 1001, the element Id of eggs in the left table matches with element Id of eggs
    in the right table and that becomes the first entry of Table 4.21\. Similarly
    for sequence Id 1002, element Id 3 matches. This results in the Table 4.21.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.21 Final table after we analyzed all the combinations for the items.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk, Eggs -> Milk |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) | Element ID (Milk) |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 1 | 2 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 1 | 3 | 4 |'
  prefs: []
  type: TYPE_TB
- en: This process continues. The algorithm stops when no frequent sequences can be
    found.
  prefs: []
  type: TYPE_NORMAL
- en: We will now implement SPADE on a dataset using Python. We are using `pyspade`
    library and hence we have to load the dataset and call the function. It generates
    the result for us. The support is kept as 0.6 here and then we are printing the
    results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![04_15a](images/04_15a.png)'
  prefs: []
  type: TYPE_IMG
- en: This concludes our four algorithms which we wish to discuss in this chapter.
    We will now move to the case study to give a real-life experience to you.
  prefs: []
  type: TYPE_NORMAL
- en: 4.8 Case study for association rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Association rule mining is quite a helpful and powerful solution. We are going
    to solve an actual case study using association rules.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that at the start of the chapter, we suggested to study the pattern of
    a grocery store. What is the logic of such arrangements in the store?
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this: You are working for a grocery retailer like Walmart or Tesco
    or Spar or Marks & Spencer’s etc. And they have to plan the visual layout of a
    new store. Obviously, it is imperative that retail stores utilize the space in
    the store wisely and to the maximum of its capacity. At the same time, it is vital
    that the movement of the customers is not hindered. Customers should have access
    to all the items at display and can navigate easily. You might have experienced
    some stores where we feel choked and bombarded with displays while others are
    neatly stacked.'
  prefs: []
  type: TYPE_NORMAL
- en: How do we solve this problem?
  prefs: []
  type: TYPE_NORMAL
- en: There can be multiple solutions to this problem. Some retailers might wish to
    group the items based on their categories. They might want to keep all the baking
    products in one shelf or use any other condition. We are studying the machine
    learning example here.
  prefs: []
  type: TYPE_NORMAL
- en: Using market basket analysis, we can generate the rules which indicate the respective
    relationships between various items. We can predict which items are frequently
    bought together and they can be kept together in the store. For example, if we
    know that milk and bread are bought together, then bread can be kept near the
    milk counter. The customer purchasing milk can locate bread easily and continue
    with their purchase.
  prefs: []
  type: TYPE_NORMAL
- en: But it is not as easy as it sounds. Let us solve this case step-by-step.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business problem definition**: the very first step is defining the business
    problem which is clear to us. We wish to discover the relationships between various
    items so that the arrangement in the store can be made better. Here *planograms*
    come into the picture. Planograms help the retailer plan the utilization of the
    space in the store in a wise manner so that the customer can also navigate and
    access the products easily. It can be considered as a visual layout of the store.
    An example can be shown as in Figure 4.16.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 4.16 An example of planogram is shown here. Planograms are very useful
    for visual merchandising.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![04_16](images/04_16.png)'
  prefs: []
  type: TYPE_IMG
- en: In the figure, we can see that there are specific areas for each and every item
    category. Association rules are quite insightful to help generate directions for
    planograms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data discovery**: the next step is the data discovery wherein the historical
    transactions are scouted and loaded into a database. Typically, a transaction
    can look like the Table 4.22.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.22 Example of invoices generated in real-world retail store. It is quite
    a challenge to convert this data format into the one which can be consumed by
    the association rule algorithms.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Date | Items | Amount |'
  prefs: []
  type: TYPE_TB
- en: '| 1001 | 01-Jun-21 | Milk, eggs, cheese, bread | $10 |'
  prefs: []
  type: TYPE_TB
- en: '| 1002 | 01-Jun-21 | Bread, banana, apples, butter | $15 |'
  prefs: []
  type: TYPE_TB
- en: '| 1003 | 01-Jun-21 | Butter, carrots, cheese, eggs, bread, milk, bananas |
    $19 |'
  prefs: []
  type: TYPE_TB
- en: '| 1004 | 01-Jun-21 | Milk | $1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1005 | 01-Jun-21 | Bread | $0.80 |'
  prefs: []
  type: TYPE_TB
- en: '**Data preparation**: this step perhaps is the most difficult step. As you
    would have realized that association rules model creation is a very simple task.
    We have libraries that can do the heavy lifting for us. But the data set expected
    by them is in a particular format. This is a tedious task, quite time-consuming
    and requires a lot of data pre-processing skills.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are a few considerations you have to keep in mind while preparing the
    data set, which are:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Sometimes we get **NULL** or **blank values** during the data preparation phase.
    Missing values in the data sets can lead to problems while computing. In other
    machine learning solution, we would advise to treat the missing values. In the
    case of association rules, we would suggest to ignore the respective transactions
    and do not consider it in the final dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Many times, we get **junk values** in the data. Special characters like !@%^&*()_
    are found in the datasets. It can be attributed to incorrect entries in the system.
    Hence, data cleaning is required.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are covering the data pre-processing step in great detail in the appendix
    of the book, wherein we deal with NULL values and junk values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Converting Table into a format which can be understood and consumed by the association
    rule learning algorithms is an imperative but arduous step. Go through the concept
    of SQL pivoting to understand the concept better. Else, you might need someone
    (a data engineer) to create the dataset for you.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model preparation:** perhaps the easiest of the steps is modelling. We have
    already solved Python solutions for different algorithms. So, you should be quite
    comfortable with it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model interpretation**: creating the model might be easy but interpretation
    of the rules is not. Most of the time, you can rules like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '#NA -> (Milk, Cheese) – such a rule is obviously non-usable and does ot make
    any sense. It indicated that the data preparation was not correct and some junk
    values are still present in the dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Some items) -> (Packaging material) – perhaps the most obvious rule but again
    not usable. This rule indicates that whenever shopping is done, packaging material
    is also purchased, quite obvious right?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Potatoes, Tomatoes) -> (Onions) : this kind of rule might look correct but
    it a common sense knowledge that the retailer would already know. Obviously, most
    of the customers who are buying vegetables will buy potatoes, tomatoes, and onions
    together. Such rules, might not add much value to the business.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Threshold for support, confidence and lift allows to filter out the most important
    rules. We can sort the rules in the descending order of the lift and then remove
    the most obvious ones.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Business subject-matter expert**: it is of vital importance that business
    stakeholders and subject matter experts are involved at each and every step. In
    this case study, the operations team, visual merchandising team, product teams
    and marketing teams are the key players which should be closely aligned at each
    and every step.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the rules are generated and accepted, then we can use them to improve the
    planogram for the retail space. The retailer can use them to improve the marketing
    strategy and improve product promotions. For example, if a rule like (A, B) ->
    (C) is accepted, the retailer might wish to create a bundle of the products and
    sell them as a single entity. It will increase the average number of items purchased
    in the same transaction for the business.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This case study can be extended to any other domain or business function. For
    example, the same steps can be used if we wish to examine user’s movement across
    web pages. Web developers can analyze the historical clicks and usages of the
    customers on their websites. By identifying the patterns, they can find out what
    user tends to click and which features will maximize their engagement. Medical
    practitioners can use association rules to better diagnose patients. The doctors
    can compare the probability of the symptoms in relationship with other symptoms
    and provide a more accurate diagnosis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now examine the limitations of these algorithms and other solutions
    which are available for association rules and sequence rules.
  prefs: []
  type: TYPE_NORMAL
- en: 4.9 Closing Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are some assumptions and limitations in the association rules and sequence
    rules we have studied.
  prefs: []
  type: TYPE_NORMAL
- en: The respective significance of an item is ignored while we generate the rules.
    For example, if a customer purchased 5 cans of milk and one kg of apples in a
    transaction, it is treated similarly to an invoice in which one can of milk and
    five kg of apples are purchased. Hence, we have to bear in mind that the respective
    *weight* of an item in not being considered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cost of an item indicated the perceived value of a product. Some products
    which are costly are more important and hence, if they are purchased by the customer
    more revenue can be generated. While analyzing the invoices, we ignore the cost
    associated with an item.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: While analyzing the sequence, we have not considered the respective time periods
    between the two transactions. For example, if between T1 and T2, there were 10
    days while between T2 and T3 there were 40 days – both are considered as same.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In all the analyses, we have considered different categories as the same. Perishable
    items and non-perishable items are treated in a similar fashion. For example,
    fresh milk with a shelf life of 2-3 days is treated similarly to washing powder
    which has unlimited shelf life.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Many times we receive non-interesting rules after analysis. These results are
    from common sense (Potatoes, Tomatoes) -> (Onion). Such rules are not of much
    use. We face such an issue a lot of the time.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: While non-interesting rules are a challenge, a huge number of discovered rules
    are again one of the problems. We get hundreds of rules and it becomes difficult
    to understand and analyze each one of them. Here, the thresholding becomes handy.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The time and memory requirements for computations are huge. The algorithms require
    scanning the data sets many times and hence it is quite a time-consuming exercise.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The rules generated are dependent on the data set which has been used for analysis.
    For example, if we analyze the data set generated during summers only, we cannot
    use the rules for winters as consumers' preferences change between different weathers.
    Moreover, we have to refresh the algorithms over time since with the passage of
    time, the macro and micro economic factors change and hence, the algorithms should
    be refreshed too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are some other algorithms which are also of interest. For association
    rules, we can have multi-relation association rules, k-optimal pattern discovery,
    approximate frequent data set, generalized association rules, high order pattern
    discovery etc. For sequence mining, we have Generalized Sequence Pattern, FreeSpan,
    PrefixSpan, Mining associated patterns etc. These algorithms are quite interesting
    and can be studied for knowledge enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: Association rules and sequence mining are quite interesting topics. Various
    business domains and functions are increasingly using association rules to understand
    the pattern of events. These insights allow the teams to take sound and scientific
    decisions to improve the customer experience and overall engagement. This chapter
    is the first chapter in the second part of the book. We have explored association
    rules and sequence mining in this chapter. These are studied using Apriori, FP
    and ECLAT algorithms and for sequence mining we used SPADE.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are studying advanced clustering algorithms. So stay
    tuned!
  prefs: []
  type: TYPE_NORMAL
- en: You can now progress to question section.
  prefs: []
  type: TYPE_NORMAL
- en: Practical next steps and suggested readings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Go through these research papers for association rules algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fast discovery of association rules ([http://www.cs.bme.hu/~marti/adatbanya/apriori_hashtree.pdf](adatbanya.html))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fast algorithms for Mining Association Rules ([https://rakesh.agrawal-family.com/papers/vldb94apriori.pdf](papers.html))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Efficient analysis of Pattern and Association Rule Mining Approaches ([https://arxiv.org/pdf/1402.2892.pdf](pdf.html))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A review of association rule mining techniques with respect to their privacy
    preserving capabilities ([https://www.ripublication.com/ijaer17/ijaerv12n24_216.pdf](ijaer17.html))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For sequence mining, go through these research papers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SPADE: An efficient algorithm for mining frequent sequences ([https://link.springer.com/content/pdf/10.1023/A:1007652502315.pdf](10.1023.html))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sequential mining: patterns and algorithm analysis ([https://arxiv.org/pdf/1311.0350.pdf](pdf.html))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sequential pattern mining algorithm based on interestingness ([https://ieeexplore.ieee.org/document/8567170](document.html))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A new approach for problem of Sequential Pattern Mining ([https://link.springer.com/chapter/10.1007/978-3-642-34630-9_6](10.1007.html))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 4.10 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We studied association rules which can be used to find compelling relationships
    between the variables which are present in the data sets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We covered the concepts of support, confidence, lift, and conviction which are
    used to measure the efficacy of the rules generated.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We then moved to apriori algorithm which utilizes a “bottom-up” approach where
    the first candidates are generated based of the frequency of the subsets. Apriori
    scans the entire data iteratively and hence takes a lot of time.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We discussed ECLAT which is a depth-first search method. It performs the search
    in a vertical fashion throughout the dataset. Since it does not scan the dataset
    iteratively, it is faster than apriori.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We also covered frequent-pattern growth algorithm which works on representing
    the data base in the form of a tree called a frequent pattern tree or FP tree.
    Because of this frequent pattern, there is no need for generating the candidates
    as done in Apriori algorithm and hence it is less time-consuming.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We then covered sequence-based learning technique known as SPADE where we also
    take the sequence in which the various events have happened in a particular sequence.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We finally had the Python implementation of the techniques using apyori, pyECLAT,
    fpgrowth_py and pyspade.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
