["```py\npip install kaen[cli,docker]\n```", "```py\nkaen --help\n```", "```py\nUsage: kaen [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  dojo     Manage a dojo training environment.\n  hpo      Manage hyperparameter optimization.\n  init     Initialize a training dojo in a specified infrastructure...\n  job      Manage jobs in a specific dojo training environment.\n  jupyter  Work with a Jupyter notebook environment.\n```", "```py\nkaen jupyter\n```", "```py\nStarted Jupyter. Attempting to navigate to Jupyter in your browser using\n➥ http://127.0.0.1:8888/?token=...\n```", "```py\n!mkdir -p src\n```", "```py\n%%writefile src/model_v1.py\nimport sys\nimport json\nimport time\nimport torch as pt\nimport pytorch_lightning as pl\nfrom distutils.util import strtobool\n\npt.set_default_dtype(pt.float64)\nclass DcTaxiModel(pl.LightningModule):\n    def __init__(self, **kwargs):\n      super().__init__()\n      self.save_hyperparameters()\n      pt.manual_seed(int(self.hparams.seed))\n\n      self.step = 0\n      self.start_ts = time.perf_counter()\n      self.train_val_rmse = pt.tensor(0.)\n\n      #create a list of hidden layer neurons, e.g. [3, 5, 8]\n      num_hidden_neurons = json.loads(self.hparams.num_hidden_neurons)\n\n      self.layers = \\\n        pt.nn.Sequential(\n          pt.nn.Linear(int(self.hparams.num_features),\n                        num_hidden_neurons[0]),\n          pt.nn.ReLU(),\n          *self.build_hidden_layers(num_hidden_neurons, pt.nn.ReLU()),\n          pt.nn.Linear(num_hidden_neurons[-1], 1)\n      )\n\n      if 'batch_norm_linear_layers' in self.hparams \\\n        and strtobool(self.hparams.batch_norm_linear_layers):\n        self.layers = self.batch_norm_linear(self.layers)\n\n    def build_hidden_layers(self, num_hidden_neurons, activation):\n      linear_layers = [ pt.nn.Linear(num_hidden_neurons[i],\n          num_hidden_neurons[i+1]) \\\n            for i in range(len(num_hidden_neurons) - 1) ]\n\n      classes = [activation.__class__] * len(num_hidden_neurons)\n\n      activation_instances = list(map(lambda x: x(), classes))\n\n      hidden_layer_activation_tuples = \\\n        list(zip(linear_layers, activation_instances))\n\n      hidden_layers = [i for sublist in \\\n        hidden_layer_activation_tuples for i in sublist]\n\n      return hidden_layers\n\n    def batch_norm_linear(self, layers):\n      idx_linear = \\\n        list(filter(lambda x: type(x) is int,\n            [idx if issubclass(layer.__class__, pt.nn.Linear) else None \\\n              for idx, layer in enumerate(layers)]))\n      idx_linear.append(sys.maxsize)\n      layer_lists = [list(iter(layers[s:e])) \\\n        for s, e in zip(idx_linear[:-1], idx_linear[1:])]\n      batch_norm_layers = [pt.nn.BatchNorm1d(layer[0].in_features) \\\n        for layer in layer_lists]\n      batch_normed_layer_lists = [ [bn, *layers] \\\n        for bn, layers in list(zip(batch_norm_layers, layer_lists)) ]\n      return pt.nn.Sequential(*[layer \\\n        for nested_layer in batch_normed_layer_lists \\\n        for layer in nested_layer ])\n\n    def batchToXy(self, batch):\n      batch = batch.squeeze_()\n      X, y = batch[:, 1:], batch[:, 0]\n      return X, y\n\n    def forward(self, X):\n      y_est = self.layers(X)\n      return y_est.squeeze_()\n\n    def log(self, k, v, **kwargs):\n        super().log(k, v,\n                on_step = kwargs['on_step'],\n                on_epoch = kwargs['on_epoch'],\n                prog_bar = kwargs['prog_bar'],\n                logger = kwargs['logger'],)\n\n    def training_step(self, batch, batch_idx):\n        self.step += 1\n\n        X, y = self.batchToXy(batch) #unpack batch into features and label\n\n        y_est = self.forward(X)\n\n        loss = pt.nn.functional.mse_loss(y_est, y)\n\n        for k,v in {\n          \"train_step\": self.step,\n          \"train_mse\": loss.item(),\n          \"train_rmse\": loss.sqrt().item(),\n          \"train_steps_per_sec\": \\\n            self.step / (time.perf_counter() - self.start_ts),\n\n        }.items():\n          self.log(k, v, step = self.step, on_step=True, on_epoch=True,\n                                            prog_bar=True, logger=True)\n\n        self.train_val_rmse = loss.sqrt()\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n      X, y = self.batchToXy(batch)\n\n      with pt.no_grad():\n          loss = pt.nn.functional.mse_loss(self.forward(X), y)\n\n      for k,v in {\n        \"val_mse\": loss.item(),\n        \"val_rmse\": loss.sqrt().item(),\n        \"train_val_rmse\": (self.train_val_rmse + loss.sqrt()).item(),\n      }.items():\n        self.log(k, v, step = self.step, on_step=True, on_epoch=True,\n                                          prog_bar=True, logger=True)\n\n      return loss\n\n    def test_step(self, batch, batch_idx):\n      X, y = self.batchToXy(batch)\n\n      with pt.no_grad():\n          loss = pt.nn.functional.mse_loss(self.forward(X), y)\n\n      for k,v in {\n          \"test_mse\": loss.item(),\n          \"test_rmse\": loss.sqrt().item(),\n      }.items():\n        self.log(k, v, step = self.step, on_step=True, on_epoch=True,\n                                          prog_bar=True, logger=True)\n\n    def configure_optimizers(self):\n        optimizers = {'Adam': pt.optim.AdamW,\n                      'SGD': pt.optim.SGD}\n        optimizer = optimizers[self.hparams.optimizer]\n\n        return optimizer(self.layers.parameters(),\n                            lr = float(self.hparams.lr))\n```", "```py\n%%writefile src/trainer.py\nfrom model_v1 import DcTaxiModel\n\nimport os\nimport time\nimport kaen\nimport torch as pt\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch.distributed as dist\nfrom torch.utils.data import DataLoader\nfrom torch.nn.parallel import DistributedDataParallel\n\nfrom kaen.torch import ObjectStorageDataset as osds\n\ndef train(model, train_glob, val_glob, test_glob = None):\n    #set the pseudorandom number generator seed\n    seed = int(model.hparams['seed']) \\                          ❶\n                if 'seed' in model.hparams \\\n                else int( datetime.now().microsecond )\n\n    np.random.seed(seed)\n    pt.manual_seed(seed)\n\n    kaen.torch.init_process_group(model.layers)                  ❷\n\n    trainer = pl.Trainer(gpus = pt.cuda.device_count() \\\n                            if pt.cuda.is_available() else 0,\n        max_epochs = 1,\n        limit_train_batches = int( model.hparams.max_batches ) \\\n                                 if 'max_batches' in model.hparams else 1,\n        limit_val_batches = 1,\n        num_sanity_val_steps = 1,\n        val_check_interval = min(20, int( model.hparams.max_batches ) ),\n        limit_test_batches = 1,\n        log_every_n_steps = 1,\n        gradient_clip_val=0.5,\n        progress_bar_refresh_rate = 0,\n        weights_summary = None,)\n\n    train_dl = \\\n    DataLoader(osds(train_glob,\n                    worker = kaen.torch.get_worker_rank(),\n                    replicas = kaen.torch.get_num_replicas(),\n                    shard_size = \\                              ❸\n                      int(model.hparams.batch_size),\n                    batch_size = \\                              ❹\n                      int(model.hparams.batch_size),\n                    storage_options = {'anon': False},\n                   ),\n               pin_memory = True)\n\n    val_dl = \\\n    DataLoader(osds(val_glob,\n                    batch_size = int(model.hparams.batch_size),\n                    storage_options = {'anon': False},\n                   ),\n               pin_memory = True)\n\n    trainer.fit(model,\n              train_dataloaders = train_dl,\n              val_dataloaders = val_dl)\n    if test_glob is not None:\n        test_dl = \\\n          DataLoader(osds(test_glob,\n                          batch_size = int(model.hparams.batch_size),\n                          storage_options = {'anon': False},\n                         ),\n                    pin_memory = True)\n\n        trainer.test(model,\n                    dataloaders=test_dl)\n\n    return model, trainer\n\nif __name__ == \"__main__\":\n    model, trainer = train(DcTaxiModel(**{\n            \"seed\": \"1686523060\",\n            \"num_features\": \"8\",\n            \"num_hidden_neurons\": \"[3, 5, 8]\",\n            \"batch_norm_linear_layers\": \"1\",\n            \"optimizer\": \"Adam\",\n            \"lr\": \"0.03\",\n            \"max_batches\": \"1\",\n            \"batch_size\": str(2 ** 18),}),\n\n      train_glob = \\\n        os.environ['KAEN_OSDS_TRAIN_GLOB'] \\\n          if 'KAEN_OSDS_TRAIN_GLOB' in os.environ \\\n          else 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/train.csv',\n\n      val_glob = \\\n        os.environ['KAEN_OSDS_VAL_GLOB'] \\\n          if 'KAEN_OSDS_VAL_GLOB' in os.environ \\\n          else 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/valid.csv',\n\n      test_glob = \\\n        os.environ['KAEN_OSDS_TEST_GLOB'] \\\n          if 'KAEN_OSDS_TEST_GLOB' in os.environ \\\n          else 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/valid.csv')\n\n    print(trainer.callback_metrics)\n```", "```py\n%%bash\npython3 src/trainer.py\n```", "```py\n#pytorch distributed training requires MASTER_ADDR and MASTER_PORT to be set\nos.environ['MASTER_ADDR'] = \\\n  os.environ['KAEN_JOB_MANAGER_IP'] \\                            ❶\n  if 'KAEN_JOB_MANAGER_IP' in os.environ else \"127.0.0.1\"\n\nMASTER_ADDR = os.environ['MASTER_ADDR']\nos.environ['MASTER_PORT'] = \\                                    ❷\n  os.environ['MASTER_PORT'] if 'MASTER_PORT' in os.environ else \"12355\"\nMASTER_PORT = os.environ['MASTER_PORT']\n\nBACKEND = os.environ['KAEN_BACKEND'] \\                           ❸\n                    if 'KAEN_BACKEND' in os.environ else \"gloo\"\nRANK = int(os.environ['KAEN_RANK'])                              ❹\nWORLD_SIZE = int(os.environ['KAEN_WORLD_SIZE'])                  ❺\n\nif not dist.is_initialized():\n    dist.init_process_group(init_method = \"env://\",              ❻\n                            backend = BACKEND,\n                            rank = RANK,\n                            world_size = WORLD_SIZE)\n    model.layers = \\                                              ❼\n      DistributedDataParallel(model.layers, device_ids=[])\n```", "```py\nDOCKER_HUB_USER = input()\nDOCKER_HUB_USER\n```", "```py\nimport getpass\nDOCKER_HUB_PASSWORD = getpass.getpass()\n\n!echo \"{DOCKER_HUB_PASSWORD}\" | \\\ndocker login --username {DOCKER_HUB_USER} --password-stdin\n\nDOCKER_HUB_PASSWORD = None\n```", "```py\n!docker pull kaenai/pytorch-mlflow-aws-base:latest\n```", "```py\n%%writefile Dockerfile\nFROM kaenai/pytorch-mlflow-aws-base:latest\nCOPY *.py /workspace/\n```", "```py\n!docker build -t {DOCKER_HUB_USER}/dctaxi:latest -f Dockerfile src/\n```", "```py\n!docker run -it {DOCKER_HUB_USER}/dctaxi:latest \\\n\"python /workspace/trainer.py\"\n```", "```py\n!docker push {DOCKER_HUB_USER}/dctaxi:latest\n```", "```py\nimport optuna\nimport numpy as np\nfrom kaen.hpo.optuna import BaseOptunaService\nclass DcTaxiHpoService(BaseOptunaService):\n  def hparams(self):\n    trial = self._trial         ❶\n\n    #define hyperparameter\n    return {\n        \"seed\": \\               ❷\n          trial.suggest_int('seed', 0, np.iinfo(np.int32).max)\n    }\n```", "```py\ndef hparams(self):\n  trial = self._trial\n\n  return {\n    \"seed\": \\\n        trial.suggest_int('seed', 0, np.iinfo(np.int32).max - 1),\n\n    \"optimizer\": \\\n        trial.suggest_categorical('optimizer', ['Adam']),\n\n    \"lr\": \\\n        trial.suggest_loguniform('lr', 0.001, 0.1),\n\n    \"num_hidden_neurons\": \\\n        [trial.suggest_categorical(f\"num_hidden_layer_{layer}_neurons\", \\\n            [7, 11, 13, 19, 23]) for layer in \\\n            range(trial.suggest_categorical('num_layers',\n                                            [11, 13, 17, 19]))],\n\n    \"batch_size\": \\\n        trial.suggest_categorical('batch_size',\n                                  [2 ** i for i in range(16, 22)]),\n\n    \"max_batches\": \\\n        trial.suggest_int('max_batches', 40, 400, log = True)\n  }\n```", "```py\ndef on_experiment_end(self, experiment, parent_run):\n    study = self._study\n    try:\n      for key, fig in {\n        \"plot_param_importances\": \\\n            optuna.visualization.plot_param_importances(study),\n\n        \"plot_parallel_coordinate_all\": \\\n            optuna.visualization.plot_parallel_coordinate(study, \\\n                params=[\"max_batches\",\n                        \"lr\",\n                        \"num_hidden_layer_0_neurons\",\n                        \"num_hidden_layer_1_neurons\",\n                        \"num_hidden_layer_2_neurons\"]),\n\n        \"plot_parallel_coordinate_l0_l1_l2\": \\\n            optuna.visualization.plot_parallel_coordinate(study, \\\n                params=[\"num_hidden_layer_0_neurons\",\n                        \"num_hidden_layer_1_neurons\",\n                        \"num_hidden_layer_2_neurons\"]),\n\n        \"plot_contour_max_batches_lr\": \\\n            optuna.visualization.plot_contour(study, \\\n                params=[\"max_batches\", \"lr\"]),\n      }.items():\n        fig.write_image(key + \".png\")\n        self.mlflow_client.log_artifact(run_id = parent_run.info.run_id,\n                            local_path = key + \".png\")\n\n    except:\n      print(f\"Failed to correctly persist experiment \n➥             visualization artifacts\")\n      import traceback\n      traceback.print_exc()\n\n    #log the dataframe with the study summary\n    study.trials_dataframe().describe().to_html(experiment.name + \".html\")\n    self.mlflow_client.log_artifact(run_id = parent_run.info.run_id,\n                        local_path = experiment.name + \".html\")\n\n    #log the best hyperparameters in the parent run\n    self.mlflow_client.log_metric(parent_run.info.run_id,\n                                  \"loss\", study.best_value)\n    for k, v in study.best_params.items():\n      self.mlflow_client.log_param(parent_run.info.run_id, k, v)\n```", "```py\n%%writefile src/hpo.py\nimport optuna\nimport numpy as np\nfrom kaen.hpo.optuna import BaseOptunaService\n\nclass DcTaxiHpoService(BaseOptunaService):\n  def hparams(self):\n    trial = self._trial\n\n    #define hyperparameters\n    return {\n      \"seed\": trial.suggest_int('seed', 0, np.iinfo(np.int32).max - 1),\n      \"optimizer\": trial.suggest_categorical('optimizer', ['Adam']),\n      \"lr\": trial.suggest_loguniform('lr', 0.001, 0.1),\n      \"num_hidden_neurons\": \\\n        [trial.suggest_categorical(f\"num_hidden_layer_{layer}_neurons\",\n          [7, 11, 13, 19, 23]) for layer in \\\n            range(trial.suggest_categorical('num_layers',\n                                            [11, 13, 17, 19]))],\n\n      \"batch_size\": \\\n        trial.suggest_categorical('batch_size', \\\n                                  [2 ** i for i in range(16, 22)]),\n\n      \"max_batches\": trial.suggest_int('max_batches', 40, 400, log = True)\n    }\n\n  def on_experiment_end(self, experiment, parent_run):\n    study = self._study\n    try:\n      for key, fig in {\n        \"plot_param_importances\": \\\n          optuna.visualization.plot_param_importances(study),\n        \"plot_parallel_coordinate_all\": \\\n          optuna.visualization.plot_parallel_coordinate(study,\n            params=[\"max_batches\",\n                    \"lr\",\n                    \"num_hidden_layer_0_neurons\",\n                    \"num_hidden_layer_1_neurons\",\n                    \"num_hidden_layer_2_neurons\"]),\n        \"plot_parallel_coordinate_l0_l1_l2\": \\\n          optuna.visualization.plot_parallel_coordinate(study,\n            params=[\"num_hidden_layer_0_neurons\",\n            \"num_hidden_layer_1_neurons\",\n            \"num_hidden_layer_2_neurons\"]),\n\n        \"plot_contour_max_batches_lr\": \\\n          optuna.visualization.plot_contour(study,\n            params=[\"max_batches\", \"lr\"]),\n      }.items():\n        fig.write_image(key + \".png\")\n        self.mlflow_client.log_artifact(run_id = parent_run.info.run_id,\n                            local_path = key + \".png\")\n\n    except:\n      print(f\"Failed to correctly persist experiment \n➥             visualization artifacts\")\n      import traceback\n      traceback.print_exc()\n\n    #log the dataframe with the study summary\n    study.trials_dataframe().describe().to_html(experiment.name + \".html\")\n    self.mlflow_client.log_artifact(run_id = parent_run.info.run_id,\n                        local_path = experiment.name + \".html\")\n\n    #log the best hyperparameters in the parent run\n    self.mlflow_client.log_metric(parent_run.info.run_id,\n                                    \"loss\", study.best_value)\n    for k, v in study.best_params.items():\n      self.mlflow_client.log_param(parent_run.info.run_id, k, v)\n```", "```py\n!docker pull kaenai/optuna-mlflow-hpo-base:latest\n```", "```py\n%%writefile Dockerfile\nFROM kaenai/optuna-mlflow-hpo-base:latest\nENV KAEN_HPO_SERVICE_PREFIX=hpo \\\n    KAEN_HPO_SERVICE_NAME=DcTaxiHpoService\n\nCOPY hpo.py /workspace/.\n```", "```py\n!docker build -t {DOCKER_HUB_USER}/dctaxi-hpo:latest -f Dockerfile src/\n```", "```py\n!docker push {DOCKER_HUB_USER}/dctaxi-hpo:latest.\n```", "```py\n%%writefile src/experiment.py\nimport os\nfrom model_v1 import DcTaxiModel\nfrom trainer import train\nfrom kaen.hpo.client import BaseMLFlowClient\n\nclass DcTaxiExperiment(BaseMLFlowClient):\n\n    def on_run_start(self, run_idx, run):\n        print(f\"{run}({run.info.status}): starting...\")\n\n        #create a set of default hyperparameters\n        default_hparams = {\"seed\": \"1686523060\",\n                        \"num_features\": \"8\",\n                        \"num_hidden_neurons\": \"[3, 5, 8]\",\n                        \"batch_norm_linear_layers\": \"1\",\n                        \"optimizer\": \"Adam\",\n                        \"lr\": \"0.03\",\n                        \"max_batches\": \"1\",\n                        \"batch_size\": str(2 ** 18),}\n\n        #fetch the MLFlow hyperparameters if available\n        hparams = run.data.params if run is not None \\\n                    and run.data is not None else \\\n                    default_hparams\n\n        #override the defaults with the MLFlow hyperparameters\n        hparams = {**default_hparams, **hparams}\n\n        untrained_model = DcTaxiModel(**hparams)\n        def log(self, k, v, **kwargs):\n            if self.mlflow_client and 0 == int(os.environ['KAEN_RANK']):\n                if 'step' in kwargs and kwargs['step'] is not None:\n                    self.mlflow_client.log_metric(run.info.run_id,\n                      k, v, step = kwargs['step'])\n                else:\n                    self.mlflow_client.log_metric(run.info.run_id,\n                       k, v)\n\n        import types\n        untrained_model.log = types.MethodType(log, self)\n\n        model, trainer = \\\n          train(untrained_model,\n                train_glob = os.environ['KAEN_OSDS_TRAIN_GLOB'],\n                val_glob = os.environ['KAEN_OSDS_VAL_GLOB'],\n                test_glob = os.environ['KAEN_OSDS_TEST_GLOB'])\n\n        print(trainer.callback_metrics)\n```", "```py\n%%writefile Dockerfile\nFROM kaenai/pytorch-mlflow-aws-base:latest\nCOPY * /workspace/\nENV KAEN_HPO_CLIENT_PREFIX=experiment \\\n    KAEN_HPO_CLIENT_NAME=DcTaxiExperiment\n```", "```py\n!docker build -t {DOCKER_HUB_USER}/dctaxi:latest -f Dockerfile src/\n```", "```py\n!docker push {DOCKER_HUB_USER}/dctaxi:latest.\n```", "```py\n!kaen dojo init --provider local\n```", "```py\n!kaen dojo ls\n```", "```py\n[MOST_RECENT_DOJO] = !kaen dojo ls | head -n 1\nMOST_RECENT_DOJO\n```", "```py\n!kaen dojo activate {MOST_RECENT_DOJO}\n```", "```py\n!kaen dojo inspect {MOST_RECENT_DOJO}\n```", "```py\n!kaen job create --dojo {MOST_RECENT_DOJO} \\\n--image {DOCKER_HUB_USER}/dctaxi:latest\n```", "```py\n[MOST_RECENT_JOB] = !kaen job ls | head -n 1\nMOST_RECENT_JOB\n```", "```py\n!kaen job inspect {MOST_RECENT_JOB}\n```", "```py\n!kaen hpo enable \\\n--image {DOCKER_HUB_USER}/dctaxi-hpo:latest \\\n--num-runs 1 \\\n--service-prefix hpo \\\n--service-name DcTaxiHpoService \\\n--port 5001 5001 \\\n{MOST_RECENT_JOB}\n```", "```py\n!kaen job inspect {MOST_RECENT_JOB}\n```", "```py\nimport os\nos.environ['MOST_RECENT_JOB'] = MOST_RECENT_JOB\n\nos.environ['BUCKET_ID'] = None\nos.environ['AWS_ACCESS_KEY_ID'] = None\nos.environ['AWS_SECRET_ACCESS_KEY'] = None\nos.environ['AWS_DEFAULT_REGION'] = None\n```", "```py\n%%bash\necho $BUCKET_ID\necho $AWS_ACCESS_KEY_ID\necho $AWS_SECRET_ACCESS_KEY\necho $AWS_DEFAULT_REGION\necho $MOST_RECENT_JOB\n```", "```py\n!kaen job start \\\n--replicas 1 \\\n-e KAEN_HPO_JOB_RUNS 1 \\\n-e AWS_DEFAULT_REGION $AWS_DEFAULT_REGION \\\n-e AWS_ACCESS_KEY_ID $AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY $AWS_SECRET_ACCESS_KEY \\\n-e KAEN_OSDS_TRAIN_GLOB \"s3://dc-taxi-$BUCKET_ID-\n➥ $AWS_DEFAULT_REGION/csv/dev/part*.csv\" \\\n-e KAEN_OSDS_VAL_GLOB \"s3://dc-taxi-$BUCKET_ID-\n➥ $AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n-e KAEN_OSDS_TEST_GLOB \"s3://dc-taxi-$BUCKET_ID-\n➥ $AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n$MOST_RECENT_JOB\n```", "```py\n!kaen dojo init --provider aws \\\n--worker-instance-type t3.xlarge --manager-instance-type t3.xlarge\n```", "```py\n[MOST_RECENT_DOJO] = !kaen dojo ls | head -n 1\nMOST_RECENT_DOJO\n```", "```py\n!kaen dojo activate {MOST_RECENT_DOJO}\n```", "```py\n!kaen dojo inspect {MOST_RECENT_DOJO}\n```", "```py\n!kaen job create --dojo {MOST_RECENT_DOJO} \\\n--image {DOCKER_HUB_USER}/dctaxi:latest\n```", "```py\n[MOST_RECENT_JOB] = !kaen job ls | head -n 1\nos.environ['MOST_RECENT_JOB'] = MOST_RECENT_JOB\nMOST_RECENT_JOB\n```", "```py\n!kaen hpo enable \\\n--num-runs 1 \\\n--image {DOCKER_HUB_USER}/dctaxi-hpo:latest \\\n--service-prefix hpo \\\n--service-name DcTaxiHpoService \\\n--port 5001 5001 \\\n{MOST_RECENT_JOB}\n```", "```py\n!echo \"http://$(kaen dojo inspect {MOST_RECENT_DOJO} \\\n| grep KAEN_DOJO_MANAGER_IP | cut -d '=' -f 2):5001\"\n```", "```py\n!kaen job start \\\n--replicas 1 \\\n-e AWS_DEFAULT_REGION $AWS_DEFAULT_REGION \\\n-e AWS_ACCESS_KEY_ID $AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY $AWS_SECRET_ACCESS_KEY \\\n-e KAEN_OSDS_TRAIN_GLOB \"s3://dc-taxi-$BUCKET_ID-\n➥ $AWS_DEFAULT_REGION/csv/dev/part*.csv\" \\\n-e KAEN_OSDS_VAL_GLOB \"s3://dc-taxi-$BUCKET_ID-\n➥ $AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n-e KAEN_OSDS_TEST_GLOB \"s3://dc-taxi-$BUCKET_ID-\n➥ $AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n$MOST_RECENT_JOB\n```", "```py\n!kaen dojo rm {MOST_RECENT_DOJO}.\n```"]