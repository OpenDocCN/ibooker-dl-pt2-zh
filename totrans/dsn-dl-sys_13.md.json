["```py\ndef main():\n  parser = argparse.ArgumentParser( \\\n    description=\"PyTorch MNIST Example\")\n  parser.add_argument(\"--batch-size\", \\              ❶\n    type=int, default=64, metavar=\"N\", \\\n    help=\"input batch size for training (default: 64)\")\n  parser.add_argument(\"--lr\", \\\n    type=float, default=0.01, metavar=\"LR\", \\        ❶\n    help=\"learning rate (default: 0.01)\") \n```", "```py\n2022-01-23T05:19:53Z INFO  Epoch[5] Train-accuracy=0.932769\n2022-01-23T05:19:53Z INFO  Epoch[5] Time cost=31.698\n2022-01-23T05:19:54Z INFO  Epoch[5] Validation-accuracy=0.924463\n2022-01-23T05:19:58Z INFO  Epoch[6] Batch [0-100] Speed: 1749.16 .. \n```", "```py\napiVersion: kubeflow.org/v1beta1\nkind: Experiment\nmetadata:\n namespace: kubeflow\n name: bayesian-optimization\nspec:\n Objective:\n   type: maximize\n   goal: 0.99\n   objectiveMetricName: Validation-accuracy    ❶\n   additionalMetricNames:\n     - Train-accuracy\n```", "```py\nalgorithm:\n  algorithmName: bayesianoptimization    ❶\n  algorithmSettings:\n    - name: \"random_state\"\n      value: \"10\"\nparallelTrialCount: 3\nmaxTrialCount: 12\nmaxFailedTrialCount: 3\nParameters:                              ❷\n   - name: lr\n     parameterType: double\n     feasibleSpace:\n       min: \"0.01\"\n       max: \"0.03\"\n   - name: num-layers\n     parameterType: int\n     feasibleSpace:\n       min: \"2\"\n       max: \"5\"\n   - name: optimizer\n     parameterType: categorical\n     feasibleSpace:\n       list:\n         - sgd\n         - adam\n         - ftrl\n```", "```py\n trialTemplate:\n   primaryContainerName: training-container\n   trialParameters:                          ❶\n     - name: learningRate\n       description: Learning rate for the training model\n       reference: lr\n     - name: numberLayers\n       description: Number of training model layers\n       reference: num-layers\n     - name: optimizer\n       description: Training model optimizer (sdg, adam or ftrl)\n       reference: optimizer\n   trialSpec:                                ❷\n     apiVersion: batch/v1\n     kind: Job\n     spec:\n       template:\n         spec:\n           containers:\n             - name: training-container\n               image: docker.io/kubeflowkatib/mxnet-mnist:latest\n               command:                      ❸\n                 - \"python3\"\n                 - \"/opt/mxnet-mnist/mnist.py\"\n                 - \"--batch-size=64\"\n                 - \"--lr=${trialParameters.learningRate}\"\n                 - \"--num-layers=${trialParameters.numberLayers}\"\n                 - \"--optimizer=${trialParameters.optimizer}\"\n           restartPolicy: Never\n```", "```py\n% kubectl apply -f bayesian-optimization.yaml\nexperiment.kubeflow.org/bayesian-optimization created\n\n% kubectl get experiment -n kubeflow\nNAME                    TYPE      STATUS   AGE\nbayesian-optimization   Created   True     46s\n```", "```py\n% kubectl describe experiment bayesian-optimization -n kubeflow\n```", "```py\nStatus:\n  Completion Time:  2022-01-23T05:27:19Z\n  Conditions:                              ❶\n    .. .. .. \n    Message:               Experiment is created\n    Type:                  Created\n    .. .. ..\n    Message:               Experiment is running\n    Reason:                ExperimentRunning\n    Status:                False\n    Type:                  Running\n    .. .. ..\n    Message:               Experiment has succeeded because max trial count has reached\n    Reason:                ExperimentMaxTrialsReached\n    Status:                True\n    Type:                  Succeeded\n  Current Optimal Trial:                   ❷\n    Best Trial Name:  bayesian-optimization-9h25bvq9\n    Observation:\n      Metrics:                             ❸\n        Latest:  0.979001\n        Max:     0.979001\n        Min:     0.955713\n        Name:    Validation-accuracy\n        Latest:  0.992621\n        Max:     0.992621\n        Min:     0.906333\n        Name:    Train-accuracy\n    Parameter Assignments:                 ❹\n      Name:    lr\n      Value:   0.014183662191100063\n      Name:    num-layers\n      Value:   3\n      Name:    optimizer\n      Value:   sgd\n  Start Time:  2022-01-23T05:13:00Z\n  Succeeded Trial List:                    ❺\n    .. .. ..\n    bayesian-optimization-5s59vfwc\n    bayesian-optimization-r8lnnv48\n    bayesian-optimization-9h25bvq9\n    .. .. ..\n  Trials:            12\n  Trials Succeeded:  12 \n```", "```py\n-> % k describe trial bayesian-optimization-mnist-pytorch-88c9rdjx \\\n     -n kubeflow\nName:         bayesian-optimization-mnist-pytorch-88c9rdjx\n.. .. ..\nKind:         Trial\nSpec:\n  .. .. ..\n  Parameter Assignments:\n    Name:                  lr\n    Value:                 0.010547476197421666\n    Name:                  num-layers\n    Value:                 3\n    Name:                  optimizer\n    Value:                 ftrl\n\nStatus:\n  Completion Time:  2022-01-23T06:23:50Z\n  Conditions:\n    .. .. ..\n    Message:  Trial has failed. Job message: Job has reached the specified backoff limit\n    Reason:   TrialFailed. Job reason: BackoffLimitExceeded     ❶\n   .. .. ..\n```", "```py\n% kubectl logs bayesian-optimization-mkqgq6nm--1-qnbtt -c \\\n metrics-logger-and-collector -n kubeflow\n```", "```py\nTrial Name: bayesian-optimization-mkqgq6nm                                                                ❶\n2022-01-23T05:17:17Z INFO  start with arguments Namespace(                                                ❷\nadd_stn=False, batch_size=64, disp_batches=100,\n dtype='float32', gc_threshold=0.5, gc_type='none', gpus=None, \nimage_shape='1, 28, 28', ... warmup_epochs=5,\nwarmup_strategy='linear', wd=0.0001)\nI0123 05:17:20.159784    16 main.go:136] 2022-01-23T05:17:20Z INFO\ndownloaded http:/ /data.mxnet.io/data/mnist/t10k-labels-idx1-ubyte.gz\n➥ into t10k-labels-idx1-ubyte.gz successfully                                                            ❸\n.. .. ..\nI0123 05:17:26.711552   16 main.go:136] 2022-01-23T05:17:26Z INFO   Epoch[0] Train-accuracy=0.904084      ❹\n.. .. ..\nI0123 05:17:26.995733   16 main.go:136] 2022-01-23T05:17:26Z INFO   Epoch[0] Validation-accuracy=0.920482 ❺\nI0123 05:17:27.576586   16 main.go:136] 2022-01-23T05:17:27Z INFO   Epoch[1] Batch [0-100]  Speed: 20932.09 samples/sec  accuracy=0.926825\nI0123 05:17:27.871579   16 main.go:136] 2022-01-23T05:17:27Z INFO   Epoch[1] Batch [100-200]  Speed: 21657.24 samples/sec  accuracy=0.930937\n```", "```py\ntrialTemplate:\n  primaryContainerName: pytorch\n  trialParameters:                       ❶\n    - name: learningRate\n      description: Learning rate for the training model\n      reference: lr\n   - name: momentum\n      description: Momentum for the training model\n      reference: momentum\n   trialSpec:\n      apiVersion: kubeflow.org/v1\n      kind: PyTorchJob                   ❷\n      spec:\n        pytorchReplicaSpecs:\n          Master:                        ❸\n            replicas: 1                  ❸\n            restartPolicy: OnFailure\n            template:\n              spec:\n                containers:\n                  - name: pytorch\n                    image: docker.io/kubeflowkatib/pytorch-mnist:latest\n                    command:\n                      - \"python3\"\n                      - \"/opt/pytorch-mnist/mnist.py\"\n                      - \"--epochs=1\"\n                      - \"--lr=${trialParameters.learningRate}\"\n                      - \"--momentum=${trialParameters.momentum}\"\n Worker:\n            replicas: 2                  ❹\n            restartPolicy: OnFailure\n            template:\n              spec:\n                containers:\n                  - name: pytorch\n                    image: docker.io/kubeflowkatib/pytorch-mnist:latest\n                    command:\n                      - \"python3\"\n                      - \"/opt/pytorch-mnist/mnist.py\"\n                      - \"--epochs=1\"\n                      - \"--lr=${trialParameters.learningRate}\"\n                      - \"--momentum=${trialParameters.momentum}\"\n```", "```py\nservice Suggestion {\n  rpc GetSuggestions(GetSuggestionsRequest) \n    returns (GetSuggestionsReply);\n  rpc ValidateAlgorithmSettings(ValidateAlgorithmSettingsRequest)\n    returns (ValidateAlgorithmSettingsReply);\n}\n```", "```py\nclass NewAlgorithmService(                               ❶\n  api_pb2_grpc.SuggestionServicer,                       ❶\n  HealthServicer):                                       ❶\n  def ValidateAlgorithmSettings(self, request, context):\n    # Optional, it is used to validate \n    # algorithm settings defined by users.\n    Pass\n\n  def GetSuggestions(self, request, context):            ❷\n    search_space = HyperParameterSearchSpace.convert(request.experiment)\n\n    trials = Trial.convert(request.trials)               ❸\n\n    # Implement the logic to use your algorithm \n    # to generate new assignments \n    # for the given current request number.\n    list_of_assignments = your_logic(search_space,       ❹\n      trials, request.current_request_number)            ❹\n\n    return api_pb2.GetSuggestionsReply(\n      trials=Assignment.generate(list_of_assignments))\n```", "```py\nserver = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\nservice = YourNewAlgorithmService()\napi_pb2_grpc.add_SuggestionServicer_to_server(service, server)\nhealth_pb2_grpc.add_HealthServicer_to_server(service, server)\nserver.add_insecure_port(DEFAULT_PORT)\nprint(\"Listening...\")\nserver.start()\n```", "```py\nsuggestion: |-\n  {\n    \"tpe\": {\n      \"image\": \"docker.io/kubeflowkatib/suggestion-hyperopt\"\n  },\n    \"random\": {\n      \"image\": \"docker.io/kubeflowkatib/suggestion-hyperopt\"\n  },\n+   \"<new-algorithm-name>\": {\n+     \"image\": \"new algorithm image path\"\n+ }\n```"]