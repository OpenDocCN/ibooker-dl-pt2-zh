["```js\n> let a = ['hello', 'world', 2 * 1009]\n> a;\n(3) [\"hello\", \"world\", 2018]\n```", "```js\n<script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest'></script>\n<script>\nconst trainData = {\n  sizeMB:  [0.080, 9.000, 0.001, 0.100, 8.000,\n            5.000, 0.100, 6.000, 0.050, 0.500,\n            0.002, 2.000, 0.005, 10.00, 0.010,\n            7.000, 6.000, 5.000, 1.000, 1.000],\n  timeSec: [0.135, 0.739, 0.067, 0.126, 0.646,\n            0.435, 0.069, 0.497, 0.068, 0.116,\n            0.070, 0.289, 0.076, 0.744, 0.083,\n            0.560, 0.480, 0.399, 0.153, 0.149]\n};\nconst testData = {\n  sizeMB:  [5.000, 0.200, 0.001, 9.000, 0.002,\n            0.020, 0.008, 4.000, 0.001, 1.000,\n            0.005, 0.080, 0.800, 0.200, 0.050,\n            7.000, 0.005, 0.002, 8.000, 0.008],\n  timeSec: [0.425, 0.098, 0.052, 0.686, 0.066,\n            0.078, 0.070, 0.375, 0.058, 0.136,\n            0.052, 0.063, 0.183, 0.087, 0.066,\n            0.558, 0.066, 0.068, 0.610, 0.057]\n};\n</script>\n```", "```js\nconst trainTensors = {\n  sizeMB: tf.tensor2d(trainData.sizeMB, [20, 1]),       ***1***\n  timeSec: tf.tensor2d(trainData.timeSec, [20, 1])\n};\nconst testTensors = {\n  sizeMB: tf.tensor2d(testData.sizeMB, [20, 1]),\n  timeSec: tf.tensor2d(testData.timeSec, [20, 1])\n};\n```", "```js\nconst model = tf.sequential();\nmodel.add(tf.layers.dense({inputShape: [1], units: 1}));\n```", "```js\n    timeSec = kernel * sizeMB + bias\n```", "```js\nmodel.compile({optimizer: 'sgd', loss: 'meanAbsoluteError'});\n```", "```js\nmeanAbsoluteError = average( absolute(modelOutput - targets) )\n```", "```js\nmodelOutput = [1.1, 2.2, 3.3, 3.6]\ntargets =     [1.0, 2.0, 3.0, 4.0]\n```", "```js\nmeanAbsoluteError = average([|1.1 - 1.0|, |2.2 - 2.0|,\n                             |3.3 - 3.0|, |3.6 - 4.0|])\n\n                  = average([0.1, 0.2, 0.3, 0.4])\n                  = 0.25\n```", "```js\n(async function() {\n  await model.fit(trainTensors.sizeMB,\n                  trainTensors.timeSec,\n                  {epochs: 10});\n})();\n```", "```js\n> model.evaluate(testTensors.sizeMB, testTensors.timeSec).print();\nTensor\n    0.31778740882873535\n```", "```js\n> const avgDelaySec = tf.mean(trainData.timeSec);\n> avgDelaySec.print();\nTensor\n    0.2950500249862671\n```", "```js\n> tf.mean(tf.abs(tf.sub(testData.timeSec, 0.295))).print();\nTensor\n    0.22020000219345093\n```", "```js\n// chaining API pattern\n> testData.timeSec.sub(0.295).abs().mean().print();\nTensor\n    0.22020000219345093\n```", "```js\n>  model.fit(trainTensors.sizeMB,\n             trainTensors.timeSec,\n             {epochs: 200});              ***1***\n\n>  model.evaluate(testTensors.sizeMB, testTensors.timeSec).print();\nTensor\n    0.04879039153456688\n```", "```js\n> const smallFileMB = 1;\n> const bigFileMB = 100;\n> const hugeFileMB = 10000;\n> model.predict(tf.tensor2d([[smallFileMB], [bigFileMB],\n     [hugeFileMB]])).print();\nTensor\n    [[0.1373825  ],\n     [7.2438402  ],\n     [717.8896484]]\n```", "```js\n> model.predict(tf.tensor1d([smallFileMB, bigFileMB, hugeFileMB])).print();\nUncaught Error: Error when checking : expected dense_Dense1_input to have 2\n     dimension(s), but got array with shape [3]\n```", "```js\nconst model = tf.sequential([tf.layers.dense({inputShape: [1], units: 1})]);\nmodel.compile({optimizer: 'sgd', loss: 'meanAbsoluteError'});\n(async () => await model.fit(trainTensors.sizeMB,\n                             trainTensors.timeSec,\n                             {epochs: 10}))();\nmodel.evaluate(testTensors.sizeMB, testTensors.timeSec);\nmodel.predict(tf.tensor2d([[7.8]])).print();\n```", "```js\noutput = kernel * input + bias\n```", "```js\ny’ = v * x,\n```", "```js\nloss = square(y’ - y) = square(v * x - y)\n```", "```js\n-(-20) * 0.01 = 0.2\n```", "```js\nv = 0 + 0.2 = 0.2\n```", "```js\ngit clone https://github.com/tensorflow/tfjs-examples.git\ncd tfjs-examples/boston-housing\n```", "```js\nyarn && yarn watch\n```", "```js\n// Initialize a BostonHousingDataset object defined in data.js.\nconst bostonData = new BostonHousingDataset();\nconst tensors = {};\n\n// Convert the loaded csv data, of type number[][] into 2d tensors.\nexport const arraysToTensors = () => {\n  tensors.rawTrainFeatures = tf.tensor2d(bostonData.trainFeatures);\n  tensors.trainTarget = tf.tensor2d(bostonData.trainTarget);\n  tensors.rawTestFeatures = tf.tensor2d(bostonData.testFeatures);\n  tensors.testTarget = tf.tensor2d(bostonData.testTarget);\n}\n\n// Trigger the data to load asynchronously once the page has loaded.\nlet tensors;\ndocument.addEventListener('DOMContentLoaded', async () => {\n  await bostonData.loadData();\n  arraysToTensors();\n}, false);\n```", "```js\nexport const computeBaseline = () => {\n  const avgPrice = tf.mean(tensors.trainTarget);             ***1***\n  console.log(`Average price: ${avgPrice.dataSync()[0]}`);\n\n  const baseline =\n      tf.mean(tf.pow(tf.sub(\n          tensors.testTarget, avgPrice), 2));                ***2***\n\n  console.log(\n      `Baseline loss: ${baseline.dataSync()[0]}`);           ***3***\n};\n```", "```js\nAverage price: 22.768770217895508\nBaseline loss: 85.58282470703125\n```", "```js\nnormalizedFeature = (feature - mean(feature)) / std(feature)\n```", "```js\n/**\n * Calculates the mean and standard deviation of each column of an array.\n *\n * @param {Tensor2d} data Dataset from which to calculate the mean and\n *                        std of each column independently.\n *\n * @returns {Object} Contains the mean and std of each vector\n *                   column as 1d tensors.\n */\nexport function determineMeanAndStddev(data) {\n  const dataMean = data.mean(0);\n  const diffFromMean = data.sub(dataMean);\n  const squaredDiffFromMean = diffFromMean.square();\n  const variance = squaredDiffFromMean.mean(0);\n  const std = variance.sqrt();\n  return {mean, std};\n}\n/**\n * Given expected mean and standard deviation, normalizes a dataset by\n * subtracting the mean and dividing by the standard deviation.\n *\n * @param {Tensor2d} data: Data to normalize.\n *    Shape: [numSamples, numFeatures].\n * @param {Tensor1d} mean: Expected mean of the data. Shape [numFeatures].\n * @param {Tensor1d} std: Expected std of the data. Shape [numFeatures]\n *\n * @returns {Tensor2d}: Tensor the same shape as data, but each column\n * normalized to have zero mean and unit standard deviation.\n */\nexport function normalizeTensor(data, dataMean, dataStd) {\n  return data.sub(dataMean).div(dataStd);\n}\n```", "```js\nconst dataMean = data.mean(0);\n```", "```js\n> dataMean.shape\n[12]\n> dataMean.print();\n     [3.3603415, 10.6891899, 11.2934837, 0.0600601, 0.5571442, 6.2656188,\n     68.2264328, 3.7099338, 9.6336336, 409.2792969, 18.4480476, 12.5154343]\n```", "```js\nconst diffFromMean = data.sub(dataMean);\n```", "```js\nconst std = data.sub(data.mean(0)).square().mean().sqrt();\n```", "```js\nx = tf.randomUniform([64, 3, 11, 9]);    ***1***\ny = tf.randomUniform([11, 9]);           ***2***\nz = tf.maximum(x, y);                    ***3***\n```", "```js\nexport const linearRegressionModel = () => {\n  const model = tf.sequential();\n  model.add(tf.layers.dense(\n      {inputShape: [bostonData.numFeatures], units: 1}));\n  return model;\n};\n```", "```js\nconst LEARNING_RATE = 0.01;\nmodel.compile({\n    optimizer: tf.train.sgd(LEARNING_RATE),\n    loss: 'meanSquaredError'});\n```", "```js\nawait model.fit(tensors.trainFeatures, tensors.trainTarget, {\n  batchSize: BATCH_SIZE\n  epochs: NUM_EPOCHS,\n});\n```", "```js\nlet trainLoss;\nawait model.fit(tensors.trainFeatures, tensors.trainTarget, {\n  batchSize: BATCH_SIZE,\n  epochs: NUM_EPOCHS,\n  callbacks: {\n    onEpochEnd: async (epoch, logs) => {\n      await ui.updateStatus(\n         `Epoch ${epoch + 1} of ${NUM_EPOCHS} completed.`);\n      trainLoss = logs.loss;\n      await ui.plotData(epoch, trainLoss);\n    }\n  }\n});\n```", "```js\nlet trainLoss;\nlet valLoss;\nawait model.fit(tensors.trainFeatures, tensors.trainTarget, {\n  batchSize: BATCH_SIZE,\n  epochs: NUM_EPOCHS,\n  validationSplit: 0.2,\n  callbacks: {\n    onEpochEnd: async (epoch, logs) => {\n      await ui.updateStatus(\n          `Epoch ${epoch + 1} of ${NUM_EPOCHS} completed.`);\n      trainLoss = logs.loss;\n      valLoss = logs.val_loss;\n      await ui.plotData(epoch, trainLoss, valLoss);\n    }\n  }\n});\n```", "```js\nawait ui.updateStatus('Running on test data...');\nconst result = model.evaluate(\n    tensors.testFeatures, tensors.testTarget, {batchSize: BATCH_SIZE});\nconst testLoss = result.dataSync()[0];\nawait ui.updateStatus(\n    `Final train-set loss: ${trainLoss.toFixed(4)}\\n` +\n    `Final validation-set loss: ${valLoss.toFixed(4)}\\n` +\n    `Test-set loss: ${testLoss.toFixed(4)}`);\n```", "```js\noutput = kernel · features + bias\n```", "```js\nfunction innerProduct(a, b) {\n    output = 0;\n    for (let i = 0 ; i < a.length ; i++) {\n        output += a[i] * b[i];\n    }\n    return output;\n}\n```", "```js\n> model.layers[0].getWeights()[0]\n```", "```js\n> Float32Array(12) [-0.44015952944755554, 0.8829045295715332,\n     0.11802537739276886, 0.9555914402008057, -1.6466193199157715,\n     3.386948347091675, -0.36070501804351807, -3.0381457805633545,\n     1.4347705841064453, -1.3844640254974365, -1.4223048686981201,\n     -3.795234441757202]\n```", "```js\nlet trainLoss;\nlet valLoss;\nawait model.fit(tensors.trainFeatures, tensors.trainTarget, {\n  batchSize: BATCH_SIZE,\n  epochs: NUM_EPOCHS,\n  validationSplit: 0.2,\n  callbacks: {\n    onEpochEnd: async (epoch, logs) => {\n      await ui.updateStatus(\n          `Epoch ${epoch + 1} of ${NUM_EPOCHS} completed.`);\n      trainLoss = logs.loss;\n        valLoss = logs.val_loss;\n      await ui.plotData(epoch, trainLoss, valLoss);\n      model.layers[0].getWeights()[0].data().then(kernelAsArr => {\n        // console.log(kernelAsArr);\n        const weightsList = describeKerenelElements(kernelAsArr);\n        ui.updateWeightDescription(weightsList);\n      });\n    }\n  }\n});\n```"]