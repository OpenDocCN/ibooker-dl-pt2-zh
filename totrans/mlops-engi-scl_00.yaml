- en: front matter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言部分
- en: preface
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言
- en: A useful piece of feedback that I got from a reviewer of this book was that
    it became a “cheat code” for them to scale the steep MLOps learning curve. I hope
    that the content of this book will help you become a better informed practitioner
    of machine learning engineering and data science, as well as a more productive
    contributor to your projects, your team, and your organization.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从这本书的一位审稿人那里得到的一条有用的反馈是，它成为了他们攀登陡峭的 MLOps 学习曲线的“秘籍”。我希望本书的内容能帮助您成为更加了解机器学习工程和数据科学的从业者，同时也是您项目、团队和组织更具生产力的贡献者。
- en: 'In 2021, major technology companies are vocal about their efforts to “democratize”
    artificial intelligence (AI) by making technologies like deep learning more accessible
    to a broader population of scientists and engineers. Regrettably, the democratization
    approach taken by the corporations focuses too much on core technologies and not
    enough on the practice of delivering AI systems to end users. As a result, machine
    learning (ML) engineers and data scientists are well prepared to create experimental,
    proof-of-concept AI prototypes but fall short in successfully delivering these
    prototypes to production. This is evident from a wide spectrum of issues: from
    unacceptably high failure rates of AI projects to ethical controversies about
    AI systems that make it to end users. I believe that, to become successful, the
    effort to democratize AI must progress beyond the myopic focus on core, enabling
    technologies like Keras, PyTorch, and TensorFlow. *MLOps* emerged as a unifying
    term for the practice of taking experimental ML code and running it effectively
    in production. Serverless ML is the leading cloud-native software development
    model for ML and MLOps, abstracting away infrastructure and improving productivity
    of the practitioners.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 2021 年，主要技术公司公开表示努力“民主化”人工智能（AI），通过使深度学习等技术更容易接触到更广泛的科学家和工程师。遗憾的是，企业采取的民主化方法过分关注核心技术，而不足够关注将
    AI 系统交付给最终用户的实践。因此，机器学习（ML）工程师和数据科学家准备充足，能够创建实验性的 AI 原型，但在成功将这些原型交付到生产环境中则做得不够。这一点从各种各样的问题中显而易见：从
    AI 项目的失败率不可接受到关于成功交付给最终用户的 AI 系统的道德争议。我相信，要取得成功，民主化 AI 的努力必须超越对核心、启用技术（如 Keras、PyTorch
    和 TensorFlow）的狭隘关注。*MLOps* 成为了一个统一的术语，用于将实验性的 ML 代码有效地运行到生产环境中。无服务器 ML 是主导的云原生软件开发模型，用于
    ML 和 MLOps，抽象出基础架构，提高了从业者的生产力。
- en: I also encourage you to make use of the Jupyter notebooks that accompany this
    book. The DC taxi fare project used in the notebook code is designed to give you
    the practice you need to grow as a practitioner. Happy reading and happy coding!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我还鼓励您使用附带本书的 Jupyter 笔记本。笔记本代码中使用的 DC 出租车费项目旨在为您提供成长为从业者所需的练习。祝阅读愉快，编码愉快！
- en: acknowledgments
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: I am forever grateful to my daughter, Sophia. You are my eternal source of happiness
    and inspiration. My wife, Alla, was boundlessly patient with me while I wrote
    my first book. You were always there to support me and to cheer me along. To my
    father, Mikhael, I wouldn’t be who I am without you.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我永远感激我的女儿 Sophia。你是我永恒的幸福和灵感之源。我的妻子 Alla，在我写第一本书时对我有着无限的耐心。你总是在那里支持我，为我加油打气。对我的父亲
    Mikhael，没有你，我不会成为现在的我。
- en: 'I also want to thank the people at Manning who made this book possible: Marina
    Michaels, my development editor; Frances Buontempo, my technical development editor;
    Karsten Strøbaek, my technical proofreader; Deirdre Hiam, my project editor; Michele
    Mitchell, my copyeditor; and Keri Hales, my proofreader.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我也要感谢 Manning 公司的工作人员，使这本书得以出版：我的开发编辑 Marina Michaels；我的技术开发编辑 Frances Buontempo；我的技术校对
    Karsten Strøbaek；我的项目编辑 Deirdre Hiam；我的副本编辑 Michele Mitchell；以及我的校对员 Keri Hales。
- en: 'Many thanks go to the technical peer reviewers: Conor Redmond, Daniela Zapata,
    Dianshuang Wu, Dimitris Papadopoulos, Dinesh Ghanta, Dr. Irfan Ullah, Girish Ahankari,
    Jeff Hajewski, Jesús A. Juárez-Guerrero, Trichy Venkataraman Krishnamurthy, Lucian-Paul
    Torje, Manish Jain, Mario Solomou, Mathijs Affourtit, Michael Jensen, Michael
    Wright, Pethuru Raj Chelliah, Philip Kirkbride, Rahul Jain, Richard Vaughan, Sayak
    Paul, Sergio Govoni, Srinivas Aluvala, Tiklu Ganguly, and Todd Cook. Your suggestions
    helped make this a better book.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢技术同行审阅者：Conor Redmond，Daniela Zapata，Dianshuang Wu，Dimitris Papadopoulos，Dinesh
    Ghanta，Dr. Irfan Ullah，Girish Ahankari，Jeff Hajewski，Jesús A. Juárez-Guerrero，Trichy
    Venkataraman Krishnamurthy，Lucian-Paul Torje，Manish Jain，Mario Solomou，Mathijs
    Affourtit，Michael Jensen，Michael Wright，Pethuru Raj Chelliah，Philip Kirkbride，Rahul
    Jain，Richard Vaughan，Sayak Paul，Sergio Govoni，Srinivas Aluvala，Tiklu Ganguly 和
    Todd Cook。您的建议帮助我们制作出更好的书籍。
- en: about this book
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于本书
- en: Thank you for purchasing *MLOps Engineering at Scale*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买《规模化MLOps工程》。
- en: Who should read this book
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谁应该阅读本书
- en: To get the most value from this book, you’ll want to have existing skills in
    data analysis with Python and SQL, as well as have some experience with machine
    learning. I expect that if you are reading this book, you are interested in developing
    your expertise as a machine learning engineer, and you are planning to deploy
    your machine learning—based prototypes to production.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要从本书中获得最大的价值，你需要具备使用Python和SQL进行数据分析的现有技能，并且具有一些机器学习经验。我期望，如果你正在阅读本书，你对作为机器学习工程师的专业知识感兴趣，并且计划将基于机器学习的原型部署到生产环境中。
- en: This book is for information technology professionals or those in academia who
    have had some exposure to machine learning and are working on or are interested
    in launching a machine learning system in production. There is a refresher on
    machine learning prerequisites for this book in appendix A. Keep in mind that
    if you are brand new to machine learning you may find that studying both machine
    learning and cloud-based infrastructure for machine learning at the same time
    can be overwhelming.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书适用于信息技术专业人士或学术界人士，他们在机器学习方面有一定的接触，并且正在开发或有兴趣在生产中推出机器学习系统。附录 A 中提供了本书的机器学习先决条件复习。请记住，如果您对机器学习全新，您可能会发现同时学习机器学习和基于云的机器学习基础设施可能会让人不知所措。
- en: If you are a software or a data engineer, and you are planning on starting a
    machine learning project, this book can help you gain a deeper understanding of
    the machine learning project life cycle. You will see that although the practice
    of machine learning depends on traditional information technologies (i.e., computing,
    storage, and networking), it is different from the traditional information technology
    in practice. The former is significantly more experimental and more iterative
    than you may have experienced as a software or a data professional, and you should
    be prepared for the outcomes to be less known in advance. When working with data,
    the machine learning practice is more like the scientific process, including forming
    hypotheses about data, testing alternative models to answer questions about the
    hypothesis, and ranking and choosing the best performing models to launch atop
    your machine learning platform.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是软件工程师或数据工程师，并计划开始一个机器学习项目，这本书可以帮助你更深入地了解机器学习项目的生命周期。你会发现，尽管机器学习的实践依赖于传统信息技术（即计算、存储和网络），但在实践中与传统信息技术有所不同。前者比你作为软件工程师或数据专业人员所经历的实验性更强，更加迭代，你应该为结果可能较少事先了解而做好准备。在处理数据时，机器学习实践更像是科学过程，包括对数据形成假设，测试替代模型以回答假设问题，并排名和选择表现最佳的模型来部署到你的机器学习平台上。
- en: If you are a machine learning engineer or practitioner, or a data scientist,
    keep in mind that this book is not about making you a better researcher. The book
    is not written to educate you about the frontiers of science in machine learning.
    This book also will not attempt to reteach you the machine learning basics, although
    you may find the material in appendix A, targeted at information technology professionals,
    a useful reference. Instead, you should expect to use this book to become a more
    valuable collaborator on your machine learning team. The book will help you do
    more with what you already know about data science and machine learning so that
    you can deliver ready-to-use contributions to your project or your organization.
    For example, you will learn how to implement your insights about improving machine
    learning model accuracy and turn them into production-ready capabilities.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一名机器学习工程师或从业者，或者是一名数据科学家，请记住，本书不是要让你成为更好的研究者。本书不旨在教育你关于机器学习科学前沿的知识。本书也不会试图重新教授你机器学习的基础知识，尽管你可能会发现附录
    A 中针对信息技术专业人员的材料是一个有用的参考。相反，你应该期望使用本书成为你机器学习团队中更有价值的合作者。本书将帮助你更好地利用你已经掌握的关于数据科学和机器学习的知识，以便你能够为你的项目或组织提供可即用的贡献。例如，你将学会如何实现关于提高机器学习模型准确性的见解，并将其转化为生产就绪的能力。
- en: 'How this book is organized: A road map'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书的组织结构：路线图
- en: This book is composed of three parts. In part 1, I chart out the landscape of
    what it takes to put a machine learning system in production, describe an engineering
    gap between experimental machine learning code and production machine learning
    systems, and explain how serverless machine learning can help bridge the gap.
    By the end of part 1, I’ll have taught you how to use serverless features of a
    public cloud (Amazon Web Services) to get started with a real-world machine learning
    use case, prepare a working machine learning data set for the use case, and ensure
    that you are prepared to apply machine learning to the use case.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为三个部分。在第一部分，我概述了将机器学习系统投入生产所需的条件，描述了实验性机器学习代码与生产机器学习系统之间的工程差距，并解释了无服务器机器学习如何帮助弥合这一差距。到第一部分结束时，我将教你如何使用公共云（Amazon
    Web Services）的无服务器特性来开始一个真实的机器学习用例，为该用例准备一个工作机器学习数据集，并确保你已经准备好将机器学习应用于该用例。
- en: Chapter 1 presents a broad view on the field on machine learning systems engineering
    and what it takes to put the systems in production.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 1 章全面介绍了机器学习系统工程领域以及将系统投入生产所需的条件。
- en: Chapter 2 introduces you to the taxi trips data set for the Washington, DC,
    municipality and teaches you how to start using the data set for machine learning
    in the Amazon Web Services (AWS) public cloud.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 2 章向你介绍了华盛顿特区出租车行程数据集，并教你如何在亚马逊 Web Services（AWS）公共云中开始使用该数据集进行机器学习。
- en: Chapter 3 applies the AWS Athena interactive query service to dig deeper into
    the data set, uncover data quality issues, and then address them through a rigorous
    and principled data quality assurance process.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 3 章运用 AWS Athena 交互式查询服务，深入挖掘数据集，发现数据质量问题，然后通过严格和原则性的数据质量保证流程加以解决。
- en: Chapter 4 demonstrates how to use statistical measures to summarize data set
    samples and to quantify their similarity to the entire data set. The chapter also
    covers how to pick the right size for your test, training, and validation data
    sets and use distributed processing in the cloud to prepare the data set samples
    for machine learning.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 4 章演示了如何使用统计量来总结数据集样本并量化它们与整个数据集的相似性。该章还涵盖了如何选择测试、训练和验证数据集的正确大小，并使用云中的分布式处理来准备用于机器学习的数据集样本。
- en: In part 2, I teach you to use the PyTorch deep learning framework to develop
    models for a structured data set, explain how to distribute and scale up machine
    learning model training in the cloud, and show how to deploy trained machine learning
    models to scale with user demand. In the process, you’ll learn to evaluate and
    assess the performance of alternative machine learning model implementations and
    how to pick the right one for the use case.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 2 部分，我将教你如何使用 PyTorch 深度学习框架为结构化数据集开发模型，解释如何在云中分发和扩展机器学习模型训练，并展示如何部署经过训练的机器学习模型以满足用户需求的扩展。在这个过程中，你将学会评估和评估替代机器学习模型实现的性能，并选择适合用例的正确模型。
- en: Chapter 5 covers the PyTorch fundamentals by introducing the core tensor application
    programming interface (API) and helping you gain a level of fluency with using
    the API.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5章介绍了 PyTorch 的基础知识，介绍了核心张量应用程序编程接口（API），并帮助您熟练使用该 API。
- en: Chapter 6 focuses on the deep learning aspects of PyTorch, including support
    for automatic differentiation, alternative gradient descent algorithms, and supporting
    utilities.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6章专注于 PyTorch 的深度学习方面，包括自动微分支持、替代梯度下降算法和支持工具。
- en: Chapter 7 explains how to scale up your PyTorch programs by teaching about the
    graphical processing unit (GPU) features and how to take advantage of them to
    accelerate your deep learning code.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7章解释了如何通过教授图形处理单元（GPU）特性来扩展您的 PyTorch 程序，并如何利用这些特性加速您的深度学习代码。
- en: Chapter 8 teaches about data parallel approaches for distributed PyTorch training
    and covers, in-depth, the distinction between traditional, parameter, server-based
    approaches and the ring-based distributed training (e.g., Horovod).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8章介绍了分布式 PyTorch 训练的数据并行方法，并深入介绍了传统参数服务器方法和基于环形的分布式训练方法（例如，Horovod）之间的区别。
- en: In part 3, I introduce you to the battle-tested techniques of machine learning
    practitioners and cover feature engineering, hyperparameter tuning, and machine
    learning pipeline assembly. By the conclusion of this book, you will have set
    up a machine learning platform that ingests raw data, prepares it for machine
    learning, applies feature engineering, and trains high-performance, hyperparameter-tuned
    machine learning models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3部分中，我向您介绍了经过考验的机器学习实践技术，并介绍了特征工程、超参数调整和机器学习流水线组装。通过本书的结尾，您将建立一个机器学习平台，该平台摄取原始数据，为机器学习准备数据，应用特征工程，并训练高性能、超参数调整的机器学习模型。
- en: Chapter 9 explores the use cases around feature selection and feature engineering,
    using case studies to build intuition about the features that can be selected
    or engineered for the DC taxi data set.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9章探讨了围绕特征选择和特征工程的用例，使用案例研究来建立对可以选择或设计为 DC 出租车数据集的特征的直觉。
- en: Chapter 10 teaches how to eliminate boilerplate engineering code in your DC
    taxi PyTorch model implementation by adopting a framework called PyTorch Lightning.
    Also, the chapter navigates through the steps required to train, validate, and
    test your enhanced deep learning model.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10章教您如何通过采用一个名为 PyTorch Lightning 的框架来消除 DC 出租车 PyTorch 模型实现中的样板工程代码。此外，该章节还介绍了训练、验证和测试增强的深度学习模型所需的步骤。
- en: Chapter 11 integrates your deep learning model with an open-source hyperparameter
    optimization framework called Optuna, helping you train multiple models based
    on alternative hyperparameter values, and then ranking the trained models according
    to their loss and metric performance.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第11章将您的深度学习模型与一个名为 Optuna 的开源超参数优化框架集成，帮助您基于备选超参数值训练多个模型，然后根据它们的损失和指标性能对训练好的模型进行排序。
- en: Chapter 12 packages your deep learning model implementation into a Docker container
    in order to run it through the various stages of the entire machine learning pipeline,
    starting from the development data set all the way to a trained model ready for
    production deployment.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第12章将您的深度学习模型实现打包成一个 Docker 容器，以便通过整个机器学习流水线的各个阶段运行它，从开发数据集一直到准备用于生产部署的训练好的模型。
- en: About the code
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于代码
- en: 'You can access the code for this book from my Github repository: [github.com/osipov/smlbook](http://github.com/osipov/smlbook).
    The code in this repository is packaged as Jupyter notebooks and is designed to
    be used in a Linux-based Jupyter notebook environment. This means that you have
    options when it comes to how you can execute the code. If you have your own, local
    Jupyter environment, for example, with the Jupyter native client (JupyterApp:
    [https://github.com/jupyterlab/jupyterlab_app](https://github.com/jupyterlab/jupyterlab_app))
    or a Conda distribution ([https://jupyter.org/install](https://jupyter.org/install)),
    that’s great! If you do not use a local Jupyter distribution, you can run the
    code from the notebooks using a cloud-based service such as Google Colab or Binder.
    My Github repository README.md file includes badges and hyperlinks to help you
    launch chapter-specific notebooks in Google Colab.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '您可以从我的 Github 仓库访问本书的代码：[github.com/osipov/smlbook](http://github.com/osipov/smlbook)。该仓库中的代码以
    Jupyter 笔记本的形式打包，并设计用于在基于 Linux 的 Jupyter 笔记本环境中使用。这意味着在执行代码时您有多种选择。例如，如果您拥有自己的本地
    Jupyter 环境，那么使用 Jupyter 本机客户端（JupyterApp: [https://github.com/jupyterlab/jupyterlab_app](https://github.com/jupyterlab/jupyterlab_app))
    或 Conda 分发（[https://jupyter.org/install](https://jupyter.org/install)）就很棒！如果您不使用本地
    Jupyter 分发，您可以使用 Google Colab 或 Binder 等云服务从笔记本中运行代码。我的 Github 仓库 README.md 文件包括徽章和超链接，以帮助您在
    Google Colab 中启动特定章节的笔记本。'
- en: I strongly urge you to use a local Jupyter installation as opposed to a cloud
    service, especially if you are worried about the security of your AWS account
    credentials. Some steps of the code will require you to use your AWS credentials
    for tasks like creating storage buckets, launching AWS Glue extract-transform-load
    (ETL) jobs, and more. The code for chapter 12 must be executed on node with Docker
    installed, so I recommend planning to use a local Jupyter installation on a laptop
    or a desktop where you have sufficient capacity to install Docker. You can find
    out more about Docker installation requirements in appendix B.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议您使用本地 Jupyter 安装，而不是云服务，特别是如果您担心您的 AWS 账户凭证的安全性。代码的一些步骤将要求您使用您的 AWS 凭证来执行诸如创建存储桶、启动
    AWS Glue 提取转换加载（ETL）作业等任务。第 12 章的代码必须在安装了 Docker 的节点上执行，因此我建议您计划在具有足够容量安装 Docker
    的笔记本电脑或台式机上使用本地 Jupyter 安装。有关 Docker 安装要求的更多信息，请参阅附录 B。
- en: liveBook discussion forum
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: liveBook 讨论论坛
- en: Purchase of *MLOps for Engineering at Scale* includes free access to liveBook,
    Manning’s online reading platform. Using liveBook’s exclusive discussion features,
    you can attach comments to the book globally or to specific sections or paragraphs.
    It’s a snap to make notes for yourself, ask and answer technical questions, and
    receive help from the author and other users.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 购买 *大规模工程中的 MLOps* 包括免费访问 liveBook，Manning 的在线阅读平台。使用 liveBook 的独家讨论功能，您可以全局附加评论到书籍或特定章节或段落。为自己做笔记，提出和回答技术问题，并从作者和其他用户那里获得帮助都是轻而易举的。
- en: To access the forum, go to [https://livebook.manning.com/#!/book/mlops-engineering-at-scale/discussion](https://livebook.manning.com/#!/book/mlops-engineering-at-scale/discussion).
    Be sure to join the forum and say hi! You can also learn more about Manning’s
    forums and the rules of conduct at [https://livebook.manning.com/#!/discussion](https://livebook.manning.com/#!/discussion).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问论坛，请转到[https://livebook.manning.com/#!/book/mlops-engineering-at-scale/discussion](https://livebook.manning.com/#!/book/mlops-engineering-at-scale/discussion)。一定要加入论坛并打个招呼！你还可以了解更多关于
    Manning 论坛和行为规则的信息，请访问[https://livebook.manning.com/#!/discussion](https://livebook.manning.com/#!/discussion)。
- en: Manning’s commitment to our readers is to provide a venue where a meaningful
    dialogue between individual readers and between readers and the author can take
    place. It is not a commitment to any specific amount of participation on the part
    of the author, whose contribution to the forum remains voluntary (and unpaid).
    We suggest you try asking the author some challenging questions lest his interest
    stray! The forum and the archives of previous discussions will be accessible from
    the publisher’s website as long as the book is in print.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Manning 对我们的读者的承诺是提供一个场所，个人读者和读者与作者之间可以进行有意义的对话。这并不意味着作者有任何具体的参与承诺，他对论坛的贡献仍然是自愿的（且未付酬）。我们建议您尝试向作者提出一些具有挑战性的问题，以免他失去兴趣！只要图书仍在印刷中，论坛和以前的讨论存档将可以从出版商的网站访问。
- en: about the author
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于作者
- en: '| ![250Osipov](Images/Osipov.png)  | Carl Osipov has been working in the information
    technology industry since 2001, with a focus on projects in big data analytics
    and machine learning in multi-core, distributed systems, such as service-oriented
    architecture and cloud computing platforms. While at IBM, Carl helped IBM Software
    Group to shape its strategy around the use of Docker and other container-based
    technologies for serverless cloud computing using IBM Cloud and Amazon Web Services.
    At Google, Carl learned from the world’s foremost experts in machine learning
    and helped manage the company’s efforts to democratize artificial intelligence
    with Google Cloud and TensorFlow. Carl is an author of over 20 articles in professional,
    trade, and academic journals; an inventor with six patents at USPTO; and the holder
    of three corporate technology awards from IBM. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| ![250Osipov](Images/Osipov.png)  | Carl Osipov自2001年以来一直在信息技术行业工作，专注于大数据分析和多核分布式系统中的机器学习项目，比如面向服务的体系结构和云计算平台。在IBM期间，卡尔帮助IBM软件集团塑造了其围绕使用Docker和其他基于容器的技术进行无服务器云计算的策略，使用了IBM
    Cloud和Amazon Web Services。在Google，卡尔向世界顶尖的机器学习专家学习，并帮助管理公司努力通过Google Cloud和TensorFlow实现人工智能的大众化。卡尔是《专业，贸易和学术期刊》上的20多篇文章的作者；美国专利与商标局的六项专利的发明人；以及IBM获得的三项企业技术奖的获得者。
    |'
- en: about the cover illustration
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于封面插图
- en: The figure on the cover of *MLOps Engineering at Scale* is captioned “Femme
    du Thibet,” or a woman of Tibet. The illustration is taken from a collection of
    dress costumes from various countries by Jacques Grasset de Saint-Sauveur (1757—1810),
    titled *Costumes de Différents Pays*, published in France in 1797\. Each illustration
    is finely drawn and colored by hand. The rich variety of Grasset de Saint-Sauveur’s
    collection reminds us vividly of how culturally apart the world’s towns and regions
    were just 200 years ago. Isolated from each other, people spoke different dialects
    and languages. In the streets or in the countryside, it was easy to identify where
    they lived and what their trade or station in life was just by their dress.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*MLOps规模工程*封面上的图画标题为“Femme du Thibet”，即一位来自西藏的妇女。这幅插图取自雅克·格拉塞·德·圣索维尔（1757-1810）的《不同国家的服装》系列，该系列于1797年在法国出版。每幅插图都是精细绘制和手工上色的。格拉塞·德·圣索维尔的收藏丰富多样，生动地提醒了我们200年前世界各地城镇和地区在文化上的巨大差异。人们相互隔离，说着不同的方言和语言。在街上或在乡间地区，可以通过服装轻松地辨别他们居住的地方，以及他们的行业或社会地位。'
- en: The way we dress has changed since then and the diversity by region, so rich
    at the time, has faded away. It is now hard to tell apart the inhabitants of different
    continents, let alone different towns, regions, or countries. Perhaps we have
    traded cultural diversity for a more varied personal life—certainly for a more
    varied and fast-paced technological life.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时起，我们的着装方式已经发生了变化，当时地区的多样性已经消失。现在很难区分不同大陆的居民，更不用说不同的城镇，地区或国家。也许我们已经以文化多样性换取了更加多样化的个人生活——当然也换取了更加多样化和快节奏的技术生活。
- en: At a time when it is hard to tell one computer book from another, Manning celebrates
    the inventiveness and initiative of the computer business with book covers based
    on the rich diversity of regional life of two centuries ago, brought back to life
    by Grasset de Saint-Sauveur’s pictures.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在难以辨别一本电脑书与另一本之际，Manning通过以格拉塞·德·圣索维尔的图片为基础的书籍封面，庆祝计算机商业的独创性和主动性，并将两个世纪前地区生活丰富多样性的丰盛多样性重新带回生活。
