- en: A.1\. Installing tfjs-node-gpu on Linux
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We assume you have installed Node.js and npm on your system and that the paths
    to node and npm are included in your system path. If not, see [https://nodejs.org/en/download/](https://nodejs.org/en/download/)
    for downloadable installers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download the CUDA Toolkit from [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads).
    Be sure to choose the suitable version for the version of tfjs-node-gpu you intend
    to use. At the time of this writing, the latest version of tfjs-node-gpu is 1.2.10,
    which works with CUDA Toolkit version 10.0\. In addition, be sure to select the
    correct operating system (Linux), architecture (for example, x86_64 for machines
    with mainstream Intel CPUs), Linux distribution, and version of the distribution.
    You will have the option to download several types of installers. Here, we assume
    you download the “runfile (local)” file (as opposed to, for example, the local
    .deb package) for use in the subsequent steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In your downloads folder, make the just-downloaded runfile executable. For example,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use `sudo` to run the runfile. Note that the CUDA Toolkit installation process
    may need to install or upgrade the NVIDIA driver if the version of the NVIDIA
    driver already installed on your machine is too old or if no such driver has been
    installed. If this is the case, you need to stop the X server by dropping to the
    shell-only model. On Ubuntu and Debian distributions, you can enter the shell-only
    model with the shortcut key Ctrl-Alt-F1. Follow the prompts on the screen to install
    the CUDA Toolkit installation, followed by a reboot of the machine. If you are
    in shell-only mode, you can reboot back to the normal GUI mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If step 3 completed correctly, the `nvidia-smi` command should now be available
    on your path. You can use it to check the status of your GPUs. It provides information
    such as the name, temperature-sensor reading, fan speed, processor, and memory
    usage of the NVIDIA GPUs installed on your machine, in addition to the current
    NVIDIA driver version. It is a handy tool for real-time monitoring of your GPU
    when you are using tfjs-node-gpu to train deep neural networks. A typical printed
    message from `nvidia-smi` looks like the following (note this machine has two
    NVIDIA GPUs):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the path to the 64-bit CUDA library files to your `LD_LIBRARY_PATH` environment
    variable. Assuming that you are using the bash shell, you can add the following
    line to your .bashrc file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: tfjs-node-gpu uses the `LD_LIBRARY_PATH` environment variable to find the required
    dynamic library files when starting up.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Download CuDNN from [https://developer.nvidia.com/cudnn](https://developer.nvidia.com/cudnn).
    Why do you need CuDNN in addition to CUDA? This is because CUDA is a generic computation
    library with uses in fields other than deep learning (for example, fluid dynamics).
    CuDNN is NVIDIA’s library for accelerated deep neural network operations built
    on top of CUDA. NVIDIA may require you to create a login account and answer some
    survey questions in order to download CuDNN. Be sure to download the version of
    CuDNN that matches the version of CUDA Toolkit installed in the previous steps.
    For example, CuDNN 7.6 goes with CUDA Toolkit 10.0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Unlike CUDA Toolkit, the downloaded CuDNN doesn’t come with an executable installer.
    Instead, it is a compressed tarball that contains a number of dynamic library
    files and C/C++ headers. These files should be extracted and copied into the appropriate
    destination folders. You can use a sequence of commands like the following to
    achieve this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that all the required drivers and libraries have been installed, you can
    quickly verify CUDA and CuDNN by importing tfjs-node-gpu in node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then, at the Node.js command-line interface,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If everything went well, you should see a number of logging lines confirming
    the discovery of a GPU (or multiple GPUs, depending on your system configuration)
    ready for use by tfjs-node-gpu:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now you are all set to use the full features of tfjs-node-gpu. Just make sure
    you include the following dependencies in your package.json (or their later versions):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In your main .js file, make sure you import the basic dependencies, including
    `@tensorflow/tfjs` and `@tensorflow/tfjs-node-gpu`. The former gives you the general
    API of TensorFlow.js, while the latter wires TensorFlow.js operations to the high-performance
    computation kernels implemented on CUDA and CuDNN:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
