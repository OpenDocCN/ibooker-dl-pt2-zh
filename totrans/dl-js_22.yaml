- en: Chapter 13\. Summary, conclusions, and beyond
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*This chapter covers*'
  prefs: []
  type: TYPE_NORMAL
- en: Looking back at the high-level concepts and ideas about AI and deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick overview of the different types of deep-learning algorithms we’ve visited
    in this book, when they are useful, and how to implement them in TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pretrained models from the ecosystem of TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations of deep learning as it currently stands; and an educated prediction
    for trends in deep learning that we will see in the coming years
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guidance for how to further advance your deep-learning knowledge and stay up-to-date
    with the fast-moving field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the final chapter of this book. Previous chapters have been a grand
    tour of the current landscape of deep learning, enabled by the vehicles of TensorFlow.js
    and your own hard work. Through this journey, you have hopefully gained quite
    a few new concepts and skills. It is time to step back and look at the big picture
    again, as well as get a refresher on some of the most important concepts you’ve
    learned. This last chapter will summarize and review core concepts while expanding
    your horizons beyond the relatively basic notions you’ve learned so far. We want
    to make sure you realize this and are properly equipped to take the next steps
    of the journey on your own.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with a bird’s-eye view of what you should take away from this book.
    This should refresh your memory regarding some of the concepts you’ve learned.
    Next, we’ll present an overview of some key limitations of deep learning. To use
    a tool properly, you should not only know what it *can* do but also what it *can’t*
    do. The chapter ends with a list of resources and strategies for furthering your
    knowledge and skills about deep learning and AI in the JavaScript ecosystem and
    staying up-to-date with new developments.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1\. Key concepts in review
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section briefly synthesizes the key takeaways from this book. We will start
    from the overall landscape of the AI field and end with why bringing deep learning
    and JavaScript together introduces unique and exciting opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.1\. Various approaches to AI
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: First of all, deep learning is not synonymous with AI or even with machine learning.
    *Artificial intelligence* is a broad field with a long history. It can generally
    be defined as “all attempts to automate the cognitive process”—in other words,
    the automation of thought. This can range from very basic tasks, such as an Excel
    spreadsheet, to very advanced endeavors, such as a humanoid robot that can walk
    and talk.
  prefs: []
  type: TYPE_NORMAL
- en: '*Machine learning* is one of the many subfields of AI. It aims at automatically
    developing programs (called *models*) purely from exposure to training data. This
    process of turning data into a program (the model) is called *learning*. Although
    machine learning has been around for a long time (at least several decades), it
    only started to take off in practical applications in the 1990s.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deep learning* is one of many forms of machine learning. In deep learning,
    models consist of many steps of representation transformation, applied one after
    another (hence the adjective “deep”). These operations are structured into modules
    called *layers*. Deep-learning models are typically stacks of many layers or,
    more generally, graphs of many layers. These layers are parameterized by *weights*,
    numeric values that help transform a layer’s input into its output and are updated
    during the training process. The “knowledge” learned by a model during training
    is embodied in its weights. The training process is primarily about finding a
    good set of values for these weights.'
  prefs: []
  type: TYPE_NORMAL
- en: Even though deep learning is just one among many approaches to machine learning,
    it has proven to be a breakout success compared to other approaches. Let’s quickly
    review the reasons behind deep learning’s success.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.2\. What makes deep learning stand out among the subfields of machine learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the span of only a few years, deep learning has achieved tremendous breakthroughs
    in multiple tasks that have been historically thought of as extremely difficult
    for computers, especially in the area of machine perception—namely, extracting
    useful information from images, audio, video, and similar modalities of perceptual
    data with a sufficiently high accuracy. Given sufficient training data (in particular,
    *labeled* training data), it is now possible to extract from perceptual data almost
    anything that humans can extract, sometimes with an accuracy that exceeds that
    of humans. Hence, it is sometimes said that deep learning has largely “solved
    perception,” although this is true only for a fairly narrow definition of perception
    (see [section 13.2.5](#ch13lev2sec10) for the limitations of deep learning).
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to its unprecedented technical success, deep learning has single-handedly
    brought about the third and by far the largest-so-far *AI summer*, also referred
    to as the *deep-learning revolution*, which is a period of intense interest, investment,
    and hype in the field of AI. Whether this period will end in the near future,
    and what happens to it afterward, are topics of speculation and debate. But one
    thing is certain: in stark contrast with previous AI summers, deep learning has
    provided enormous value to a large number of technology companies, enabling human-level
    image classification, object detection, speech recognition, smart assistants,
    natural language processing, machine translation, recommendation systems, self-driving
    cars, and more. The hype may recede (rightfully), but the sustained technological
    impact and economic value of deep learning will remain. In that sense, deep learning
    could be analogous to the internet: it may be overly hyped for a few years, causing
    unreasonable expectations and overinvestment, but in the long term, it will remain
    a major revolution that will impact many areas of technology and transform our
    lives.'
  prefs: []
  type: TYPE_NORMAL
- en: We are particularly optimistic about deep learning because even if we were to
    make no further academic progress in it in the next decade, putting the existing
    deep-learning techniques to every applicable practical problem would still be
    a game changer for many industries (online advertisement, finance, industrial
    automation, and assistive technologies for people with disabilities, just to list
    a few). Deep learning is nothing short of a revolution, and progress is currently
    happening at an incredibly fast pace due to an exponential investment in resources
    and headcount. From where we stand, the future looks bright, although short-term
    expectations may be somewhat overly optimistic; deploying deep learning to the
    full extent of its potential will take well over a decade.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.3\. How to think about deep learning at a high level
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the most surprising aspects of deep learning is how simple it is, given
    how well it works and how more complicated machine-learning techniques that came
    before it didn’t work quite as well. Ten years ago, nobody expected that we could
    achieve such amazing results on machine-perception problems by using only parametric
    models trained with gradient descent. Now it turns out that all you need is sufficiently
    large parametric models trained with gradient descent and sufficiently many labeled
    examples. As Richard Feynman once said about his understanding of the universe,
    “It’s not complicated, it’s just a lot of it.”^([[1](#ch13fn1)])
  prefs: []
  type: TYPE_NORMAL
- en: ¹
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Richard Feynman, interview, “The World from Another Point of View,” Yorkshire
    Television, 1972.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In deep learning, everything is represented as a series of numbers—in other
    words, a *vector*. A vector can be viewed as a *point* in a *geometric space*.
    Model inputs (tabular data, images, text, and so on) are first vectorized, or
    turned into a set of points in the input vector space. In a similar way, the targets
    (labels) are also vectorized and turned into their corresponding set of points
    in the target vector space. Then, each layer in a deep neural network performs
    one simple geometric transformation on the data that goes through it. Together,
    the chain of layers in the neural network forms a complex geometric transformation,
    made of a series of simple geometric transformations. This complex transformation
    attempts to map the points in the input vector space to those in the target vector
    space. This transformation is parameterized by the weights of the layers, which
    are iteratively updated based on how good the transformation currently is. A key
    characteristic of this geometric transformation is that it is *differentiable:*
    this is what makes gradient descent possible.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.4\. Key enabling technologies of deep learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The deep-learning revolution that’s currently unfolding didn’t start overnight.
    Instead, like any other revolution, it’s the product of an accumulation of several
    enabling factors—slowly at first, and then suddenly accelerating once critical
    mass is reached. In the case of deep learning, we can point out the following
    key factors:'
  prefs: []
  type: TYPE_NORMAL
- en: Incremental algorithmic innovations, first spread over two decades^([[2](#ch13fn2)])
    and then accelerating as more research effort was poured into deep learning after
    2012.^([[3](#ch13fn3)])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ²
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Starting with the invention of backpropagation by Rumelhart, Hinton, and Williams,
    convolutional layers by LeCun and Bengio, and recurrent networks by Graves and
    Schmidthuber.
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ³
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, improved weight initialization methods, new activation functions,
    dropout, batch normalization, residual connections.
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: The availability of large amounts of labeled data, spanning many data modalities,
    including perceptual (images, audio, and video), numeric, and text, which enables
    large models to be trained on sufficient amounts of data. This is a byproduct
    of the rise of the consumer internet, spurred by the popularization of mobile
    devices, as well as Moore’s law applied to storage media.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The availability of fast, highly parallelized computation hardware at a low
    cost, especially the GPUs produced by NVIDIA—first gaming GPUs repurposed for
    parallel computing and then chips designed ground-up for deep learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A complex stack of open source software that makes this computational power
    available to many human developers and learners, while hiding the enormous amount
    of complexity underneath: the CUDA language, the web browser’s WebGL shader languages,
    and frameworks such as TensorFlow.js, TensorFlow, and Keras, which perform automatic
    differentiation and provide easy-to-use, high-level building blocks such as layers,
    loss functions, and optimizers. Deep learning is changing from the exclusive domain
    of specialists (researchers, graduate students in AI, and engineers with an academic
    background) into a tool for every programmer. TensorFlow.js is an exemplary framework
    in this front. It brings two rich and vibrant ecosystems together: the cross-platform
    ecosystem of JavaScript and the fast-advancing deep-learning ecosystem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A manifestation of the wide and deep impact of the deep-learning revolution
    is its fusion with technological stacks different from the one in which it originated
    (the C++ and Python ecosystem and the numeric computation field). Its cross-pollination
    with the JavaScript ecosystem, the main theme of the book, is a prime example
    of that. In the next section, we will review the key reasons why bringing deep
    learning to the world of JavaScript unlocks exciting new opportunities and possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.5\. Applications and opportunities unlocked by deep learning in JavaScript
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The main purpose of training a deep-learning model is to make it available for
    users to use. For many types of input modalities, such as images from the webcam,
    sounds from the microphone, and text and gesture input by the user, the data is
    generated and directly available on the client. JavaScript is perhaps the most
    mature and ubiquitous language and ecosystem for client-side programming. The
    same code written in JavaScript can be deployed as web pages and UIs on a wide
    range of devices and platforms. The web browser’s WebGL API enables cross-platform
    parallel computation on a variety of GPUs, which is leveraged by TensorFlow.js.
    These factors make JavaScript an attractive option for the deployment of deep-learning
    models. TensorFlow.js offers a converter tool that allows you to convert models
    trained with popular Python frameworks such as TensorFlow and Keras into a web-friendly
    format and deploy them into web pages for inference and transfer learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from the ease of deployment, there are also a number of additional advantages
    to serving and fine-tuning deep-learning models using JavaScript:'
  prefs: []
  type: TYPE_NORMAL
- en: Compared to server-side inference, client-side inference foregoes the latency
    of two-way data transfer, benefiting availability and leading to a smoother user
    experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By performing computation at the edge using on-device GPU acceleration, client-side
    deep learning removes the need to manage server-side GPU resources, significantly
    reducing the complexity and maintenance costs of your technology stack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By virtue of keeping the data and inference results on the client, the user’s
    data privacy is protected. This is important for domains such as healthcare and
    fashion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The visual and interactive nature of the browser and other JavaScript-based
    UI environments provides unique opportunities for visualization, aided understanding,
    and teaching of neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow.js supports not only inference but also training. This opens the
    door to client-side transfer learning and fine-tuning, which leads to better personalization
    of machine-learning models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the web browser, JavaScript provides a platform-independent API for access
    to on-device sensors, such as webcams and microphones, which accelerates the development
    of cross-platform applications that use inputs from these sensors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to its client-side eminence, JavaScript extends its prowess to the
    server side. In particular, Node.js is a highly popular framework for server-side
    applications in JavaScript. Using the Node.js version of TensorFlow.js (tfjs-node),
    you can train and serve deep-learning models outside the web browser and hence
    without resource constraints. This taps into the vast ecosystem of Node.js and
    simplifies the tech stack for members of the community. All of this can be achieved
    by using essentially the same TensorFlow.js code that you write for the client
    side, which brings you closer to the vision of “write once, run everywhere,” as
    has been demonstrated by several examples throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2\. Quick overview of the deep-learning workflow and algorithms in TensorFlow.js
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the historical overview out of the way, let’s now visit the technical aspects
    of TensorFlow.js. In this section, we will review the general workflow you should
    follow when approaching a machine-learning problem and highlight some of the most
    important considerations and common pitfalls. We will then go over the various
    neural network building blocks (layers) that we’ve covered in the book. In addition,
    we’ll survey the pretrained models in the TensorFlow.js ecosystem, which you can
    use to accelerate your development cycle. To wrap up this section, we will present
    the range of machine-learning problems you can potentially address by using these
    building blocks, stimulating you to imagine how deep neural networks written in
    TensorFlow.js can assist you in addressing your own machine-learning problems.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.1\. The universal workflow of supervised deep learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Deep learning is a powerful tool. But perhaps somewhat surprisingly, the most
    difficult and time-consuming part of the machine-learning workflow is often everything
    that comes before designing and training such models (and for models deployed
    to production, what comes after it, too). These difficult steps include understanding
    the problem domain well enough to be able to determine what sort of data is needed,
    what sort of predictions can be made with reasonable accuracy and generalization
    power, how the machine-learning model fits into the overall solution that addresses
    a practical problem, and how to measure the degree to which the model succeeds
    at doing its job. Although these are prerequisites for any successful application
    of machine learning, they aren’t something that a software library such as TensorFlow.js
    can automate for you. As a reminder, what follows is a quick summary of the typical
    supervised-learning workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Determine if machine learning is the right approach*. First, consider if machine
    learning is the right approach to your problem, and proceed with the following
    steps only if the answer is yes. In some cases, a non-machine-learning approach
    will work equally well or perhaps even better, at a lower cost.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Define the machine-learning problem*. Determine what sort of data is available
    and what you are trying to predict using the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Check if your data is sufficient*. Determine if the amount of data you already
    have is sufficient for model training. You may need to collect more data or hire
    people to manually label an unlabeled dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Identify a way to reliably measure the success of a trained model on your
    goal*. For simple tasks, this may be just prediction accuracy, but in many cases,
    it will require more sophisticated, domain-specific metrics.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Prepare the evaluation process*. Design the validation process that you’ll
    use to evaluate your models. In particular, you should split your data into three
    homogeneous yet nonoverlapping sets: a training set, a validation set, and a test
    set. The validation- and test-set labels ought not to leak into the training data.
    For instance, with temporal prediction, the validation and test data should come
    from time intervals after the training data. Your data-preprocessing code should
    be covered by tests to guard against bugs ([section 12.1](kindle_split_025.html#ch12lev1sec1)).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Vectorize the data*. Turn your data into tensors, or *n*-dimensional arrays—the
    lingua franca of machine-learning models in frameworks such as TensorFlow.js and
    TensorFlow. You often need to preprocess the tensorized data in order to make
    it more amenable to your models (for example, through normalization).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Beat the commonsense baseline*. Develop a model that beats a non-machine-learning
    baseline (such as predicting the population average for a regression problem or
    predicting the last datapoint in a time-series prediction problem), thereby demonstrating
    that machine learning can truly add value to your solution. This may not always
    be the case (see step 1).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Develop a model with sufficient capacity*. Gradually refine your model architecture
    by tuning hyperparameters and adding regularization. Make changes based on the
    prediction accuracy on the validation set only, not the training set or the test
    set. Remember that you should get your model to overfit the problem (achieve a
    better prediction accuracy on the training set than on the validation set), thus
    identifying a model capacity that’s greater than what you need. Only then should
    you begin to use regularization and other approaches to reduce overfitting.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Tune hyperparameters*. Beware of validation-set overfitting when tuning hyperparameters.
    Because hyperparameters are determined based on the performance on the validation
    set, their values will be overspecialized for the validation set and therefore
    may not generalize well to other data. It is the purpose of the test set to obtain
    an unbiased estimate of the model’s accuracy after hyperparameter tuning. So,
    you shouldn’t use the test set when tuning the hyperparameters.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Validate and evaluate the trained model*. As we discussed in [section 12.1](kindle_split_025.html#ch12lev1sec1),
    test your model with an up-to-date evaluation dataset, and decide if the prediction
    accuracy meets a predetermined criterion for serving actual users. In addition,
    perform a deeper analysis of the model’s quality on different slices (subsets)
    of the data, aiming at detecting any unfair behaviors (such as vastly different
    accuracies on different slices of the data) or unwanted biases.^([[4](#ch13fn4)])
    Proceed to the final step only if the model passes these evaluation criteria.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ⁴
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fairness in machine learning is a nascent field of study; see the following
    link for more discussion [http://mng.bz/eD4Q](http://mng.bz/eD4Q).
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Optimize and deploy the model*. Perform model optimization in order to shrink
    its size and boost its inference speed. Then deploy the model into the serving
    environment, such as a web page, a mobile app, or an HTTP service endpoint ([section
    12.3](kindle_split_025.html#ch12lev1sec3)).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This recipe is for supervised learning, which is encountered in many practical
    problems. Other types of machine-learning workflows covered in this book include
    (supervised) transfer learning, RL (reinforcement learning), and generative deep
    learning. Supervised transfer learning ([chapter 5](kindle_split_016.html#ch05))
    shares the same workflow as nontransfer supervised learning, with the slight difference
    that the model design and training steps build on a pretrained model and may require
    a smaller amount of training data than training a model from scratch. Generative
    deep learning has a different type of goal from supervised learning—that is, to
    create fake examples that look as real as possible. In practice, there are techniques
    that turn the training of generative models into supervised learning, as we saw
    in the VAE and GAN examples in [chapter 9](kindle_split_021.html#ch09). RL, on
    the other hand, involves a fundamentally different problem formulation and consequently
    a dramatically different workflow—one in which the primary players are the environment,
    the agent, the actions, the reward structure, and the algorithm or model types
    employed to solve the problem. [Chapter 11](kindle_split_023.html#ch11) provided
    a quick overview of the basic concepts and algorithms in RL.
  prefs: []
  type: TYPE_NORMAL
- en: '13.2.2\. Reviewing model and layer types in TensorFlow.js: A quick reference'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'All the numerous neural networks covered in this book can be divided into three
    families: densely connected networks (also referred to as MLPs, or multilayer
    perceptrons), convnets (convolutional networks), and recurrent networks. These
    are the three basic families of networks that every deep-learning practitioner
    should be familiar with. Each type of network is suitable for a specific type
    of input: a network architecture (MLP, convolutional, or recurrent) encodes assumptions
    about the structure of the input data—a hypothesis space within which the search
    for a good model via backpropagation and hyperparameter tuning occurs. Whether
    a given architecture will work for a given problem depends entirely on how well
    the structure in the data matches the assumption of the network architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These different network types can easily be combined in a LEGO-like fashion
    to form more complex and multimodal networks. In a way, deep-learning layers are
    LEGO bricks for differentiable information processing. We provide a quick overview
    of the mapping between the modality of input data and the appropriate network
    architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: Vector data (without temporal or serial order)—MLPs (dense `layers)`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image data (black-and-white, grayscale, or color)—2D convnets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Audio data as spectrograms—2D convnets or RNNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text data—1D convnets or RNNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time-series data—1D convnets or RNNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumetric data (such as 3D medical images)—3D convnets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video data (sequence of images)—either 3D convnets (if you need to capture motion
    effects) or a combination of a frame-by-frame 2D convnet for feature extraction
    followed by either an RNN or a 1D convnet to process the resulting feature sequence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s dive a little deeper into each of the three major architecture families,
    the tasks they are good at, and how to use them through TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: Densely connected networks and multilayer perceptrons
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The terms *densely connected networks* and *multilayer perceptron* are largely
    exchangeable, with the caveat that a densely connected network can contain as
    little as one layer, while an MLP must consist of at least a hidden layer and
    an output layer. We will use the term *MLP* to refer to all models built primarily
    with dense layers for the sake of succinctness. Such networks are specialized
    for unordered vector data (for example, the numeric features in the phishing-website-detection
    problem and the housing-price-prediction problem). Each dense layer attempts to
    model the relation between all possible pairs of input features and the layer’s
    output activations. This is achieved through a matrix multiplication between the
    dense layer’s kernel and the input vector (followed by addition with a bias vector
    and an activation function). The fact that every output activation is affected
    by every input feature is the reason such layers and the networks built on them
    are referred to as *densely connected* (or referred to as *fully connected* by
    some authors). This is in contrast to other types of architecture (convnets and
    RNNs) in which an output element depends only on a subset of the elements in the
    input data.
  prefs: []
  type: TYPE_NORMAL
- en: MLPs are most commonly used for categorical data (for example, where the input
    features are a list of attributes, such as in the phishing-website-detection problem).
    They are also often used as the final output stages of most neural networks for
    classification and regression, which may contain convolutional or recurrent layers
    as feature extractors that feed feature inputs to such MLPs. For instance, the
    2D convnets we covered in [chapters 4](kindle_split_015.html#ch04) and [5](kindle_split_016.html#ch05)
    all end with one or two dense layers, and so do the recurrent networks we visited
    in [chapter 9](kindle_split_021.html#ch09).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s briefly review how to select the activation of the output layer of an
    MLP for different types of tasks in supervised learning. To perform binary classification,
    the final dense layer of your MLP should have exactly one unit and use the sigmoid
    activation. The `binaryCrossentropy` loss function should be used as the loss
    function during the training of such a binary-classifier MLP. The examples in
    your training data should have binary labels (labels of 0 or 1). Specifically,
    the TensorFlow.js code looks like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: To perform single-label multiclass classification (where each example has exactly
    one class among multiple candidate classes), end your stack of layers with a dense
    layer that contains a softmax activation and a number of units equal to the number
    of classes. If your targets are one-hot encoded, use `categoricalCrossentropy`
    as the loss function; if they are integer indices, use `sparseCategoricalCrossentropy`.
    For instance,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To perform multilabel multiclass classification (where each example can have
    several correct classes), end your stack of layers with a dense layer that contains
    a sigmoid activation and a number of units equal to the number of all candidate
    classes. Use `binaryCrossentropy` for the loss function. Your targets should be
    k-hot encoded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To perform regression toward a vector of continuous values, end your stack
    of layers with a dense layer with the number of units equal to the number of values
    you are trying to predict (often only one number, such as the price of housing
    or a temperature value) and the default linear activation. Several loss functions
    can be suitable for regression. The most commonly used ones are `meanSquaredError`
    and `meanAbsoluteError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Convolutional networks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Convolutional layers look at local spatial patterns by applying the same geometric
    transformation to different spatial locations (patches) in an input tensor. This
    results in representations that are translation-invariant, making convolutional
    layers highly data efficient and modular. This idea is applicable to spaces of
    any dimensionality: 1D (sequences), 2D (images or similar representation of nonimage
    quantities, such as sound spectrograms), 3D (volumes), and so forth. You can use
    the `tf.layers.conv1d` layer to process sequences, the conv2d layer to process
    images, and the conv3d layer to process volumes.'
  prefs: []
  type: TYPE_NORMAL
- en: Convnets consist of stacks of convolutional and pooling layers. The pooling
    layers let you spatially downsample the data, which is required to keep feature
    maps to a reasonable size as the number of features grows, and to allow subsequent
    layers to “see” a greater spatial extent of the convnet’s input images. Convnets
    are often terminated with a flatten layer or a global pooling layer, turning spatial
    feature maps into vectors, which can in turn be processed by a stack of dense
    layers (an MLP) to achieve classification or regression outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is highly likely that regular convolution will soon be mostly (or completely)
    replaced by an equivalent but faster and more efficient alternative: depthwise
    separable convolution (`tf.layers.separableConv2d` layers). When you are building
    a network from scratch, using depthwise separable convolution is highly recommended.
    The separableConv2d layer can be used as a drop-in replacement for `tf.layers
    .conv2d`, resulting in a smaller and faster network that performs equally well
    or better on its task. Following is a typical image-classification network (single-label
    multiclass classification, in this case). Its topology contains repeating patterns
    of convolution-pooling layer groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Recurrent networks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: RNNs work by processing sequences of inputs one timestamp at a time and maintaining
    a state throughout. A state is typically a vector or a set of vectors (a point
    in a geometric space). RNNs should be used preferentially over 1D convnets in
    the case of sequences in which the patterns of interest are not temporally invariant
    (for instance, time-series data in which the recent past is more important than
    the distant past).
  prefs: []
  type: TYPE_NORMAL
- en: 'Three RNN layer types are available in TensorFlow.js: simpleRNN, GRU, and LSTM.
    For most practical purposes, you should use either GRU or LSTM. LSTM is the more
    powerful of the two, but it is also computationally more expensive. You can think
    of GRU as a simpler and cheaper alternative to LSTM.'
  prefs: []
  type: TYPE_NORMAL
- en: In order to stack multiple RNN layers on top of each other, every layer except
    the last one needs to be configured to return the full sequence of its outputs
    (each input timestep will correspond to an output timestep). If no stacking of
    RNN layers is required, usually the RNN layer needs to return only the last output,
    which in itself contains information about the entire sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of using a single RNN layer together with a dense
    layer to perform binary classification of a vector sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next is a model with a stack of RNN layers for single-label multiclass classification
    of a vector sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Layers and regularizers that help mitigate overfitting and improve convergence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Apart from the aforementioned mainstay layer types, some other types of layers
    are applicable across a wide range of model and problem types and assist the training
    process. Without these layers, the state-of-the-art accuracies on many machine-learning
    tasks wouldn’t be as high as they are today. For instance, the dropout and batchNormalization
    layers are often inserted in MLPs, convnets, and RNNs to help the model converge
    faster during training and to reduce overfitting. The following example shows
    a regression MLP with dropout layers included:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 13.2.3\. Using pretrained models from TensorFlow.js
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When the machine-learning problem you aim to solve is specific to your application
    or dataset, building and training a model from scratch is the right way to go,
    and TensorFlow.js empowers you to do that. However, in some cases, the problem
    you face is a generic one for which there exist pretrained models that either
    match your requirement exactly or can satisfy your needs with only minor tweaking.
    A collection of pretrained models is available from TensorFlow.js and third-party
    developers who build on them. Such models provide clean and easy-to-use APIs.
    They are also packaged nicely as npm packages that you can conveniently depend
    on in your JavaScript applications (including web apps and Node.js projects).
  prefs: []
  type: TYPE_NORMAL
- en: Using such pretrained models in appropriate use cases can substantially accelerate
    your development. Since it’s impossible to list all the TensorFlow.js-based pretrained
    models out there, we will survey only the most popular ones that we are aware
    of. The packages with the name prefix @tensorflow-models/ are first-party and
    maintained by the TensorFlow.js team, while the rest are the work of third-party
    developers.
  prefs: []
  type: TYPE_NORMAL
- en: '@tensorflow-models/mobilenet is a lightweight image-classification model. It
    outputs the probability scores for the 1,000 ImageNet classes given an input image.
    It is useful for labeling images in web pages and for detecting specific contents
    from the webcam input stream, as well as for transfer-learning tasks involving
    image inputs. While @tensorflow-models/mobilenet is concerned with generic image
    classes, there are third-party packages for more domain-specific image classification.
    For instance, nsfwjs classifies images into those that contain pornographic and
    other inappropriate content versus safe content, which is useful for parental
    control, safe browsing, and similar applications.'
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in [chapter 5](kindle_split_016.html#ch05), object detection
    differs from image classification in that it outputs not only *what* objects an
    image contains but also *where* they are in the coordinate system of the image.
    @tensorflow-models/coco-ssd is an object-detection model capable of detecting
    90 classes of objects. For each input image, it can detect multiple target objects
    with potentially overlapping bounding boxes, if they exist ([figure 13.1](#ch13fig01),
    panel A).
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.1\. Screenshots from several pretrained, npm-package models built
    with TensorFlow.js. Panel A: @tensorflow-models/coco-ssd is a multitarget object
    detector. Panel B: face-api.js is for real-time face and facial-key-point detection
    (reproduced from [https://github.com/justadudewhohacks/face-api.js](https://github.com/justadudewhohacks/face-api.js)
    with permission by Vincent Mühler). Panel C: handtrack.js tracks the location
    of one or both hands in real time (reproduced from [https://github.com/victordibia/handtrack.js/](https://github.com/victordibia/handtrack.js/)
    with permission by Victor Dibia). Panel D: @tensorflow-models/posenet detects
    skeletal key points of the human body using image input in real time. Panel E:
    @tensorflow-models/toxicity detects and labels seven types of inappropriate content
    in any English text input.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](13fig01_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For web applications, certain types of objects are of especially high interest
    due to their potential for enabling novel and fun computer-human interactions.
    These include the human face, the hands, and the whole body. For each of the three,
    there are specialized third-party models based on TensorFlow.js. For the face,
    face-api.js and handsfree both support real-time face tracking and detection of
    facial landmarks (such as the eyes or mouth; [figure 13.1](#ch13fig01), panel
    B). For the hands, handtrack.js can track the location of one or both hands in
    real time ([figure 13.1](#ch13fig01), panel C). For the whole body, @tensorflow-models/posenet
    enables high-precision, real-time detection of skeletal key points (such as shoulders,
    elbows, hips, and knees; [figure 13.1](#ch13fig01), panel D).
  prefs: []
  type: TYPE_NORMAL
- en: For the audio input modality, @tensorflow-models/speech-commands offers a pretrained
    model that detects 18 English words in real time, directly utilizing the browser’s
    WebAudio API. Although this is not as powerful as large-vocabulary continuous
    speech recognition, it nonetheless enables a range of voice-based user interactions
    in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: There are also pretrained models for text input. For instance, the model from
    @tensorflow-models/toxicity determines how toxic given English input texts are
    along several dimensions (for example, threatening, insulting, or obscene), which
    is useful for aided content moderation ([figure 13.1](#ch13fig01), panel E). The
    toxicity model is built on top of a more generic natural language processing model
    called @tensorflow-models/universal-sentence-encoder, which maps any given English
    sentence into a vector that can then be used for a wide range of natural language
    processing tasks, such as intent classification, topic classification, sentiment
    analysis, and question answering.
  prefs: []
  type: TYPE_NORMAL
- en: It needs to be emphasized that some of the models mentioned not only support
    simple inference but also can form the basis for transfer learning or downstream
    machine learning, which lets you apply the power of these pretrained models to
    your domain-specific data without a lengthy model-building or training process.
    This is partly due to the LEGO-like composability of layers and models. For example,
    the output of the universal sentence encoder is primarily intended to be used
    by a downstream model. The speech-commands model has built-in support for you
    to collect voice samples for new word classes and train a new classifier based
    on the samples, which is useful for voice-command applications that require custom
    vocabulary or user-specific voice adaptation. In addition, outputs from models
    such as PoseNet and face-api.js regarding the moment-by-moment location of the
    head, hands, or body posture can be fed into a downstream model that detects specific
    gestures or movement sequences, which is useful for many applications, such as
    alternative communication for accessibility use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the input modality-oriented models mentioned previously, there are
    also TensorFlow.js-based third-party pretrained models oriented toward artistic
    creativity. For instance, ml5.js includes a model for fast style transfer between
    images and a model that can draw sketches automatically. @magenta/music features
    a model that can transcribe piano music (“audio-to-score”) and MusicRNN, a “language
    model for melodies” that can “write” melodies based on a few seeding notes, along
    with other intriguing pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: The collection of pretrained models is large and continues to grow. The JavaScript
    community and the deep-learning community both have an open culture and sharing
    spirit. As you go further on your deep-learning journey, you may come across interesting
    new ideas that are potentially useful to other developers, at which point you
    are encouraged to train, package, and upload your models to npm in the form of
    the pretrained models we’ve mentioned, followed by interaction with users and
    making iterative improvements to your package. Then you’ll truly become a contributing
    member of the JavaScript deep-learning community.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.4\. The space of possibilities
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'With all these layers and pretrained modules as building blocks, what useful
    and fun models can you build? Remember, building deep-learning models is like
    playing with LEGO bricks: layers and modules can be plugged together to map essentially
    anything to anything, as long as the inputs and outputs are represented as tensors,
    and the layers have compatible input and output tensor shapes. The resulting stack
    of layers that is the model performs a differentiable geometric transformation,
    which can learn the mapping relation between the input and the output as long
    as the relation is not overly complex given the model’s capacity. In this paradigm,
    the space of possibilities is infinite. This section offers a few examples to
    inspire you to think beyond the basic classification and regression tasks that
    we’ve emphasized in this book.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have sorted the suggestions by input and output modalities. Note that quite
    a few of them stretch the limits of what is possible. Although a model could be
    trained on any of the tasks, given that a sufficient amount of training data is
    available, in some cases, such a model probably wouldn’t generalize well far from
    its training data:'
  prefs: []
  type: TYPE_NORMAL
- en: Mapping vector to vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Predictive healthcare*—Mapping patient medical records to predicted treatment
    outcomes'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Behavioral targeting*—Mapping a set of website attributes to a potential viewer’s
    behavior on the website (including page views, clicks, and other engagements)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Product quality control*—Mapping a set of attributes related to a manufactured
    product to predictions about how well the product will perform on the market (sales
    and profits in different areas of the market)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping image to vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Medical image AI*—Mapping medical images (such as X-rays) to diagnostic results'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Automatic vehicle steering*—Mapping images from cameras to vehicle control
    signals, such as wheel-steering actions'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Diet helper*—Mapping images of foods and dishes to predicted health effects
    (for example, calorie counts or allergy warnings)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cosmetic product recommendation*—Mapping selfie images to recommended cosmetic
    products'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping time-series data to vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Brain-computer interfaces*—Mapping electroencephalogram (EEG) signals to user
    intentions'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Behavioral targeting*—Mapping past history of product purchases (such as movie
    or book purchases) to probabilities of purchasing other products in the future'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prediction of earthquakes and aftershocks*—Mapping seismic instrument data
    sequences to the predicted likelihoods of earthquakes and ensuing aftershocks'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping text to vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Email sorter*—Mapping email content to generic or user-defined labels (for
    example, work-related, family-related, and spam)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Grammar scorer*—Mapping student writing samples to writing-quality scores'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Speech-based medical triaging*—Mapping a patient’s description of illness
    to the medical department that the patient should be referred to'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping text to text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reply-message suggestion*—Mapping emails to a set of possible response messages'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Domain-specific question answering*—Mapping customer questions to automated
    reply texts'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Summarization*—Mapping a long article to a short summary'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping images to text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Automated alt-text generation*—Given an image, generating a short snippet
    of text that captures the essence of the content'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mobility aids for the visually impaired*—Mapping images of interior or exterior
    surroundings to spoken guidance and warnings about potential mobility hazards
    (for example, locations of exits and obstacles)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping images to images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Image super-resolution*—Mapping low-resolution images to higher-resolution
    ones'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Image-based 3D reconstruction*—Mapping ordinary images to images of the same
    object but viewed from a different angle'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping image and time-series data to vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Doctor’s multimodal assistant*—Mapping a patient’s medical image (such as
    an MRI) and history of vital signs (blood pressure, heart rate, and so on) to
    predictions of treatment outcomes'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping image and text to text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Image-based question answering*—Mapping an image and a question related to
    it (for instance, an image of a used car and a question about its make and year)
    to an answer'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping image and vector to image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Virtual try-on for clothes and cosmetic products*—Mapping a user’s selfie
    and a vector representation of a cosmetic or garment to an image of the user wearing
    that product'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping time-series data and vector to time-series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Musical style transfer*—Mapping a musical score (such as a classical piece
    represented as a timeseries of notes) and a description of the desired style (for
    example, jazz) to a new musical score in the desired style'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As you may have noticed, the last four categories in this list involve mixed
    modalities in input data. At this point in our technological history, where most
    things in life have been digitized and can hence be represented as tensors, what
    you can potentially achieve with deep learning is limited only by your own imagination
    and the availability of training data. Although almost any mapping is possible,
    not every mapping is. We’ll discuss in the next section what deep learning *cannot*
    do yet.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2.5\. Limitations of deep learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The space of applications that can be implemented with deep learning is nearly
    infinite. As a result, it is easy to overestimate the power of deep neural networks
    and be overly optimistic about what problems they can solve. This section briefly
    talks about some of the limitations that they still have.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks do not see the world in the same way humans do
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A risk we face when trying to understand deep learning is *anthropomorphization*—that
    is, the tendency to misinterpret deep neural networks as mimicking perception
    and cognition in humans. Anthropomorphizing deep neural networks is demonstrably
    wrong in a few regards. First, when humans perceive a sensory stimulus (such as
    an image with a girl’s face in it or an image with a toothbrush), they not only
    perceive the brightness and color patterns of the input but also extract the deeper
    and more important concepts represented by those superficial patterns (for example,
    the face of a young, female individual or a dental hygiene product, and the relation
    between the two). Deep neural networks, on the other hand, don’t work this way.
    When you’ve trained an image-captioning model to map images to text output, it
    is wrong to believe that the model understands the image in a human sense. In
    some cases, even the slightest departure from the sort of images present in the
    training data can cause the model to generate absurd captions (as in [figure 13.2](#ch13fig02)).
  prefs: []
  type: TYPE_NORMAL
- en: Figure 13.2\. Failure of an image-captioning model trained with deep learning
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](13fig02_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In particular, the peculiar, nonhuman way in which deep neural networks process
    their inputs is highlighted by *adversarial examples*, which are samples purposefully
    designed to trick a machine-learning model into making classification mistakes.
    As we demonstrated by finding the maximally activating images for convnet filters
    in [section 7.2](kindle_split_019.html#ch07lev1sec2), it’s possible to do gradient
    ascent in the input space to maximize the activation of a convnet filter. The
    idea can be extended to output probabilities, so we can perform gradient ascent
    in the input space to maximize the model’s predicted probability for any given
    output class. By taking a picture of a panda and adding a “gibbon gradient” to
    it, we can cause a model to misclassify the image as a gibbon ([figure 13.3](#ch13fig03)).
    This is despite the fact that the gibbon gradient is noise-like and small in magnitude,
    so that the resulting adversarial image looks indistinguishable from the original
    panda image to humans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.3\. Adversarial example: changes imperceptible to human eyes can
    throw off a deep convnet’s classification result. See more discussion on adversarial
    attacks of deep neural networks at [http://mng.bz/pyGz](http://mng.bz/pyGz).'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](13fig03_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So, deep neural networks for computer vision don’t possess a real understanding
    of images—at least not in a human sense. Another area in which human learning
    stands in sharp contrast with deep learning is how the two types of learning generalize
    from a limited number of training examples. Deep neural networks can do what can
    be called *local generalization*. [Figure 13.4](#ch13fig04) illustrates a scenario
    in which a deep neural network and a human are tasked to learn the boundary of
    a single class in a 2D parametric space by using only a small number of (say,
    eight) training examples. The human realizes that the shape of the class boundary
    should be smooth and the region should be connected, and quickly draws a single
    closed curve as the “guesstimated” boundary. A neural network, on the other hand,
    suffers from a lack of abstraction and prior knowledge. Therefore, it may end
    up with an ad hoc irregular boundary severely overfit to the few training samples.
    The trained model will generalize very poorly beyond the training samples. Adding
    more samples can help the neural network but is not always practically possible.
    The main problem is that the neural network is created from scratch, just for
    this particular problem. Unlike a human individual, it doesn’t have any prior
    knowledge to rely on and hence doesn’t know what to “expect.”^([[5](#ch13fn5)])
    This is the fundamental reason behind a major limitation of current deep-learning
    algorithms: namely, a large number of human-labeled training data is usually required
    to train a deep neural network to decent generalization accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: ⁵
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are research efforts to train a single deep neural network on many different
    and seemingly unrelated tasks to facilitate cross-domain knowledge sharing (see,
    for example, Lukasz Kaiser et al., “One Model To Learn Them All,” submitted 16
    Jun. 2017, [https://arxiv.org/abs/1706.05137](https://arxiv.org/abs/1706.05137)).
    But such multitask models have not received wide adoption yet.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Figure 13.4\. Local generalization in deep-learning models vs. extreme generalization
    in human intelligence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](13fig04_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 13.3\. Trends in deep learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we’ve discussed, deep learning has made amazing progress in recent years,
    but it still suffers from some limitations. But the field is not static; it keeps
    advancing at a breathtaking velocity, so it’s likely that some of the limitations
    will be ameliorated in the near future. This section contains a set of educated
    guesses about what important breakthroughs in deep learning we’ll witness in the
    coming years:'
  prefs: []
  type: TYPE_NORMAL
- en: First, unsupervised or semisupervised learning could see significant advancements.
    This will have a profound impact on all forms of deep learning because even though
    labeled datasets are costly to construct and hard to come across, there is an
    abundance of unlabeled datasets in all sorts of business domains. If we can invent
    a way to use a small amount of labeled data to guide the learning from a vast
    amount of unlabeled data, it will unlock many new applications for deep learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, hardware for deep learning may continue to be improved, ushering in
    more and more powerful neural network accelerators (such as the future generations
    of the Tensor Processing Unit^([[6](#ch13fn6)])). This will allow researchers
    to train ever more powerful networks with ever larger datasets and thereby continue
    to push forward the state-of-the-art accuracy on many machine-learning tasks,
    such as computer vision, speech recognition, natural language processing, and
    generative models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⁶
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Norman P. Jouppi et al., “In-Datacenter Performance Analysis of a Tensor Processing
    Unit™,” 2017, [https://arxiv.org/pdf/1704.04760.pdf](https://arxiv.org/pdf/1704.04760.pdf).
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Designing model architecture and tuning model hyperparameters will likely become
    more and more automated. We are already seeing a trend in this area, as exemplified
    by technologies such as AutoML^([[7](#ch13fn7)]) and Google Vizier.^([[8](#ch13fn8)])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⁷
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Barret Zoph and Quoc V. Le, “Neural Architecture Search with Reinforcement Learning,”
    submitted 5 Nov. 2016, [https://arxiv.org/abs/1611.01578](https://arxiv.org/abs/1611.01578).
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ⁸
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Daniel Golovin, “Google Vizier: A Service for Black-Box Optimization,” Proc.
    23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
    2017, pp. 1487–1495, [http://mng.bz/O9yE](http://mng.bz/O9yE).'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: The sharing and reuse of neural network components will likely continue to grow.
    Transfer learning based on pretrained models will gain further momentum. State-of-the-art
    deep-learning models are getting increasingly powerful and generic by the day.
    They are increasingly trained on larger and larger datasets, sometimes with huge
    amounts of computation power for the sake of automated architectural search and
    hyperparameter tuning (see the first and second predictions). As a consequence,
    it’s becoming more sensible and economical to reuse such pretrained models, for
    either direct inference or transfer learning, than to train them from scratch
    over and over again. In a way, this makes the field of deep learning more similar
    to traditional software engineering, in which high-quality libraries are depended
    on and reused regularly, to the benefit of standardization and the development
    velocity of the field as a whole.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning may be deployed to new areas of application, improving many existing
    solutions and opening up new practical use cases. In our opinion, the potential
    areas of application are truly limitless. Fields including agriculture, finance,
    education, transportation, healthcare, fashion, sports, and entertainment present
    countless opportunities waiting to be explored for deep-learning practitioners.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As deep learning penetrates more application domains, there will likely be a
    growing emphasis on deep learning at the edge because edge devices are closest
    to where the users are. As a result, the field will likely invent smaller and
    more power-efficient neural network architectures that achieve the same prediction
    accuracy and speed as existing, larger models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these predictions will affect deep learning in JavaScript, but the last
    three predictions are especially relevant. Expect more powerful and efficient
    models to become available to TensorFlow.js in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4\. Pointers for further exploration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As final parting words, we want to give you some pointers about how to keep
    learning and updating your knowledge and skills after you’ve turned the last page
    of this book. The field of modern deep learning as we know it today is only a
    few years old, despite a long, slow prehistory stretching back decades. With an
    exponential increase in financial resources and research headcount since 2013,
    the field as a whole is now moving at a frenetic pace. Many of the things you
    learned in this book won’t stay relevant for very long. It is the core ideas of
    deep learning (learning from data, reducing manual feature engineering, layer-by-layer
    transformation of representation) that will likely stick around for a longer time.
    More importantly, the foundation of knowledge you developed by reading this book
    will hopefully prepare you to learn about new developments and trends in the field
    of deep learning on your own. Fortunately, the field has an open culture in which
    most cutting-edge advances (including many datasets!) are published in the form
    of openly accessible and free preprints, accompanied by public blog posts and
    tweets. Here are a few top resources you should be familiar with.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.1\. Practice real-world machine-learning problems on Kaggle
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An effective way to acquire real-world experience in machine learning (and especially
    deep learning) is to try your hand at competitions on Kaggle ([https://kaggle.com](https://kaggle.com)).
    The only real way to learn machine learning is through actual coding, model building,
    and tuning. That’s the philosophy of the book, as reflected in its numerous code
    examples ready for you to study, tweak, and hack. But nothing is as effective
    in teaching you how to do machine learning as building your models and machine-learning
    systems in a ground-up fashion, using a library such as TensorFlow.js. On Kaggle,
    you can find an array of constantly renewed data-science competitions and datasets,
    many of which involve deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Although most Kaggle users use Python tools (such as TensorFlow and Keras) to
    solve the competitions, most of the datasets on Kaggle are language-agnostic.
    So, it is entirely feasible to solve most Kaggle problems using a non-Python deep-learning
    framework like TensorFlow.js. By participating in a few competitions, maybe as
    a part of a team, you’ll become familiar with the practical side of some of the
    advanced best practices described in this book, especially hyperparameter tuning
    and avoiding validation-set overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.2\. Read about the latest developments on arXiv
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Deep-learning research, in contrast with some other academic fields, takes
    place almost completely in the open. Papers are made publicly and freely accessible
    as soon as they are finalized and pass review, and a lot of related software is
    open source. ArXiv ([https://arxiv.org](https://arxiv.org))—pronounced “archive”
    (the X stands for the Greek letter *chi*)—is an open-access preprint server for
    mathematics, physics, and computer science papers. It has become the de facto
    way to publish cutting-edge work in the field of machine learning and deep learning,
    and hence is also the de facto way to stay up-to-date with the field. This allows
    the field to move extremely fast: all new findings and inventions are instantly
    available for all to see, to critique, and to build on.'
  prefs: []
  type: TYPE_NORMAL
- en: An important downside of ArXiv is the sheer quantity of new papers posted every
    day, which makes it impossible to skim them all. The fact that many of the papers
    on ArXiv aren’t peer-reviewed makes it difficult to identify which ones are important
    and of high quality. The community has built tools to help with these challenges.
    For example, a website called ArXiv Sanity Preserver ([arxiv-sanity.com](http://arxiv-sanity.com))
    serves as a recommendation engine for new ArXiv papers and can help you keep track
    of new developments in specific vertical domains of deep learning (such as natural
    language processing or object detection). Additionally, you can use Google Scholar
    to keep track of publications in your areas of interest and by your favorite authors.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.3\. Explore the TensorFlow.js Ecosystem
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'TensorFlow.js has a vibrant and growing ecosystem of documentation, guides,
    tutorials, blogosphere, and open source projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Your main reference for working with TensorFlow.js is the official online documentation
    at [www.tensorflow.org/js/](http://www.tensorflow.org/js/). The detailed, up-to-date
    API documentation is available at [https://js.tensorflow.org/api/latest/](https://js.tensorflow.org/api/latest/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can ask questions about TensorFlow.js on Stack Overflow using the tag “tensorflow.js”:
    [https://stackoverflow.com/questions/tagged/tensorflow.js](https://stackoverflow.com/questions/tagged/tensorflow.js).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For general discussion about the library, use the Google Group: [https://groups.google.com/a/tensorflow.org/forum/#!forum/tfjs](https://groups.google.com/a/tensorflow.org/forum/#!forum/tfjs).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also follow members of the TensorFlow.js team who have an active presence
    on Twitter, including
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://twitter.com/sqcai](https://twitter.com/sqcai)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://twitter.com/nsthorat](https://twitter.com/nsthorat)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://twitter.com/dsmilkov](https://twitter.com/dsmilkov)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://twitter.com/tensorflow](https://twitter.com/tensorflow)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Final words
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the end of *Deep Learning with JavaScript*! We hope you’ve learned a
    thing or two about AI, deep learning, and how to perform some basic deep-learning
    tasks in JavaScript using TensorFlow.js. Like any interesting and useful topic,
    learning about AI and deep learning is a life-long journey. The same can be said
    for the application of AI and deep learning to practical problems. This is true
    for professionals and amateurs alike. For all the progress made in deep learning
    so far, most of the fundamental questions remain unanswered, and most of the practical
    potential of deep learning has barely been tapped. Please keep learning, questioning,
    researching, imaging, hacking, building, and sharing! We look forward to seeing
    what you build using deep learning and JavaScript!
  prefs: []
  type: TYPE_NORMAL
