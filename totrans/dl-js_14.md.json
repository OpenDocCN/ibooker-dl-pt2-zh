["```js\nimport * as tf from '@tensorflow/tfjs';\n```", "```js\n  const myArray = [{xs: [1, 0, 9], ys: 10},\n                   {xs: [5, 1, 3], ys: 11},\n                   {xs: [1, 1, 9], ys: 12}];\n  const myFirstDataset = tf.data.array(myArray);    ***1***\n  await myFirstDataset.forEachAsync(\n       e => console.log(e));                        ***2***\n\n// Yields output like\n// {xs: Array(3), ys: 10}\n// {xs: Array(3), ys: 11}\n// {xs: Array(3), ys: 12}\n```", "```js\n  const myURL =\n      \"https://storage.googleapis.com/tfjs-examples/\" +\n          \"multivariate-linear-regression/data/train-data.csv\";\n  const myCSVDataset = tf.data.csv(myURL);                       ***1***\n  await myCSVDataset.forEachAsync(e => console.log(e));          ***2***\n\n// Yields output of 333 rows like\n// {crim: 0.327, zn: 0, indus: 2.18, chas: 0, nox: 0.458, rm: 6.998,\n// age: 45.8, tax: 222}\n// ...\n```", "```js\n> const data = tf.data.csv(\n     'file://./relative/fs/path/to/boston-housing-train.csv');\n```", "```js\n  let numPlaysSoFar = 0;                            ***1***\n\n  function rollTwoDice() {\n    numPlaysSoFar++;\n    return [Math.ceil(Math.random() * 6), Math.ceil(Math.random() * 6)];\n  }\n\n  function* rollTwoDiceGeneratorFn() {              ***2***\n    while(true) {                                   ***2***\n      yield rollTwoDice();                          ***2***\n    }\n  }\n\n  const myGeneratorDataset = tf.data.generator(     ***3***\n      rollTwoDiceGeneratorFn);                      ***3***\n  await myGeneratorDataset.take(1).forEachAsync(    ***4***\n      e => console.log(e));                         ***4***\n\n// Prints to the console a value like\n// [4, 2]\n```", "```js\nfunction* countDownFrom10() {\n  for (let i = 10; i > 0; i--) {\n    yield(i);\n  }\n}\n\nconst dataset = tf.data.generator(countDownFrom10);\n```", "```js\nfunction countDownFrom10Func() {\n  let i = 10;\n  return {\n    next: () => {\n      if (i > 0) {\n        return {value: i--, done: false};\n      } else {\n        return {done: true};\n      }\n    }\n  }\n}\n\nconst dataset = tf.data.generator(countDownFrom10Func);\n```", "```js\n  const seed = Math.floor(\n      Math.random() * 10000);                     ***1***\n  const trainData = tf.data.array(IRIS_RAW_DATA)\n       .shuffle(IRIS_RAW_DATA.length, seed);      ***1***\n       .take(N);                                  ***2***\n       .map(preprocessFn);\n  const testData = tf.data.array(IRIS_RAW_DATA)\n       .shuffle(IRIS_RAW_DATA.length, seed);      ***1***\n       .skip(N);                                  ***3***\n       .map(preprocessFn);\n```", "```js\n  let count = 0;\n\n  // Identity function which also increments count.\n  function identityFn(x) {\n    count += 1;\n    return x;\n  }\n\n  console.log('skip before map');\n  await tf.data.array([1, 2, 3, 4, 5, 6])\n      .skip(6)                            ***1***\n    .map(identityFn)\n    .forEachAsync(x => undefined);\n  console.log(`count is ${count}`);\n\n  console.log('map before skip');\n  await tf.data.array([1, 2, 3, 4, 5, 6])\n      .map(identityFn)                    ***2***\n    .skip(6)\n    .forEachAsync(x => undefined);\n  console.log(`count is ${count}`);\n\n// Prints:\n// skip before map\n// count is 0\n// map before skip\n// count is 6\n```", "```js\n  function newStreamingZeroMeanFn() {    ***1***\n    let samplesSoFar = 0;\n    let sumSoFar = 0;\n    return (x) => {\n      samplesSoFar += 1;\n      sumSoFar += x;\n      const estimatedMean = sumSoFar / samplesSoFar;\n      return x - estimatedMean;\n    }\n  }\n  const normalizedDataset1 =\n     unNormalizedDataset1.map(newStreamingZeroMeanFn());\n  const normalizedDataset2 =\n     unNormalizedDataset2.map(newStreamingZeroMeanFn());\n```", "```js\nmodel.fit(images, targets, modelFitArgs)\n```", "```js\nmodel.fitDataset(dataset, modelFitDatasetArgs)\n```", "```js\ngit clone https://github.com/tensorflow/tfjs-examples.git\ncd tfjs-examples/data-generator\nyarn\nyarn watch\n```", "```js\n  import * as game from './game';                    ***1***\n\n  let numSimulationsSoFar = 0;\n\n  function runOneGamePlay() {\n    const player1Hand = game.randomHand();           ***2***\n    const player2Hand = game.randomHand();           ***2***\n    const player1Win = game.compareHands(            ***3***\n        player1Hand, player2Hand);                   ***3***\n    numSimulationsSoFar++;\n    return {player1Hand, player2Hand, player1Win};   ***4***\n  }\n\n  function* gameGeneratorFunction() {\n    while (true) {\n      yield runOneGamePlay();\n    }\n  }\n\n  export const GAME_GENERATOR_DATASET =\n     tf.data.generator(gameGeneratorFunction);\n\n  await GAME_GENERATOR_DATASET.take(1).forEach(\n      e => console.log(e));\n\n// Prints\n// {player1Hand: [11, 9, 7, 8],\n// player2Hand: [10, 9, 5, 1],\n// player1Win: 1}\n```", "```js\n  function gameToFeaturesAndLabel(gameState) {              ***1***\n     return tf.tidy(() => {\n      const player1Hand = tf.tensor1d(gameState.player1Hand, 'int32');\n      const handOneHot = tf.oneHot(\n          tf.sub(player1Hand, tf.scalar(1, 'int32')),\n          game.GAME_STATE.max_card_value);\n\n      const features = tf.sum(handOneHot, 0);               ***2***\n      const label = tf.tensor1d([gameState.player1Win]);\n      return {xs: features, ys: label};\n    });\n  }\n\n  let BATCH_SIZE = 50;\n\n  export const TRAINING_DATASET =\n     GAME_GENERATOR_DATASET.map(gameToFeaturesAndLabel)     ***3***\n                                 .batch(BATCH_SIZE);        ***4***\n\n  await TRAINING_DATASET.take(1).forEach(\n      e => console.log([e.shape, e.shape]));\n\n// Prints the shape of the tensors:\n// [[50, 13], [50, 1]]\n```", "```js\n  // Construct model.\n  model = tf.sequential();\n  model.add(tf.layers.dense({\n    inputShape: [game.GAME_STATE.max_card_value],\n    units: 20,\n    activation: 'relu'\n  }));\n  model.add(tf.layers.dense({units: 20, activation: 'relu'}));\n  model.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));\n  // Train model\n  await model.fitDataset(TRAINING_DATASET, {                              ***1***\n    batchesPerEpoch: ui.getBatchesPerEpoch(),                             ***2***\n    epochs: ui.getEpochsToTrain(),\n    validationData: TRAINING_DATASET,                                     ***3***\n    validationBatches: 10,                                                ***4***\n    callbacks: {\n      onEpochEnd: async (epoch, logs) => {\n        tfvis.show.history(\n            ui.lossContainerElement, trainLogs, ['loss', 'val_loss'])\n        tfvis.show.history(                                               ***5***\n            ui.accuracyContainerElement, trainLogs, ['acc', 'val_acc'],\n            {zoomToFitAccuracy: true})\n      },\n    }\n  }\n```", "```js\n    while (true) { ... }\n    ```", "```js\n    for (let i = 0; i<ui.getBatchesPerEpoch(); i++) { ... }\n    ```", "```js\ngit clone https://github.com/tensorflow/tfjs-examples.git\ncd tfjs-examples/data-csv\nyarn && yarn watch\n```", "```js\nconst myData = tf.data.csv(url);\n```", "```js\n  const url = document.getElementById('queryURL').value;\n  const myData = tf.data.csv(url);                          ***1***\n  await myData.take(10).forEach(\n      x => console.log(JSON.stringify(x))));                ***2***\n\n// Output is like\n// {\"crim\":0.26169,\"zn\":0,\"indus\":9.9,\"chas\":0,\"nox\":0.544,\"rm\":6.023, ...\n// ,\"medv\":19.4}\n// {\"crim\":5.70818,\"zn\":0,\"indus\":18.1,\"chas\":0,\"nox\":0.532,\"rm\":6.75, ...\n// ,\"medv\":23.7}\n// ...\n```", "```js\nconst myData = tf.data.csv(url, {\n     hasHeader: false,\n     columnNames: [\"firstName\", \"lastName\", \"id\"]\n   });\n```", "```js\n  const url = document.getElementById('queryURL').value;\n  const myData = tf.data.csv(url);\n       const columnNames = await myData.columnNames();   ***1***\n  console.log(columnNames);\n  // Outputs something like [\n  //     \"crim\", \"zn\", \"indus\", ..., \"tax\",\n  //     \"ptratio\", \"lstat\"] for Boston Housing\n```", "```js\n  const url = document.getElementById('queryURL').value;\n  const sampleIndex = document.getElementById(            ***1***\n      'whichSampleInput').valueAsNumber;                  ***1***\n  const myData = tf.data.csv(url);                        ***2***\n  const sample = await myData\n                           .skip(sampleIndex)             ***3***\n                           .take(1)                       ***4***\n                           .toArray();                    ***5***\n\n  console.log(sample);\n  // Outputs something like: [{crim: 0.3237, zn: 0, indus: 2.18, ..., tax:\n  // 222, ptratio: 18.7, lstat: 2.94}]\n  // for Boston Housing.\n```", "```js\n  const url = 'http://some.bad.url';\n  const sampleIndex = document.getElementById(\n      'whichSampleInput').valueAsNumber;\n  const myData = tf.data.csv(url);              ***1***\n  let columnNames;\n  try {\n    columnNames = await myData.columnNames();   ***2***\n  } catch (e) {\n    ui.updateColumnNamesMessage(`Could not connect to ${url}`);\n  }\n```", "```js\n>  const url = 'http://path/to/your/private.csv'\n>  const requestInfo = new Request(url);\n>  const API_KEY = 'abcdef123456789'\n>  requestInfo.headers.append('Authorization', API_KEY);\n>  const myDataset = tf.data.csv(requestInfo);\n```", "```js\nconst videoElement = document.createElement('video');  ***1***\nvideoElement.width = 100;\nvideoElement.height = 100;\nonst webcam = await tf.data.webcam(videoElement);      ***2***\nconst img = await webcam.capture();                    ***3***\nimg.print();\nwebcam.stop();                                         ***4***\n```", "```js\nconst videoElement = undefined;\nconst webcamConfig = {\n    facingMode: 'user',\n    resizeWidth: 100,\n   resizeHeight: 100};\nconst webcam = await tf.data.webcam(\n    videoElement, webcamConfig);         ***1***\n```", "```js\nconst videoElement = document.createElement('video');\nvideoElement.width = 300;\nvideoElement.height = 300;            ***1***\n\nconst webcamConfig = {\n    resizeWidth: 150,\n    resizeHeight: 100,                ***2***\n    centerCrop: true                  ***3***\n};\n\nconst webcam = await tf.data.webcam(\n    videoElement, webcamConfig);      ***4***\n```", "```js\n// No:\n    let webcam = await tfd.webcam(myElement)\n    webcam = webcam.map(myProcessingFunction);\n    const imgTensor = webcam.capture();\n    // use imgTensor here.\n    tf.dispose(imgTensor)\n```", "```js\n// Yes:\n    let webcam = await tfd.webcam(myElement);\n    const imgTensor = myPreprocessingFunction(webcam.capture());\n    // use imgTensor here.\n    tf.dispose(imgTensor)\n```", "```js\nasync function getImage() {                     ***1***\n  return (await webcam.capture())               ***2***\n      .expandDims(0)\n      .toFloat()\n      .div(tf.scalar(127))\n      .sub(tf.scalar(1));\n\nwhile (isPredicting) {\n  const img = await getImage();                 ***3***\n\n  const predictedClass = tf.tidy(() => {\n    // Capture the frame from the webcam.\n\n    // Process the image and make predictions...\n     ...\n\n    await tf.nextFrame();                       ***4***\n  }\n```", "```js\nasync function init() {\n  try {\n    webcam = await tfd.webcam(\n        document.getElementById('webcam'));                 ***1***\n  } catch (e) {\n    console.log(e);\n    document.getElementById('no-webcam').style.display = 'block';\n  }\n  truncatedMobileNet = await loadTruncatedMobileNet();\n\n  ui.init();\n\n  // Warm up the model. This uploads weights to the GPU and compiles the\n  // WebGL programs so the first time we collect data from the webcam it\n  // will be quick.\n  const screenShot = await webcam.capture();\n  truncatedMobileNet.predict(screenShot.expandDims(0));     ***2***\n  screenShot.dispose();                                     ***3***\n}\n```", "```js\nconst mic = await tf.data.microphone({               ***1***\n  fftSize: 1024,\n  columnTruncateLength: 232,\n  numFramesPerSpectrogram: 43,\n  sampleRateHz: 44100,\n  smoothingTimeConstant: 0,\n  includeSpectrogram: true,\n  includeWaveform: true\n});\nconst audioData = await mic.capture();               ***2***\nconst spectrogramTensor = audioData.spectrogram;     ***3***\nconst waveformTensor = audioData.waveform;           ***4***\nmic.stop();                                          ***5***\n```", "```js\n  const plottingData = {\n    x: [],\n    y: [],\n    mode: 'markers',\n    type: 'scatter',\n    marker: {symbol: 'circle', size: 8}\n  };\n  const filename = 'https://storage.googleapis.com/learnjs-data/csv-\n     datasets/california_housing_train.csv';\n  const dataset = tf.data.csv(filename);\n  await dataset.take(1000).forEachAsync(row => {    ***1***\n    plottingData.x.push(i++);\n    plottingData.y.push(row['longitude']);\n  });\n\n  Plotly.newPlot('plot', [plottingData], {\n    width: 700,\n    title: 'Longitude feature vs sample index',\n    xaxis: {title: 'sample index'},\n    yaxis: {title: 'longitude'}\n  });\n```", "```js\nfor (let windowSize of [10, 50, 250, 6000]) {\n   shuffledDataset = dataset.shuffle(windowSize);\n   myPlot(shuffledDataset, windowSize)\n}\n```", "```js\nweight = Math.min(MAX_WEIGHT, Math.max(weight, MIN_WEIGHT));\n```", "```js\nisOutlierWeight = weight > MAX_WEIGHT | weight < MIN_WEIGHT;\n```", "```js\n  const filteredDataset =\n      tf.data.csv(csvFilename)\n     .filter(e => e['featureName']);     ***1***\n```", "```js\n  async function calculateMeanOfNonMissing(              ***1***\n      dataset, featureName) {                            ***1***\n    let samplesSoFar = 0;\n    let sumSoFar = 0;\n    await dataset.forEachAsync(row => {\n      const x = row[featureName];\n      if (x != null) {                                   ***2***\n        samplesSoFar += 1;\n        sumSoFar += x;\n      }\n    });\n    return sumSoFar / samplesSoFar;                      ***3***\n  }\n\n  function replaceMissingWithImputed(                    ***4***\n      row, featureName, imputedValue)) {                 ***4***\n    const x = row[featureName];\n    if (x == null) {\n      return {...row, [featureName]: imputedValue};\n    } else {\n      return row;\n    }\n  }\n\n  const rawDataset tf.data.csv(csvFilename);\n  const imputedValue = await calculateMeanOfNonMissing(\n      rawDataset, 'myFeature');\n  const imputedDataset = rawDataset.map(                 ***5***\n      row => replaceMissingWithImputed(                  ***5***\n          row, 'myFeature', imputedValue));              ***5***\n```", "```js\nfunction addMissingness(row, featureName)) {          ***1***\n  const x = row[featureName];\n  const isMissing = (x == null) ? 1 : 0;\n  return {...row, [featureName + '_isMissing']: isMissing};\n}\n\nconst rawDataset tf.data.csv(csvFilename);\nconst datasetWithIndicator = rawDataset.map(\n      (row) => addMissingness(row, featureName);      ***2***\n```", "```js\n  function augmentFn(sample) {                           ***1***\n    const img = sample.image;\n    const augmentedImg = randomRotate(\n        randomSkew(randomMirror(img))));                 ***2***\n    return {image: augmentedImg, label: sample.label};\n  }\n\n  const (trainingDataset, validationDataset} =           ***3***\n      getDatsetsFromSource();                            ***3***\n  augmentedDataset = trainingDataset                     ***4***\n     .repeat().map(augmentFn).batch(BATCH_SIZE);         ***4***\n\n  // Train model\n  await model.fitDataset(augmentedDataset, {             ***5***\n    batchesPerEpoch: ui.getBatchesPerEpoch(),\n    epochs: ui.getEpochsToTrain(),\n    validationData: validationDataset.repeat(),          ***6***\n    validationBatches: 10,\n    callbacks: { ... },\n    }\n  }\n```"]