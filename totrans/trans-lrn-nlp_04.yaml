- en: '3 Getting started with baselines: Benchmarking and optimization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing a pair of natural language processing (NLP) problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establishing problem baselines using key traditional methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baselining with representative deep pretrained language models, ELMo and BERT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we continue our direct dive into solving NLP problems we started
    in the previous chapter. We continue with our goal to establish a set of baselines
    for a pair of concrete NLP problems, which we will later be able to use to measure
    progressive improvements gained from leveraging increasingly sophisticated transfer
    learning approaches. We complete the exercise that we started in chapter 2, where
    we introduced a pair of practical problems, preprocessed the corresponding data,
    and initiated baselining by exploring some generalized linear methods. In particular,
    we introduced the email spam and the Internet Movie Database (IMDB) movie review
    classification examples and used logistic regression and a support vector machine
    (SVM) to baseline them.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we explore decision-tree-based and neural-network-based methods.
    The decision-tree-based methods we look at include random forests and gradient-boosting
    machines. With regard to the neural-network-based methods, we apply the simplest
    form of transfer learning to a pair of recently popularized deep pretrained language
    models, ELMo and BERT. This work involves fine-tuning only a handful of the final
    layers of each network on a target dataset. This activity will serve as an applied
    hands-on introduction to the main theme of the book—transfer learning for NLP.
    Additionally, we explore optimizing the performance of models via hyperparameter
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: We begin by exploring decision-tree-based methods in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Decision-tree-based models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A decision tree is a decision support aid that models decisions and their consequences
    as *trees*—a graph where any two nodes are connected by exactly one path. An alternative
    definition of a tree is a flowchart that transforms input values into output categories.
    More details about this type of model can be found in chapter 1.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we apply two of the most common decision-tree-based methods—random
    forests and gradient-boosting machines—to our two running problems.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Random forests (RFs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Random* *forests* (RFs) provide a practical machine learning method for applying
    decision trees by generating a large number of specialized trees and collecting
    their outputs. RFs are extremely flexible and widely applicable, making them often
    the second algorithm practitioners try after logistic regression for baselining.
    See chapter 1 for more detailed discussions around RFs and their historical context.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build our classifier using the popular library scikit-learn, as shown
    next.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.1 Training and testing a random forest classifier
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Loads scikit's random forest classifier library
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Creates a random forest classifier
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Trains the classifier to learn how the training features relate to the training
    response variable
  prefs: []
  type: TYPE_NORMAL
- en: Training the RF classifier on the email example data with this code took under
    a second in our experience and achieved an accuracy score of 0.945\. Training
    it on the IMDB example similarly took under a second and achieved an accuracy
    score of 0.665\. This exercise further confirms the initial hunch from the previous
    chapter that the IMDB review problem is harder than the email classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Gradient-boosting machines (GBMs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This variant of decision-tree-based machine learning algorithms iteratively
    learns new decision-tree-based models that address the weak points of models from
    the previous iterations. At the time of this writing, they are widely considered
    to be the best class of methods for addressing nonperceptual machine learning
    problems. They do present some disadvantages, unfortunately, including a larger
    model size, a higher risk of overfitting, and less interpretability than some
    other decision tree models.
  prefs: []
  type: TYPE_NORMAL
- en: The code for training a gradient-boosting machine (GBM) classifier is shown
    in the next listing. Again, we use the implementation of these models in scikit-learn.
    Note that the implementation in the Python library XGBoost is widely considered
    to be more memory-efficient and more readily scalable/parallelizable.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.2 Training/testing a gradient-boosting machine classifier
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ❶ GBM algorithm
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Additional sklearn functions
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Fits the algorithm on the overall data
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Predicts the training set
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Performs k-fold cross-validation
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Prints the model report
  prefs: []
  type: TYPE_NORMAL
- en: ❼ Predicts the test data
  prefs: []
  type: TYPE_NORMAL
- en: Note that in listing 3.2, in addition to the usual training accuracy score,
    we report *k-fold cross-validation* and the *area under the receiver operating
    characteristic* (ROC) *curve* to evaluate the model. It’s necessary to do this
    here because GBMs are particularly prone to overfitting, and reporting these metrics
    helps us monitor that risk. Another reason is that the exercise allows you to
    review these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, k-fold cross-validation (with a default value of k=5 folds)
    randomly splits the training dataset into k partitions, or folds, and trains the
    model on k-1 of them while evaluating/validating performance on the remaining
    kth partition, repeating this process k times, with each partition serving as
    a validation set. It then reports the performance using the statistics of these
    k evaluation iterations. This process allows us to reduce the risk of the model
    overfitting on some parts of the dataset and underperforming on others.
  prefs: []
  type: TYPE_NORMAL
- en: Note Put simply, overfitting refers to fitting too many parameters to too little
    data. This scenario hurts the model’s ability to generalize to new data and often
    manifests as improving training metrics with no improvement in validation metrics.
    It can be alleviated by collecting more data, simplifying the model to reduce
    the number of training parameters, and other approaches that we will highlight
    throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be used to call the function and evaluate it on each
    of the two running examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For the email spam classification example, this yields the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'For the IMDB movie review classification example, this yields the result shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: At first glance, looking at these results, one may be tempted to conclude that
    the GBM numerical experiment is more expensive compared to those carried out for
    the prior methods we looked at—taking almost 10 minutes to complete in the case
    of the IMDB example on Kaggle. However, we must take into account the fact that
    when the k-fold cross-validation exercise is carried out, the model is trained
    repeatedly k=5 times to obtain a more reliable estimate of performance. Each training
    thus takes approximately two minutes—not as drastic an increase in training time
    as would be deduced without considering the k-fold cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: We can see some evidence of overfitting—the testing accuracy is lower than the
    k-fold training accuracy for the first example. Moreover, in the case of the IMDB
    example, the k-fold cross-validation scores are noticeably lower than the training
    score on the overall dataset, underscoring the importance of using the k-fold
    cross-validation approach for tracking overfitting in this model type. We discuss
    some approaches to improving the accuracy of the classifier further in the penultimate
    section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'So what exactly is the ROC curve? It is the plot of the false positive rate
    (FPR) versus the true positive rate (TPR) and an important characteristic used
    to evaluate and tune classifiers. It shows the trade-off in these important qualities
    of a classifier as the decision threshold—the probability value beyond which a
    predicted confidence begins to be classified as a member of a given class—is varied
    between 0 and 1\. The following code can now be used to plot this curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ❶ We first need to find the maximum probabilities for each example.
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Calculates the ROC curve values
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Generates the labeled ROC curve plot with the matplotlib library
  prefs: []
  type: TYPE_NORMAL
- en: The resulting ROC curve for the email classification example is shown in figure
    3.1\. The straight line with a slope of 1 represents the FPR-versus-TPR trade-off
    corresponding to random chance. The further to the left the ROC curve is from
    this line, the better performing the classifier. As a result, the area under the
    ROC curve can be used as a measure of performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![03_01](../Images/03_01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 ROC curve for the email classification example
  prefs: []
  type: TYPE_NORMAL
- en: One important property of decision-tree-based methods is that they can provide
    features an importance score, which can be used to detect the most important features
    in a given dataset. We do this by inserting a couple lines of code right before
    the return statement of the function in listing 3.2, as shown in listing 3.3.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.3 Gradient-boosting machine classification code with feature importance
    scores
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ❶ GBM algorithm
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Additional sklearn functions
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Fits the algorithm on the overall data
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Predicts the training set
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Performs k-fold cross-validation
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Prints the model report
  prefs: []
  type: TYPE_NORMAL
- en: ❼ Adds new code to compute the importances of features
  prefs: []
  type: TYPE_NORMAL
- en: ❽ Predicts the test data
  prefs: []
  type: TYPE_NORMAL
- en: For the IMDB example, this yields the plot in figure 3.2\. We see that words
    like “worst” and “awful” are very important to the classification decision, which
    makes qualitative sense, because one can imagine a negative critic using these
    words. On the other hand, words like “loved” may be used by a positive reviewer.
  prefs: []
  type: TYPE_NORMAL
- en: 'A point of caution: Importance scores seem to work well for this example, but
    they should not always be blindly trusted. For instance, it has been widely recognized
    that these importance scores can be biased toward continuous variables, as well
    as high cardinality categorical variables.'
  prefs: []
  type: TYPE_NORMAL
- en: We now proceed to applying to our two running examples some neural network models,
    arguably the most important class of models for NLP today.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Neural network models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed in chapter 1, neural networks are the most important class of
    machine learning algorithms for handling perceptual problems such as computer
    vision and NLP.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will train two representative pretrained neural network
    language models on the two example problems we have been baselining in this and
    the previous chapter. We consider the Embeddings from Language Models (ELMo) and
    Bidirectional Encoder Representations from Transformers (BERT).
  prefs: []
  type: TYPE_NORMAL
- en: '![03_02](../Images/03_02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 Importance scores for the various tokens discovered by the gradient-boosting
    machine classifier for the IMDB classification example
  prefs: []
  type: TYPE_NORMAL
- en: ELMo includes elements of convolutional and recurrent (specifically *long short-term
    memory* [LSTM]) elements, whereas the appropriately named BERT is transformer-based.
    These terms were introduced in chapter 1 and will be addressed in more detail
    in subsequent chapters. We employ the simplest form of transfer learning fine-tuning,
    where a single dense classification layer is trained on top of the corresponding
    pretrained embedding over our dataset of labels from the previous sections.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Embeddings from Language Models (ELMo)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Embeddings from Language Models (ELMo) model, named after the popular *Sesame
    Street* character, was among the first models to demonstrate the effectiveness
    of transferring pretrained language model knowledge to general NLP tasks. The
    model was trained to predict the next word in a sequence of words, which can be
    done in an unsupervised manner on very large corpora, and showed that the weights
    obtained as a result could generalize to a variety of other NLP tasks. We will
    not discuss the architecture of this model in detail in this section—we’ll get
    to that in a later chapter. Here we focus on building intuition, but it suffices
    to mention that the model employs character-level convolutions to build up preliminary
    embeddings of each word token, followed by bidirectional LSTM layers, which introduce
    the context of surrounding words into the final embeddings produced by the model.
  prefs: []
  type: TYPE_NORMAL
- en: Having briefly introduced ELMo, let’s proceed to train it for each of the two
    running example datasets. The ELMo model is available through the TensorFlow Hub,
    which provides an easy platform for sharing TensorFlow models. We will use Keras
    with a TensorFlow backend to build our model. In order to make the TensorFlow
    Hub model usable by Keras, we need to define a custom Keras layer that instantiates
    it in the right format. This is achieved using the function shown in the next
    listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.4 Instantiating TensorFlow Hub ELMo as a custom Keras layer
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Imports the required dependencies
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Initializes the session
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Creates a custom layer that allows us to update weights
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Downloads the pretrained ELMo model from TensorFlow Hub
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Extracts the trainable parameters—four weights in the weighted average of
    the ELMo model layers; see the earlier TensorFlow Hub link for more details
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Specifies the shape of the output
  prefs: []
  type: TYPE_NORMAL
- en: Before using this function to train a model, we will need to adapt our preprocessed
    data a bit for this model architecture. In particular, recall that we assembled
    a bag-of-words representation for the traditional models from the variable `raw_data`,
    which was produced by listing 2.7 and is a NumPy array containing a list of word
    tokens per email. In this case, we instead use the function and code in listing
    3.5 to combine each such list into a single text string. This is the format in
    which the ELMo TensorFlow Hub model expects the input, and we are glad to oblige.
  prefs: []
  type: TYPE_NORMAL
- en: Note The combined string in this case has stop words removed, a step that is
    often not required in deep learning practice due to the uncanny ability of artificial
    neural networks to figure out what is important and what isn’t—feature engineering,
    automatically. In our case, because we are trying to compare the strengths and
    weaknesses of the different model types for this problem, applying the same kind
    of preprocessing for all algorithms makes sense and is arguably the right approach.
    We note, however, that ELMo was pretrained on a corpus containing stop words,
    as was BERT.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.5 Converting data to the form expected by the ELMo TensorFlow Hub
    model
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Converts data into the right format
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Concatenates the tokens for each email into a single string
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Shuffles the raw data first
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Converts 70% of the data for training
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Converts the remaining 30% of the data for testing
  prefs: []
  type: TYPE_NORMAL
- en: Having converted the data into the right format, we use the code in the next
    listing to build and train the Keras ELMo TensorFlow Hub model.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.6 Building ELMo Keras model using custom layer defined in listing
    3.4
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: ❶ New layer outputting 256-dimensional feature vectors
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Classification layer
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Loss, metric, and optimizer choices
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Shows the model architecture for inspection
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Fits the model for five epochs
  prefs: []
  type: TYPE_NORMAL
- en: A few things should be noted here, given that this is our first encounter with
    some detailed aspects of deep learning design. First of all, notice that we have
    added an additional layer on top the pretrained ELMo embedding, producing 256-dimensional
    feature vectors. We have also added a classification layer of output dimension
    1\. The activation function `sigmoid` transforms its input into the interval between
    0 and 1 and is essentially the logistic curve in figure 2.6\. We can interpret
    its output as the probability of the positive class, and when it exceeds some
    prespecified threshold (usually 0.5), we can classify the corresponding input
    to the network as the said positive class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model is fitted for five “major steps,” or epochs, over the whole dataset.
    The Keras code statement `model.summary()` in listing 3.6 prints the model details
    and produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We note—without delving into too much further detail, because this will be
    addressed in chapter 4—that most of the trainable parameters in this case (approximately
    260 thousand of them) are coming from the layers we added on top of the custom
    ELMo model. This is our first instance of transfer learning: learning a pair of
    new layers on top of the pretrained model shared by ELMo’s creators. It is important
    to use a powerful GPU for most neural network experiments, and the value of the
    `batch_size` parameter, which specifies how much data is fed to the GPU at each
    step, can be extremely important to the speed of convergence. It will vary with
    the GPU being used, or the lack thereof. In practice, one can increase the value
    of this parameter until the speed of convergence of a typical problem instance
    does not benefit from the increase, or whenever the GPU memory is no longer large
    enough for a single data batch to fit on it during an iteration of the algorithm—whichever
    happens first. Additionally, when dealing with a multi-GPU scenario, some evidence
    has been experimentally shown[¹](#pgfId-1086936) that the optimal scaling-up schedule
    of the batch size is linear in the number of GPUs.'
  prefs: []
  type: TYPE_NORMAL
- en: On a free NVIDIA Tesla K80 GPU via a Kaggle Kernel (see our companion GitHub
    repository[²](#pgfId-1086941) for Kaggle notebook links), we achieve the performance
    on our email dataset for the first five epochs as shown in figure 3.3 for a typical
    run. We found a `batch_size` of 32 to work well for us in that context.
  prefs: []
  type: TYPE_NORMAL
- en: '![03_03](../Images/03_03.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 Convergence of the validation and training accuracy scores for the
    first five epochs of training the ELMo model on the email classification example
  prefs: []
  type: TYPE_NORMAL
- en: Each epoch takes approximately 10 seconds to complete—this information is printed
    by our code. We see that a validation accuracy of approximately 97.3% is attained
    at the fourth epoch (meaning the results were reached in under a minute). This
    performance is comparable to the performance of the logistic regression approach,
    which is only slightly better at 97.7% (see also table 3.1). We note that the
    behavior of the algorithm is stochastic—it behaves differently from run to run.
    Thus, your own convergence will vary somewhat, even on architecture similar to
    what we used. It is typical in practice to try the algorithm run a few times and
    pick the best set of parameters among the stochastic and varying results attained.
    Finally, we note that the divergence of training and validation accuracies is
    suggestive of the beginning of overfitting, as indicated in the figure. This lends
    credence to the hypothesis that increasing the amount of signal by increasing
    the length of tokens, as specified by the hyperparameter `maxtokenlen`, and the
    number of tokens per email, as specified by `maxtokens`, may increase performance
    further. Naturally, increasing the number of samples per class by cranking up
    `Nsamp` should also work to improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: For the IMDB example, the ELMo model code yields the convergence output shown
    in figure 3.4.
  prefs: []
  type: TYPE_NORMAL
- en: '![03_04](../Images/03_04.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 Convergence of the validation and training accuracy scores for the
    first five epochs of training the ELMo model on the IMDB movie review classification
    example
  prefs: []
  type: TYPE_NORMAL
- en: Each epoch again takes approximately 10 seconds and achieves a validation accuracy
    of approximately 70% in under a minute at the second epoch. We will see how to
    improve the performances of these models in the next and final sections of this
    chapter. Note that some evidence of overfitting can be observed at the third and
    later epochs, as the training accuracy continues to improve—the fit to the data
    improves, whereas the validation accuracy remains lower.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Bidirectional Encoder Representations from Transformers (BERT)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Bidirectional Encoder Representations from Transformers (BERT) model was
    also named after a popular *Sesame Street* character as a nod to the trend started
    by ELMo. At the time of writing, its variants achieve some of the best performance
    in transferring pretrained language model knowledge to downstream NLP tasks. The
    model was similarly trained to predict words in a sequence of words, although
    the exact *masking* procedure is somewhat different and will be discussed in detail
    later in the book. It can also be done in an unsupervised manner on very large
    corpuses, and the resulting weights similarly generalize to a variety of other
    NLP tasks. Arguably, to familiarize yourself with transfer learning in NLP, it
    is indispensable to also familiarize yourself with BERT.
  prefs: []
  type: TYPE_NORMAL
- en: Just as we did with ELMo, we will avoid discussing the architecture of this
    deep learning model in complete detail in this section—we will cover that in a
    subsequent chapter. It will suffice to mention here that the model employs character-level
    convolutions to build up preliminary embeddings of word tokens, followed by transformer-based
    encoders with self-attention layers that provide the model with a context of surrounding
    words. The transformer functionally replaced the role of the bidirectional LSTMs
    employed by ELMo. Recalling from chapter 1 that transformers have some advantages
    over LSTMs with respect to training scalability, we see some of the motivation
    behind this model. Again, we will use Keras with a TensorFlow backend to build
    our model.
  prefs: []
  type: TYPE_NORMAL
- en: Having briefly introduced BERT, let’s proceed to train it for each of the two
    running example datasets. The BERT model is also available through the TensorFlow
    Hub. To make the hub model usable by Keras, we similarly define a custom Keras
    layer that instantiates it in the right format, as shown in the next listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.7 Instantiating TensorFlow Hub BERT as a custom Keras layer
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Default number of top layers to unfreeze for training
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Choice of regularization type
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Pretrained model to use; this is the large, uncased original version of the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: ❹ BERT embedding dimension, that is, the size of the resulting output semantic
    vectors
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Removes unused layers
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Enforces the number of unfrozen layers to fine-tune
  prefs: []
  type: TYPE_NORMAL
- en: ❼ Trainable weights
  prefs: []
  type: TYPE_NORMAL
- en: ❽ Inputs to BERT take a very specific triplet form; we will show how to generate
    it in the next listing.
  prefs: []
  type: TYPE_NORMAL
- en: ❾ BERT “masks” some words and then attempts to predict them as learning target.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to what we did for ELMo in the previous subsection, we perform a sequence
    of analogous postprocessing steps on the data from the prior sections to put it
    into the format required by the BERT model. In addition to what we did in listing
    3.5 to concatenate the bag-of-words token representations into a list of strings,
    we subsequently need to convert each concatenated string into three arrays—*input
    IDs*, *input masks**,* and *segment IDs*—prior to feeding them to the BERT model.
    The code for doing this is shown in listing 3.8\. Having converted the data into
    the right format, we use the remaining code in the same listing 3.8 to build and
    train the Keras BERT TensorFlow Hub model.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.8 Converting data to form expected by BERT, building and training
    model
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Function for building model
  prefs: []
  type: TYPE_NORMAL
- en: ❷ We do not retrain any BERT layers but rather use the pretrained model as an
    embedding and retrain some new layers on top of it.
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Vanilla TensorFlow initialization calls
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Creates a compatible tokenizer using a function in the BERT source repository
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Converts data to the “InputExample” format using a function in the BERT source
    repository
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Converts the InputExample format into the triplicate final BERT input format,
    using a function in the BERT source repository
  prefs: []
  type: TYPE_NORMAL
- en: ❼ Builds the model
  prefs: []
  type: TYPE_NORMAL
- en: ❽ Instantiates the variables
  prefs: []
  type: TYPE_NORMAL
- en: ❾ Trains the model
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the ELMo model we built in the previous subsection, we put a pair
    of layers on top of the pretrained model and train only those, which amounts to
    about 200 thousand parameters. With hyperparameters set at comparable values with
    all of the prior methods, we achieved validation accuracies of approximately 98.3%
    and 71% for the email and movie review classification problems, respectively (within
    five epochs).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Optimizing performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In looking at the performance results of the various algorithms from the previous
    sections of the chapter, as well as those from the previous chapter, we might
    be tempted to make conclusions right away about which algorithm is best-performing
    for each problem we looked at. For instance, we may conclude that BERT and logistic
    regression are the best algorithms for the email classification problem, with
    an accuracy of around 98%, whereas ELMo is not that far behind, followed by the
    decision-tree-based methods and SVM in last place. On the other hand, for the
    IMDB movie review classification problem, BERT appears to be the winner with a
    performance of approximately 71%, followed by ELMo, and only then logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: We must remember, however, that we know this to be true for sure only at the
    *hyperparameter* *settings* at which we initially evaluated the algorithms—`Nsamp`
    `=` `1000,` `maxtokens` `=` `50,` `maxtokenlen` `=` `20`—in addition to any algorithm-specific
    default parameter values. To make general statements with confidence, we need
    to explore the space of hyperparameters more thoroughly by evaluating the performance
    of all algorithms at many hyperparameter settings, a process typically referred
    to as *hyperparameter tuning* *or optimization*. It may be that the best performance
    found through this process for each algorithm will change their performance ranking,
    and in general, this will help us achieve better accuracies for our problems of
    interest.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 Manual hyperparameter tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hyperparameter tuning is often initially performed manually, driven by intuition.
    We describe such an approach here for the hyperparameters `Nsamp`, `maxtokens`
    `and` `maxtokenlen`, which are general across all the algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first assume that the initial amount of data trained—with `Nsamp`*=1000*,
    for example—is all the data we have. We hypothesize that if we increase the number
    of tokens in the data for each document—`maxtokens`—and increase the maximum length
    of any such token—`maxtokenlen`—we would be able to increase the amount of signal
    for making the classification decision and, thereby, the resulting accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: For the email classification problem, we first increase both of these, from
    values of 50 and 20, respectively, to 100 each. Accuracy results for doing this
    for logistic regression (LR), support vector machines (SVMs), random forests (RFs),
    gradient-boosting machines (GBMs), ELMo, and BERT are shown in second row of table
    3.1\. Furthermore, we increase `maxtokens` to 200 to yield the results in the
    third row of table 3.1.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.1 Comparison of algorithm accuracies at different general hyperparameter
    settings explored during the manual tuning process for the email classification
    example
  prefs: []
  type: TYPE_NORMAL
- en: '| General hyperparameter settings | LR | SVM | RF | GBM | ELMo | BERT |'
  prefs: []
  type: TYPE_TB
- en: '| Nsamp = 1000 maxtokens = 50 maxtokenlen = 20 | 97.7% | 70.2% | 94.5% | 94.2%
    | 97.3% | 98.3% |'
  prefs: []
  type: TYPE_TB
- en: '| Nsamp = 1000 maxtokens = 100 maxtokenlen = 100 | 99.2% | 72.3% | 97.2% |
    97.3% | 98.2% | 98.8% |'
  prefs: []
  type: TYPE_TB
- en: '| Nsamp = 1000, maxtokens = 200, maxtokenlen = 100 | 98.7% | 90.0% | 97.7%
    | 97.2% | 99.7% | 98.8% |'
  prefs: []
  type: TYPE_TB
- en: We see based on this that, although SVMs is clearly the worst-performing classifier
    for this problem, logistic regression, ELMo, and BERT can achieve nearly perfect
    performance. Note also that ELMo is the clear winner in the presence of more signal—something
    we would have missed without the optimization step. However, the simplicity and
    speed of logistic regression would likely result in it being picked as the classifier
    of choice for this email classification problem in production.
  prefs: []
  type: TYPE_NORMAL
- en: We now repeat a similar sequence of hyperparameter testing steps for the IMDB
    movie review classification problem. We first increase `maxtokens` and `maxtokenlen`
    to 100 each and then increase `maxtokens` further to 200\. The resulting algorithm
    performances are listed in table 3.2, along with the performances at the initial
    hyperparameter settings.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.2 Comparison of algorithm accuracies at different general hyperparameter
    settings explored during the manual tuning process for the IMDB movie review classification
    example
  prefs: []
  type: TYPE_NORMAL
- en: '| General hyperparameter settings | LR | SVM | RF | GBM | ELMo | BERT |'
  prefs: []
  type: TYPE_TB
- en: '| Nsamp = 1000 maxtokens = 50 maxtokenlen = 20 | 69.1% | 66.0% | 63.9% | 67.0%
    | 69.7% | 71.0% |'
  prefs: []
  type: TYPE_TB
- en: '| Nsamp = 1000 maxtokens = 100 maxtokenlen = 100 | 74.3% | 72.5% | 70.0% |
    72.0% | 75.2% | 79.1% |'
  prefs: []
  type: TYPE_TB
- en: '| Nsamp = 1000 maxtokens = 200 maxtokenlen = 100 | 79.0% | 78.3% | 67.2% |
    77.5% | 77.7% | 81.0% |'
  prefs: []
  type: TYPE_TB
- en: BERT appears to be the best model for this problem across the board, followed
    by ELMo and logistic regression. Observe that this problem has more headroom for
    improvement, consistent with our earlier observation that this problem is more
    difficult than the email classification one. This leads us to hypothesize that
    pretrained knowledge transfer has more of an effect on harder problems, which
    makes intuitive sense. This concept is also consistent with general advice that
    stipulates that neural network models are likely to be preferable to other approaches
    when significant labeled data is available, assuming the problem to be solved
    is complex enough for the additional data to be needed in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Systematic hyperparameter tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A number of tools exist for more systematic and exhaustive hyperparameter searches
    on ranges of hyperparameters. These include the Python methods `GridSearchCV`,
    which performs an exhaustive search over a specified parameter grid, and `HyperOpt,`
    which does a random search over parameter ranges. Here, we present code for using
    `GridSearchCV` to tune an algorithm of choice as an illustrative example. Note
    that we tune only some internal algorithm-specific hyperparameters in this exercise,
    with the general ones we tuned in the last subsection fixed, for simplicity of
    illustration.
  prefs: []
  type: TYPE_NORMAL
- en: We pick email classification with RF with the initial general hyperparameter
    settings as our illustrative example. The reason for this choice is that it takes
    about a second for each fit of this algorithm on this problem, and because the
    grid search will perform a lot of fits, this example can be executed quickly for
    the greatest learning value for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first import the required method and check which RF hyperparameters are
    available for tuning as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: ❶ GridSearchCV scikit-learn import statement
  prefs: []
  type: TYPE_NORMAL
- en: ❷ clf is the RF classifier from listing 2.13.
  prefs: []
  type: TYPE_NORMAL
- en: 'This yields the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We pick three of these hyperparameters to search over and specify three values
    for each of them, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We then carry out the grid search using the following code, making sure to
    print out final test accuracy and best hyperparameter values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Defines the grid search object with a specified hyperparameter grid
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Fits the grid search to the data
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Displays the results
  prefs: []
  type: TYPE_NORMAL
- en: 'This experiment required training the classifier at 3*3*3=27 points, because
    each of the three hyperparameter grids has three requested points on it. The overall
    experiment took less than five minutes to complete and yielded an accuracy of
    95.7%. This is an improvement of more than 1% over the original score of 94.5%.
    The raw output from the code is shown next, specifying best hyperparameter values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Indeed, when we performed the tuning across the board on all classifiers, we
    found that we could boost the performance of each by 1-2%, without affecting the
    conclusions on the best classifier for each problem reached in the previous subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is typical to try a variety of algorithms on any given problem of interest
    to find the best combination of model complexity and performance for your circumstances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baselines usually start with the simplest algorithms, such as logistic regression,
    and become increasingly complex until the right performance/complexity trade-off
    is attained.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important model design choices include metrics for evaluating performance, loss
    functions to guide the training algorithm, and best validation practices, among
    many others, and these can vary by model and problem type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperparameter tuning is an important step of the model-development pipeline,
    because initial hyperparameter settings may severely misrepresent the best attainable
    performance that can be found by tuning it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple models tend to work best when the amount of available data isn’t very
    large and/or for easier problems, whereas complex neural network models tend to
    do better, and as such be worth the extra complexity, when more data is available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '1. P. Goyal et al., “Accurate, Large Minibatch SGD: Training ImageNet in 1
    Hour,” *arXhiv* (2018).'
  prefs: []
  type: TYPE_NORMAL
- en: 2. [https://github.com/azunre/transfer-learning-for-nlp](https://github.com/azunre/transfer-learning-for-nlp)
  prefs: []
  type: TYPE_NORMAL
