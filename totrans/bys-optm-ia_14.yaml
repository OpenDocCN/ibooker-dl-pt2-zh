- en: 11 Optimizing multiple objectives at the same time
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 同时优化多个目标
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖内容
- en: The problem of optimizing multiple objectives at the same time
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时优化多个目标的问题
- en: Training multiple GPs to learn about multiple objectives at the same time
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练多个 GP 同时学习多个目标
- en: Jointly optimizing multiple objectives
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共同优化多个目标
- en: 'Every day, we are faced with optimization tradeoffs:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 每天，我们都面临着优化的权衡：
- en: “This coffee tastes good, but there’s too much sugar.”
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “这杯咖啡尝起来不错，但糖太多了。”
- en: “That shirt looks great, but it’s out of my price range.”
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “那件衬衫看起来很棒，但超出了我的价格范围。”
- en: “The neural network I just trained has a high accuracy, but it is too big and
    takes too long to train.”
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “我刚训练的神经网络准确率很高，但太大了，训练时间太长。”
- en: 'In an attempt to achieve a good performance on some objective, we sacrifice
    another criterion that’s just as important: a coffee drinker with a sweet tooth
    might optimize the taste of their coffee while using an unhealthy amount of sugar;
    a shopper scores a clothing article high on looks and low on affordability; an
    ML engineer develops a neural network that has good predictive performance but
    is too large to be used in a real-time application. By focusing on one optimization
    objective, we might perform badly on another objective that needs to be accounted
    for. We should instead model *all* objective functions that are to be optimized
    into our optimization procedure and attempt to jointly optimize them all. For
    example, we should look for coffee recipes that are both tasty and low in sugar,
    clothing items that are both fashionable and affordable, or ML models that perform
    well and are practical to implement. This type of optimization problem is called
    *multiobjective optimization*.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在某个目标上取得良好的性能，我们牺牲了另一个同样重要的标准：一个喜欢甜食的咖啡饮用者可能会优化咖啡的味道，同时使用不健康数量的糖；购物者在外观上打分高而在价格上打分低的服装；ML工程师开发出具有良好预测性能但太大以至于无法在实时应用中使用的神经网络。通过专注于一个优化目标，我们可能在需要考虑的另一个目标上表现不佳。相反，我们应该将所有要优化的目标函数建模到我们的优化过程中，并尝试联合优化它们所有。例如，我们应该寻找既美味又低糖的咖啡配方，时尚又实惠的服装，或者性能良好且实用的ML模型。这种类型的优化问题称为多目标优化。
- en: Definition A multiobjective optimization problem, as the name suggests, involves
    multiple objective functions that are to be optimized *at the same time*. The
    goal is to find data points that achieve high values on all of the objectives.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 多目标优化问题，正如其名称所示，涉及到多个要同时优化的目标函数。其目标是找到在所有目标上都达到高值的数据点。
- en: Of course, in any nontrivial multiobjective optimization problem, we might have
    *competing* objectives, for which the only way to achieve good performance on
    one objective function is to sacrifice performance on another objective. This
    inherent conflict between optimization objectives gives rise to the need to balance
    these objectives (very much like the need to balance exploitation and exploration,
    discussed in section 4.1.2, which are the two “objectives” we need to optimize
    for inside the BayesOpt loop).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在任何非平凡的多目标优化问题中，我们可能会有竞争的目标，为了在一个目标函数上获得良好的性能，唯一的方法是牺牲另一个目标上的性能。这种优化目标之间的固有冲突导致了需要平衡这些目标的需求（非常类似于需要平衡探索和开发，讨论在第4.1.2节中，这是BayesOpt循环内需要优化的两个“目标”）。
- en: In this chapter, we learn about multiobjective optimization, how to successfully
    address it by finding data points whose performance on one objective cannot be
    improved without sacrificing another objective, and how to apply BayesOpt to this
    problem when the objective functions are expensive-to-query black boxes. Multiobjective
    optimization is a common problem across many fields, and by the end of this chapter,
    we add the ability to tackle this problem to our toolkit using Bayesian methods.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习多目标优化，如何通过找到在一个目标上表现无法改善而不牺牲另一个目标的数据点成功地解决它，以及如何在目标函数是昂贵的黑箱的情况下将 BayesOpt
    应用于这个问题。多目标优化是许多领域都面临的共同问题，到本章结束时，我们将使用贝叶斯方法来解决这个问题的能力添加到我们的工具包中。
- en: 11.1 Balancing multiple optimization objectives with BayesOpt
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 使用 BayesOpt 平衡多个优化目标
- en: 'Applications of multiobjective optimization are ubiquitous:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 多目标优化的应用无处不在：
- en: In engineering and manufacturing, engineers often face a tradeoff between multiple
    objectives, such as the quality of a product versus the manufacturing cost. For
    example, car manufacturers are constantly optimizing their production line to
    maximize quality and minimize cost.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在工程和制造领域，工程师经常面临多个目标之间的权衡，比如产品质量与制造成本之间的权衡。例如，汽车制造商不断优化生产线以最大化质量，同时最小化成本。
- en: In resource allocation problems, such as the distribution of monetary and medical
    aid across poor communities or to those affected by natural disasters, decision-makers
    need to balance having the largest effect on these communities and the various
    logistical difficulties in distribution.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在资源分配问题中，如在贫困社区或自然灾害受灾人群之间分配货币和医疗援助，决策者需要在对这些社区产生最大影响和各种物流分配困难之间取得平衡。
- en: Similar to the examples of the cost-constrained optimization problem we discussed
    in section 8.1.1, scientists developing drugs to treat a certain disease need
    to balance maximizing effectiveness against the disease and minimizing side effects
    on patients.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与我们在第8.1.1节中讨论的成本受限优化问题类似，开发治疗某种疾病的药物的科学家需要在最大化疗效和最小化对患者的副作用之间取得平衡。
- en: More relevant to ML engineers, a practical ML model that can be deployed in
    the real world needs to achieve good performance while maintaining a low training
    cost.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于机器学习工程师更相关的是，一个可以在现实世界中部署的实用机器学习模型需要在保持低训练成本的同时实现良好的性能。
- en: 'Unlike optimization settings discussed in previous chapters, we no longer have
    a single optimization objective to focus on. In many of these problems, the objectives
    we need to optimize are in conflict with each other: only by sacrificing our performance
    on one metric can we improve on another. One way to think about this inherent
    conflict between the optimization objectives is that we have to “juggle” the various
    objectives at the same time: we can’t simply focus on certain objectives while
    ignoring the others. This need to juggle multiple objectives at the same time
    is visualized in figure 11.1\. Fortunately, the fact that there is now more than
    one objective function doesn’t affect most of the BayesOpt workflow we have developed
    throughout this book.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前章节讨论的优化设置不同，我们不再有单一的优化目标可以专注。在许多这些问题中，我们需要优化的目标之间存在冲突：只有牺牲一个指标的性能我们才能在另一个指标上取得提高。思考这些优化目标之间固有的冲突的一种方式是，我们必须同时“权衡”各种目标：我们不能简单地专注于某些目标而忽略其他目标。这种同时权衡多个目标的需求在图11.1中可视化。幸运的是，现在有多个目标函数不会影响我们在本书中开发的大部分贝叶斯优化工作流程。
- en: '![](../../OEBPS/Images/11-01.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-01.png)'
- en: Figure 11.1 A cartoon illustrating the balance we must achieve in multiobjective
    optimization, where we need to juggle different objective functions
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：漫画说明我们在多目标优化中需要取得的平衡，我们需要同时权衡不同的目标函数。
- en: Modeling multiple objective functions using multiple GPs
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多个高斯过程模型建模多个目标函数
- en: In previous chapters, we trained a GP model on observed data to model our belief
    about the single objective function to be optimized. In this chapter, we have
    multiple objective functions to model, but each of these objectives can still
    be modeled as a GP. By maintaining these multiple GPs, we have a way to reason
    about all objective functions in a probabilistic manner.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们根据观察到的数据训练了一个高斯过程模型以建模我们对单一优化目标函数的信念。在本章中，我们需要建模多个目标函数，但每个这些目标仍然可以被建模为高斯过程。通过维护这些多个高斯过程，我们有一种以概率方式推理所有目标函数的方法。
- en: Figure 11.2 shows the BayesOpt loop in which there are two objective functions
    to be optimized. Compared to figure 1.6, step 1 now has a GP for each of the objectives,
    and each data point identified by the BayesOpt policy is evaluated on all objective
    functions at step 3.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2展示了贝叶斯优化循环，其中有两个需要优化的目标函数。与图1.6相比，第1步现在针对每个目标都有一个高斯过程，而贝叶斯优化策略识别的每个数据点在第3步都要对所有目标函数进行评估。
- en: '![](../../OEBPS/Images/11-02.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-02.png)'
- en: Figure 11.2 The multiobjective BayesOpt loop with two objective functions. A
    GP trains on data from each objective function, and the BayesOpt policy decides
    which data point to evaluate the objective functions with next.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：多目标贝叶斯优化循环，具有两个目标函数。每个目标函数的数据进行高斯过程训练，而贝叶斯优化策略决定下一步评估目标函数的数据点。
- en: Training a GP on data from each objective is straightforward to implement; in
    fact, we’ve already done this for constrained optimization in chapter 8, where
    we train one GP on the objective function and another on the constraint function.
    In other words, we only need to focus on the design of the BayesOpt policy in
    step 2 of figure 11.2 to help us make effective decisions during optimization.
    We focus on learning how the BayesOpt policy should address the balance between
    the multiple objectives so that we can find high-performing data points as quickly
    as possible in the rest of this chapter.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个目标的数据进行GP训练非常容易实现；事实上，我们已经在第8章对约束优化进行了这样的训练，在那里我们对目标函数进行了一次GP训练，对约束函数进行了另一次GP训练。换句话说，我们只需要专注于图11.2中第2步中贝叶斯优化策略的设计，以帮助我们在优化过程中做出有效的决策。我们重点研究了贝叶斯优化策略如何应对多个目标之间的平衡，以便在本章的其余部分尽快找到性能优异的数据点。
- en: 11.2 Finding the boundary of the most optimal data points
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 寻找最优数据点的边界
- en: In this section, we learn about mathematical concepts that are commonly used
    in multiobjective optimization to quantify how much progress we have made during
    optimization. These concepts help us establish the target of the optimization
    strategy we develop later in this chapter. To make our discussion concrete, we
    use the code in the CH11/01 - Computing hypervolume.ipynb notebook.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了在多目标优化中常用于量化我们在优化过程中取得多大进展的数学概念。这些概念帮助我们建立本章后面我们开发的优化策略的目标。为了使我们的讨论具体化，我们使用了CH11/01
    - 计算超体积.ipynb笔记本中的代码。
- en: 'We start out with the two objective functions that we need to optimize at the
    same time:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从需要同时优化的两个目标函数开始：
- en: The first objective is the familiar Forrester function used in previous chapters.
    The global optimum of this objective function is located on the right side of
    the search space. This function is implemented as `objective1()` in the following
    code.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个目标是在以前章节中使用的熟悉的Forrester函数。该目标函数的全局最优解位于搜索空间的右侧。该函数在以下代码中实现为`objective1()`。
- en: We also have another objective function, implemented as `objective2()`, which
    has a different functional form and behavior from Forrester. Crucially, the global
    optimum of this objective is located on the left side of the search space—the
    mismatch in the locations of the global optima of the two objective functions
    simulates the tradeoff that is common in multiobjective optimization problems.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还有另一个目标函数，实现为`objective2()`，其具有与Forrester不同的功能形式和行为。关键是，该目标的全局最优解位于搜索空间的左侧——两个目标函数的全局最优解位置的不匹配模拟了多目标优化问题中常见的权衡。
- en: We write a helper function `joint_objective()` that returns the values of the
    two objective functions in a PyTorch tensor for a given input data point `x`.
    This function helps keep our code concise.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们编写一个辅助函数`joint_objective()`，它返回给定输入数据点`x`的两个目标函数的值的PyTorch张量。这个函数有助于保持我们的代码简洁。
- en: 'Finally, we define the search space of our optimization problem to be between
    –5 and 5:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们将我们的优化问题的搜索空间定义为-5到5之间。
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ The first objective function
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 第一个目标函数
- en: ❷ The second objective function
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 第二个目标函数
- en: ❸ The helper function that calls both objective functions
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 调用两个目标函数的辅助函数
- en: ❹ The bounds of the search space
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 搜索空间的边界
- en: 'Figure 11.3 shows these two objective functions in our search space. We see
    that the data points that maximize the two objectives are different from each
    other: the solid curve is maximized around *x* = 4.5, while the dashed curve is
    maximized around *x* = –4.5\. This difference means that we have two conflicting
    objectives, and the joint optimization of these two functions requires trading
    off their objective values.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3显示了我们搜索空间中的这两个目标函数。我们看到最大化这两个目标的数据点彼此不同：实线曲线在*x*=4.5附近最大化，而虚线曲线在*x*=-4.5附近最大化。这种差异意味着我们有两个相互冲突的目标，并且这两个函数的联合优化需要权衡它们的目标值。
- en: '![](../../OEBPS/Images/11-03.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-03.png)'
- en: Figure 11.3 The two objective functions that make up our current multiobjective
    optimization problem. The data points that maximize the two objectives are different
    from each other, so there’s a tradeoff in the optimization of the two objectives.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 我们当前的多目标优化问题的两个目标函数。最大化这两个目标的数据点彼此不同，因此在优化这两个目标时存在权衡。
- en: By “trading off,” we mean there exist points *x* in our search space whose values
    for the first objective (denoted as *f*[1](*x*)) cannot be improved unless their
    values for the second objective (denoted as *f*[2](*x*)) are lowered. In other
    words, there are data points that optimize one objective function in the sense
    that their values cannot be exceeded unless we sacrifice another objective function.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“权衡”，我们指的是存在搜索空间中的点*x*，其第一个目标的值（表示为*f*[1](*x*)）无法提高，除非第二个目标的值（表示为*f*[2](*x*)）降低。换句话说，存在一些数据点在优化一个目标函数方面，其值无法超过，除非我们牺牲另一个目标函数。
- en: As an example, consider *x* = –5 as indicated in figure 11.3\. This is the data
    point on the very far left of the search space. This point has an objective value
    *f*[1](–5) of roughly 4 and an objective value *f*[2](–5) of roughly 1.5\. Now,
    *x* = –5 is one of the data points where, if we want to do better than 4 on the
    first objective *f*[1](*x*), we will have to do worse than 1.5 on *f*[2](*x*).
    Indeed, the only way for us to achieve a higher *f*[1](*x*) value than 4 is to
    query on the rightmost portion of the search space where *x* > 4\. Here, the values
    of *f*[2](*x*) fall below 0.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑图11.3中标示的*x* = –5。这是搜索空间的最左边的数据点。这个点的目标值*f*[1](–5)大约为4，目标值*f*[2](–5)大约为1.5。现在，*x*
    = –5是一个数据点，如果我们想在第一个目标*f*[1](*x*)上做得比4更好，我们将不得不在第二个目标*f*[2](*x*)上做得不如1.5。事实上，我们要实现高于4的*f*[1](*x*)值的唯一方式是查询空间的最右侧，其中*x*
    > 4。在这里，*f*[2](*x*)的值下降到0以下。
- en: 'Conversely, the region on the right (*x* > 4) is also where the tension between
    *f*[1](*x*) and *f*[2](*x*) exists: to increase the value of *f*[2](*x*), we would
    have to move away to the left of the space, in which case the value of *f*[1](*x*)
    would suffer.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，右侧的区域（*x* > 4）也是*f*[1](*x*)和*f*[2](*x*)之间的紧张存在的地方：要增加*f*[2](*x*)的值，我们必须向空间左侧移动，这样*f*[1](*x*)的值就会受到影响。
- en: Definition A data point whose value for an objective cannot be exceeded unless
    its value for another objective decreases is called *nondominated*. The opposite,
    a *dominated* point *x*[1], is one such that there exists another point *x*[2],
    whose objective values all exceed those of *x*[1]. A nondominated point can also
    be called a *Pareto optimal*, *Pareto efficient*, or *noninferior*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：数据点其一个目标的值无法超过，除非另一个目标的值降低，称为*非支配*。相反，*支配*点*x*[1]是指存在另一个点*x*[2]，其所有目标值都超过*x*[1]的点。非支配点也可以称为*帕累托最优*、*帕累托有效*或*非劣*。
- en: 'The point *x* = –5, therefore, is a nondominated point, and so are some of
    the points where *x* > 4\. An example of a dominated point is *x* = –1.9 in figure
    11.3, which gives *f*[1](–1.9) ≈ *f*[2](–1.9) ≈ 1\. This point is dominated by
    *x* = –5 since the former’s objective values are lower than those of the latter:
    *f*[1](–1.9) < *f*[1](–5) and *f*[2](–1.9) < *f*[2](–5).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，点*x* = –5是一个非支配点，一些点当*x* > 4也是非支配点。图11.3中的一个支配点的例子是*x* = –1.9，它给出了*f*[1](–1.9)
    ≈ *f*[2](–1.9) ≈ 1。这个点被*x* = –5支配，因为前者的目标值低于后者：*f*[1](–1.9) < *f*[1](–5)和*f*[2](–1.9)
    < *f*[2](–5)。
- en: 'In many cases, we have infinitely many nondominated points. Figure 11.4 shows
    the nondominated points in our current problem as dash-shaded regions (we talk
    about how to find these nondominated points later in this section; for now, let’s
    focus on the behavior of these nondominated points):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们有无限多个非支配点。图11.4展示了我们当前问题中的非支配点作为虚线阴影区域（我们将在本节稍后讨论如何找到这些非支配点；现在，让我们关注这些非支配点的行为）：
- en: We see that *x* = –5 is, indeed, a nondominated point, along with many points
    around that region that give high values for the second objective *f*[2](*x*).
    The points outside this region don’t yield higher *f*[2](*x*) values, so the points
    inside the region are nondominated. We call this set of points *group 1*.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们发现*x* = –5确实是一个非支配点，以及该区域周围许多点给出了较高的第二个目标*f*[2](*x*)的值。超出此区域的点不会产生更高的*f*[2](*x*)值，因此该区域内的点是非支配的。我们将这些点称为*group
    1*。
- en: A smaller region on the right that gives high values for the first objective
    *f*[1](*x*) is also nondominated. This set of points is called *group 2*.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右侧的小区域为第一个目标*f*[1](*x*)提供了较高的值，同样是非支配的。这些点称为*group 2*。
- en: There’s a third, smallest region around *x* = 4 that’s also nondominated, whose
    values for *f*[1](*x*) are not exceeded by the nondominated points on the far
    left of the search space. Though this region doesn’t contain the global optimum
    of either objective function, the region trades off between the values of the
    two objectives and is, therefore, nondominated. We call these points *group 3*.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*x*=4周围还有一个第三个最小区域，它也是非支配的，在搜索空间的左侧没有被非支配点的*f*[1](*x*)值超过。尽管这个区域不包含任何目标函数的全局最优解，但该区域在两个目标的值之间进行权衡，因此是非支配的。我们称这些点为“群组3”。
- en: '![](../../OEBPS/Images/11-04.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-04.png)'
- en: Figure 11.4 The two objective functions and the nondominated points. There are
    infinitely many nondominated points in this multiobjective optimization problem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 两个目标函数和非支配点。在这个多目标优化问题中有无穷多个非支配点。
- en: The nondominated points are valuable in multi objective optimization because
    they, themselves, are solutions to the optimization problem, as we cannot improve
    upon them without sacrificing at least one objective. Further, by studying the
    nondominated points, their relationship with one another, and how they are spread
    out within the search space, we can understand more about the tradeoff between
    the multiple objectives in our optimization problem. Hence, a reasonable goal
    of multiobjective optimization is to find many nondominated points.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 非支配点在多目标优化中非常有价值，因为它们本身就是优化问题的解，除非牺牲至少一个目标，否则我们无法改进它们。通过研究非支配点，它们之间的关系以及它们在搜索空间中的分布，我们可以更加了解优化问题中多个目标之间的权衡。因此，多目标优化的一个合理目标是找到尽可能多的非支配点。
- en: However, it’s not immediately clear how we should concretely quantify this goal
    of finding nondominated points. We shouldn’t simply seek to uncover as many nondominated
    points as possible, since there can be, and often are, infinitely many of them.
    Instead, we use a quantity that is easier to think about if we were to visualize
    the data points in a different space.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们并不立即清楚如何具体量化找到非支配点的目标。我们不应该简单地寻求揭示尽可能多的非支配点，因为它们可能是无限多的。相反，我们使用一个更容易思考的量，如果我们通过将数据点可视化到一个不同的空间来观察它。
- en: In figures 11.3 and 11.4, the *x*-axis corresponds to the data points themselves,
    and the *y*-axis corresponds to the objective values of these data points. To
    study the tradeoff between two conflicting objectives, we can also use a scatter
    plot, where the *x*-coordinate of a given data point *x* is the value for the
    first objective *f*[1](*x*), and the *y*-coordinate is the value for the second
    objective *f*[2](*x*).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在图11.3和11.4中，*x*-轴对应于数据点本身，*y*-轴对应于这些数据点的目标值。为了研究两个冲突目标之间的权衡，我们还可以使用散点图，其中给定数据点*x*的*x*-坐标是第一个目标函数*f*[1](*x*)的值，*y*-坐标是第二个目标函数*f*[2](*x*)的值。
- en: 'Figure 11.5 shows this scatter plot for each point in a dense grid of 201 equally
    spaced points between –5 and 5, where dominated points are denoted as dots and
    nondominated points as stars. We see that whether a point is dominated or not
    is more easily determined in this space: for each data point *x*[1], if there’s
    another data point *x*[2] that’s placed above and to the right of *x*[1], then
    *x*[1] is a dominated point; conversely, if there isn’t any point *x*[2] that’s
    simultaneously above and to the right of *x*[1], then *x*[1] is nondominated.
    We also see in figure 11.5 the three groups of nondominated points corresponding
    to those in the discussion regarding figure 11.4.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 展示了在-5和5之间的201个等距点的密集网格中每个点的散点图，被支配的点用点表示，非支配点用星号表示。我们可以看出，在这个空间中，一个点是否被支配更容易确定：对于每个数据点*x*[1]，如果存在另一个数据点*x*[2]，它位于*x*[1]的上方且右侧，则*x*[1]是一个被支配的点；相反，如果不存在同时位于*x*[1]的上方且右侧的点*x*[2]，则*x*[1]是非支配的。在图
    11.5 中我们还可以看到三个非支配点的组，与图 11.4 相关的讨论相符。
- en: '![](../../OEBPS/Images/11-05.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-05.png)'
- en: Figure 11.5 Scatter plot of data points based on their values for the two objective
    functions. Dominated points are denoted as dots; nondominated points are stars.
    The three groups of nondominated points correspond to those in the discussion
    regarding figure 11.4.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 基于两个目标函数值的数据点的散点图。被支配的点用点表示，非支配点用星号表示。非支配点的三个组对应于图 11.4 中的讨论。
- en: 'From the set of nondominated points, visualized in the space of the objective
    values, we now introduce another concept: the *Pareto frontier*. Figure 11.6 visualizes
    the Pareto frontier of our current optimization problem.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从可视化的目标值空间中的非支配点集合中，我们现在引入另一个概念：Pareto 前沿。图 11.6 可视化了当前优化问题的 Pareto 前沿。
- en: '![](../../OEBPS/Images/11-06.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片 11.6](../../OEBPS/Images/11-06.png)'
- en: Figure 11.6 The Pareto frontier that traces through the nondominated points.
    No data point lies beyond (above and to the right of) this Pareto frontier.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 通过非支配点绘制的 Pareto 前沿。没有数据点位于此 Pareto 前沿的右侧（上方和右侧）。
- en: Definition The curve that traces through the nondominated points is called the
    *Pareto frontier*. It’s called a *frontier* because when we view all data points
    as a set, this curve of the nondominated points makes up a boundary, or a frontier,
    of the set beyond which no data point lies.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 跟踪非支配点的曲线称为 *Pareto 前沿*。它被称为 *前沿*，因为当我们将所有数据点视为一个集合时，非支配点的这条曲线构成了集合的边界或前沿，在该边界或前沿之外没有数据点。
- en: The concept of the Pareto frontier is crucial in multiobjective optimization
    because the frontier directly leads to a metric that can quantify progress in
    a multiobjective optimization problem. In particular, we focus on how much of
    the space—the one defined by the collected objective values from multiple objectives—the
    Pareto frontier covers; that is, the area inside (below and to the left) of the
    Pareto frontier. This area is shown as the shaded region in the left panel of
    figure 11.7.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Pareto 前沿的概念在多目标优化中至关重要，因为前沿直接导致可以量化多目标优化问题中的进展的度量标准。特别是，我们关注 Pareto 前沿覆盖的空间——由多个目标的收集目标值定义的空间——的大小；也就是说，Pareto
    前沿内部（下方和左侧）的区域。该区域显示为图 11.7 的左侧面板中的阴影区域。
- en: Definition We use the term *dominated hypervolume* (or, sometimes, simply *hypervolume*)
    to denote how much of the space is covered by the Pareto frontier. When there
    are two objective functions, like in our example, the space is two-dimensional
    and the dominated hypervolume is the area of the dominated region. When there
    are more than two objectives, the dominated hypervolume measures the same quantity
    but in higher dimensions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 我们使用术语 *支配超体积*（有时简称为 *超体积*）来表示 Pareto 前沿覆盖了多少空间。在我们的示例中有两个目标函数，因此空间是二维的，支配超体积是支配区域的面积。当有两个以上的目标时，支配超体积以更高维度度量相同的数量。
- en: The scattered points shown in the left panel of figure 11.7 are generated using
    a dense grid of 201 points across the search space so that we can study the behavior
    of the Pareto frontier and its hypervolume in full detail. In other words, this
    dense grid represents the result of an exhaustive search of the space to fully
    map out the Pareto frontier.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧图 11.7 中显示的分散点是使用密集的网格在搜索空间中生成的，以便我们可以详细研究 Pareto 前沿及其超体积的行为。换句话说，这个密集的网格代表了对空间的穷尽搜索，以完全绘制出
    Pareto 前沿。
- en: As a point of comparison, the right panel of figure 11.7 shows the result of
    20 points selected uniformly at random between –5 and 5\. From the selected points,
    we, again, find those that aren’t dominated by any other points within the set
    of 20 points and draw the Pareto frontier of this second dataset.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 作为比较的一点，图 11.7 的右侧面板显示了在 -5 到 5 之间均匀选择的 20 个点的结果。从所选点中，我们再次找到在 20 个点集内没有被任何其他点支配的点，并绘制此第二个数据集的
    Pareto 前沿。
- en: '![](../../OEBPS/Images/11-07.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片 11.7](../../OEBPS/Images/11-07.png)'
- en: Figure 11.7 The dominated hypervolume of a dense grid (left), which is equivalent
    to an exhaustive search, and that of 20 data points randomly selected at random
    (right). The first dataset has a larger dominated volume and, therefore, does
    a better job at multiobjective optimization than the second dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 密集网格的支配超体积（左侧），等效于穷举搜索，以及随机选择的 20 个数据点（右侧）。第一个数据集具有更大的支配体积，因此在多目标优化方面的表现比第二个数据集好。
- en: Unlike the case on the left, where we fully cover the search space, the small
    dataset on the right only has four nondominated points. In the context of multiobjective
    optimization, we make more progress with the first dataset (from the exhaustive
    search) than we do with the second (from the random search).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 与左侧情况不同，左侧完全覆盖搜索空间，而右侧的小数据集只有四个非支配点。在多目标优化的背景下，我们使用第一个数据集（来自穷举搜索）比使用第二个数据集（来自随机搜索）取得更多进展。
- en: Compared to the dataset from the exhaustive search, these four nondominated
    points make up a more jagged Pareto frontier, which, in turn, has a much smaller
    dominated hypervolume. In other words, this measure of dominated hypervolume can
    be used to quantify optimization progress in a multiobjective optimization problem.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与穷尽搜索得到的数据集相比，这四个非支配点构成了一个更加锯齿状的帕累托前沿，进而拥有一个更小的被支配超体积。换句话说，这个被支配超体积的度量可以用来量化多目标优化问题中的优化进展。
- en: Note In a multiobjective optimization problem, we measure optimization progress
    by the hypervolume of the dominated region resulting from the current collected
    data. The bigger the dominated hypervolume of our collected data, the more progress
    we have made in simultaneously optimizing our objective functions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 在多目标优化问题中，我们通过当前收集的数据产生的被支配区域的超体积来衡量优化进展。我们收集的数据的被支配超体积越大，我们同时优化目标函数的进展就越大。
- en: According to the hypervolume metric, figure 11.7 shows that an exhaustive search
    does a better job than a random search (with fewer queries) at optimization, which
    is an expected result. But to quantify *how much* better the former search strategy
    is, we need a way to compute this hypervolume metric. For this computation, a
    *reference point* is needed; this reference point acts as an endpoint for the
    dominated region, setting a lower-left bound for the region. We can think of this
    reference point as the worst possible outcome we can observe under a multiobjective
    optimization setting, so the hypervolume of the region between this reference
    point and the Pareto frontier quantifies how much we have improved from this worst
    possible outcome. (The worst possible outcome for each objective function, if
    not known to us, the BayesOpt users, can be set at a particular value that we
    think is the bare minimum each query can achieve.)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 根据超体积度量，图 11.7 显示，穷尽搜索比随机搜索（查询更少）在优化方面做得更好，这是一个预期结果。但是要量化前者搜索策略比后者好多少，我们需要一种计算这个超体积度量的方法。对于这个计算，需要一个参考点；这个参考点充当被支配区域的终点，为该区域设置了一个左下边界。我们可以将这个参考点视为在多目标优化设置下我们能观察到的最差结果，因此该区域与帕累托前沿之间的超体积量化了我们从这个最差结果改进了多少。（如果我们不知道每个目标函数的最差结果，BayesOpt
    用户可以将每个查询可以达到的最低值设定为我们认为的最低值。）
- en: Note In multiobjective optimization, a common reference point is an *array*,
    each of whose elements corresponds to the lowest value of an objective function
    to be maximized.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 在多目标优化中，一个常见的参考点是一个 *数组*，其中的每个元素对应于要最大化的目标函数的最低值。
- en: For example, the reference point for our current optimization problem is [–2.0292,
    –0.4444] since the first element, –2.0292, is the minimum value of the first objective
    function (the solid curve in figure 11.3), and –0.4444 is the minimum value of
    the second objective (the dashed curve in figure 11.3). This reference point is
    visualized in figure 11.8 as the star, which, again, sets a lower bound for the
    dominated space.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们当前优化问题的参考点为[–2.0292, –0.4444]，因为第一个元素–2.0292是第一个目标函数的最小值（图 11.3 中的实线曲线），–0.4444是第二个目标的最小值（图
    11.3 中的虚线曲线）。这个参考点在图 11.8 中被可视化为星号，再次为被支配空间设定了一个下限。
- en: '![](../../OEBPS/Images/11-08.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-08.png)'
- en: Figure 11.8 The reference point in a multiobjective optimization problem, which
    sets a lower bound for the dominated space. The hypervolume is computed to be
    the volume of the region between the reference point and the Pareto frontier.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8 在多目标优化问题中的参考点，它为被支配空间设定了一个下限。超体积计算为参考点与帕累托前沿之间区域的体积。
- en: With this reference point, we can compute the hypervolume of the dominated region
    of a dataset collected by a multiobjective optimization policy. The algorithm
    to complete this computation involves dividing the dominated region into multiple
    nonintersecting hyperrectangles that collectively make up the dominated region.
    From there, we can easily compute the hypervolume of each hyperrectangle and sum
    them up to obtain the hypervolume of the entire region. The interested reader
    can refer to the research paper by Renaud Lacour, Kathrin Klamroth, and Carlos
    M. Fonseca that proposes this algorithm ([http://mng.bz/jPdp](http://mng.bz/jPdp)).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个参考点，我们可以计算由多目标优化策略收集的数据集占优区域的超体积。完成这个计算的算法涉及将占优区域分成多个不相交的超矩形，这些超矩形共同构成了占优区域。从那里，我们可以容易地计算每个超矩形的超体积，并将它们相加以获得整个区域的超体积。有兴趣的读者可以参考Renaud
    Lacour、Kathrin Klamroth和Carlos M. Fonseca等人提出的此算法的研究论文（[http://mng.bz/jPdp](http://mng.bz/jPdp)）。
- en: With BoTorch, we can import and run this algorithm without the need to implement
    the low-level details. More specifically, assume we have stored the collected
    labels found during optimization in variable `train_y`. As we have two objective
    functions in our example, `train_y` should have a shape of *n*-by-2, where *n*
    is the number of data points in the collected set. We can then use the following
    code to compute the hypervolume measure, where
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用BoTorch，我们可以导入和运行此算法，而无需实现底层细节。具体而言，假设我们已将优化期间找到的收集标签存储在变量`train_y`中。因为我们的示例中有两个目标函数，所以`train_y`的形状应为*n*-by-2，其中*n*是收集集合中数据点的数量。然后，我们可以使用下面的代码来计算超体积度量，其中
- en: The `DominatedPartitioning` class implements the partitioning of a dominated
    region. To initialize this object, we pass in the reference point and the collected
    labels `train_y`.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DominatedPartitioning`类实现了占优区域的分区。为了初始化此对象，我们传入参考点和收集标签`train_y`。'
- en: 'We then call the `compute_hypervolume()` method on the dominated region object
    to compute its hypervolume:'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们调用占优区域对象的`compute_hypervolume()`方法来计算其超体积度量：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Imports the class implementation of the dominated region
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入占优区域类的实现
- en: ❷ Computes the hypervolume of the dominated region with respect to the reference
    point
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算相对于参考点的占优区域的超体积度量
- en: Using this method, we can compute the hypervolumes of the exhaustive and random
    search, as shown in the left and middle panels of figure 11.9\. We see that the
    exhaustive search does achieve a higher hypervolume (31.49) than that of the random
    search (25.72).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此方法，我们可以计算完全搜索和随机搜索的超体积度量，如图11.9左侧和中间面板所示。我们看到，与随机搜索的超体积度量（25.72）相比，完全搜索确实实现了更高的超体积度量（31.49）。
- en: '![](../../OEBPS/Images/11-09.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-09.png)'
- en: Figure 11.9 The multiobjective optimization results of various search strategies
    and the corresponding hypervolumes. BayesOpt achieves almost the same hypervolume
    as an exhaustive search, with significantly fewer queries.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9各种搜索策略的多目标优化结果及相应的超体积度量。BayesOpt几乎达到了完全搜索的超体积度量，但查询少了很多。
- en: In the right panel of figure 11.9, we also see the corresponding result achieved
    by the BayesOpt strategy we learn about in the next section with just 20 data
    points. With only one-tenth of the budget (20 versus 201), BayesOpt achieves almost
    the same hypervolume as the exhaustive search. Compared to the random search with
    the same budget, BayesOpt is able to map out the true Pareto frontier more fully
    and achieve a much higher hypervolume.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在图11.9的右侧面板中，我们还可以看到我们在下一节学习的BayesOpt策略仅使用了20个数据点就实现了相应的结果。只有预算的十分之一（20与201），BayesOpt就几乎达到了完全搜索的超体积度量。与具有相同预算的随机搜索相比，BayesOpt能够更全面地映射出真正的Pareto前沿，并实现更高的超体积度量。
- en: 11.3 Seeking to improve the optimal data boundary
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 寻求改进最佳数据边界
- en: 'How should a BayesOpt policy aim to maximize the hypervolume of the dominated
    region within its collected data? A simple strategy is to alternate between optimizing
    each of the objectives in an iteratively manner: at this iteration of the BayesOpt
    loop, we seek to maximize the first objective *f*[1](*x*); at the next iteration,
    we aim to maximize the second objective *f*[2](*x*); and so on. During an iteration,
    we have a specific objective we want to optimize, which we can achieve by using
    the various BayesOpt policies we learned in chapters 4 through 6\. For the remainder
    of this chapter, we use Expected Improvement (EI), which we learned in section
    4.3\. EI is a policy commonly used in practice, thanks to its algorithmic simplicity
    and consistent performance.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化策略应如何最大化其收集数据中受支配区域的超体积？一个简单的策略是在迭代方式下交替优化每个目标：在贝叶斯优化循环的这一次迭代中，我们试图最大化第一个目标
    *f*[1](*x*)；在下一次迭代中，我们则试图最大化第二个目标 *f*[2](*x*)；依此类推。在一个迭代中，我们有一个特定的目标要优化，我们可以通过使用我们在第
    4 至 6 章学到的各种贝叶斯优化策略来实现这一点。在本章的其余部分中，我们使用了期望改进（EI），这是我们在第 4.3 节中学到的。EI是一种在实践中常用的策略，因为它的算法简单且性能稳定。
- en: Assume that in our multiobjective optimization problem, we have observed the
    data points indicated by the Xs in the top panels of figure 11.10\. By training
    a GP on the dataset belonging to each objective function, we obtain the GP predictions
    for the first objective (top-left panel) and the second objective (top-right panel).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在我们的多目标优化问题中，我们观察到图 11.10 顶部面板中 X 标记的数据点。通过对属于每个目标函数的数据集进行 GP 训练，我们得到了第一个目标的
    GP 预测（左上角面板）和第二个目标的 GP 预测（右上角面板）。
- en: In the bottom panels of figure 11.10, we show the acquisition scores of the
    individual EI policies on the corresponding objective functions. The bottom-left
    EI seeks to maximize the first objective *f*[1](x), while the bottom-right EI
    searches for the optimum of the second objective *f*[2](*x*). We see that the
    conflict between the two objectives is clear here when the first EI focuses on
    the right region of the search space, where *f*[1](*x*) is maximized, while the
    second EI looks at the left region, where *f*[2](*x*) is maximized.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 11.10 的底部面板中，我们展示了各个 EI 策略在相应目标函数上的收购分数。左下角的 EI 试图最大化第一个目标 *f*[1](x)，而右下角的
    EI 则寻找第二个目标 *f*[2](*x*) 的最优解。我们可以看到，当第一个 EI 关注搜索空间的右侧区域，即 *f*[1](*x*) 最大化的区域时，而第二个
    EI 则关注左侧区域，即 *f*[2](*x*) 最大化的区域时，两个目标之间的冲突在这里是明显的。
- en: '![](../../OEBPS/Images/11-10.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-10.png)'
- en: Figure 11.10 The current GP belief about each of the two objective functions
    (top) and the corresponding EI acquisition scores (bottom). Each EI policy seeks
    to optimize its own objective function and focuses on separate regions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10：关于两个目标函数的当前 GP 信念（顶部）和相应的 EI 收购分数（底部）。每个 EI 策略都试图优化自己的目标函数，并关注不同的区域。
- en: Note The acquisition score of a datapoint, as computed by a BayesOpt policy,
    quantifies how valuable the data point is to our search for an objective function’s
    optimum. The higher the acquisition score, the more valuable the data point, and
    the point giving the highest acquisition score is the point the policy recommends
    to be queried.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：由贝叶斯优化策略计算的数据点的收购分数 quantifies了数据点对我们搜索目标函数最优解的价值。收购分数越高，数据点越有价值，而给出最高收购分数的点是策略建议查询的点。
- en: In the alternating strategy we came up with previously, we either follow the
    first EI policy and query the point around *x* = 4.5 or follow the second EI and
    query the point around *x* = –4.5, depending on whether it’s *f*[1](*x*)’s or
    *f*[2](*x*)’s turn to be optimized. We use this alternating strategy as a baseline
    to compare our final solution against.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前提出的交替策略中，我们要么遵循第一个EI策略并查询 *x* = 4.5 附近的点，要么遵循第二个EI并查询 *x* = –4.5 附近的点，这取决于是
    *f*[1](*x*) 还是 *f*[2](*x*) 被优化的轮次。我们将这种交替策略作为基准，用来与我们最终的解决方案进行比较。
- en: What should this solution be to allow us to do better than the simple strategy
    of alternating between different objective functions? We note that by having a
    GP to model each of the objectives to be maximized, we have a way to probabilistically
    reason about the value each potential new query gives on each objective *simultaneously*.
    Specifically, we know that the value each potential new query gives on each objective
    follows a known normal distribution; this normal distribution is our prediction
    about the value of the query.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比简单交替不同目标函数的策略做得更好，这个解决方案应该是什么？我们注意到，通过让每个要最大化的目标都有一个GP模型，我们可以概率地推理出每个潜在新查询在每个目标上的值*同时*。具体来说，我们知道每个潜在新查询在每个目标上的价值都遵循一个已知的正态分布；这个正态分布是我们对查询价值的预测。
- en: This prediction allows us to reason about whether each potential new query is
    a nondominated point and if so, how much it will increase the hypervolume of the
    dominated region. Each newly observed nondominated point extends the boundary
    of the dominated region (that is, the Pareto frontier) and, therefore, increases
    the dominated hypervolume. We, therefore, can use the increase in the hypervolume
    that each new query leads to, on average, as the acquisition score to quantify
    how valuable the query is. The bigger the increase in hypervolume that we can
    expect from a query, the more it will help us make optimization progress.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个预测让我们能够推理出每个潜在新查询是否是一个无支配点，如果是的话，它将如何增加被支配区域的超体积。每个新观察到的无支配点都会延伸被支配区域的边界（即Pareto边界），因此增加了支配超体积。因此，我们可以使用每个新查询导致的超体积增加的期望值作为收购分数，来量化查询的价值。我们能够期望从查询获得的超体积增加越大，它对我们进行优化的帮助就越大。
- en: Of course, we can’t know for sure how much of an increase in hypervolume we
    will obtain from a query until we actually make the query on the objective functions.
    However, again, we can reason about this hypervolume increase in a probabilistic
    manner. That is, we can compute the *expected value* of the increase in hypervolume
    that will result from a potential query.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们无法确定通过查询会获得多少超体积的增加，直到我们真正对目标函数进行查询。然而，我们可以通过一种概率方式来推理这个超体积增加。也就是说，我们可以计算可能查询产生的超体积增加的*期望值*。
- en: Like the algorithm that determines the hypervolume of a dominated region, this
    computation of the expected increase in hypervolume involves dividing the dominated
    region into hyperrectangles and is quite complicated. We, once again, won’t go
    into the mathematical details here, but you can refer to the research paper by
    Kaifeng Yang, Michael Emmerich, André Deutz, and Thomas Bäck that proposes the
    corresponding BayesOpt policy, which is called *Expected Hypervolume Improvement*
    (EHVI), for more details ([http://mng.bz/WzYw](http://mng.bz/WzYw)).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，类似于确定被支配区域的超体积的算法，这个对超体积增加的期望计算涉及将被支配区域分成超矩形，非常复杂。再一次地，我们这里不会详细介绍数学细节，但是你可以参考杨凯锋、米歇尔·埃默里奇、安德烈·德茨和托马斯·贝克提出的相应BayesOpt策略的研究论文，该论文称为*预期超体积增加*（EHVI）以获取更多详情（[http://mng.bz/WzYw](http://mng.bz/WzYw)）。
- en: Definition The Expected Hypervolume Improvement policy uses the expected value
    of the increase in hypervolume of the dominated region that a new data point will
    result in as the acquisition score of that data point. This policy is the generalization
    of EI to the multiobjective setting, where we aim to maximize the dominated hypervolume.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 预期超体积增加策略使用新数据点导致的被支配区域超体积增加的期望值作为该数据点的收购分数。这个策略是将EI推广到了多目标设置的结果，其中我们的目标是最大化被支配超体积。
- en: 'Figure 11.11 shows the acquisition scores of EHVI in the bottom-right panel
    on the same dataset as in figure 11.10\. We see that compared to the individual
    EI policies, EHVI nicely balances the two objectives by assigning high acquisition
    scores to multiple regions that likely extend the Pareto frontier: the leftmost
    region of the search space has the highest score, but the rightmost region, along
    with other regions in between, also has nonnegligible acquisition scores.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11显示了与图11.10中相同数据集的EHVI的收购分数在底部右侧面板中。我们可以看到，与单个EI策略相比，EHVI通过将高收购分数分配给可能扩展Pareto边界的多个区域来很好地平衡了两个目标：搜索空间的最左侧区域的得分最高，但最右侧区域以及中间的其他区域也有非常可观的收购分数。
- en: '![](../../OEBPS/Images/11-11.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-11.png)'
- en: Figure 11.11 The current GP belief about each of the two objective functions
    (top), the corresponding EI acquisition scores (bottom left), and the EHVI acquisition
    scores (bottom right). EHVI balances the two objectives, assigning high acquisition
    scores to multiple regions that likely extend the Pareto frontier.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11 当前 GP 对每个目标函数的信念（顶部）、对应的 EI 获取分数（左下角）和 EHVI 获取分数（右下角）的看法。EHVI 平衡了这两个目标，将高获取分数分配给可能延伸
    Pareto 边界的多个区域。
- en: To verify that this EHVI strategy does, indeed, give us an advantage in multiobjective
    optimization, we implement the policy and run it on our current problem. The code
    we use is included in the CH11/02 - Multi-objective BayesOpt loop.ipynb notebook.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这个 EHVI 策略确实在多目标优化中给我们带来了优势，我们实现了这个策略并在当前问题上运行它。我们使用的代码包含在 CH11/02 - Multi-objective
    BayesOpt loop.ipynb 笔记本中。
- en: 'First, we need the class implementation of the GP model and a helper function
    `fit_gp_model()` that facilitates the training of each GP on observed data. As
    we have implemented these components in previous chapters, we won’t show the code
    for them here again; you can refer to section 4.1.1 for a refresher on this code.
    At each step of the BayesOpt loop, we call the helper function to initialize and
    train a GP on each objective function’s data. In our case, we have two objective
    functions, so we call the helper function twice, each time with either `train_y[:,`
    `0]`, which are the labels observed from the first objective *f*[1](*x*), or `train_y[:,`
    `1]`, the labels from the second objective *f*[2](*x*):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要 GP 模型的类实现和一个帮助函数 `fit_gp_model()`，它有助于在观察到的数据上训练每个 GP。由于我们在前几章中已经实现了这些组件，所以我们不会再次在这里展示它们的代码；您可以参考第
    4.1.1 节来复习这些代码。在 BayesOpt 循环的每一步中，我们调用帮助函数在每个目标函数的数据上初始化和训练一个 GP。在我们的情况下，我们有两个目标函数，所以我们分别调用帮助函数两次，每次分别使用
    `train_y[:,` `0]`（从第一个目标 *f*[1](*x*) 观察到的标签）或 `train_y[:,` `1]`（从第二个目标 *f*[2](*x*)
    观察到的标签）。
- en: '[PRE2]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We then implement the EHVI policy using the `ExpectedHypervolumeImprovement`
    class from the `botorch.acquisition.multi_objective.analytic` module. To initialize
    the policy object, we set the following arguments:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 `botorch.acquisition.multi_objective.analytic` 模块中的 `ExpectedHypervolumeImprovement`
    类来实现 EHVI 策略。为了初始化策略对象，我们设置以下参数：
- en: The argument `model` takes in a list of GPs, each of which models an objective
    function. This list of GPs is implemented as an instance of the `ModelListGP`
    class, taking in the individual GP objects (`model1`, `model2`).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数 `model` 接受一系列的 GPs，每个 GP 建模一个目标函数。这个 GP 列表被实现为 `ModelListGP` 类的一个实例，接受单独的
    GP 对象 (`model1`, `model2`)。
- en: The argument `ref_point` takes in the reference point, which is necessary for
    the computation of hypervolume and potential hypervolume increases.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数 `ref_point` 接受参考点，这对于计算 HV 和潜在 HV 增加量是必要的。
- en: 'Finally, the argument `partitioning` takes in an instance of the `FastNondominatedPartitioning`
    class, which facilitates the computation of hypervolume increases. The initialization
    of this object, similar to a `DominatedPartitioning` object we saw previously,
    takes in a reference point and the observed labels `train_y`:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，参数 `partitioning` 接受 `FastNondominatedPartitioning` 类的一个实例，它有助于计算 HV 增加量。这个对象的初始化与我们之前看到的
    `DominatedPartitioning` 对象类似，接受一个参考点和观察标签 `train_y`：
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Imports the necessary classes
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入必要的类
- en: ❷ The list of GP models, each for one objective function
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ GP 模型列表，每个模型对应一个目标函数
- en: ❸ The reference point
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 参考点
- en: ❹ The nondominated partitioning object to compute the hypervolume increase
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 无支配分区对象用于计算 HV 增加量
- en: 'Using the `policy` object for the EHVI policy, we can then compute the acquisition
    score, denoting the expected hypervolume increase, which results from a potential
    new observation. We can then find the data point that gives the highest score,
    using the helper function `optimize_acqf()`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 EHVI 策略的 `policy` 对象，我们可以计算获取分数，表示由潜在新观测引起的预期 HV 增加量。然后我们可以使用辅助函数 `optimize_acqf()`
    找到给出最高分数的数据点：
- en: '[PRE4]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The variable `next_x` stores the location of the query we will make our objective
    functions with next: `next_y` `=` `joint_objective(next_x)`.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 `next_x` 存储我们将在下一步中使用的查询位置：`next_y` `=` `joint_objective(next_x)`。
- en: 'That’s all we need to run EHVI on our current optimization problem. As a point
    of reference, we also test the previously discussed alternating optimization strategy,
    in which we use regular EI to optimize a selected objective function. As we have
    two objectives, we simply switch back and forth between the two (`num_queries`,
    here, is the total number of evaluations we can make in a BayesOpt run):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们在当前优化问题上运行 EHVI 所需的一切。作为参考，我们还测试了之前讨论过的交替优化策略，在这种策略中，我们使用常规的 EI 来优化选择的目标函数。由于我们有两个目标，我们只需在两个目标之间来回切换（这里的`num_queries`是贝叶斯优化运行中可以进行的总评估次数）：
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ If the current iteration number is even, optimizes the first objective
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果当前迭代次数为偶数，则优化第一个目标
- en: ❷ If the current iteration number is odd, optimizes the second objective
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果当前迭代次数为奇数，则优化第二个目标
- en: ❸ Creates the EI policy accordingly
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 相应地创建 EI 策略
- en: 'Finally, to quantify our optimization progress, we record the hypervolume of
    the dominated region resulting from the current dataset collected throughout the
    search. This recording is done with a tensor named `hypervolumes`, which stores
    the current dominated hypervolume at each step during an experiment, across many
    experiments. Overall, our BayesOpt loop is the following, where for each policy,
    we run the experiment multiple times, each with an initial dataset chosen uniformly
    at random:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了量化我们的优化进展，我们记录了由当前数据集在搜索过程中收集的支配区域的超体积。这个记录是用一个名为`hypervolumes`的张量完成的，它在实验过程中在每一步存储当前的支配超体积，跨多个实验。总的来说，我们的贝叶斯优化循环如下，对于每个策略，我们运行实验多次，每次都使用均匀随机选择的初始数据集：
- en: '[PRE6]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ The history of hypervolumes found throughout optimization
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 优化过程中发现的超体积历史
- en: ❷ Initializes a random initial training set
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 初始化一个随机初始训练集
- en: ❸ Records the current hypervolume
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 记录当前的超体积
- en: ❹ Retrains the models, initializes a policy, and finds the next query
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 重新训练模型，初始化一个策略，并找到下一个查询
- en: The CH11/02 - Multi-objective BayesOpt loop.ipynb notebook runs the two BayesOpt
    policies we have for 10 experiments, each with a budget of 20 queries to the objective
    functions. Figure 11.12 shows the average hypervolume and error bars as a function
    of the number of queries made by the two policies. We see that EHVI consistently
    outperforms the alternating EI policy, which illustrates the benefits of the hypervolume-based
    approach.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: CH11/02 - 多目标贝叶斯优化循环.ipynb 笔记本对我们有两个 20 个查询的实验，每个实验都有 10 次贝叶斯优化策略进行运行。图 11.12
    显示了两个策略所进行的查询次数与平均超体积和误差棒的关系。我们看到 EHVI 一直优于交替 EI 策略，这说明了基于超体积的方法的好处。
- en: '![](../../OEBPS/Images/11-12.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/11-12.png)'
- en: Figure 11.12 Average hypervolume and error bars as a function of the number
    of queries made by two BayesOpt policies. EHVI consistently outperforms the alternating
    EI policy.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12 两个贝叶斯优化策略所进行的查询次数与平均超体积和误差棒的关系。EHVI 一直优于交替 EI 策略。
- en: In this chapter, we have learned about the multiobjective optimization problem
    and how to approach it using BayesOpt. We discussed the concept of hypervolume
    as a measure of optimization performance, quantifying how much progress we have
    made in optimizing the objective functions. By using a variant of the EI policy
    to optimize the increase in hypervolume, we obtained an EHVI policy that achieves
    strong performance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了多目标优化问题以及如何使用贝叶斯优化方法来解决它。我们讨论了超体积的概念作为优化性能的衡量标准，量化了我们在优化目标函数方面取得的进展。通过使用
    EI 策略的变体来优化超体积的增加，我们得到了一个表现强劲的 EHVI 策略。
- en: Unfortunately, there are other aspects of multiobjective BayesOpt that can’t
    be covered in this chapter. Specifically, in addition to EHVI, we can consider
    other optimization policies. One common technique is *scalarization*, which combines
    multiple competing objectives into one by taking a weighted sum. This strategy
    is a generalization of the alternating EI policy, which we can think of as assigning
    a weight of 1 to one objective and a weight of 0 to the other at each iteration.
    The interested reader can refer to the BoTorch documentation (see [https://botorch.org/docs/multi_objective](https://botorch.org/docs/multi_objective)
    and [https://botorch.org/tutorials/multi_objective_bo](https://botorch.org/tutorials/multi_objective_bo)),
    which provides a brief summary of different multiobjective optimization policies
    that BoTorch offers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，本章无法涵盖多目标贝叶斯优化的其他方面。具体来说，除了EHVI之外，我们还可以考虑其他优化策略。一种常见的技术是*标量化*，它通过取加权和将多个竞争目标合并为一个目标。该策略是交替EI策略的一般化，我们可以认为在每次迭代中将一个目标的权重设置为1，另一个目标的权重设置为0。感兴趣的读者可以参考BoTorch文档（请参阅[https://botorch.org/docs/multi_objective](https://botorch.org/docs/multi_objective)和[https://botorch.org/tutorials/multi_objective_bo](https://botorch.org/tutorials/multi_objective_bo)），该文档提供了BoTorch提供的不同多目标优化策略的简要摘要。
- en: '11.4 Exercise: Multiobjective optimization of airplane design'
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 练习：飞机设计的多目标优化
- en: In this exercise, we apply the multiobjective optimization techniques we have
    learned to the problem of optimizing the aerostructural design of an airplane.
    This problem was first introduced in exercise 2 of chapter 7 and was modified
    as a cost-constrained problem in exercise 2 of chapter 8\. We reuse the code from
    chapter 8 here. This exercise allows us to observe the performance of the Expected
    Hypervolume Improvement (EHVI) policy in a multidimensional problem. The solution
    is included in the CH11/03 - Exercise 1.ipynb notebook.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将所学的多目标优化技术应用于优化飞机的航空结构设计问题。这个问题首次在第7章的练习2中介绍，并在第8章的练习2中修改为成本约束问题。我们在这里重用第8章的代码。这个练习使我们能够观察到期望超体积改进（EHVI）策略在多维问题中的性能。解决方案包含在CH11/03
    - Exercise 1.ipynb笔记本中。
- en: 'Take the following steps:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: Copy the code for the objective functions `flight_utility()` and `flight_cost()`
    from exercise 2 of chapter 8\. Negate the sign of the returned value of the second
    function, `flight_cost()`. We use these two functions as objectives for our multiobjective
    optimization problem.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从第8章的练习2中复制目标函数`flight_utility()`和`flight_cost()`的代码。取反第二个函数`flight_cost()`返回值的符号。我们将这两个函数用作多目标优化问题的目标。
- en: Write a helper function that takes in an input `X` (which could contain multiple
    data points) and returns the values of `X` evaluated on the two objective functions.
    The returned value should be a tensor of size *n*-by-2, where *n* is the number
    of data points in `X`.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个辅助函数，该函数接受一个输入`X`（可能包含多个数据点），并返回在两个目标函数上评估的`X`的值。返回的值应该是一个大小为*n*-by-2的张量，其中*n*是`X`中数据点的数量。
- en: Declare the search space to be the four-dimensional unit square. That is, the
    four lower bounds are 0, and the four upper bounds are 1.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明搜索空间为四维单位正方形。即，四个下限为0，四个上限为1。
- en: To compute the hypervolume of a dataset collected by an optimization algorithm,
    we need a reference point. Declare this reference point to be [–1.5, –2], which
    are the corresponding lowest values of the two objective functions.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算由优化算法收集的数据集的超体积，我们需要一个参考点。声明此参考点为[–1.5, –2]，这是两个目标函数的对应最低值。
- en: Implement the class for the GP model, which should have a constant mean and
    a four-dimensional Matérn 2.5 kernel with automatic relevance determination (ARD;
    see section 3.4.2) and a helper function `fit_gp_model()` that initializes and
    trains a GP on a training set. Refer to section 4.1.1 for details on implementing
    these components.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现GP模型的类，该类应具有常数均值和一个四维Matérn 2.5核，并具有自动相关性确定（ARD；参见3.4.2节），以及一个辅助函数`fit_gp_model()`，该函数在训练集上初始化和训练GP模型。有关实现这些组件的详细信息，请参见4.1.1节。
- en: Set the number of experiments to be run to 10 and the budget (the number of
    queries to be made) in each experiment to 50.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将要运行的实验次数设置为10，每次实验的预算（要进行的查询数量）设置为50。
- en: Run the EHVI policy to optimize the two objective functions we have as well
    as the alternating EI strategy discussed in section 11.3\. Plot the average hypervolume
    and error bars achieved by these two policies (similar to figure 11.2), and compare
    their performance.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行EHVI策略来优化我们拥有的两个目标函数，以及第11.3节中讨论的交替EI策略。绘制这两个策略所实现的平均超体积和误差条形图（类似于图11.2），并比较它们的性能。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: The multiobjective optimization problem arises when there are multiple potentially
    conflicting objectives that need to be optimized at the same time. This problem
    is common in the real world as we often contend with multiple competing goals
    in many real-life tasks.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当存在多个潜在的冲突目标需要同时优化时，多目标优化问题就会出现。这个问题在现实世界中很常见，因为我们经常在许多真实任务中与多个竞争目标相争。
- en: When using BayesOpt for multiobjective optimization, we use multiple GPs to
    model our belief about the objective functions (one model for each objective).
    We can use these GPs to reason about the objective functions simultaneously in
    a probabilistic manner.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用BayesOpt进行多目标优化时，我们使用多个高斯过程来模拟我们对目标函数的信念（每个目标函数使用一个模型）。我们可以使用这些高斯过程以概率方式同时推理目标函数。
- en: A nondominated point achieves objective values that cannot be improved upon
    unless we sacrifice performance on at least one objective. Discovering nondominated
    data points is a goal of multiobjective optimization as they allow us to study
    the tradeoff between the objective functions.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非支配点实现的目标值不能得到改善，除非我们牺牲至少一个目标函数的性能。发现非支配数据点是多目标优化的目标，因为它们允许我们研究目标函数之间的权衡。
- en: Nondominated data points make up the Pareto frontier, which sets the boundary
    that represents optimality in multiobjective optimization. No data point lies
    beyond the Pareto frontier of all nondominated points.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无支配数据点构成帕累托前沿，它设置了代表多目标优化中最优的边界。没有数据点位于所有非支配点的帕累托前沿之外。
- en: The hypervolume of the dominated space—that is, the region covered by the Pareto
    frontier—measures optimization performance of a dataset collected by an algorithm.
    The larger the hypervolume, the better the algorithm’s performance will be. The
    hypervolume of a dataset can be computed by calling the `compute_hypervolume()`
    method on an instance of BoTorch’s `DominatedPartitioning` class.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支配空间的超体积（即由帕累托前沿覆盖的区域）测量算法收集的数据集的优化性能。超体积越大，算法的性能就越好。可以通过在BoTorch的"DominatedPartitioning"类的实例上调用`compute_hypervolume()`方法来计算数据集的超体积。
- en: To compute the hypervolume of a dataset, we need a reference point that serves
    as the endpoint of the dominated space. We usually set the reference point to
    be the lowest values of the objective functions to be optimized.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要计算数据集的超体积，我们需要一个作为支配空间结束点的参考点。我们通常将参考点设置为要优化的目标函数的最低值。
- en: As the GPs allow us to make predictions about the objective functions, we can
    seek to improve upon the hypervolume of our current dataset. This strategy corresponds
    to the EHVI policy, which is a variant of EI in multiobjective optimization. This
    policy successfully balances the competing objectives.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于高斯过程允许我们对目标函数进行预测，因此我们可以寻求改进当前数据集的超体积。这种策略对应于EHVI策略，是多目标优化中EI的一种变体。这种策略成功平衡了竞争性目标。
