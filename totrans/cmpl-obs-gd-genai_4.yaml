- en: '4 Creating with Generative AI: Media Resources'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generating digital images and video
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating AI-assisted video editing and text-to-video
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating presentation resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating audio-to-text and text-to-audio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text and programming code are natural targets for generative AI. After all,
    after binary, those are the languages with which your computer has the most experience.
    So, intuitively, the ability to generate the kinds of resources we discussed in
    the previous chapter was expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'But images, audio, and video would be a very different story. That’s because
    visual and audio data:'
  prefs: []
  type: TYPE_NORMAL
- en: Are inherently more complex and high-dimensional than text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack symbolic representations and have more nuanced meaning making it challenging
    to directly apply traditional programming techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be highly subjective and ambiguous making it difficult to build automated
    systems that can consistently and accurately interpret such data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack inherent context making it harder for computer systems to confidently derive
    meaning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Require significant computational resources for processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nevertheless, tools for generating media resources have been primary drivers
    of the recent explosion of interest in AI. So the rest of this chapter will be
    dedicated to exploring the practical use of AI-driven digital media creation services.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Generating images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First off, just how does a large language model (LLM) convert a text prompt
    into a visual artifact? The figure below illustrates the keys steps making up
    the training process that makes this happen.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 The training process for building a media-generation LLM
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 1](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here are the steps of that process in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: Gathering a huge collection of audio, images, and videos to learn from. These
    examples come from all over the internet and cover a wide range of styles and
    topics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the examples to learn patterns. For audio, it learns the different sounds
    and how they relate to each other (like how a melody follows a certain rhythm).
    For images, it learns what different objects look like and how they appear together.
    For videos, it figures out how different shots are put together to tell a story.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying mathematical magic to convert the audio, images, and videos into representative
    numbers. These numbers help the system understand the patterns and relationships
    in the content. It’s like the system is translating the art into a language it
    can understand.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training the model involves having the LLM search for the best patterns that
    can recreate the audio, images, and videos it’s seen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the LLM creates something, we apply feedback and adjustments by comparing
    it to real examples. The model adjusts its patterns to get better at creating
    content that’s closer to what we want.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The LLM practices (a lot) by creating new audio, images, and videos. With each
    practice round, it gets better and better at understanding the patterns and making
    its own content.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It’s important to note that AI-generated images and videos are nothing more
    than dumb computers' best efforts based on learned patterns from the training
    data and may not always reflect real-world accuracy - which should be obvious
    for those of us who have seen AI-generated humans with 6-10 fingers per hand or
    three arms. For context, "two" is traditionally the maximum number of arms attached
    to any one human. And, no, I have no clue why LLMs get this obvious thing so wrong,
    so often.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1 Providing detailed prompts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Whichever image generation service you use, the way you build your prompts
    will go a long way to determining the quality of the images that come out the
    other end. You’ll want to be descriptive while also defining the style of the
    image you want. Therefore, something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Some trees*'
  prefs: []
  type: TYPE_NORMAL
- en: '…​won’t be nearly as effective as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A sunlit wooded area in the style of John Constable*'
  prefs: []
  type: TYPE_NORMAL
- en: That example contains a *subject* ("wooded area"), *adjective* ("sunlit") and
    an *artistic style* ("John Constable"). You should try to include at least one
    of each of those three elements in your prompts. Feel free to add details like
    colors and background textures.
  prefs: []
  type: TYPE_NORMAL
- en: 'In case you’re curious, here’s what the Stable Diffusion model gave me in response
    to that last prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 A Stable Diffusion image in the style of English Romantic painter,
    John Constable
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 2](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When it comes to styles, consider adding something from this (partial) list:'
  prefs: []
  type: TYPE_NORMAL
- en: Photograph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cubist
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oil painting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matte
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Surreal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steampunk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cute creatures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fantasy worlds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cyberpunk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Old
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Renaissance painting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Realistic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expressionism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ink
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.1.2 Prompting for images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Nonetheless, I decided to ignore all that advice about styles and details and
    ask a few AI image creation platforms for possible covers to adorn this book.
    My prompt, as you can see, didn’t provide any specific descriptions. Instead,
    I gave it nothing more than an abstraction (the book title) and assumed the GAI
    will be able to translate the concept hinted to into something graphic.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Create a 6:9 cover for a book entitled "The Complete Obsolete Guide to Generative
    Artificial Intelligence" The image should contain no text or alphanumeric characters.*'
  prefs: []
  type: TYPE_NORMAL
- en: It is useful to note how I specified the aspect ratio ("6:9") to tell the software
    what shape the image should take. I also told it not to include any text. AI is
    notoriously *awful* at text.
  prefs: []
  type: TYPE_NORMAL
- en: In case anyone in the Manning art department is reading, here are a couple of
    the images I got back. This first one came from Dream Studio and looks great,
    although they did seem to miss the memo on aspect ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 A Dream Studio "book cover" image
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 3](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-3.png)'
  prefs: []
  type: TYPE_IMG
- en: This image from the Stable Diffusion model hits a lot of the right marks and,
    considering how little I gave it to work with, is pretty impressive.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 A Stable Diffusion "book cover" image
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 4](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'I find more image generation services every time I look online. But, right
    now, these are particularly big players:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Midjourney** is a bit tricky to get started, but seems to produce a very
    high quality of images. You’ll need to create an account at [midjourney.com](www.midjourney.com.html),
    select a yearly or monthly fee account level, and then add a Midjourney server
    to your Discord account. From Discord, you can select the "Midjourney Bot" that
    should appear within the Direct Messages column in Discord. To get your first
    set of images, enter your prompt after typing `/imagine` in the text field at
    the bottom. Four possible images, once they’re generated, will appear in your
    Midjourney UI. I can’t say I understand why it’s designed that way, but a lot
    of people seem to feel it’s worth the effort.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 Midjourney being accessed within a Discord account
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 5](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-5.png)'
  prefs: []
  type: TYPE_IMG
- en: '**DALL-E** - a product of OpenAI - was the first digital image generating tool
    most of us encountered. In its time it was shocking, and brought a lot of attention
    to the underlying technologies and related possibilities. But, perhaps by design,
    it’s never produced images with the same range and photo realism as other competing
    services.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 OpenAI’s DALL-E browser-based interface
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 6](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-6.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Stable Diffusion** is a freely-available generative model that can be accessed
    through an account with services like [Hugging Face](huggingface.co.html) - a
    hosting service for many AI models, datasets and other AI tools using both free
    and pay-as-you-go levels. If you have a computer with a graphic processor unit
    (GPU) and at least 8GB of video memory, you can actually [install and run your
    own private Stable Diffusion service](stable-diffusion-ui.github.io.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.7 The Stable Diffusion GitHub page
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 7](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-7.png)'
  prefs: []
  type: TYPE_IMG
- en: '**DreamStudio** offers image generation through [their website](beta.dreamstudio.ai.html).
    You’re permitted a limited number of credits for free with more available for
    purchase. Currently, usage costs $10 for every 1,000 credits. Costs per image
    depend on size and complexity. DreamStudio is provided by stability.ai - the company
    responsible for Stable Diffusion.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 The DreamStudio browser interface
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 4 8](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-8.png)'
  prefs: []
  type: TYPE_IMG
- en: 4.2 Generating video
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If GAIs can create images, couldn’t they do the same trick with video, too?
    Well of course they can. But you will have to be a bit more specific about what
    you mean by "video."
  prefs: []
  type: TYPE_NORMAL
- en: If what you’re looking for is the ability to write a prompt (like the ones we’ve
    been using for images) and a beautiful video suddenly springs to life, well we’re
    not quite there yet. Meta and Google have both loudly announced technologies (Make-a-Video
    for Meta and Imagen Video for Google) that’ll do just that. But bear in mind that
    both those tools will absolutely, certainly, and without a doubt be available…​on
    some unspecified date in the future.
  prefs: []
  type: TYPE_NORMAL
- en: RunwayML did release a promising tool with limited access. But, considering
    the current 4-15 second maximums per output clip and the significant rendering
    times, it’s not exactly everything we’re hoping for yet.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you can expand your definition of "video" a little bit wider, then
    we might have something to talk about.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 AI-assisted video editing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One process that most certainly does exist right now involves taking existing
    videos and manipulating them so they tell a very different story.
  prefs: []
  type: TYPE_NORMAL
- en: Using stylization and masking effects, applications like [RunwayML’s Gen-1](runwayml.com.html)
    and the open source project [Text2Live](omerbt.html) can create things that high-end
    Hollywood studios have been doing for a while. The difference is that those Hollywood
    studios often spent many months and millions of dollars for the equipment and
    experts they needed. We can now get pretty much the same quality in a few seconds
    on a modestly powered laptop. In fact, you can self-host Text2Live by downloading
    it and running it on your own machine.
  prefs: []
  type: TYPE_NORMAL
- en: What can you actually do? I’d recommend you check out both the [Gen-1](runwayml.com.html)
    and [Text2Live](omerbt.html) sites for demo videos. They’ll show you how textures,
    backgrounds, lighting, and other attributes can be swapped in and out to convert
    an existing video of, say, a man running down a driveway, into an astronaut running
    across an alien planet’s surface.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Text to video slide shows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: That’s all great fun. But some of us use video for tasks that live closer to
    the office than outer space. In other words, there’s a huge market for media content
    that’s focused on education, IT training, news services, marketing, and corporate
    communications. Putting together such presentations the traditional way can take
    hours for each minute of video (I know, because I do that for a living). And that’s
    not taking into account the extra equipment and studio costs it’ll take to put
    you directly on-camera.
  prefs: []
  type: TYPE_NORMAL
- en: There are, however, AI-driven services that can take your script and generate
    a professional video consisting of a hyper-realistic computer-generated voice
    (using your choice of male or female, accent, age, and personality) and appropriate
    supporting background images and bullet-point text. You can upload your own images,
    too. The high-end players in this genre will add a human-like avatar who looks
    pretty close to an actual live human being.
  prefs: []
  type: TYPE_NORMAL
- en: Add in a script generated using ChatGPT the way we’ve seen in previous chapters,
    and you’ll be going from zero to a complete set of professional videos in minutes.
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s the catch? Ah, yes. The catch. Well the high-end stuff isn’t cheap.
    Many of the more professional services currently charge hundreds of dollars a
    year (or more) and limit output to a specified number of minutes of video each
    month. Arguably the leaders in this market include:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Synthesia](www.synthesia.io.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Elai](app.elai.io.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Steve AI](www.steve.ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fliki](fliki.ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Synthesys (not to be confused with Synthesia)](synthesys.io.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.3 Generating presentation resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There’s something about PowerPoint presentations that inspires both fear and
    loathing. There’s the loathing from meeting participants who are condemned to
    suffer through poorly planned and designed presentations. And then there’s the
    dread experienced by presenters as they face the unwanted task of painstakingly
    building their presentations slide by slide (and then suffering the hatred of
    the victims in their audiences).
  prefs: []
  type: TYPE_NORMAL
- en: And, of course, slide decks are about far more than just conference presentations.
    They’re often also the backbone structure of business and educational videos.
    Which is where this chapter’s topic comes in.
  prefs: []
  type: TYPE_NORMAL
- en: 'You see, GAI is already perfectly capable of doing all the hard work for you:
    sometimes technological innovations actually do solve problems. At least as far
    as presenters or video creators go. Their poor audiences are still pretty much
    on their own.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Gamma](gamma.app.html) is one of many text-to-presentation-deck services out
    there. I’ll focus on Gamma for this illustration simply because that’s the one
    with which I’ve had the most experience so far.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Working with some of the free introductory credits I’m allowed, I selected
    the `New with AI` option, followed by their `Text transform` path and entered
    this text in the instructions field (yup: that’s this chapter’s working title):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Generate a presentation on the topic of Creating with Generative AI: Media
    Resources using these headings:*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I then pasted the following topic headers into the content field:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating video
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI-assisted video editing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text to video slide shows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating presentation resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating music
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After that, I only had to chose a format from their list and, within a couple
    of minutes, Gamma had generated the text content, layout, and visuals for a really
    attractive presentation. You can see the PDF that was generated [on my website](bootstrap-it.com.html).
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, I’m free to edit any content that doesn’t fit my needs. But this
    is a game changer for those of us longing to escape PowerPoint Prison.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Generating voice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not happy with your accent or just don’t have a nice, quiet place to record
    your podcast or video narration? There are services that’ll take text content
    and generate audio files with your choice of voice, accent, perfect pacing, and
    no kids screaming in the background. If you’d prefer to be the narrator after
    all, you can also have your voice cloned so *it* can be used to generate your
    audio files.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, voice-to-text has been happening for decades. We’ve all heard voicemail
    systems featuring computer generated voices. What’s changing is that advances
    in AI have greatly improved the quality.
  prefs: []
  type: TYPE_NORMAL
- en: '"Improved," but not necessarily perfected. Try it yourself. Upload some content
    to, say, [Amazon’s Polly service](polly.html) and you’ll be impressed. But after
    listening carefully for at least a minute, and any listener will probably conclude
    that this isn’t really a human being speaking and, as good as it is, it’s quality
    will never be confused for Orson Welles or Winston Churchill.'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, hiring a human being with that level of oratorical skills
    to record your content would cost you considerably more than the $4.00 for every
    *million* characters Amazon will charge you. So there’s that.
  prefs: []
  type: TYPE_NORMAL
- en: Polly is primarily aimed at organizations that need to generate voice in real
    time. Think interactive website support systems. That means Polly’s customers
    are going to want programmatic API connections to script the creation and management
    of their audio. To show you how that’ll work, here’s a sample command using the
    AWS CLI (a command line API access tool) that’ll request an audio .MP3 file generated
    from the text in a local file I called `text.txt`. To make this work, you’ll need
    an AWS account. You’ll also need to have [set up and configured the AWS CLI](userguide.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note how I specified the `Matthew` voice using a US English (`en-US`) accent.
    Polly has dozens of other voices and accent options.
  prefs: []
  type: TYPE_NORMAL
- en: 'I can download the file from the specified Amazon S3 output bucket once it’s
    generated with this AWS CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: And I can remove remote copies of those files using `s3 rm`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: …​Because I believe you should always clean up your toys when you’re finished
    playing with them.
  prefs: []
  type: TYPE_NORMAL
- en: Text-to-speech is a crowded market. Besides Polly, other platforms offer API-accessed
    services. Those would include Google Cloud’s cleverly named [Text-to-Speech service](text-to-speech.html)
    and [IBM’s Watson Text to Speech Voices](self-service.html).
  prefs: []
  type: TYPE_NORMAL
- en: Besides those, there are also services that’ll let you convert text documents
    to speech one at a time through a website interface. [ElevenLabs](beta.elevenlabs.io.html)
    has a reputation as an over-performer in this field, in particular when it comes
    to creating custom voices or cloning *your* voice. [Speechify](speechify.com.html)
    is another big player.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Audio transcriptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That takes care of text-to-audio. But what about audio-to-text (otherwise known
    as *speech recognition*)? There’s no shortage of business uses for transcribing
    existing video or audio files. Can’t think of any offhand? Well how about taking
    the audio from a (boring) two hour video conference that you missed. Even though
    your boss bought your my-dog-ate-my-homework excuse at the time, you still have
    to get back up to speed by watching the recording of the conference.
  prefs: []
  type: TYPE_NORMAL
- en: You didn’t get to where you are now without being good and lazy. So here’s how
    you’re going to push back against that evil decree. You’ll submit the recording
    to an audio transcription service which will deliver you a text document containing
    a full script. You’ll then convert the script to a PDF file and upload it to the
    ChatPDF service we’ll discuss in chapter 5\. When the PDF is uploaded, you can
    request a brief but accurate summary of the script.
  prefs: []
  type: TYPE_NORMAL
- en: Better yet, there are services like [mindgrasp’s Video Summarizer](video-summarizer.html)
    that’ll do all that in a single step.
  prefs: []
  type: TYPE_NORMAL
- en: 'One example of a service that offers simple but effective summaries is [Summarize.tech](www.summarize.tech.html).
    To test them out, I fed the address of [one of my own YouTube videos](www.youtube.com.html)
    into their URL field. Within a few short seconds, I was looking at this brief
    but accurate summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '*This video discusses the security vulnerabilities that are associated with
    AWS EC2 instances. By default, these instances lack a firewall and have an open
    security group, making them vulnerable to attack. The instructor provides a real-life
    example of launching an EC2 instance with open incoming traffic and receiving
    login attempts within minutes. He stresses the importance of striking a balance
    between server functionality and infrastructure security, which will be the main
    goal of the course.*'
  prefs: []
  type: TYPE_NORMAL
- en: See? Life isn’t half as horrible as it looked when you rolled out of bed this
    morning.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally there are also APIs for transcribing audio. Two of those are [OpenAI’s
    Whisper](openai.html) and [Google’s Speech-to-Text](cloud.google.com.html).
  prefs: []
  type: TYPE_NORMAL
- en: Whisper is a dog that does lots of tricks. Among other things, it can handle
    language identification, speech translation, and multilingual speech recognition.
    Like many GPT-based apps, Whisper is built to be installed and run on your own
    computer using a valid OpenAI API key - which, as you’ve already seen, [can be
    acquired on the OpenAI site](account.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'And that’s not going to be half as complicated as you think. Within a Python
    environment, just use `pip` to install the Whisper package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll also need the open source video/audio management tool, ffmpeg. Here’s
    how installing that into a Debian/Ubuntu-based Linux system will work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And here’s the code that’ll make it work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We’ll use the `base` model, write our transcribed text (based on the `MyAudio.flac`
    input file I was using) to the variable `result`, and then display the result.
    Super simple. And it’s surprisingly accurate!
  prefs: []
  type: TYPE_NORMAL
- en: Of course you can use all the regular audio *and* video file formats as inputs,
    and select from one of five models (tiny, base, small, medium, and large).
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 Generating music
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I guess I can’t move on without talking about AI-generated music. I’m not just
    talking about ChatGPT-powered lyrics, or even software that outputs sheet music,
    but *actual* music. That means software that lets you specify details like genre,
    the instruments you want playing, the emotional tone, tempo range, time signature,
    key signature, and harmonic repetition and real music comes out the other end.
  prefs: []
  type: TYPE_NORMAL
- en: As you’ve probably heard, some of those services also make it possible to recreate
    near-perfect sound-alikes of famous singers and have them sing your own new music.
    The exact legal implications of the use of such sound-alikes are not yet clear.
  prefs: []
  type: TYPE_NORMAL
- en: Online AI music generation tools - most of which are primarily designed for
    creating background music using various genres - include [AIVA](www.aiva.ai.html),
    [boomy](boomy.com.html), [Soundful](soundful.com.html), and [Mubert](mubert.com.html).
  prefs: []
  type: TYPE_NORMAL
- en: More recently, Meta (the owners of Facebook) has released [two audio generation
    tools as open source](facebookresearch.html).
  prefs: []
  type: TYPE_NORMAL
- en: MusicGen will generate music from text prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AudioGen will give you sound effects (think: "busy street with police car siren"
    or "wind blowing through trees").'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, they’ve also released the neural audio codec, EnCodec, and the
    diffusion-based decoder, Multi Band Diffusion. You can freely download the code
    but, just like working with image generators, you will need substantial system
    resources to make it work.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We learned about generating digital images (and video) using services like Stable
    Diffusion and MidJourney
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We learned about tools that can use AI to transform existing video artifacts
    into new media
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We learned how to use AI tools like Gamma to generate presentation slide stacks
    from text prompts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We learned about audio-to-text and text-to-audio transcribing using tools like
    Amazon Polly and OpenAI Whisper
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.8 Try this for yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Why not produce an original training video using some of the media generation
    tools we’ve seen in this chapter. Here’s how you might want to go about it:'
  prefs: []
  type: TYPE_NORMAL
- en: Pick a topic ("How to make the most out of generative AI tools", perhaps) and
    prompt an LLM for a video transcript (a three minute video will require around
    500 words of text).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the LLM to summarize the script to give you a set of descriptive bullet points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using [Gamma](gamma.app.html), Select Create new > Text transform and paste
    your bullet points into content field. Then Generate slides.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Amazon Polly, generate a narration file out of the script created by your
    LLM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Mubert to generate background music.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assemble your narration, slides, and background music into a video using, say,
    the [Vimeo video maker](create.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, just for fun, use Whisper to extract a text transcript from the narration
    track on your video and see how close it is to the original script.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
