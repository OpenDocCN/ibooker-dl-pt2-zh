- en: 7 Convolutional neural networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Solving text classification by detecting patterns
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using convolutional layers to detect patterns and produce scores
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using pooling layers to aggregate the scores produced by convolution
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a convolutional neural network (CNN) by combining convolution and pooling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a CNN-based text classifier using AllenNLP
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In previous chapters, we covered linear layers and RNNs, two main neural network
    architectures commonly used in NLP. In this chapter, we introduce another important
    class of neural networks called *convolutional neural networks* (CNNs). CNNs have
    different characteristics than RNNs that make them suitable for NLP tasks where
    detecting linguistic patterns is important, such as text classification.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Introducing convolutional neural networks (CNNs)
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section introduces convolutional neural networks (CNNs), another type of
    neural network architecture that operates in a different way from how RNNs work.
    CNNs are particularly good at pattern-matching tasks and are increasingly popular
    in the NLP community.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.1 RNNs and their shortcomings
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In chapter 4, we covered sentence classification, which is an NLP task that
    receives some text as the input and produces a label for it. We also discussed
    how to use recurrent neural networks (RNNs) for that task. As a refresher, an
    RNN is a type of neural network that has a “loop” in it, which processes the input
    sequence one element at a time from the beginning until the end. The internal
    loop variable, which is updated at every step, is called the *hidden state*. When
    the RNN finishes processing the entire sequence, the hidden state at the final
    timestep represents the compressed content of the input sequence, which can be
    used for NLP tasks including sentence classification. Alternatively, you can take
    out the hidden state after every step and use it to assign labels (such as PoS
    and named entity tags) to individual words. The structure that is applied repeatedly
    in the loop is called a *cell*. An RNN with a simple multiplication and nonlinearity
    is called a *vanilla* or an *Elman* RNN. On the other hand, LSTM and GRU-based
    RNNs use more complicated cells that employ memory and gating.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: RNNs are a powerful tool in modern NLP with a wide range of applications; however,
    they are not without shortcomings. First, RNNs are slow—they need to scan the
    input sequence element by element no matter what. Their computational complexity
    is proportional to the length of the input sequences. Second, due to their sequential
    nature, RNNs are hard to parallelize. Think of a multilayer RNN where multiple
    RNN layers are stacked on top of each other (as shown in figure 7.1). In a naive
    implementation, each layer needs to wait until all the layers below it finish
    processing the input
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F01_Hagiwara](../Images/CH07_F01_Hagiwara.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 Multilayer RNN
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Third, the RNN structure is simply overkill and inefficient for some tasks.
    For example, recall the task of detecting grammatical English sentences that we
    covered in chapter 4\. In its simplest form, the task is to recognize valid and
    invalid subject-verb agreement in a two-word sentence. If a sentence contains
    phrases such as “I am” and “you are,” it’s grammatical. If it contains “I are”
    or “you am,” it’s not. In chapter 4, we built a simple LSTM-RNN with a nonlinearity
    to recognize the grammaticality of two-word sentences with a vocabulary of four
    words. But what if you need to classify whether an arbitrary long sentence with
    a very large vocabulary is grammatical? Suddenly, this process starts to sound
    very complex. Your LSTM needs to learn to pick up the signal (subject-verb agreement)
    from a large amount of noise (all other words and phrases that have nothing to
    do with agreement), while learning to do all this using the update operation that
    gets repeated for every single element of the input.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: But if you think about it, no matter how long the sentence is or how large the
    vocabulary is, your network’s job should still be quite simple—if the sentence
    contains valid collocations (such as “I am” and “you are”), it’s grammatical.
    Otherwise, it’s not. The task is actually not very far from the “if-then” sentiment
    analyzer that we saw in chapter 1\. It is obvious that the structure of LSTM RNNs
    is overkill for this task, where simple pattern matching over words and phrases
    would suffice.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 Pattern matching for sentence classification
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you look at text classification in general, many tasks can be effectively
    solved by this “pattern matching.” Take spam filtering, for example—if you want
    to detect spam emails, simply look for words and phrases such as “v1agra” and
    “business opportunity” without even reading the entire email; it doesn’t matter
    where these patterns appear. If you want to detect sentiment from movie reviews,
    detecting positive and negative words such as “amazing” and “awful” would go a
    long way. In other words, learning and detecting such local linguistic patterns,
    regardless of their location, is an effective and efficient strategy for text-classification
    tasks, and possibly for other NLP tasks as well.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 3, we learned the concept of n-grams—contiguous sequences of one
    or more words. They are often used in NLP as proxies for more formally defined
    linguistic units such as phrases and clauses. If there’s some tool that can wade
    through a large amount of noise in text and detect n-grams that serve as signals,
    it would be a great fit for text classification.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.3 Convolutional neural networks (CNNs)
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Convolutional neural networks, or CNNs, do exactly this. A CNN is a type of
    neural network that involves a mathematical operation called *convolution*, which,
    put simply, detects local patterns that are useful for the task at hand. A CNN
    usually consists of one or more convolutional layers, which do convolution, and
    pooling layers, which are responsible for aggregating the result of convolution.
    See figure 7.2 for a diagram. Sections 7.2 and 7.3 provide some detail of convolutional
    layers and pooling layers, respectively.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）正是做到这一点的。CNN是一种神经网络类型，它涉及一种称为*卷积*的数学运算，简单来说，它检测有用于当前任务的局部模式。CNN通常由一个或多个卷积层和一个或多个池化层组成，卷积层进行卷积操作，池化层负责聚合卷积结果。请参见图7.2。分别在第7.2节和第7.3节中详细介绍卷积层和池化层。
- en: '![CH07_F02_Hagiwara](../Images/CH07_F02_Hagiwara.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F02_Hagiwara](../Images/CH07_F02_Hagiwara.png)'
- en: Figure 7.2 Convolutional neural network
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 卷积神经网络
- en: CNNs, which are inspired by the visual system in the human brain, have been
    widely used for computer vision tasks such as image classification and object
    detection. In recent years, the use of CNNs has been increasingly popular in NLP,
    especially for tasks such as text classification, sequential labeling, and machine
    translation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CNN受到人脑视觉系统的启发，在计算机视觉任务（如图像分类和目标检测）中被广泛使用。近年来，CNN的使用在自然语言处理领域越来越流行，特别是在文本分类、序列标注和机器翻译等任务中。
- en: 7.2 Convolutional layers
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 卷积层
- en: In this section, we’ll discuss convolutional layers, the essential part of the
    CNN architecture. The term *convolution* may sound a bit scary, but at its essence,
    it’s just pattern matching. We’ll use diagrams and intuitive examples to illustrate
    how it really works.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论卷积层，这是CNN架构的核心部分。术语*卷积*听起来可能有点可怕，但本质上它只是一种模式匹配。我们将使用图示和直观的例子来说明它的工作原理。
- en: 7.2.1 Pattern matching using filters
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 使用滤波器进行模式匹配
- en: Convolutional layers are the most important component in CNNs. As mentioned
    earlier, convolutional layers apply a mathematical operation called convolution
    to input vectors and produce output. But what is convolution? Understanding the
    strict definition of convolution requires knowing linear algebra, so we’ll use
    some analogy and concrete examples to understand it. Imagine holding a rectangular-shaped
    patch of colored glass with complex patterns (like the stained glass you see in
    a church) and sliding it over the input sequence while looking through it. If
    the input pattern matches that of the patch, more light goes through the glass
    and you get larger output values. If the input pattern does not look like that
    of the patch or looks the opposite, you get smaller output values. In other words,
    you are looking for particular patterns in the input sequence using a patch of
    colored glass.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层是CNN中最重要的组件。如前所述，卷积层将一种称为卷积的数学运算应用于输入向量，并产生输出。但是什么是卷积？理解卷积的严格定义需要了解线性代数，因此我们将使用类比和具体示例来理解它。想象一下，你手里拿着一个带有复杂图案的矩形玻璃块（就像你在教堂里看到的彩色玻璃），在观察它的同时将其滑动到输入序列上。如果输入模式与玻璃块的模式匹配，更多的光线透过玻璃进去，你会得到更大的输出值。如果输入模式看起来不像玻璃块的模式或者相反，你会得到更小的输出值。换句话说，你正在使用带有彩色玻璃块的道具在输入序列中寻找特定的模式。
- en: This analogy is a little bit too vague, so let’s revisit the grammaticality-detection
    example we used in chapter 4 and see how we’d apply a convolutional layer to the
    task. To recap, our neural network receives a two-word sentence as an input and
    needs to distinguish grammatical sequences from ungrammatical ones. There are
    only four words in the vocabulary—“I,” “you,” “am,” and “are,” which are represented
    by word embeddings. Similarly, there are only four possibilities for the input
    sentence—“I am,” “I are,” “you am,” and “you are.” You want the network to produce
    1s for the first and the last cases and 0s for others. See figure 7.3 for an illustration.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类比比较模糊，所以让我们回顾一下我们在第4章中使用的语法检测的例子，并看看如何将卷积层应用到这个任务上。回顾一下，我们的神经网络接收一个包含两个词的句子作为输入，并需要区分出语法正确的序列和语法错误的序列。词汇表中只有四个词--“I”，“you”，“am”和“are”，它们由单词嵌入表示。类似地，输入句子只有四种可能性--“I
    am”，“I are”，“you am”和“you are”。你希望网络对前两种情况产生1，对其他情况产生0。请参见图7.3进行说明。
- en: '![CH07_F03_Hagiwara](../Images/CH07_F03_Hagiwara.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F03_Hagiwara](../Images/CH07_F03_Hagiwara.png)'
- en: Figure 7.3 Recognizing grammatical English sentences
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 识别英文语法正确的句子
- en: Now, let’s represent word embeddings as patterns. We’ll draw a black circle
    for value -1 and a white one for 1\. Then you can represent each word vector as
    a pair of two circles (see the table on the left in figure 7.3). Similarly, you
    can represent each two-word sentence as a small “patch” of two vectors, or four
    circles (see the table on the right in figure 7.3). Our task is beginning to look
    more like a pattern-recognition task, where the network needs to learn black-and-white
    patterns that correspond to grammatical sentences.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将词嵌入表示为模式。我们用黑色圆表示值-1，白色圆表示1。然后，您可以将每个单词向量表示为两个圆的一对（请参见图7.3左侧的表）。同样，您可以将每个两个词的句子表示为两个向量的小“片段”，或者四个圆（请参见图7.3右侧的表）。我们的任务开始看起来更像是一个模式识别任务，网络需要学习对应于语法句子的黑白模式。
- en: Then, let’s think of a “filter” of the same size (two circles × two circles)
    that acts as the colored glass we talked about earlier. Each circle of this filter
    is also either black or white, corresponding to values -1 and 1\. You are going
    to look at a pattern through this filter and determine whether the pattern is
    the one you are looking for. You do this by putting the filter over a pattern
    and counting the number of color matches between the two. For each one of four
    positions, you get a score of +1 if the colors match (black-black or white-white)
    and a score of -1 if they don’t (black-white or white-black). Your final score
    is the sum of four scores, which varies from -4 (no matches) to +4 (four matches).
    See figure 7.4 for some examples.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们想象一个相同大小的“滤波器”（两个圆×两个圆），它充当我们之前讨论过的彩色玻璃。该滤波器的每个圆也是黑色或白色，对应值-1和1。您将通过这个滤波器查看一个模式，并确定是否这是您要找的模式。您可以通过将滤波器放在模式上并计算两者之间的颜色匹配数量来执行此操作。对于四个位置中的每一个，如果颜色匹配（黑色-黑色或白色-白色），则得分+1，如果不匹配（黑色-白色或白色-黑色），则得分-1。您的最终得分是四个分数的总和，从-4（无匹配）到+4（四次匹配）。请参见图7.4中的一些示例。
- en: '![CH07_F04_Hagiwara](../Images/CH07_F04_Hagiwara.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F04_Hagiwara](../Images/CH07_F04_Hagiwara.png)'
- en: Figure 7.4 Examples of convolutional filters
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 卷积滤波器示例
- en: The score you get varies depending on the pattern and the filter, but as you
    can see in the figure, the score becomes larger when the filter looks similar
    to the pattern and becomes smaller when the two are not similar. You get the largest
    score (4) when the two match exactly and the smallest score (-4) when the two
    are exactly opposite. The filter acts as a pattern detector against the input.
    Although this is a very simplified example, it basically shows what a convolutional
    layer is doing. In convolutional neural networks, such filters are called *kernels*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 您得到的分数取决于模式和滤波器，但如图所示，当滤波器与模式相似时，分数变大，当两者不相似时，分数变小。当两者完全匹配时，您获得最大分数（4），当两者完全相反时，您获得最小分数（-4）。该滤波器充当输入的模式检测器。虽然这是一个非常简化的例子，但基本上显示了卷积层在做什么。在卷积神经网络中，这种滤波器称为*核*。
- en: In a more general setting, you have an input sentence of arbitrary length, and
    you slide a kernel over the sentence from left to right. See figure 7.5 for an
    illustration of this. The kernel is repeatedly applied to two consecutive words
    to produce a sequence of scores. Because the kernel we are using here covers two
    words, it is said to have a *size* of 2\. Also, because there are two dimensions
    in the input embeddings (which are called *channels*), the number of the kernel’s
    input channels is 2.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在更一般的设置中，您有一个任意长度的输入句子，并且从左到右将一个核滑过句子。请参见图7.5以了解此过程的示意图。该核反复应用于连续的两个词，以生成一系列分数。因为我们在这里使用的核覆盖了两个词，所以它被称为具有*大小*为2的核。而且，因为输入嵌入中有两个维度（称为*通道*），所以核的输入通道数量为2。
- en: '![CH07_F05_Hagiwara](../Images/CH07_F05_Hagiwara.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F05_Hagiwara](../Images/CH07_F05_Hagiwara.png)'
- en: Figure 7.5 Sliding a kernel over the input sentence
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 在输入句子上滑动核
- en: NOTE The reason embedding dimensions are called channels is because CNNs are
    most commonly applied to computer vision tasks where the input is often a 2-D
    image of different channels that correspond to intensities of different colors
    (such as red, green, and blue). In computer vision, kernels are two dimensional
    and move over the input 2-D images, which is also called *2-D convolution*. In
    NLP, however, kernels are usually one-dimensional (1-D convolution) and have only
    one size.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 Rectified linear unit (ReLU)
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the next step, let’s think about how we can get the desired output (the Desired
    column in figure 7.3) using kernels. How about if we use the filter shown in the
    second column of figure 7.4? The kernel, which we’ll call kernel 1 from now on,
    matches the first pattern exactly and gives it a high score, while giving zero
    or negative scores to others. Figure 7.6 shows the score (called score 1) when
    kernel 1 is applied to each pattern.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F06_Hagiwara](../Images/CH07_F06_Hagiwara.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 Applying kernel 1 to patterns
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Let’s forget the magnitude of the scores for now and focus on their signs (positive
    and negative). The signs for the first three patterns match between Score 1 and
    Desired, but not for the last pattern. To score it correctly—that is, to give
    it a positive score—you need to use another filter that matches the last pattern
    exactly. Let’s call this kernel 2\. Figure 7.7 shows the score (called score 2)
    when kernel 2 is applied to each pattern.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Kernel 2 can give correct scores that match the signs of the desired ones for
    the last three patterns, but not for the first one. But if you observe figures
    7.6 and 7.7 carefully, it looks like you could get closer to the desired scores
    if there was a way to somehow disregard the output when a kernel gives negative
    scores and then combine the scores from multiple kernels.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F07_Hagiwara](../Images/CH07_F07_Hagiwara.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 Applying kernel 2 to patterns
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s think of a function that clamps any negative input to zero while passing
    any positive values through unchanged. In Python, this function can be written
    as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: or even simpler
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can disregard negative values by applying this function to score 1 and score
    2, as shown in figures 7.8 and 7.9.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F08_Hagiwara](../Images/CH07_F08_Hagiwara.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 Applying ReLU to score 1
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F09_Hagiwara](../Images/CH07_F09_Hagiwara.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 Applying ReLU to score 2
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: This function, which is called a *rectified linear unit*, or ReLU (pronounced
    “rel-you”), is one of the simplest yet most commonly used activation functions
    in deep learning. It is often used with a convolutional layer, and although it
    is very simple (all it does is just clamp negative values to zero), it is still
    an activation function that enables neural networks to learn complex nonlinear
    functions (see chapter 4 for why nonlinear activation functions are important).
    It also has favorable mathematical properties that make it easier to optimize
    the network, although the theoretical details are beyond the scope of this book.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数，被称为*修正线性单元*，或称为 ReLU（发音为“rel-you”），是深度学习中最简单但最常用的激活函数之一。 它通常与卷积层一起使用，虽然它非常简单（它只是将负值夹紧为零），但它仍然是一个激活函数，它使神经网络能够学习复杂的非线性函数（参见第
    4 章，了解为什么非线性激活函数很重要）。 它还具有有利的数学属性，使得优化网络变得更容易，尽管理论细节超出了本书的范围。
- en: 7.2.3 Combining scores
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 合并分数
- en: If you look at both figures 7.8 and 7.9, the “clamped” scores—shown in the f(Score
    1) and f(Score 2) columns—capture the desired scores at least partially. All you
    need to do is combine them together (by summing) and adjust the range (by dividing
    by 4). Figure 7.10 shows the result of this.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看图 7.8 和图 7.9，所谓的“固定”分数—显示在 f(Score 1) 和 f(Score 2) 列中—至少部分地捕捉到了期望的分数。 您所需做的就是将它们结合在一起（通过求和）并调整范围（通过除以
    4）。 图 7.10 展示了这个结果。
- en: '![CH07_F10_Hagiwara](../Images/CH07_F10_Hagiwara.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F10_Hagiwara](../Images/CH07_F10_Hagiwara.png)'
- en: Figure 7.10 Combining the results from two kernels
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 结合两个内核的结果
- en: After combining, the scores match the desired outcomes exactly. All we did so
    far was design kernels that match the patterns we want to detect and then simply
    combine the scores. Compare this to the RNN example we worked on in section 4.1.3,
    where we needed to use some complicated numeric computation to derive the parameters.
    Hopefully this example is enough to show you how simple and powerful CNNs can
    be for text classification!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在合并之后，分数与期望的结果完全匹配。 到目前为止，我们所做的一切都是设计与我们想要检测的模式相匹配的内核，然后简单地组合分数。 比较一下我们在第 4.1.3
    节中处理的 RNN 示例，那里我们需要使用一些复杂的数值计算来推导参数。 希望这个例子足以向您展示 CNN 对于文本分类可以有多简单而强大！
- en: The example we worked on in this section is simply for introducing the basic
    concepts of CNNs, so we cut many corners. First, in practice, patterns and kernels
    are not just black and white but contain real-valued numbers. The score after
    applying a kernel to a pattern is obtained not by counting color matches but through
    a mathematical operation called *inner product*, which captures the similarity
    between the two. Second, the scores produced by kernels aren’t combined by some
    arbitrary operation (like we did in this section) but usually by a linear layer
    (see section 3.4.3), which can learn a linear transformation against the input
    to produce the output. Finally, kernels and the weights (magic constants w and
    b) in the final linear layer are all trainable parameters of a CNN, meaning that
    their values are adjusted so that the CNN can produce the desired scores.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中处理的示例仅用于介绍 CNN 的基本概念，因此我们偷了很多懒。 首先，在实践中，模式和内核不仅仅是黑白的，而是包含实值数字。 应用内核到模式后的分数不是通过计算颜色匹配次数得到的，而是通过一种称为*内积*的数学运算得到的，它捕捉了两者之间的相似性。
    第二，内核产生的分数不是通过某种任意的操作（就像我们在本节中所做的那样）组合在一起的，而通常是通过线性层（见 3.4.3 节）组合在一起的，该线性层可以学习针对输入的线性变换以产生输出。
    最后，内核和最终线性层中的权重（魔法常数 w 和 b）都是 CNN 的可训练参数，这意味着它们的值会被调整，以使 CNN 能够产生期望的分数。
- en: 7.3 Pooling layers
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 池化层
- en: In the previous section, we assumed that the input is just a combination of
    two words—subjects and verbs—although in practice, the input to a CNN can be of
    arbitrary length. Your CNN needs to not only detect patterns but also find them
    in a potentially large amount of noise in the input. As we saw in section 7.2,
    you slide a kernel over the sentence from left to right, and the kernel is repeatedly
    applied to two consecutive words to produce a sequence of scores. The remaining
    question is what to do with these produced scores. Specifically, what operation
    should we use in the “?” position in figure 7.11 to derive the desired score?
    This operation needs to have some properties—it must be something that can be
    applied to an arbitrarily large number of scores, because the sentence can be
    very long. It also needs to aggregate the scores in a way that is agnostic to
    where the target pattern (word embeddings for “I am”) is in the input sentence.
    Can you figure out the answer?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F11_Hagiwara](../Images/CH07_F11_Hagiwara.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 Aggregating scores to derive the desired score
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: The simplest thing you can do to aggregate the scores is to take their maximum.
    Because the largest score in figure 7.11 is 4, it will become the output of this
    layer. This aggregation operation is called *pooling*, and the neural network
    substructure that does pooling is called a *pooling layer*. You can also do other
    types of mathematical operations that do aggregation, such as taking the average,
    although taking the maximum (called *max pooling*) is most commonly used.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: The pooled score will be fed to a linear layer, optionally combined with scores
    from other kernels, and used as a predicted score. This entire process is illustrated
    in figure 7.12\. Now we have a fully functional CNN!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: As with other neural networks we’ve seen so far, the output from the linear
    layer is fed to softmax to produce a probability distribution over labels. These
    predicted values are then compared with the true labels to produce the loss and
    used for optimizing the network.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we wrap up, a few more words on CNNs: notice that the CNN in figure
    7.12 produces the same prediction value no matter where the search pattern (“I
    am”) is in the input sentence. This is due to the kernel locality as well as the
    property of the max pooling layer we just added. In general, CNNs produce the
    same prediction, even if the input sentence is modified by shifting by a few words.
    In a technical term, the CNN is called *transformation invariant*, which is an
    important property of CNNs. This property is perhaps more intuitive if you use
    an image recognition example. An image of a cat is still an image of a cat, no
    matter where the cat is in the image. Similarly, a grammatical English sentence
    (e.g., “I am a student”) is still grammatical, even if the sentence is transformed
    by adding a few words (e.g., “that’s right”) to the beginning, making it “That’s
    right, I am a student.”'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![CH07_F12_Hagiwara](../Images/CH07_F12_Hagiwara.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F12_Hagiwara](../Images/CH07_F12_Hagiwara.png)'
- en: Figure 7.12 A full CNN with multiple kernels
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.12 带有多个卷积核的完整CNN
- en: Because the kernels in a CNN do not depend on each other (unlike RNNs, where
    one cell needs to wait until all the preceding cells finish processing the input),
    CNNs are computationally efficient. GPUs can process these kernels in parallel
    without waiting on other kernels’ output. Due to this property, CNNs are usually
    faster than RNNs of similar size.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因为CNN中的卷积核不相互依赖（与RNN不同，后续单元需要等待所有前面的单元完成输入处理），所以CNN计算效率高。GPU可以并行处理这些卷积核，不用等待其他卷积核的输出。由于这个特性，CNN通常比大小相似的RNN更快。
- en: '7.4 Case study: Text classification'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 案例研究：文本分类
- en: Now that we know the basics of CNNs, in this section we are going to build an
    NLP application using a CNN and see how it works in practice. As mentioned previously,
    one of the most popular and straightforward applications of CNNs in NLP is text
    classification. CNNs are good at detecting patterns (such as salient words and
    phrases in text), which is also the key to accurate text classification.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经了解了CNN的基础知识，在本节中，我们将使用CNN构建一个NLP应用并看看它在实践中的工作原理。正如之前提到的，CNN在NLP中最受欢迎和直接的应用之一就是文本分类。CNN擅长检测文本中的模式（如突出的单词和短语），这也是准确文本分类的关键。
- en: '7.4.1 Review: Text classification'
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 复习：文本分类
- en: We already covered text classification in chapters 2 and 4, but to recap, text
    classification is a task where an NLP system assigns a label to a given piece
    of text. If the text is an email and the label is whether the email is spam, it’s
    spam filtering. If the text is a document (such as a news article) and the label
    is its topic (such as politics, business, technology, or sports), it’s called
    *document classification*. Many other variants of text classification exist, depending
    on what the input and the output are. But the task we’ll be working on in this
    section is again sentiment analysis, where the input is some text in which the
    writer’s subjective opinions are expressed (such as movie and product reviews)
    and the output is the label for the opinion (such as positive or negative, or
    even the number of stars), also called *polarity*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在第2章和第4章中介绍了文本分类，但是为了回顾一下，文本分类是指一个NLP系统给定一段文本分配一个标签的任务。如果文本是一个电子邮件，标签是邮件是否为垃圾邮件，那就是垃圾邮件过滤。如果文本是一个文档（比如新闻文章），标签是它的主题（如政治、商业、技术或体育），那就叫做*文档分类*。根据输入和输出的不同，还存在许多其他变种的文本分类。但是在本节中，我们将再次处理情感分析，它的输入是一些表达作者主观意见的文本（如电影和产品评论），输出是意见的标签（如正面或负面，甚至星级评价），也被称为*极性*。
- en: In chapters 2 and 4, we built an NLP system that detected the polarity given
    a movie review using the Stanford Sentiment Treebank, a dataset containing movie
    reviews and their polarity (strongly positive, positive, neutral, negative, or
    strongly negative). In this section, we will build the same text classifier but
    with a CNN instead of an RNN. The good news is that we can reuse most of the code
    we wrote in chapter 2 in this section—in fact, we need to modify only a few lines
    of code to swap the RNN with a CNN. This is largely thanks to AllenNLP’s powerful,
    well-designed abstractions, which let you work with many modules with different
    architectures through the common interfaces. Let’s see this in action next.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2章和第4章中，我们构建了一个NLP系统，使用Stanford Sentiment Treebank检测给定电影评论的情感极性，这是一个包含电影评论及其极性（非常正面，正面，中立，负面，非常负面）的数据集。在本节中，我们将构建同样的文本分类器，但是使用CNN而不是RNN。好消息是，我们可以重用第2章编写的大部分代码，在这一部分只需要修改几行代码将RNN替换为CNN。这在很大程度上归功于AllenNLP强大而设计良好的抽象，它可以让您通过公共接口与许多具有不同架构的模块一起工作。让我们下面看看它的运行。
- en: 7.4.2 Using CnnEncoder
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.2 使用 CnnEncoder
- en: 'Remember that back in section 4.4, we defined our LstmClassifier for text classification
    as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在第4.4节中，我们定义了文本分类的LstmClassifier如下：
- en: '[PRE2]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We hadn’t put much thought into what this definition meant, but from this constructor
    we can see that the model is built on top of two subcomponents: a TextFieldEmbedder
    called embedder and a Seq2VecEncoder called encoder, in addition to the vocabulary
    and the string for the positive label, which are not relevant to our discussion
    here. We discussed word embeddings in chapter 3 at length, although we only briefly
    touched on the encoder. What does this Seq2VecEncoder actually mean?'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'In AllenNLP, Seq2VecEncoder is a class of neural network architectures that
    take a sequence of vectors (or tensors in general) and return a single vector.
    An RNN, one example of this, takes a variable-length input consisting of multiple
    vectors and converts it into a single vector at the last cell. We created an instance
    of Seq2VecEncoder based on an LSTM-RNN using the following code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: But as long as your component has the same input and output specifications,
    you can use any neural network architecture as a Seq2VecEncoder. In programming
    language, Seq2VecEncoder is analogous to an interface in Java (and in many other
    languages)—interfaces define what your class looks like and what it does, but
    they do not care about *how* your class does it. In fact, your model can do something
    as simple as just summing up all the input vectors to produce the output, without
    any complex transformations such as nonlinearities. This is, in fact, what BagOfEmbeddingsEncoder—one
    of the Seq2VecEncoders implemented in AllenNLP—does.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use a CNN to “squash” a sequence of vectors into a single vector.
    A CNN-based Seq2VecEncoder is implemented as CnnEncoder in AllenNLP, which can
    be instantiated as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this example, embedding_dim specifies the dimensionality of the input embeddings.
    The second argument, num_filters, tells how many filters (or kernels, as explained
    in section 7.2.1) will be used per n-gram. The final argument, ngram_ filter_sizes,
    specifies the list of n-gram sizes, which are the sizes of these kernels. Here,
    we are using n-gram sizes of 2, 3, 4, and 5, meaning there are 8 kernels for bigrams,
    8 kernels for trigrams, and so on, up to 5-grams. In total, this CNN can learn
    32 different kernels to detect patterns. CnnEncoder runs these results from the
    kernels through a max pooling layer and comes up with a single vector that summarizes
    the input.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the training pipeline looks almost identical to the LSTM version
    we saw in chapter 2\. The entire code is available on Google Colab ([http://www.realworld
    nlpbook.com/ch7.html#cnn-nb](http://www.realworldnlpbook.com/ch7.html#cnn-nb)).
    There is one caveat: because some n-gram filters have a wide shape (e.g., 4- and
    5-grams), you need to make sure that each text field is at least that long, even
    when the original text is short (e.g., just one or two words). You need to know
    how batching and padding work in AllenNLP (which we’ll cover in chapter 10) to
    fully understand how to deal with this, but in a nutshell, you need to specify
    the token_min_padding_length parameter when initializing the token indexer as
    follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 7.4.3 Training and running the classifier
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you run the script, you’ll see something like the following log output
    at the end of the training:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This means that the training accuracy reaches ~99%, whereas the validation accuracy
    tops around 40%. Again, this is a typical symptom of overfitting, where your model
    is so powerful that it fits the training data well, but it doesn’t generalize
    to the validation and test datasets as well. Our CNN has many filters that can
    remember salient patterns in the training data, but these patterns are not necessarily
    the ones that help predict the labels for the validation instances. We are not
    worried too much about overfitting in this chapter. See chapter 10 for common
    techniques for avoiding overfitting.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to make predictions for new instances, you can use the same Predictor
    as we did in chapter 2\. Predictors in AllenNLP are a thin wrapper around your
    trained model, which take care of formatting the input and output in a JSON format
    and feeding the instance to the model. You can use the following snippet to make
    predictions using your trained CNN model:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Summary
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CNNs use filters called kernels and an operation called convolution to detect
    local linguistic patterns in the input.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An activation function called ReLU, which clamps negative values to zero, is
    used with convolution layers.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CNNs then use pooling layers to aggregate the result from the convolutional
    layer.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CNN prediction is transformation invariant, meaning it remains unchanged even
    after linear modification of the input.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use a CNN-based encoder as a Seq2VecEncoder in AllenNLP by modifying
    a few lines of code of your text classifier.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
