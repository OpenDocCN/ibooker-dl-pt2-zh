["```py\nimport copy\nimport torch.ao.quantization as q\n\n# deep copy the original model as quantization is done in place\nmodel_to_quantize = copy.deepcopy(model_fp32)\nmodel_to_quantize.eval()\n\n# get mappings - note use “qnnpack” for ARM and “fbgemm” for x86 CPU \nqconfig_mapping = q.get_default_qconfig_mapping(\"qnnpack\") \n\n# prepare\nprepared_model = q.prepare(model_to_quantize)\n\n# calibrate - you’ll want to use representative (validation) data.\nwith torch.inference_mode():\n    for x in dataset:\n        prepared_model(x) \n\n# quantize\nmodel_quantized = q.convert(prepared_model)\n```", "```py\nimport scipy\nimport numpy as np\nmatrix = np.array([\n    [ 1., 2., 3., 4.],\n    [ 5., 6., 7., 8.],\n    [ 9., 10., 11., 12.],\n    [13., 14., 15., 16.]\n])\nu, s, vt = scipy.sparse.linalg.svds(matrix, k=1)\nprint(u,s,vt)\n# [[-0.13472211]\n# [-0.34075767]\n# [-0.5467932 ]\n# [-0.7528288 ]], [38.62266], [[-0.4284123 -0.47437257 -0.52033263 -0.5662928 ]]\n```", "```py\nsvd_matrix = u*s*vt\nprint(svd_matrix)\n# array([[ 2.2291691, 2.4683154, 2.7074606, 2.9466066],\n#      [ 5.6383204, 6.243202 , 6.848081 , 7.4529614],\n#      [ 9.047472 , 10.018089 , 10.988702 , 11.959317 ],\n#      [12.456624 , 13.792976 , 15.129323 , 16.465673 ]], dtype=float32)\n```", "```py\nimport ray\nimport time\n\nray.init() # Start Ray\n\n# Define a regular Python function\ndef slow_function(x):\n    time.sleep(1)\n    return x\n\n# Turn the function into a Ray task\n@ray.remote\ndef slow_function_ray(x):\n    time.sleep(1)\n    return x\n\n# Execute the slow function without Ray (takes 10 seconds)\nresults = [slow_function(i) for i in range(1, 11)]\n\n# Execute the slow function with Ray (takes 1 second)\nresults_future = [slow_function_ray.remote(i) for i in range(1, 11)]\nresults_ray = ray.get(results_future)\n\nprint(\"Results without Ray: \", results)\nprint(\"Results with Ray: \", results_ray)\n\nray.shutdown()\n```"]