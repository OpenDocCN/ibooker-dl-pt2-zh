- en: 7 Using Generative AI to Outperform Legacy Research and Learning Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generating accurate and reliable investment guidance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating large Language Models (LLMs) into your skill-adoption workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating LLMs into your daily work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s been said that AI won’t put anyone out of work, but that people *using
    AI* will put people not using AI out of work.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming, of course, that AI doesn’t end up killing us all first, what can we
    do to ensure we end up in the group of happy users and not the regret-filled outsiders
    sadly looking in?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me give you some context. I’m a lot older than you might think. I wrote
    my first book on sheets of paper using a pen. It may have been a very old technology,
    but it was solar powered (translation: it was only useful when I turned the lights
    on). Granted, I did later painstakingly type out that entire book into a computer.
    But that was using sofware (WordPerfect 4.2 for DOS) that didn’t even have its
    own spellchecker.'
  prefs: []
  type: TYPE_NORMAL
- en: 'My publishing career has enjoyed periodic boosts from new technologies ever
    since. My first printer (a hand-me-down from my brother in law), my first document
    scanner, my first internet connection (yup: that actually came *after* the printer
    and the scanner), my first DSL modem, my discovery and adoption of Linux, and
    so on. Each of those changes had a noticeable impact on my productivity and efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: But none of those came close to the nuclear-powered turbo charge I got from
    generative AI (although, technically, I’m not sure a turbo charge *can* be nuclear-powered).
    It’s not just the blinding speed with which I can access details about events,
    relationships, processes, and trends. And it’s not just the sheer volume of parsed
    data that’s suddenly available to me. It’s that *everything* is moving so much
    faster now. *Everything* I do just *happens* without lag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are just a few of my interactions *from just the past week*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once upon a time, choosing a new (previously enjoyed) laptop would require
    long and deep research: Does the HP EliteBook 840 G3 have all the ports I need?
    What video chipset does it use? How does its CPU rate against benchmark performance
    scores of other CPUs I’ve run? Today? Just ask *Can you compare the specs and
    performance of an HP Elitebook 840 G1 laptop with a Lenovo ThinkPad T420?* and
    then *Would the G3 with an i5 chip be better than a G1 with an i7 chip?* and finally,
    *what kind of battery life can I expect?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once upon a time, figuring out how to access the WiFi radio card on a particular
    laptop would have involved searching online for copies of the right user manual
    and searching through the manual hoping that the information was there. Today?
    Just ask: *How do you access the WiFi card on a Lenovo ThinkPad T420?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once upon a time, getting some background to medical issues would have meant
    diving through online archives of medical studies hoping someone has actually
    done the research, that it’s been published, that it’s available online, and that
    you can extract meaning from in within a reasonable timeframe. Today? Just ask:
    *Would the results of an ECHO (echocardiogram) stress test be altered by the patient
    wearing a surgical mask (restricting his airflow)?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course you’ll remember to confirm whatever information AI gives you, *especially*
    medical information. But even so, you’ll definitely want a piece of that action.
    So let me use a few examples to give you a sense of how just about every research
    task you used to do can now be done better, faster, and more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Asking for investment guidance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Can GPT pick stock market buys and sells for you? Yes it can. Can GPT actually
    execute the transactions without your involvement? Yes. That, too, is possible.
    Is that a good idea? Perhaps not just yet. To be perfectly honest, I’m not in
    any mad rush to push that particular "Start" button.
  prefs: []
  type: TYPE_NORMAL
- en: But as we’ve seen over and over, AI tools have many *specific* strengths that
    translate to super powers when applied against the right problem scenario. Well
    I’d say that "investment guidance" is about as close to a "right problem scenario"
    as you’re likely to find.
  prefs: []
  type: TYPE_NORMAL
- en: One obvious reason for this is that making smart investment decisions involves
    digesting a **lot** of data. How much data? Just a single Form 10-K report, which
    publicly traded companies are required to file annually with the U.S. Securities
    and Exchange Commission (SEC), can contain upwards of 100,000 words. And, as a
    rule, they’re not exactly inspired writing. So don’t expect one to keep you enraptured
    through a lazy summer afternoon at the beach.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, you can’t truly understand a company’s current value, or
    accurately anticipate what the future holds, without somehow reading and absorbing
    the fundamentals contained in that 10-K - along with other documents. And don’t
    ignore how the very nature of investment research involves performing this due
    diligence not on a single company, but on dozens or thousands.
  prefs: []
  type: TYPE_NORMAL
- en: Wouldn’t it be wonderful if there were some kind of - oh, I don’t know - a digital
    tool of some sort that could access and analyse all that data for us? D’ya think
    GPT might be helpful here?
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, at least for now, forget about ChatGPT: 100,000 words is way too long
    for a chat prompt. But by this point in the book you’re already familiar with
    ways around that limitation. So here’s what happened when I took Tesla’s form
    10-K for fiscal year ended December 31, 2021 and fed it to ChatPDF.'
  prefs: []
  type: TYPE_NORMAL
- en: The document itself is available as [a web page on the SEC site](000095017022000796.html).
    To convert that to a PDF document, I first downloaded the HTML to my computer
    using `wget`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The sheer size of the file gave me some trouble, so I used the [Cloud Convert
    website](cloudconvert.com.html) to convert the file to Markddown. From there,
    the free file converter program `Pandoc` made it easy to produce a PDF:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'I dropped that PDF into ChatPDF and gave it the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '*From the 10-k document, identify and explain the significance of the most
    important items to a potential investor. Add tables, summary, and analysis where
    necessary.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s part of the response I got (the chart was helpfully delivered in Markdown
    format):'
  prefs: []
  type: TYPE_NORMAL
- en: '*On page 66 of the Form 10-K, you can find the consolidated balance sheet as
    of December 31, 2021\. Here are some of the key items that potential investors
    may be interested in:*'
  prefs: []
  type: TYPE_NORMAL
- en: '| Item | Amount (in millions) |'
  prefs: []
  type: TYPE_TB
- en: '| Cash and cash equivalents | $16,214 |'
  prefs: []
  type: TYPE_TB
- en: '| Marketable securities | $9,986 |'
  prefs: []
  type: TYPE_TB
- en: '| Total current assets | $38,535 |'
  prefs: []
  type: TYPE_TB
- en: '| Property, plant and equipment, net | $22,936 |'
  prefs: []
  type: TYPE_TB
- en: '| Total assets | $121,872 |'
  prefs: []
  type: TYPE_TB
- en: '| Total current liabilities | $23,758 |'
  prefs: []
  type: TYPE_TB
- en: '| Long-term debt | $12,385 |'
  prefs: []
  type: TYPE_TB
- en: '| Total liabilities | $63,091 |'
  prefs: []
  type: TYPE_TB
- en: '| Total stockholders’ equity | $58,781 |'
  prefs: []
  type: TYPE_TB
- en: '*Cash and cash equivalents and marketable securities are important items for
    potential investors because they represent Tesla’s liquidity position. As of December
    31, 2021, Tesla had a total of $26.2 billion in cash and marketable securities.
    This is a significant increase from the previous year’s balance of $19.4 billion.
    This increase in liquidity is a positive sign for investors as it indicates that
    Tesla has sufficient resources to fund its operations and invest in growth opportunities.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Property, plant and equipment is another important item for investors as it
    represents Tesla’s investment in fixed assets such as factories and equipment.
    As of December 31, 2021, Tesla had property, plant and equipment with a net book
    value of $22.9 billion. This represents an increase from the previous year’s balance
    of $18.6 billion which indicates that Tesla has continued to invest heavily in
    its manufacturing capabilities.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Total liabilities is also an important item for investors as it represents
    Tesla’s debt obligations. As of December 31, 2021, Tesla had total liabilities
    of $63.1 billion, which includes*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a full picture, you’ll probably want to dig deeper with more questions.
    Here’s one I tried:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Is the company’s current resource allocation at all risky?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Which inspired this response:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Yes, Tesla has identified several risks related to its resource allocation
    in the Form 10-K. The company’s plans to ramp up its business to meet sales, delivery,
    installation, servicing, and vehicle charging targets globally require significant
    cash investments and management resources. There is no guarantee that these plans
    will generate additional sales or installations of Tesla’s products, or that the
    company will be able to avoid cost overruns or hire additional personnel to support
    them. Additionally, Tesla faces risks related to supply chain disruptions, changes
    in government regulations and incentives, and competition from other companies
    in the automotive industry. These risks could impact the company’s financial performance
    and future prospects.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next question is something that would be helpful for our research:'
  prefs: []
  type: TYPE_NORMAL
- en: '*What are Tesla’s current ratio and debt-to-equity ratio?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what came back:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Based on the information provided in the Form 10-K, as of December 31, 2021,
    Tesla’s current ratio was 1.14 and its debt-to-equity ratio was 2.08\. These ratios
    can be found on page 359 of the Form 10-K under the "Current portion of debt and
    finance leases" and "Total liabilities" sections for the current year, respectively.
    It is important to note that these ratios may change over time and should be evaluated
    in conjunction with other financial metrics to gain a comprehensive understanding
    of Tesla’s financial health.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking for some context for that? A simple follow-up question can help:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Can you help me understand the significance of those ratios?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'And here’s just a little taste of the response I received:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The current ratio is a liquidity ratio that measures a company’s ability to
    pay its short-term obligations using its current assets. A current ratio of 1
    or higher is generally considered good, as it indicates that the company has enough
    current assets to cover its short-term liabilities. In Tesla’s case, the current
    ratio of 1.14 suggests that the company has enough current assets to cover its
    short-term obligations…​*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You get the idea. But that’s only the beginning. Working through an AI’s analysis
    of each company will still take significant time. But with the API tools we’ve
    already encountered in earlier chapters, there’s nothing stopping you from putting
    together a (relatively) simple automated script to:'
  prefs: []
  type: TYPE_NORMAL
- en: Download Form 10-K documents for 10, 100, or 1,000 companies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert the HTML documents to PDFs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Submit each PDF to ChatPDF through its API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompt GPT to assign each company a score based on its assessment of each 10-K
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return a list in which all assessed companies are ranked by their scores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Not sure how to write the script? Ask OpenAI’s you-know-who. Just a friendly
    heads-up: that script will probably stretch into hundreds of lines and, even with
    the help of your AI, it’ll take hours to debug.'
  prefs: []
  type: TYPE_NORMAL
- en: Keeping in mind all appropriate API charges, there’s also nothing stopping you
    from running this script every day, week, or month. Or from opening your own fully-automated
    market research service (and, a few months later, retiring to the Greek Islands
    in your super yacht).
  prefs: []
  type: TYPE_NORMAL
- en: Sound promising? Well I can assure you that we’re not the first to think of
    it. For instance, an organization called Global Predictions offers individuals
    a free service called Portfolio Pilot. The application uses sophisticated AI pipelines
    to analyse macro market conditions and apply the insights it produces to each
    user’s own portfolio profile. Using (hopefully) solid investment principles, the
    tool can offer real-time investment advice.
  prefs: []
  type: TYPE_NORMAL
- en: The kicker is that, rather than monetizing user engagement through user fees,
    advertising, or commissions on sales, Portfolio Pilot [states that](help.portfoliopilot.com.html)
    they’re "learning with and from users about how to best interact with our economic
    models, running simulations, and applying insights directly to their portfolios."
    Or, in other words, they’re leveraging the value of access to significant volumes
    of consumer investment data.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, it’s worth repeating that an LLM’s guidance - on this or any other
    topic - is just a computer blindly stringing together ones and zeros. A computer
    may be somewhat less likely to knowingly cheat you than a flesh and blood stockbroker,
    but it should still never be trusted blindly. Use the guidance as an important
    base for informed decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: No matter how complicated it might be, any PDF document (containing 120 pages
    or less) can be submitted to ChatPDF and subjected to a sustained and in-depth
    interrogation. And, as with any API, ChatPDF interactions can be automated and
    therefore incorporated into sophisticated operations. By the way, you’re definitely
    not limited to English-language documents for any of this.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Connecting search engines to AI using LangChain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we’ve already seen, the developer universe has exploded with ingenious new
    tools, applications, and processes for working with large language models and
    generative AI. One particularly versatile example is [the LangChain project](www.langchain.com.html).
    The overall goal involves providing easy integrations with various LLM models.
    But the LangChain ecosystem is also host to a growing number of (sometimes experimental)
    projects pushing the limits of the humble LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Spend some time browsing [their website](www.langchain.com.html) to get a sense
    of what’s possible. You’ll see how many tools are designed to help you build more
    powerful applications. But you can also use it as an alternative for connecting
    your favorite AI with the live internet.
  prefs: []
  type: TYPE_NORMAL
- en: Let me show you how that can work using a variation of one of LangChain’s documentation
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like many of the tools we’ve been using here, LangChain is built to be used
    with Python. If you’ve still got a Python-ready environment running, just add
    these two packages and you’ll be all set for this illustration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'What’s that *google-search-results* package all about? That’ll give you access
    to Google’s SerpAPI so you can access Google search results within programs or
    scripts. That functionality, however, comes with a catch: you’ll need to [get
    a SerpAPI key from Google](serpapi.com.html). You can create an account and get
    your key - along with 100 free searches each month - for free.'
  prefs: []
  type: TYPE_NORMAL
- en: There are certainly other ways to access internet search results from within
    your programs (using the Python *google* and *beautifulsoup4* packages, for instance),
    but it’s good for you to be familiar with SerpAPI.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you happen to run into trouble running LangChain operations, your first
    troubleshooting step should be to make sure you’ve got the latest version installed.
    This’ll get you there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Our goal here is to create a software agent (a kind of robot that uses a virtual
    web browser to collect information). We’ll instruct the agent to look for information
    that can answer the question in our prompt. But doing that will require a multi-layer
    operation (referred to as a "chain") involving "understanding" the context of
    the question and figuring out where useful information might be found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the complete code we’ll use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s break that down, step-by-step. We begin by creating environment variables
    containing our OpenAI and SerpAPI keys (don’t forget to insert your valid keys):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll import the modules that’ll provide our agent with all the tools
    it’ll need and then set the temperature to 0 - we’re going for accuracy here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'These lines will define the specific tools we want to deploy with this operation
    and then initialize the agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we’re all set to fire up our chain. As we’ve seen, that’ll include
    requesting that the agent executes a web search to figure out just how many books
    your favorite author (that would be me, of course) has written. The agent will
    then use that information to figure out the primary topics of all those books.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what I got back when I ran that code:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Entering new AgentExecutor chain…​ I should search for information about David
    Clinton’s books. Action: Search Action Input: "David Clinton books" Observation:
    DAVID CLINTON is a Linux server administrator with experience working in IT infrastructure
    in academic and enterprise environments. …​ Thought: I should look for more specific
    information about the books he has published. Action: Search Action Input: "David
    Clinton books published" Observation: Top David Clinton titles …​ The Complete
    LPI Web Development Essentials Exam Study Guide: Learn the basics of HTML, CSS,
    JavaScript, Express.js, and Node.js and …​ Thought: I should look for reviews
    of his books to determine the most common topic. Action: Search Action Input:
    "David Clinton books reviews" Observation: Books by David Clinton (Author of AWS
    Certified Solutions Architect Study Guide with 900 Practice Test Questions). Avg
    rating: 4.06 1,161 ratings 76 reviews. Thought: I now know the most common topic
    of David Clinton’s books. Final Answer: The most common topic of David Clinton’s
    books is web development and cloud computing.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Finished chain. "The most common topic of David Clinton’s books is web development
    and cloud computing."
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Note how the agent sent me verbose notes about the progress it was making.
    Those include the steps of its plan ("I should search for information…​"), the
    conclusions it made at each step ("Observation…​"), reports on its progress ("Thought…​"),
    and the "Final Answer: The most common topic of David Clinton’s books is web development
    and cloud computing." That’s not exactly how I would have put it, but I guess
    it’ll do.'
  prefs: []
  type: TYPE_NORMAL
- en: In a way what we’ve just seen is a LangChain version of the kinds of things
    we did with AutoGPT back in chapter 5\. Having multiple tools in your tool belt
    is always a great idea, because what’ll fail using one tool will often work with
    another. But this has also been an excellent general introduction to the LangChain
    ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: In case you’re curious, that consumed three of my 100 available SerpAPI searches
    for this month.
  prefs: []
  type: TYPE_NORMAL
- en: As always, I encourage you to use [the LangChain documentation](get_started.html)
    to discover more of the use-cases and just plain cool stuff that’re there waiting
    for you. But, because new applications are appearing almost daily, you should
    also keep an eye on developments in the general LangChain community.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Using LangChain to analyse multiple documents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another popular use for LanChain involves loading multiple PDF files in parallel
    and asking GPT to analyze and compare their contents. As you can see for yourself
    in [the LangChain documentation](toolkits.html), existing modules can be loaded
    to permit PDF consumption and natural langauge parsing. I’m going to walk you
    through a use-case sample that’s loosely based on the example in that documentation.
    Here’s how that begins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'That code will build your environment and set up the tools necessary for:'
  prefs: []
  type: TYPE_NORMAL
- en: Enabling OpenAI Chat (ChatOpenAI)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding and processing text (OpenAIEmbeddings, CharacterTextSplitter,
    FAISS, RetrievalQA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing an AI agent (Tool)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, you’ll create and define a `DocumentInput` class and a value called `llm`
    which sets some familiar GPT parameters that’ll both be called later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you’ll create a couple of arrays. The three `path` variables in the `files`
    array contains the URLs for recent financial reports issued by three software/IT
    services companies: Alphabet (Google), Cisco, and IBM. We’re going to have GPT
    dig into the data for us much the way we did earlier for Tesla. But this time,
    we’ll do it for three companies simultaneously, have the AI compare the results,
    and do it all without having to go to the trouble of downloading PDFs to a local
    environment.'
  prefs: []
  type: TYPE_NORMAL
- en: You can usually find such legal filings in the Investor Relations section of
    a company’s website.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This `for` loop will iterate through each value of the `files` array I just
    showed you. For each iteration, it’ll use `PyPDFLoader` to load the specified
    PDF file, `loader` and `CharacterTextSplitter` to parse the text, and the remaining
    tools to organize the data and apply the embeddings. It’ll then invoke the `DocumentInput`
    class we created earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we’ll finally be ready to create an agent and feed it our prompt
    as `input`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output that I got was short and to the point:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '''output'': ''Based on the SEC filing documents:\n\n- The company with the
    greatest short-term debt levels is IBM, with a short-term debt level of $4,760
    million.\n- The company with the highest research and development costs is Alphabet,
    with research and development costs of $11,468 million.''}'
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: LangChain lets you integrate multiple tools into generative AI operations, enabling
    multi-layered programmatic access to the live internet and more sophisticated
    LLM prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Teach yourself to program (or to speak a new language…​or anything else)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the specialized tools we’ve been working with for the past while are wonderful.
    But, when you take a step back and think about everything we’ve been doing, you’ll
    notice one simple thing that connects them all: working better and faster using
    a natural language text prompt. So it’s probably worth spending just a minute
    or two talking about how you can optimize your GPT experience. After all, an LLM
    is only going to be as useful as the prompt you give it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompting ChatGPT with some variation of "teach me how to program using Python"
    might not be enough to get the job done. When phrased that way, the topic is way
    too broad for ChatGPT to properly address in a single completion. And, besides,
    I’m not sure you should *want* to restrict yourself to just GPT. There’s already
    an internet-full of great teaching resources out there: why ignore them?'
  prefs: []
  type: TYPE_NORMAL
- en: Instead, you’ll probably do better starting off with some combination of beginner-friendly
    online tutorials - like [the official Python guide](tutorial.html) - and playing
    around by creating simple programs on your own computer. Once you’re comfortable
    with your programming work environment and all the basics, you can turn to GPT
    for help pushing you through the problems and bottlenecks that are sure to confront
    you.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, you may sometimes encounter specific concepts or code snippets
    that you find challenging or confusing. Whenever you’re stuck, leverage GPT to
    get additional clarity. By formulating your questions within the context of the
    specific problem you’re facing, you’re much more likely to get exactly what you
    need.
  prefs: []
  type: TYPE_NORMAL
- en: Be specific. For example, instead of asking, "How do I write a loop in Python?"
    ask a more targeted question like, "How do I iterate over a list using a `for`
    loop in Python?" Or, alternatively, you can move a step further back and ask "How
    do I get Python to apply an operation to each item in a long list?"
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Accurate and focused prompts are important. And a lot of what’s popularly known
    as "prompt engineering" is really just about taking the time to ensure that your
    ChatGPT prompts are sufficiently clear and provide enough context to allow the
    AI to give you the best possible response. However, I suspect that all these "rules"
    well become less and less important as GAI models get better and better at figuring
    out what you really need.
  prefs: []
  type: TYPE_NORMAL
- en: Not sure why your .NET compiler failed? Start by sharing the error message with
    GPT. Does your code produce an obviously wrong result? Share the code snippet
    that seems to be responsible and ask GPT to tell you what you’ve done wrong. As
    we’ve already seen, be specific. Be verbose. And be persistent. Asking GPT the
    same question (using subtle variations) over and over again can get you different
    results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also: make sure you stick around long enough to read the completion responses
    from start to finish. In the example that follows, ChatGPT not only gave me the
    code to solve the problem in this prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Can you give me some Python code that will import a 4k MP4 video and convert
    it to 1080p?*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Certainly! You can use the `moviepy` library in Python to import a 4K MP4
    video and convert it to 1080p resolution. Here’s an example code snippet to get
    you started:*'
  prefs: []
  type: TYPE_NORMAL
- en: '…​But, as you can see from the full response, it also anticipated possible
    problems (i.e., limited disk space and system resources) and showed me how to
    ensure my environment included all the necessary Python modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Make sure you have the `moviepy` library installed. You can install it using
    pip:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '*In the code snippet above, replace `"4k-video.mp4"` with the path to your
    actual 4K video file. The code opens the video file, resizes it to the target
    resolution of 1080p using the `resize` method, and then writes the resized video
    to the specified output file path.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The `write_videofile` function encodes the video using the H.264 codec (`libx264`)
    and AAC codec for audio. You can customize the codec options as per your requirements.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note that video processing can be computationally intensive, especially for
    large 4K videos. It may take some time to process and resize the video, depending
    on the hardware specifications of your system.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Please ensure you have enough disk space available and that your system meets
    the necessary requirements for video processing tasks.*'
  prefs: []
  type: TYPE_NORMAL
- en: This stuff obviously goes way beyond coding. ChatGPT recently successfully guided
    me through the troubleshooting process necessary to get my garage door opener
    to close properly. It sure is nice having the user manuals for all overhead garage
    door systems on earth memorized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember: it’s not about your AI magically doing everything for you. It’s about
    your AI helping you magically produce more, faster, and better.'
  prefs: []
  type: TYPE_NORMAL
- en: Let me give you one more example that I think will illustrate my point. Because
    some of my books were self-published, I’ve had to work at everything from typesetting,
    editing, cover design, and marketing. I’ve become quite effective at some of those
    tasks, and remarkably helpless at others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Case in point: working with typeface font families. Oh sure, I can tell the
    difference between serif and sans serif fonts, but don’t ask me for advice about
    where and when to use which. After all these years, I still really haven’t got
    a clue.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, when it came time to design the cover image for a recent book and online
    course I was publishing, I turned to ChatGPT for help. Here’s what I asked:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*What kind of open source font and font color should I use for the text of
    a book cover (for a book on open source technologies) where the top two thirds
    of the cover is an image that’s primarily yellow and black and the bottom third
    (where the text will go) is black?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the sage advice I got back:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Font: Open Sans or Lato. Both are versatile and easy to read fonts that work
    well in a variety of contexts. They also have a modern feel that could be a good
    fit for a book on open source technologies.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Font Color: White or light gray. To create contrast with the black background,
    it’s important to use a light-colored font that stands out. White or light gray
    can be good options that create a clean and modern look.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*It’s important to note that the font and color choices may also depend on
    the specific style and tone of your book. However, these suggestions should give
    you a good starting point for selecting a font and font color that complement
    the image on your book cover.*'
  prefs: []
  type: TYPE_NORMAL
- en: I daresay that I wouldn’t have received more complete or personalized advice
    from a high-priced design consultant. And that cover, with its DreamStudio.ai
    image and GPT-inspired font, is arguably the best I’ve ever created (although
    I’ll admit that does set the bar quite low).
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: LLMs as teaching tools are perhaps not ideal for learning something from scratch,
    but are most effective for pushing through learning blocks, highlighting specific
    foundational details, and troubleshooting when things have ground to a halt.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5 Integrating LLMs into your daily work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microsoft, having contributed billions of dollars to the development of GPT,
    is actively seeking to capitalize on their investment. One obvious (and brilliant)
    approach will involve integrating GPT functionality directly into their business
    products. Presumably, rather than having to compose a complete, functioning formula
    in a PowerBI dashboard or a figuring out the syntax for a spreadsheet formula
    in Excel, you’ll be able to describe what you’re after using natural language
    prompts.
  prefs: []
  type: TYPE_NORMAL
- en: It’s revolutionary and game changing. But it’s also a bit off in the future
    (well, from where I sit on this side of the book, it’s a bit off in the future).
    And, for obvious reasons, it’s also limited to Microsoft products.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that, even where GPT isn’t directly integrated, GPT and other
    LLMs already have the answers to just about any problem you can throw at them.
    Here are some example to illustrate.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.1 Spreadsheet integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'LLMs can help generate complex **spreadsheet** formulas for calculations (*Can
    you show me an Excel formula that will generate a random number in a cell and
    then multiply it by the square root of value of the previous cell?*) or data analysis
    (*Can you tell me the date on which the S&P 500 had its highest value based on
    the CSV file?*) no matter what brand of spreadsheet you’re using. Your favorite
    LLM can make you a spreadsheet power user, providing assistance in creating:'
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic formulas for data manipulation and analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditional formatting to highlight data based on specific criteria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automations for repetitive tasks using functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visually appealing charts and graphs from data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.5.2 Kanban integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An LLM can provide suggestions for optimizing task management and organizing
    boards, lists, and cards in **Trello** or other kanban systems. Rely on it to:'
  prefs: []
  type: TYPE_NORMAL
- en: Automate actions and create custom workflows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate reports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extract insights from usage data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.5.3 Slack integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'LLMs can help set up automated workflows using Slack’s integration tools. That
    can include:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating custom bots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and managing channels, groups, and permissions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suggesting for using apps and integrations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.5.4 Salesforce integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An LLM can simplify complicated administration tasks by assisting in creating
    customized reports and dashboards in **Salesforce** to:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualize and analyze data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up workflows and automation rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate formulas and functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.5.5 Code version control
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'LLMs can help with setting up version control workflows and using GitHub for
    code collaboration. For instance, consult your favorite LLM if you ever find yourself
    unable to remember the precise syntax or process necessary for:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating branches and pull requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing code reviews
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Issue tracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.5.6 Photoshop integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The new Adobe art generator tool, Firefly in now integrated into the Photoshop
    application, allowing you to use text prompts to:'
  prefs: []
  type: TYPE_NORMAL
- en: Use Generative Fill to modify existing images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate entirely new images within the Photoshop environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In short, if there’s an important process that you don’t happen to carry out
    often enough to reliably remember, of if there’s something new that you know is
    possible but you’re not sure exactly how, GPT and its friends are your friends.
  prefs: []
  type: TYPE_NORMAL
- en: 7.6 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We learned how LLMs can efficiently absorb and generate insights that can provide
    valuable investment guidance. More importantly, they can quickly ingest large
    volumes of any category of data and generate valuable insights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We saw how LangChain integrations can create agents will the ability to access
    the live internet and engage in sophisticated, multi-layered data collection and
    analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We learned that LLMs can enhance and turbo-charge your ability to perform just
    about any task - particularly through integrations within popular productivity
    software packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.7 Try this for yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Experiment working with [alternate uses for LangChain tools](docs.html). You
    might, for instance, try [creating a custom Bash script using the experimental
    LLMBashChain](code_writing.html). Compare the results you get from the purpose-built
    tool with what ChatGPT gives you.
  prefs: []
  type: TYPE_NORMAL
