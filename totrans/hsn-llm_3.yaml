- en: Chapter 4\. Text Generation with GPT Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：使用GPT模型进行文本生成
- en: In the first chapters of this book, we have taken our first steps into the world
    of Large Language Models (LLMs). We delved into various applications, such as
    classification and semantic search, employing models that focus on representing
    text, like BERT and its derivatives.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前几章中，我们已迈出了进入大型语言模型（LLMs）世界的第一步。我们深入探讨了各种应用，如分类和语义搜索，采用了专注于文本表示的模型，例如BERT及其衍生模型。
- en: As we progressed, we used models trained primarily for text generation, models
    that are often referred to as Generative Pre-trained Transformers (GPT). These
    models have the remarkable ability to generate text in response to *prompts* from
    the user. Through *prompt engineering*, we can design these prompts in a way that
    enhances the quality of the generated text.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们的进展，我们使用了主要用于文本生成的模型，这些模型通常被称为生成式预训练变换器（GPT）。这些模型具有响应用户*提示*生成文本的卓越能力。通过*提示工程*，我们可以以增强生成文本质量的方式设计这些提示。
- en: In this chapter, we will explore these generative models in more detail and
    dive into the realm of prompt engineering, reasoning with generative models, verification
    and even evaluating their output.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更详细地探讨这些生成模型，并深入探讨提示工程、与生成模型推理、验证甚至评估其输出的领域。
- en: Using Text Generation Models
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用文本生成模型
- en: Before we start with the fundamentals of prompt engineering, it is essential
    to explore the basics of utilizing a text generation model. How do we select the
    model to use? Do we use a proprietary or open-source model? How can we control
    the generated output? These questions will serve as our stepping stones into using
    text generation models.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始提示工程的基本知识之前，探索如何利用文本生成模型的基础知识是至关重要的。我们如何选择使用的模型？我们是使用专有模型还是开源模型？我们如何控制生成的输出？这些问题将作为我们使用文本生成模型的垫脚石。
- en: Choosing a Text Generation Model
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择文本生成模型
- en: Choosing a text generation model starts with choosing between proprietary models
    or open-source models. Although proprietary models are generally more performant,
    we focus in this book more on open-source models as they offer more flexibility
    and are free to use.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 选择文本生成模型始于在专有模型和开源模型之间进行选择。尽管专有模型通常性能更优，但我们在本书中更多地关注开源模型，因为它们提供了更多灵活性并且可以免费使用。
- en: '[Figure 4-1](#fig_1_foundation_models) shows a small selection of impactful
    foundation models, LLMs that have been pre-trained on vast amounts of text data
    and are often fine-tuned for specific applications.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-1](#fig_1_foundation_models)展示了一小部分具有影响力的基础模型，这些大型语言模型（LLMs）在大量文本数据上进行过预训练，并通常为特定应用进行了微调。'
- en: '![Foundation models ](assets/text_generation_with_gpt_models_479875_01.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![基础模型](assets/text_generation_with_gpt_models_479875_01.png)'
- en: Figure 4-1\. Foundation models
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-1：基础模型
- en: From those foundation models, hundreds if not thousands of models have been
    fine-tuned, one more suitable for certain tasks than another. Choosing the model
    to use can be a daunting task!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些基础模型中，数百个甚至数千个模型已被微调，使得某些模型更适合特定任务。选择使用的模型可能是一项艰巨的任务！
- en: We generally advise starting out with a small and recently released foundation
    model, like Llama 2 or Mistral 7B in the illustration in [Figure 4-1](#fig_1_foundation_models)
    This allows for quick iteration and as a result a thorough understanding of whether
    the model is suitable for your use case. Moreover, a smaller model requires less
    GPU memory (VRAM) which makes it easier and faster to run if you do not have a
    large GPU. Scaling up tends to be a nicer experience than scaling down.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常建议从小型且最近发布的基础模型开始，例如[图4-1](#fig_1_foundation_models)中的Llama 2或Mistral 7B。这允许快速迭代，从而深入理解该模型是否适合你的用例。此外，小型模型需要更少的GPU内存（VRAM），如果你的GPU不大，这使得运行更加容易和快速。放大通常比缩小更令人愉快。
- en: In the examples throughout this chapter, we will employ a model from the Zephyr
    family, namely [Zephyr 7B-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta).
    They are models fine-tuned on Mistral 7B, a relatively small but quite capable
    open-source LLM.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的示例中，我们将采用来自Zephyr系列的模型，即[Zephyr 7B-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)。这些模型是在Mistral
    7B上经过微调的，Mistral 7B是一个相对较小但相当强大的开源大型语言模型（LLM）。
- en: If you’re taking your first steps in generative AI, it’s important to start
    with a smaller model. This provides a great introduction and lays a solid foundation
    for progressing to larger models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在生成AI领域刚起步，重要的是从一个较小的模型开始。这为初学者提供了很好的介绍，并为进阶到更大的模型打下坚实的基础。
- en: Loading a Text Generation Model
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载文本生成模型
- en: “How to load a text generation model” can actually be a chapter by itself. There
    are dozens of packages out there each with their compression and inference strategies
    to squeeze out performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: “如何加载文本生成模型”实际上可以单独成为一个章节。市面上有几十个包，各自拥有不同的压缩和推理策略来提高性能。
- en: 'The most straightforward method of doing so is through the well-known HuggingFace
    Transformers library:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是通过众所周知的HuggingFace Transformers库：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To use the model, we will have to take a closer look at its prompt template.
    Any LLM requires a specific template so that it can differentiate between recent
    and older query/answer pairs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用该模型，我们需要仔细查看它的提示模板。任何LLM都需要特定的模板，以便它能够区分最近和较旧的查询/响应对。
- en: 'To illustrate, let us ask the LLM to make a joke about chickens:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们请LLM讲个关于鸡的笑话：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Aside from our main prompt, we also generated a system prompt that provides
    context or guidance to an LLM for generating the response. As illustrated in [Figure 4-2](#fig_2_the_template_zephyr_expects_when_interacting_with),
    the prompt template helps the LLM understand the difference between types of prompts
    and also between text generated by the LLM and the user.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们的主要提示外，我们还生成了一个系统提示，为LLM提供生成响应的上下文或指导。如[图4-2](#fig_2_the_template_zephyr_expects_when_interacting_with)所示，提示模板帮助LLM理解不同类型提示之间的区别，以及LLM生成的文本与用户文本之间的区别。
- en: '![The template Zephyr expects when interacting with the model.](assets/text_generation_with_gpt_models_479875_02.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Zephyr在与模型互动时所期望的模板。](assets/text_generation_with_gpt_models_479875_02.png)'
- en: Figure 4-2\. The template Zephyr expects when interacting with the model.
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-2\. Zephyr在与模型互动时所期望的模板。
- en: 'Using that prompt, we can let the LLM give an answer:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用该提示，我们可以让LLM给出答案：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Which outputs:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果为：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that we know how to create a prompt using a chat template, let us explore
    how we can control the output of the model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道如何使用聊天模板创建提示，让我们深入探讨如何控制模型的输出。
- en: Controlling the Model Output
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制模型输出
- en: Other than prompt engineering, we can control the kind of output that we want
    by adjusting the model parameters. In our previous example, you might have noticed
    that we used several parameters in the `pipe` function, including `temperature`
    and `top_p`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提示工程，我们还可以通过调整模型参数来控制我们想要的输出类型。在之前的示例中，你可能注意到我们在`pipe`函数中使用了多个参数，包括`temperature`和`top_p`。
- en: These parameters control the randomness of the output. A part of what makes
    LLMs exciting technology is that it can generate different responses for the exact
    same prompt. Each time an LLM needs to generate a token, it assigns a likelihood
    number to each possible token.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数控制输出的随机性。使LLM成为令人兴奋技术的一部分在于它可以为完全相同的提示生成不同的响应。每当LLM需要生成一个标记时，它会为每个可能的标记分配一个可能性数字。
- en: As illustrated in [Figure 4-3](#fig_3_the_model_chooses_the_next_token_to_generate_based),
    in the sentence “*I am driving a…*” the likelihood of that sentence being followed
    by tokens like “*car*” or “*truck*” is generally higher than a token like “elephant”.
    However, there is still a possibility of “*elephant*” being generated but it is
    much lower.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图4-3](#fig_3_the_model_chooses_the_next_token_to_generate_based)所示，在句子“*我正在开着一辆…*”中，后面跟上“*车*”或“*卡车*”等标记的可能性通常高于“*大象*”。然而，“*大象*”仍然有生成的可能性，但它的概率要低得多。
- en: '![The model chooses the next token to generate based on their likelihood scores.](assets/text_generation_with_gpt_models_479875_03.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![模型根据它们的可能性评分选择生成下一个标记。](assets/text_generation_with_gpt_models_479875_03.png)'
- en: Figure 4-3\. The model chooses the next token to generate based on their likelihood
    scores.
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-3\. 模型根据它们的可能性评分选择生成下一个标记。
- en: Temperature
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 温度
- en: The `temperature` controls the randomness or the creativity of the text generated.
    It defines how likely it is to choose tokens that are less probable. The underlying
    idea is that a temperature of 0 generates the same response every time because
    it always chooses the most likely word. As illustrated in [Figure 4-4](#fig_4_a_higher_temperature_increases_the_likelihood_that),
    a higher value allows less probable words to be generated.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`temperature` 控制生成文本的随机性或创造性。它定义了选择不太可能的标记的可能性。基本思想是，温度为 0 时每次都会生成相同的响应，因为它总是选择最可能的单词。如
    [图 4-4](#fig_4_a_higher_temperature_increases_the_likelihood_that) 所示，较高的值允许生成不太可能的单词。'
- en: '![A higher temperature increases the likelihood that less probable tokens are
    generated  and vice versa.](assets/text_generation_with_gpt_models_479875_04.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![较高的温度增加了生成不太可能的标记的可能性，反之亦然。](assets/text_generation_with_gpt_models_479875_04.png)'
- en: Figure 4-4\. A higher temperature increases the likelihood that less probable
    tokens are generated, and vice versa.
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4。较高的温度增加了生成不太可能的标记的可能性，反之亦然。
- en: As a result, a higher temperature (e.g., 0.8) generally results in a more diverse
    output while a lower temperature (e.g., 0.2) creates a more deterministic output.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，较高的温度（例如 0.8）通常会导致更具多样性的输出，而较低的温度（例如 0.2）则会产生更确定性的输出。
- en: top_p
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: top_p
- en: '`top_p`, also known as nucleus sampling, is a sampling technique that controls
    which subset of tokens (the nucleus) the LLM can consider. It will consider tokens
    until it reaches their cumulative probability. If we set top_p to 0.1, it will
    consider tokens until it reaches that value. If we set `top_p` to 1, it will consider
    all tokens.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`top_p`，也称为核采样，是一种控制 LLM 可以考虑哪些标记（核）的采样技术。它会考虑标记直到达到其累积概率。如果我们将 top_p 设置为 0.1，它会考虑标记直到达到该值。如果我们将
    `top_p` 设置为 1，它会考虑所有标记。'
- en: As shown in [Figure 4-5](#fig_5_a_higher_top_p_increases_the_number_of_tokens_that),
    by lowering the value, it will consider fewer tokens and generally give less “creative”
    output whilst increasing the value allows the LLM to choose from more tokens.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 4-5](#fig_5_a_higher_top_p_increases_the_number_of_tokens_that) 所示，通过降低该值，将考虑更少的标记，通常会产生较少的“创造性”输出，而增加该值则允许
    LLM 从更多的标记中进行选择。
- en: '![A higher top_p increases the number of tokens that can be selected to generate  and
    vice versa.](assets/text_generation_with_gpt_models_479875_05.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![较高的 top_p 增加了可以选择生成的标记数量，反之亦然。](assets/text_generation_with_gpt_models_479875_05.png)'
- en: Figure 4-5\. A higher top_p increases the number of tokens that can be selected
    to generate, and vice versa.
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5。较高的 top_p 增加了可以选择生成的标记数量，反之亦然。
- en: Similarly, the `top_k` parameter controls exactly how many tokens the LLM can
    consider. If you change its value to 100, the LLM will only consider the top 100
    most probable tokens.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`top_k` 参数精确控制 LLM 可以考虑多少个标记。如果将其值更改为 100，LLM 将仅考虑前 100 个最可能的标记。
- en: As shown in Table 5-1, these parameters allow the user to have a sliding scale
    between being creative (high `temperature` and `top_p`) and being predictable
    (lower `temperature` and `top_p`).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 5-1 所示，这些参数使用户在创造性（高 `temperature` 和 `top_p`）与可预测性（低 `temperature` 和 `top_p`）之间拥有一个滑动尺度。
- en: '![A screenshot of a computer'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机的屏幕截图'
- en: Description automatically generated](assets/text_generation_with_gpt_models_479875_06.png)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Description automatically generated](assets/text_generation_with_gpt_models_479875_06.png)
- en: Figure 4-6\. Examples of use cases when selecting values for `temperature` and
    `top_p`.
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6。选择 `temperature` 和 `top_p` 值时的使用案例示例。
- en: Intro to Prompt Engineering
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程简介
- en: An essential part of working with text-generative LLMs is prompt engineering.
    By carefully designing our prompts we can guide the LLM to generate desired responses.
    Whether the prompts are questions, statements, or instructions, the main goal
    of prompt engineering is to elicit a useful response from the model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 与文本生成 LLM 相关的重要部分是提示工程。通过仔细设计我们的提示，我们可以引导 LLM 生成所需的响应。无论提示是问题、陈述还是指令，提示工程的主要目标是从模型中引发有用的响应。
- en: However, prompt engineering is also more than just designing effective prompts.
    It can be used as a tool to evaluate the output of a model, design safeguards,
    and safety mitigation methods. This is an iterative process of prompt optimization
    and requires experimentation. There is not and unlikely will ever be a perfect
    prompt design.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，提示工程不仅仅是设计有效的提示。它还可以作为评估模型输出、设计保护措施和安全缓解方法的工具。这是一个提示优化的迭代过程，需要实验。不存在，也不太可能有完美的提示设计。
- en: In this section, we will go through common methods for prompt engineering, and
    small tips and tricks to understand what the effect is of certain prompts. These
    skills allow us to understand the capabilities of LLMs and lie at the foundation
    of interfacing with these kinds of models.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by answering the question: What should be in a prompt?'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: The Basic Ingredients of a Prompt
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An LLM is a prediction machine. Based on a certain input, the prompt, it tries
    to predict the words that might follow it. At its core, and as illustrated in
    [Figure 4-7](#fig_6_a_basic_example_of_a_prompt_no_instruction_is_giv), the prompt
    does not need to be more than just a few words to elicit a response from the LLM.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![A basic example of a prompt. No instruction is given so the LLM will simply
    try to complete the sentence.](assets/text_generation_with_gpt_models_479875_07.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Figure 4-7\. A basic example of a prompt. No instruction is given so the LLM
    will simply try to complete the sentence.
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: However, although the illustration works as a basic example, it fails to complete
    a specific task. Instead, we generally approach prompt engineering by asking a
    specific question or task the LLM should complete. To elicit the desired response,
    we need a more structured prompt.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: For example, and as shown in [Figure 4-8](#fig_7_two_components_of_a_basic_instruction_prompt_the),
    we could ask the LLM to classify a sentence into either having positive or negative
    sentiment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![Two components of a basic instruction prompt  the instruction itself and
    the data it refers to.](assets/text_generation_with_gpt_models_479875_08.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: Figure 4-8\. Two components of a basic instruction prompt, the instruction itself
    and the data it refers to.
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This extends the most basic prompt to one consisting of two components–the instruction
    itself and the data that relates to the instruction.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: More complex use cases might require more components to be necessary in a prompt.
    For instance, to make sure the model only outputs “negative” or “positive” we
    can introduce output indicators that help guide the model. In [Figure 4-9](#fig_8_extending_the_prompt_with_an_output_indicator_whic),
    we prefix the sentence with “Text:” and add “Sentiment:” to prevent the model
    from generating a complete sentence. Instead, this structure indicates that we
    expect either “negative” or “positive”.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![Extending the prompt with an output indicator which allows for a specific
    output.](assets/text_generation_with_gpt_models_479875_09.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Figure 4-9\. Extending the prompt with an output indicator which allows for
    a specific output.
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can continue adding or updating the elements of a prompt until we elicit
    the response we were looking for. We could add additional examples, describe the
    use case in more detail, provide additional context, etc. These components are
    merely examples and are not a limited set of possibilities. The creativity that
    comes with designing these components is key.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Although a prompt is a single piece of text it is tremendously helpful to think
    of prompts as pieces of a larger puzzle. Have I described the context of my question?
    Does the prompt have an example of the output?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提示是单一的文本，但将提示视为更大拼图的一部分是非常有帮助的。我是否描述了我的问题的上下文？提示中是否包含了输出的示例？
- en: Instruction-based Prompting
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于指令的提示
- en: Although prompting comes in many flavors, from discussing philosophy with the
    LLM to role-playing with your favorite superhero, prompting is often used to have
    the LLM answer a specific question or resolve a certain task. This is referred
    to as instruction-based prompting.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提示有很多种形式，从与LLM讨论哲学到与自己喜欢的超级英雄角色扮演，提示通常用于让LLM回答特定问题或解决某项任务。这被称为基于指令的提示。
- en: '[Figure 4-10](#fig_9_examples_of_use_cases_that_employ_instruction_base) illustrates
    a number of use cases in which instruction-based prompting plays an important
    role. We already did one of these in the previous example, namely supervised classification.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-10](#fig_9_examples_of_use_cases_that_employ_instruction_base)展示了多个在基于指令的提示中发挥重要作用的用例。我们在之前的示例中已经进行了其中一个，即监督分类。'
- en: '![Examples of use cases that employ instruction based prompting.](assets/text_generation_with_gpt_models_479875_10.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![使用基于指令的提示的用例示例。](assets/text_generation_with_gpt_models_479875_10.png)'
- en: Figure 4-10\. Examples of use cases that employ instruction-based prompting.
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-10\. 使用基于指令的提示的用例示例。
- en: Each of these tasks requires different formats of prompting and more specifically,
    different questions to be asked of the LLM. Asking the LLM to summarize a piece
    of text will not suddenly result in classification. To illustrate, examples of
    prompts for some of these use cases can be found in [Figure 4-11](#fig_10_prompt_examples_of_common_use_cases_notice_how_wi).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务每个都需要不同格式的提示，更具体地说，需要向LLM提出不同的问题。要求LLM总结一段文本并不会突然导致分类。为了说明，一些这些用例的提示示例可以在[图4-11](#fig_10_prompt_examples_of_common_use_cases_notice_how_wi)中找到。
- en: '![Prompt examples of common use cases. Notice how within a use case  the structure
    and location of the instruction can be changed.](assets/text_generation_with_gpt_models_479875_11.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![常见用例的提示示例。注意在一个用例中，指令的结构和位置可以改变。](assets/text_generation_with_gpt_models_479875_11.png)'
- en: Figure 4-11\. Prompt examples of common use cases. Notice how within a use case,
    the structure and location of the instruction can be changed.
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-11\. 常见用例的提示示例。注意在一个用例中，指令的结构和位置可以改变。
- en: 'Although these tasks require different instructions, there is actually a lot
    of overlap in the prompting techniques used to improve the quality of the output.
    A non-exhaustive list of these techniques includes:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些任务需要不同的指令，但实际上在用于提高输出质量的提示技术上有很多重叠。这些技术的非详尽列表包括：
- en: Specificity
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 特异性
- en: Accurately describe what you want to achieve. Instead of asking the LLM to “Write
    a description for a product.” ask it to “Write a description for a product in
    less than two sentences and use a formal tone.”.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 准确描述你想要实现的目标。与其问LLM“写一个产品描述。”不如问它“用少于两句话写一个产品描述，并使用正式的语气。”。
- en: Hallucination
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉
- en: LLMs may generate incorrect information confidently, which is referred to as
    hallucination. To reduce its impact, we can ask the LLM to only generate an answer
    if it knows the answer. If it does not know the answer, respond with “I don’t
    know”.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可能会自信地生成不正确的信息，这被称为幻觉。为了减少其影响，我们可以要求LLM仅在知道答案的情况下生成回答。如果它不知道答案，则回应“我不知道”。
- en: Order
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序
- en: Either begin or end your prompt with the instruction. Especially with long prompts,
    information in the middle is often forgotten. LLMs tend to focus on information
    either at the beginning of a prompt (primacy effect) or the end of a prompt (recency
    effect).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要么在提示的开始或结束时给出指令。尤其是在长提示中，中间的信息往往被遗忘。LLM倾向于关注提示开头（首因效应）或结尾（近因效应）中的信息。
- en: Here, specificity is arguably the most important aspect. An LLM does not know
    what you want unless you are specific in what you want to achieve and why.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，特异性可以说是最重要的方面。一个大型语言模型（LLM）不知道你想要什么，除非你对自己想要实现的目标和原因非常具体。
- en: Advanced Prompt Engineering
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级提示工程
- en: On the surface, creating a good prompt might seem straightforward. Ask a specific
    question, be accurate, add some examples and you are done! However, prompting
    can grow complex quite quickly and as a result is an often underestimated component
    of leveraging LLMs.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上，创建一个好的提示似乎很简单。问一个具体的问题，准确，添加一些示例，你就完成了！然而，提示很快就会变得复杂，因此常常被低估为利用LLM的一个组成部分。
- en: Here, we will go through several advanced techniques for building up your prompts,
    starting with the iterative workflow of building up complex prompts all the way
    to using LLMs sequentially to get improved results. Eventually, we will even build
    up to advanced reasoning techniques.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将通过几种高级技术来构建你的提示，从构建复杂提示的迭代工作流程开始，一直到顺序使用LLM以获得更好的结果。最终，我们甚至将建立高级推理技术。
- en: The Potential Complexity of a Prompt
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示的潜在复杂性
- en: As we explored in the intro to prompt engineering, a prompt generally consists
    of multiple components. In our very first example, our prompt consisted of instruction,
    data, and output indicators. As we mentioned before, no prompt is limited to just
    these three components and you can build it up as complex as you want.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在提示工程导言中探讨的，提示通常由多个组件组成。在我们的第一个示例中，提示由指令、数据和输出指标组成。正如我们之前提到的，没有提示仅限于这三种组件，你可以根据需要构建得越复杂越好。
- en: 'These advanced components can quickly make a prompt quite complex. Some common
    components are:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些高级组件可以快速使提示变得相当复杂。一些常见的组件包括：
- en: '*Persona*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*角色*'
- en: Describe what role the LLM should take on. For example, use *“You are an expert
    in astrophysics.”* if you want to ask a question about astrophysics.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 描述LLM应该扮演的角色。例如，如果你想问关于天体物理学的问题，可以使用*“你是天体物理学专家。”*
- en: '*Instruction*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*指令*'
- en: The task itself. Make sure this is as specific as possible. We do not want to
    leave much room for interpretation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 任务本身。确保这一点尽可能具体。我们不想留太多解释的余地。
- en: '*Context*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*上下文*'
- en: Additional information describing the context of the problem or task. It answers
    questions like *“What is the reason for the instruction?”*.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 描述问题或任务上下文的额外信息。它回答类似*“指令的原因是什么？”*的问题。
- en: '*Format*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*格式*'
- en: The format the LLM should use to output the generated text. Without it, the
    LLM will come up with a format itself which is troublesome in automated systems.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应使用的输出生成文本的格式。如果没有它，LLM将自行生成格式，这在自动化系统中是麻烦的。
- en: '*Audience*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*受众*'
- en: For whom the generated text should be. This also describes the level of the
    generated output. For education purposes, it is often helpful to use ELI5 (*“Explain
    it like I’m 5.”*)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 生成文本应面向谁。这也描述了生成输出的级别。出于教育目的，使用ELI5（*“像我5岁时那样解释。”*）往往很有帮助。
- en: '*Tone*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*语气*'
- en: The tone of voice the LLM should use in the generated text. If you are writing
    a formal email to your boss, you might not want to use an informal tone of voice.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在生成文本时应使用的语气。如果你正在给老板写正式邮件，可能不想使用非正式的语气。
- en: '*Data*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据*'
- en: The main data related to the task itself.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 与任务本身相关的主要数据。
- en: To illustrate, let us extend the classification prompt that we had earlier and
    use all of the above components. This is demonstrated in [Figure 4-12](#fig_11_an_example_of_a_complex_prompt_with_many_component).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们扩展之前的分类提示，并使用上述所有组件。这在[图4-12](#fig_11_an_example_of_a_complex_prompt_with_many_component)中展示。
- en: '![An example of a complex prompt with many components.](assets/text_generation_with_gpt_models_479875_12.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![一个包含多个组件的复杂提示示例。](assets/text_generation_with_gpt_models_479875_12.png)'
- en: Figure 4-12\. An example of a complex prompt with many components.
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-12\. 一个包含多个组件的复杂提示示例。
- en: This complex prompt demonstrates the modular nature of prompting. We can add
    and remove components freely and judge their effect on the output. As illustrated
    in [Figure 4-13](#fig_12_iterating_over_modular_components_is_a_vital_part), we
    can slowly build up our prompt and explore the effect of each change.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个复杂的提示展示了提示的模块化特性。我们可以自由添加和删除组件，并判断它们对输出的影响。如[图4-13](#fig_12_iterating_over_modular_components_is_a_vital_part)所示，我们可以逐步构建提示，并探索每次变化的影响。
- en: '**![Iterating over modular components is a vital part of prompt engineering.
    ](assets/text_generation_with_gpt_models_479875_13.png)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**![对模块组件的迭代是提示工程的重要部分。](assets/text_generation_with_gpt_models_479875_13.png)**'
- en: Figure 4-13\. Iterating over modular components is a vital part of prompt engineering.**  **The
    changes are not limited to simply introducing or removing components. Their order,
    as we saw before with the recency and primacy effects, can affect the quality
    of the LLM’s output.
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-13\. 迭代模块组件是提示工程的重要组成部分。**  **这些变化不仅限于简单地引入或移除组件。正如我们之前看到的近期效应和首因效应，它们的顺序会影响LLM的输出质量。
- en: In other words, experimentation is vital when finding the best prompt for your
    use case. With prompting, we essentially have ourselves in an iterative cycle
    of experimentation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，实验在找到适合你用例的最佳提示时至关重要。通过提示，我们实际上处于一个迭代实验的循环中。
- en: 'Try it out yourself! Use the complex prompt to add and/or remove parts to observe
    its impact on the generated prompts. You will quickly notice when pieces of the
    puzzle are worth keeping. You can use your own data by adding it to the `data`
    variable:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试一下！使用复杂提示添加和/或移除部分，以观察其对生成提示的影响。当你发现拼图中值得保留的部分时，会很快注意到。你可以通过将自己的数据添加到`data`变量中来使用自己的数据：
- en: '[PRE4]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Tip
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Almost weekly there are new components of a prompt that might increase the accuracy
    of the output. There are all manners of components that we could add and creative
    components like using emotional stimuli (e.g., “This is very important for my
    career.”) are discovered on a weekly basis.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每周都有新的提示组件可能提高输出的准确性。我们可以添加各种各样的组件，每周都会发现使用情感刺激（例如，“这对我的职业非常重要。”）等创造性组件。
- en: Part of the fun in prompt engineering is that you can be as creative as possible
    to figure out which combination of prompt components contribute to your use case.
    There are few constraints to develop a format that works for you.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程的一大乐趣在于你可以尽可能地富有创造力，以找出哪些提示组件的组合对你的用例有帮助。开发一个适合你的格式几乎没有约束。
- en: 'However, note that some prompts work better for certain models compared to
    others as their training data might be different or if they are trained for different
    purposes.**  **## In-Context Learning: Providing Examples'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请注意，某些提示对特定模型的效果更好，因为它们的训练数据可能不同，或者它们的训练目的不同。**  **## 上下文学习：提供示例
- en: In the previous sections, we tried to accurately describe what the LLM should
    do. Although accurate and specific descriptions help the LLM to understand the
    use case, we can go one step further.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们试图准确描述大型语言模型（LLM）应该做什么。尽管准确和具体的描述有助于LLM理解用例，但我们可以更进一步。
- en: Instead of describing the task, why do we not just show the task?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么不直接展示任务，而是描述它呢？
- en: We can provide the LLM with examples of exactly the thing that we want to achieve.
    This is often referred to as in-context learning, where we provide the model with
    correct examples.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向LLM提供我们想要实现的事物的确切示例。这通常被称为上下文学习，我们向模型提供正确的示例。
- en: As illustrated in [Figure 4-14](#fig_13_an_example_of_a_complex_prompt_with_many_component),
    this comes in a number of forms depending on how many examples you show the LLM.
    Zero-shot prompting does not leverage examples, one-shot prompts use a single
    example, and few-shot prompts use two or more examples.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 4-14](#fig_13_an_example_of_a_complex_prompt_with_many_component)所示，展示给LLM的示例数量会影响形式。零-shot
    提示不利用示例，one-shot 提示使用一个示例，而few-shot 提示使用两个或更多示例。
- en: '![An example of a complex prompt with many components.](assets/text_generation_with_gpt_models_479875_14.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![复杂提示的示例，包含多个组件。](assets/text_generation_with_gpt_models_479875_14.png)'
- en: Figure 4-14\. An example of a complex prompt with many components.
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-14\. 复杂提示的示例，包含多个组件。
- en: Adopting the original phrase, we believe that “an example is worth a thousand
    words”. These examples provide a direct example of what and how the LLM should
    achieve.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 采用原始短语，我们认为“一个例子胜过千言万语”。这些示例提供了LLM应该如何实现的直接示例。
- en: We can illustrate this method with a simple example taken from the original
    paper describing this method. The goal of the prompt is to generate a sentence
    with a made-up word. To improve the quality of the resulting sentence, we can
    show the generative model an example of what a proper sentence with a made-up
    word would be.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用一个简单的示例来说明这种方法，该示例取自描述此方法的原始论文。提示的目标是生成一个包含虚构单词的句子。为了提高生成句子的质量，我们可以向生成模型展示一个包含虚构单词的正确句子的示例。
- en: 'To do so, we will need to differentiate between our question (`user`) and the
    answers that were provided by the model (`assistant`):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要区分我们的提问（`user`）和模型提供的答案（`assistant`）：
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The prompt illustrates the need to differentiate between the user and assistant.
    If we did not, it would seem as if we were talking to ourselves:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can use this prompt to run our model:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result is a proper sentence using the made-up word “screeg”:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As with all prompt components, one or few shot-prompting is not the be-all and
    end-all of prompt engineering. We can use it as one piece of the puzzle to further
    enhance the descriptions that we gave it. The model can still “choose”, through
    random sampling, to ignore the instructions
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Chain Prompting: Breaking up the Problem'
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In previous examples, we explored splitting up prompts into modular components
    to improve the performance of LLMs. Although this works well for many use cases,
    this might not be feasible for highly complex prompts or use cases.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Instead of breaking the problem within a prompt, we can do so between prompts.
    Essentially, we take the output of one prompt and use it as input for the next.
    Thereby creating a continuous chain of interactions that solves our problem.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate, let us say we want to use an LLM to create a product name, slogan,
    and sales pitch for us based on a number of product features. Although we can
    ask the LLM to do this in one go, we can instead break the problem up into pieces.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: As a result, and as illustrated in [Figure 4-16](#fig_15_chain_of_thought_prompting_uses_reasoning_examples),
    we get a sequential pipeline that first creates the product name, uses that with
    the product features as input to create the slogan, and finally, uses the features,
    product name, and slogan to create the sales pitch.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '![Using a description of a product s features  chain prompts to create a suitable
    name  slogan  and sales pitch.](assets/text_generation_with_gpt_models_479875_15.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
- en: Figure 4-15\. Using a description of a product’s features, chain prompts to
    create a suitable name, slogan, and sales pitch.
  id: totrans-142
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This technique of chaining prompts allows the LLM to spend more time on each
    individual question instead of tackling the whole problem.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Let us illustrate this with a small example.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this example, we ask the model first to create a name and slogan. Then, we
    can use the output to ask for a good sales pitch based on the product’s characteristics.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives us the following output:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Although we need two calls to the model, a major benefit is that we can give
    each call different parameters. For instance, the number of tokens created was
    relatively small for the name and slogan whereas the pitch can be much longer.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'It can be used for a variety of use cases, including:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '*Response validation*'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Asking the LLM to double-check previously generated outputs
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '*Parallel prompts*'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Create multiple prompts in parallel and do a final pass to merge them. For example,
    ask multiple LLMs to generate multiple recipes in parallel and use the combined
    result to create a shopping list.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '*Writing stories*'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Leverage the LLM to write books or stories by breaking the problem down into
    components. For example, by first writing a summary, develop characters and build
    the story beats before diving into creating the dialogue.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 利用LLM撰写书籍或故事，可以将问题拆解为各个组成部分。例如，首先撰写摘要，再发展角色并构建故事情节，然后再深入创作对话。
- en: In Chapter 6, we will go beyond chaining LLMs and chain other pieces of technology
    together, like memory, search, and more! Before that, this idea of prompt chaining
    will be explored further in the next sections describing more complex prompt chaining
    methods like self-consistency, chain-of-thought, and tree-of-thought.**  **# Reasoning
    with Generative Models
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在第六章中，我们将超越链接LLM，连接其他技术组件，如内存、搜索等！在此之前，提示链的这一概念将在接下来的部分中进一步探讨，描述更复杂的提示链方法，如自一致性、链式思维和树状思维。**  **#
    与生成模型的推理
- en: In the previous sections, we focused mostly on the modular component of prompts,
    building them up through iteration. These advanced prompt engineering techniques,
    like prompt chaining, proved to be the first step toward enabling complex reasoning
    with generative models.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的部分中，我们主要集中于提示的模块化组件，通过迭代构建它们。这些先进的提示工程技术，如提示链，证明了实现生成模型复杂推理的第一步。
- en: To allow for this complex reasoning, it is a good moment to step back and explore
    what reasoning entails. To simplify, our methods of reasoning can be divided into
    system 1 and 2 thinking processes, as illustrated in Figure 5-X.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许这种复杂的推理，现在是退后一步探讨推理内容的好时机。简单来说，我们的推理方法可以分为系统1和系统2思维过程，如图5-X所示。
- en: System 1 thinking represents automatic, intuitive, and near-instantaneous. It
    shares similarities with generative models that automatically generate tokens
    without any self-reflective behavior. In contrast, systems 2 thinking is a conscious,
    slow, and logical process, akin to brainstorming and self-reflection.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 系统1思维代表自动、直觉和几乎瞬时的反应。它与生成模型有相似之处，生成模型自动生成令牌而没有任何自我反思行为。相反，系统2思维是一个有意识、缓慢和逻辑的过程，类似于头脑风暴和自我反思。
- en: If we could give a generative model the ability of self-reflection, we would
    essentially be emulating the system 2 way of thinking which tends to produce more
    thoughtful responses than system 1 thinking.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能够赋予生成模型自我反思的能力，我们实际上是在模拟系统2的思维方式，这通常比系统1思维产生更深思熟虑的响应。
- en: In this section, we will explore several techniques that attempt to mimic these
    kinds of thought processes of human reasoners with the aim of improving the output
    of the model.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨几种技术，试图模仿这些人类推理者的思维过程，旨在提高模型的输出。
- en: 'Chain-of-Thought: Think Before Answering'
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 链式思维：回答前思考
- en: The first and major step towards complex reasoning in generative models was
    through a method called Chain-of-Thought (CoT). CoT aims to have the generative
    model “think” first rather than answering the question directly without any reasoning.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 实现生成模型复杂推理的第一大步骤是通过一种称为链式思维（CoT）的方法。CoT旨在让生成模型“思考”后再回答问题，而不是直接回答而不进行任何推理。
- en: As illustrated in [Figure 4-16](#fig_15_chain_of_thought_prompting_uses_reasoning_examples),
    it provides examples in a prompt that demonstrate the reasoning the model should
    do before generating its response. These reasoning processes are referred to as
    “thoughts”. This helps tremendously for tasks that involve a higher degree of
    complexity, like mathematical questions. Adding this reasoning step allows the
    model to distribute more compute over the reasoning process.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图4-16](#fig_15_chain_of_thought_prompting_uses_reasoning_examples)所示，它在提示中提供了示例，展示了模型在生成响应之前应进行的推理。这些推理过程被称为“思考”。这对涉及更高复杂度的任务（如数学问题）帮助巨大。增加这个推理步骤使模型能够在推理过程中分配更多计算资源。
- en: '![Chain of Thought prompting uses reasoning examples to persuade the generative
    model to use reasoning in its answer.](assets/text_generation_with_gpt_models_479875_16.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![链式思维提示使用推理示例来说服生成模型在其回答中使用推理。](assets/text_generation_with_gpt_models_479875_16.png)'
- en: Figure 4-16\. Chain-of-Thought prompting uses reasoning examples to persuade
    the generative model to use reasoning in its answer.
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-16. 链式思维提示使用推理示例来说服生成模型在其回答中使用推理。
- en: 'We will use the example they used in their paper to demonstrate this phenomenon.
    To start with, let’s explore the output of a standard prompt without CoT. Instead
    of providing a single query, we differentiate between the user and the assistant
    when providing examples:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用他们在论文中使用的例子来演示这一现象。首先，让我们探讨一下没有 CoT 的标准提示的输出。我们在提供示例时，不仅提供单一查询，而是区分用户和助手：
- en: '[PRE11]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This gives us the incorrect answer:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了错误的答案：
- en: '[PRE12]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Instead, we will use CoT to have the model present its reasoning before giving
    the answer:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们将使用 CoT 让模型在给出答案之前展示其推理过程：
- en: '[PRE13]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This time, we got the correct response:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们得到了正确的响应：
- en: '[PRE14]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This reasoning process is especially helpful because the model does so before
    generating the answer. By doing so, it can leverage the knowledge it has generated
    thus far to compute the correct answer.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个推理过程尤其有帮助，因为模型是在生成答案之前这样做的。通过这样做，它可以利用迄今为止生成的知识来计算正确的答案。
- en: Zero-shot Chain-of-Thought
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零-shot 思维链
- en: Although CoT is a great method for enhancing the output of a generative model,
    it does require one or more examples of reasoning in the prompt which the user
    might not have access to.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 CoT 是增强生成模型输出的好方法，但它确实需要一个或多个推理示例，而用户可能没有这些示例。
- en: Instead of providing examples, we can simply ask the generative model to provide
    the reasoning. There are many different forms that work but a common and effective
    method is to use the phrase “Let’s think step-by-step” which is illustrated in
    [Figure 4-17](#fig_16_chain_of_thought_prompting_without_using_examples).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以简单地要求生成模型提供推理，而不是提供示例。有许多不同的形式有效，但一个常见且有效的方法是使用短语“让我们一步一步思考”，如[图 4-17](#fig_16_chain_of_thought_prompting_without_using_examples)所示。
- en: '![Chain of Thought prompting without using examples. Instead  it uses the phrase  Let
    s think step by step  to prime reasoning in its answer. ](assets/text_generation_with_gpt_models_479875_17.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![不使用示例的思维链提示。相反，它使用短语“让我们一步一步思考”来激发其回答中的推理。](assets/text_generation_with_gpt_models_479875_17.png)'
- en: Figure 4-17\. Chain-of-Thought prompting without using examples. Instead, it
    uses the phrase “Let’s think step-by-step” to prime reasoning in its answer.
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-17\. 不使用示例的思维链提示。相反，它使用短语“让我们一步一步思考”来激发其回答中的推理。
- en: 'Using the example we used before, we can simply append that phrase to the prompt
    to enable CoT-like reasoning:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前的例子，我们可以简单地将该短语附加到提示中，以启用类似 CoT 的推理：
- en: '[PRE15]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Again, we got the correct response but now without needing to provide examples:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们得到了正确的响应，但现在不需要提供示例：
- en: '[PRE16]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This is why it is so important to “show your work” when doing calculations.
    By addressing the reasoning process we can justify the answer and be more sure
    of the answer.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是在进行计算时“展示你的过程”如此重要的原因。通过关注推理过程，我们可以为答案提供依据，更加确定答案的正确性。
- en: Tip
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Although the prompt “*Let’s think step-by-step*” can improve the output, you
    are not constrained by this exact formulation. Alternatives exist like “*Take
    a deep breath and think step-by-step*” and “*Let’s work through this problem step-by-step*”.
    The authors demonstrated the usefulness of coming up with alternative formulations.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提示“*让我们一步一步思考*”可以改善输出，但你并不受限于这个确切的表述。还有替代方案，例如“*深呼吸一下，逐步思考*”和“*让我们逐步解决这个问题*”。作者证明了提出替代表述的实用性。
- en: '**Self-Consistency: Sampling Outputs**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**自我一致性：抽样输出**'
- en: Using the same prompt multiple times can lead to different results if we allow
    for a degree of creativity through parameters like `temperature` and `top_p`.
    As a result, the quality of the output might improve or degrade depending on the
    random selection of tokens. In other words, luck!
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果通过 `temperature` 和 `top_p` 等参数允许一定程度的创造性，使用相同的提示多次可能会导致不同的结果。因此，输出的质量可能会因随机选择的词元而提高或降低。换句话说，这全看运气！
- en: To counteract this degree of randomness and improve the performance of generative
    models, self-consistency was introduced. This method asks the generative model
    the same prompt multiple times and takes the majority result as the final answer.
    During this process, each answer can be affected by different `temperature` and
    `top_p` values to increase the diversity of sampling.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了抵消这种随机性并提高生成模型的性能，引入了自我一致性。这种方法多次向生成模型提出相同的提示，并将多数结果作为最终答案。在这个过程中，每个答案可能会受到不同
    `temperature` 和 `top_p` 值的影响，以增加抽样的多样性。
- en: As illustrated in [Figure 4-18](#fig_17_by_sampling_from_multiple_reasoning_paths_we_can),
    this method can further be improved by adding Chain-of-Thought prompting to improve
    its reasoning whilst only using the answer for the voting procedure.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图4-18](#fig_17_by_sampling_from_multiple_reasoning_paths_we_can)所示，通过添加链式思维提示，可以进一步改进此方法，以提高推理能力，同时仅使用答案进行投票程序。
- en: '![By sampling from multiple reasoning paths  we can use majority voting to
    extract the most likely answer.](assets/text_generation_with_gpt_models_479875_18.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![通过从多个推理路径中采样，我们可以使用多数投票提取最可能的答案。](assets/text_generation_with_gpt_models_479875_18.png)'
- en: Figure 4-18\. By sampling from multiple reasoning paths, we can use majority
    voting to extract the most likely answer.
  id: totrans-194
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-18。通过从多个推理路径中采样，我们可以使用多数投票提取最可能的答案。
- en: Although this method works quite well to improve the output, it does require
    a single question to be asked multiple times. As a result, although the method
    can improve performance, it becomes *n* times slower where *n* is the number of
    output samples.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管此方法在提高输出方面效果良好，但确实需要对同一个问题进行多次提问。因此，尽管该方法可以提高性能，但它变得* n * 倍慢，其中 * n * 是输出样本的数量。
- en: 'Tree-of-Thought: Exploring Intermediate Steps'
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维树：探索中间步骤
- en: The ideas of Chain-of-Thought and Self-consistency are meant to enable more
    complex reasoning. By sampling from multiple “thoughts” and making them more thoughtful,
    we aim to improve the output of generative models.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 链式思维和自洽性旨在实现更复杂的推理。通过从多个“思想”中进行采样并使其更具思考性，我们旨在提高生成模型的输出。
- en: These techniques scratch only the surface of what is currently being done to
    enable this complex reasoning. An improvement to these approaches can be found
    in Tree-of-Thought which allows for an in-depth exploration of several ideas.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术仅仅触及了当前为实现这种复杂推理所做工作的表面。思维树对这些方法的改进使得多个想法的深入探索成为可能。
- en: The method works as follows. When faced with a problem that requires multiple
    reasoning steps, it often helps to break it down into pieces. At each step, and
    as illustrated in [Figure 4-19](#fig_18_by_leveraging_a_tree_based_structure_generative_m),
    the generative model is prompted to explore different solutions to the problem
    at hand. It then votes for the best solution and then continues to the next step.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的工作原理如下。当面临需要多次推理步骤的问题时，通常有助于将其拆分成几个部分。在每一步，如[图4-19](#fig_18_by_leveraging_a_tree_based_structure_generative_m)所示，生成模型被提示探索当前问题的不同解决方案。然后它投票选出最佳解决方案，接着继续到下一步。
- en: '![By leveraging a tree based structure  generative models can generate intermediate
    thoughts to be rated. The most promising thoughts are kept and the lowest are
    pruned.](assets/text_generation_with_gpt_models_479875_19.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![通过利用基于树的结构，生成模型可以生成待评估的中间思想。最有前景的思想被保留，最差的被剪除。](assets/text_generation_with_gpt_models_479875_19.png)'
- en: Figure 4-19\. By leveraging a tree-based structure, generative models can generate
    intermediate thoughts to be rated. The most promising thoughts are kept and the
    lowest are pruned.
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-19。通过利用基于树的结构，生成模型可以生成待评估的中间思想。最有前景的思想被保留，最差的被剪除。
- en: This method is tremendously helpful when needing to consider multiple paths,
    like when writing a story or coming up with creative ideas.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要考虑多条路径时，这种方法非常有帮助，例如在编写故事或想出创意时。
- en: A disadvantage of this method is that it requires many calls to the generative
    models which slows the application significantly. Fortunately, there has been
    a successful attempt to convert the Tree-of-Thought framework into a simple prompting
    technique.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个缺点是需要多次调用生成模型，这会显著减慢应用程序的运行速度。幸运的是，已经成功尝试将思维树框架转化为一种简单的提示技术。
- en: 'Instead of calling the generative model multiple times, we ask the model to
    mimic that behavior by emulating a conversation between multiple experts. These
    experts will question each other until they reach a consensus. An example of a
    Tree-of-Thought prompt is:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 与其多次调用生成模型，我们让模型通过模拟多个专家之间的对话来模仿这种行为。这些专家将相互质疑，直到达成共识。一个思维树提示的例子是：
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can use this prompt to explore how an LLM might respond to complex questions:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用此提示来探索大型语言模型（LLM）如何回应复杂问题：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'As a result, it generated the correct answer by leveraging the discussion between
    multiple experts:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，它通过利用多个专家之间的讨论生成了正确答案：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: It is interesting to see such an elaborate conservation between “experts” and
    demonstrates the creativity that comes with prompt engineering.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 看到“专家”之间如此详细的讨论是有趣的，并展示了提示工程带来的创造力。
- en: Output Verification
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输出验证
- en: Systems and applications built with generative models might eventually end up
    in production. When that happens, it is important that we verify and control the
    output of the model to prevent breaking the application and to create a robust
    generative AI application.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成模型构建的系统和应用程序最终可能会投入生产。当发生这种情况时，验证和控制模型的输出以防止破坏应用程序并创建稳健的生成AI应用程序是重要的。
- en: 'Reasons for validating the output might include:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 验证输出的原因可能包括：
- en: '*Structured output*'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*结构化输出*'
- en: By default, most generative models create free-form text without adhering to
    specific structures other than those defined by natural language. Some use cases
    require their output to be structured in certain formats, like JSON.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，大多数生成模型创建自由格式文本，而不遵循自然语言以外的特定结构。某些用例要求它们的输出以特定格式结构化，如JSON。
- en: '*Valid output*'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*有效输出*'
- en: Even if we allow the model to generate structured output, it still has the capability
    to freely generate its content. For instance, when a model is asked to output
    either one of two choices, it should not come up with a third.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们允许模型生成结构化输出，它仍然能够自由生成其内容。例如，当模型被要求输出两个选择之一时，它不应提出第三个选择。
- en: '*Ethics*'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*伦理*'
- en: Some open-source generative models have no guardrails and will generate outputs
    that do not consider safety or ethical considerations. For instance, use cases
    might require the output to be free of profanity, personally identifiable information
    (PII), bias, cultural stereotypes, etc.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开源生成模型没有安全限制，会生成不考虑安全或伦理的输出。例如，某些用例可能要求输出不包含亵渎、个人可识别信息（PII）、偏见、文化刻板印象等。
- en: '*Accuracy*'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*准确性*'
- en: Many use cases require the output to adhere to certain standards or performance.
    The aim is to double-check whether the generated information is factually accurate,
    coherent, or free from hallucination.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 许多用例要求输出遵循特定标准或性能。其目的是仔细检查生成的信息是否在事实准确性、一致性或是否无幻觉方面。
- en: Controlling the output of a generative model, as we explored with parameters
    like `top_p` and `temperature`, is not an easy feat. These models require help
    to generate consistent output conforming to certain guidelines.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 控制生成模型的输出，如我们通过`top_p`和`temperature`等参数探讨的，并不是一件容易的事情。这些模型需要帮助才能生成符合某些指导方针的一致输出。
- en: 'Generally, there are three ways of controlling the output of a generative model:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，有三种方式控制生成模型的输出：
- en: '*Examples*'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例*'
- en: Provide a number of examples of the expected output.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 提供预期输出的多个示例。
- en: '*Grammar*'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '*语法*'
- en: Control the token selection process.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 控制标记选择过程。
- en: '*Fine-tuning*'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*微调*'
- en: Tune a model on data that contains the expected output
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在包含预期输出的数据上调优模型
- en: In this section, we will go through the first two methods. The third, fine-tuning
    a model, is left for Chapter 12 where we will in-depth into fine-tuning methods.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论前两种方法。第三种方法，即微调模型，将留到第12章，我们将在其中深入探讨微调方法。
- en: Providing Examples
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提供示例
- en: A simple and straightforward method to fix the output is to provide the generative
    model with examples of what the output should look like. As we explored before,
    few-shot learning is a helpful technique that guides the output of the generative
    model. This method can be generalized to guide the structure of the output as
    well.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 修复输出的一个简单明了的方法是向生成模型提供输出应有的示例。如前所述，少量示例学习是一种有效的技术，可以指导生成模型的输出。此方法也可以推广以指导输出的结构。
- en: 'For example, let us consider an example where we want the generative model
    to create a character profile for an RPG game. We start by using no examples:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑一个示例，我们希望生成模型为RPG游戏创建角色档案。我们开始时不使用示例：
- en: '[PRE20]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This gives us the following structure which we truncated to prevent overly
    long descriptions:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下结构，我们截断了它以防止过长的描述：
- en: '[PRE21]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Although this is valid JSON, we might not want certain attributes like “strength”
    or “age”. Instead, we can provide the model with a number of examples that indicate
    the expected format:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是有效的JSON，但我们可能不希望某些属性，如“强度”或“年龄”。相反，我们可以向模型提供一些示例，指示预期的格式：
- en: '[PRE22]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This gives us the following which we again truncated to prevent overly long
    descriptions:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下内容，我们再次截断了它以防止过长的描述：
- en: '[PRE23]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The model perfectly followed the example we gave it which allows for more consistent
    behavior. This also demonstrates the importance of leveraging few-shot learning
    to improve the structure of the output and not only its content.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型完美遵循了我们给出的示例，从而实现了更一致的行为。这也展示了利用少量样本学习来改善输出结构而不仅仅是内容的重要性。
- en: An important note here is that it is still up to the model whether it will adhere
    to your suggested format or not. Some models are better than others at following
    instructions.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重要说明是，模型是否遵循你建议的格式仍然取决于模型本身。有些模型在遵循指令方面表现得比其他模型更好。
- en: 'Grammar: Constrained Sampling'
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语法：约束采样
- en: 'Few-shot learning has a big disadvantage: we cannot explicitly prevent certain
    output from being generated. Although we guide the model and give it instructions,
    it might still not follow it entirely.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 少量样本学习有一个重大缺点：我们无法明确防止生成某些输出。尽管我们引导模型并给出指令，但它可能仍然不会完全遵循。
- en: Instead, packages have been rapidly to constrain and validate the output of
    generative models, like Guidance, Guardrails, and LMQL. In part, they leverage
    generative models to validate their own output, as illustrated in [Figure 4-20](#fig_19_use_an_llm_to_check_whether_the_output_correctly_f).
    The generative models retrieve the output as new prompts and attempt to validate
    it based on a number of predefined guardrails.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，许多工具迅速被开发出来以限制和验证生成模型的输出，如Guidance、Guardrails和LMQL。部分上，它们利用生成模型验证自身输出，如[图4-20](#fig_19_use_an_llm_to_check_whether_the_output_correctly_f)所示。生成模型将输出作为新提示检索，并尝试根据一系列预定义的规则进行验证。
- en: '![Use an LLM to check whether the output correctly follows our rules.](assets/text_generation_with_gpt_models_479875_20.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![使用LLM检查输出是否正确遵循我们的规则。](assets/text_generation_with_gpt_models_479875_20.png)'
- en: Figure 4-20\. Use an LLM to check whether the output correctly follows our rules.
  id: totrans-247
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-20\. 使用LLM检查输出是否正确遵循我们的规则。
- en: Similarly, as illustrated in [Figure 4-21](#fig_20_use_an_llm_to_generate_only_the_pieces_of_informat),
    it can also be used to control the formatting of the output by generating parts
    of its format ourselves as we already know how it should be structured.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如[图4-21](#fig_20_use_an_llm_to_generate_only_the_pieces_of_informat)所示，它还可以通过生成我们已知应如何结构化的格式部分来控制输出格式。
- en: '![Use an LLM to generate only the pieces of information we do not know beforehand.
    ](assets/text_generation_with_gpt_models_479875_21.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![使用LLM仅生成我们事先不知道的信息片段。](assets/text_generation_with_gpt_models_479875_21.png)'
- en: Figure 4-21\. Use an LLM to generate only the pieces of information we do not
    know beforehand.
  id: totrans-250
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-21\. 使用LLM仅生成我们事先不知道的信息片段。
- en: This process can be taken one step further and instead of validating the output
    we can already perform validation during the token sampling process. When sampling
    tokens, we can define a number of grammars or rules that the LLM should adhere
    to when choosing its next token. For instance, if we ask the model to either return
    “positive”, “negative” or “neutral” when performing sentiment classification,
    it might still return something else. As illustrated in [Figure 4-22](#fig_21_constrain_the_token_selection_to_only_three_possib),
    by constraining the sampling process, we can have the LLM only output what we
    are interested in.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以更进一步，而不是在输出验证后进行，我们可以在令牌采样过程中进行验证。在采样令牌时，我们可以定义一系列语法或规则，以便LLM在选择下一个令牌时遵循。例如，如果我们要求模型在执行情感分类时返回“正面”、“负面”或“中性”，它仍然可能返回其他内容。如[图4-22](#fig_21_constrain_the_token_selection_to_only_three_possib)所示，通过限制采样过程，我们可以让LLM只输出我们感兴趣的内容。
- en: '![Constrain the token selection to only three possible tokens   positive    neutral   and  negative
    .](assets/text_generation_with_gpt_models_479875_22.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![将令牌选择限制为仅三个可能的令牌：正面、中性和负面。](assets/text_generation_with_gpt_models_479875_22.png)'
- en: 'Figure 4-22\. Constrain the token selection to only three possible tokens:
    “positive”, “neutral”, and “negative”.'
  id: totrans-253
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-22\. 将令牌选择限制为仅三个可能的令牌：“正面”、“中性”和“负面”。
- en: Note that this is still affected by parameters such as `top_p` and `temperature`
    and the illustrated is quite constrained.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这仍然受到`top_p`和`temperature`等参数的影响，所示内容非常受限。
- en: Let us illustrate this phenomenon with llama-cpp-python, which is a library,
    like transformers, that we can use to load in our language model. It is generally
    used to efficiently load and use compressed models (through quantization; see
    Chapter 13).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 llama-cpp-python 来说明这一现象，这是一种库，类似于 transformers，我们可以用它来加载我们的语言模型。它通常用于有效加载和使用压缩模型（通过量化；见第
    13 章）。
- en: 'We start by downloading the quantized version of the model by running the following
    in your terminal:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在终端中运行以下命令来下载模型的量化版本：
- en: '[PRE24]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25] import httpx from llama_cpp.llama import Llama, LlamaGrammar # We load
    the JSON grammar from the official llama.cpp repository grammar = httpx.get(     "https://raw.githubusercontent.com/ggerganov/llama.cpp/master/grammars/json_arr.gbnf"
    ) grammar = LlamaGrammar.from_string(grammar.text) # Load a pre-quantized LLM
    llm = Llama("zephyr-7b-beta.Q4_K_M.gguf") [PRE26] import json # Run the generative
    model and ask it to create a character in JSON format response = llm(     "Create
    a warrior for an RPG in JSON format.",     max_tokens=-1,     grammar=grammar
    ) # Print the output in nicely-formatted JSON print(json.dumps(json.loads(response[''choices''][0][''text'']),
    indent=4)) [PRE27] [     {         "name": "Swordmaster",         "level": 10,
            "health": 250,         "mana": 100,         "strength": 18,         "dexterity":
    16,         "intelligence": 10,         "armor": 75,         "weapon": "Two-Handed
    Sword",         "specialty": "One-handed Swords"     } ] [PRE28]`  `# Summary    In
    this chapter, we explored the basics of using generative models through prompt
    engineering and output verification. We focused on the creativity and potential
    complexity that comes with prompt engineering. We discovered that the components
    of a prompt are key in generating the output that is right for our use case. As
    a result, experimentation is vital when prompt engineering.    In the next chapter,
    we explore advanced techniques for leveraging generative models. These techniques
    go beyond prompt engineering and are meant to enhance the capabilities of these
    models. From giving a model external memory to using external tools, we aim to
    give a generative model superpowers!`**'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE25] 从 llama_cpp.llama 导入 httpx、Llama 和 LlamaGrammar # 我们从官方的 llama.cpp
    存储库加载 JSON 语法 grammar = httpx.get(     "https://raw.githubusercontent.com/ggerganov/llama.cpp/master/grammars/json_arr.gbnf"
    ) grammar = LlamaGrammar.from_string(grammar.text) # 加载一个预量化的 LLM llm = Llama("zephyr-7b-beta.Q4_K_M.gguf")
    [PRE26] 导入 json # 运行生成模型，并要求它以 JSON 格式创建一个角色 response = llm(     "为 RPG 创建一个 JSON
    格式的战士。",     max_tokens=-1,     grammar=grammar ) # 以格式良好的 JSON 打印输出 print(json.dumps(json.loads(response[''choices''][0][''text'']),
    indent=4)) [PRE27] [     {         "name": "剑术大师",         "level": 10,         "health":
    250,         "mana": 100,         "strength": 18,         "dexterity": 16,         "intelligence":
    10,         "armor": 75,         "weapon": "双手剑",         "specialty": "单手剑"     }
    ] [PRE28]`  `# 概要    在这一章中，我们通过提示工程和输出验证探讨了生成模型的基础知识。我们关注了提示工程带来的创造力和潜在复杂性。我们发现提示的组件是生成符合我们用例输出的关键。因此，在进行提示工程时，实验至关重要。    在下一章中，我们将探索利用生成模型的高级技术。这些技术超越了提示工程，旨在增强这些模型的能力。从给模型提供外部记忆到使用外部工具，我们旨在赋予生成模型超级能力！`**'
