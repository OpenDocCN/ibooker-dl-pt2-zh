["```py\n>>> import numpy as np\n\n>>> topic = {}\n>>> tfidf = dict(list(zip('cat dog apple lion NYC love'.split(),\n...     np.random.rand(6))))  # #1\n>>> topic['petness'] = (.3 * tfidf['cat'] +\\\n...                     .3 * tfidf['dog'] +\\\n...                      0 * tfidf['apple'] +\\\n...                      0 * tfidf['lion'] -\\\n...                     .2 * tfidf['NYC'] +\\\n...                     .2 * tfidf['love'])  # #2\n>>> topic['animalness']  = (.1 * tfidf['cat']  +\\\n...                         .1 * tfidf['dog'] -\\\n...                         .1 * tfidf['apple'] +\\\n...                         .5 * tfidf['lion'] +\\\n...                         .1 * tfidf['NYC'] -\\\n...                         .1 * tfidf['love'])\n>>> topic['cityness']    = ( 0 * tfidf['cat']  -\\\n...                         .1 * tfidf['dog'] +\\\n...                         .2 * tfidf['apple'] -\\\n...                         .1 * tfidf['lion'] +\\\n...                         .5 * tfidf['NYC'] +\\\n...                         .1 * tfidf['love'])\n```", "```py\n>>> word_vector = {}\n>>> word_vector['cat']  =  .3*topic['petness'] +\\\n...                        .1*topic['animalness'] +\\\n...                         0*topic['cityness']\n>>> word_vector['dog']  =  .3*topic['petness'] +\\\n...                        .1*topic['animalness'] -\\\n...                        .1*topic['cityness']\n>>> word_vector['apple']=   0*topic['petness'] -\\\n...                        .1*topic['animalness'] +\\\n...                        .2*topic['cityness']\n>>> word_vector['lion'] =   0*topic['petness'] +\\\n...                        .5*topic['animalness'] -\\\n...                        .1*topic['cityness']\n>>> word_vector['NYC']  = -.2*topic['petness'] +\\\n...                        .1*topic['animalness'] +\\\n...                        .5*topic['cityness']\n>>> word_vector['love'] =  .2*topic['petness'] -\\\n...                        .1*topic['animalness'] +\\\n...                        .1*topic['cityness']\n```", "```py\n>>> import pandas as pd\n>>> pd.options.display.width = 120  # #1\n>>> DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/-/raw/master/'\n...             'src/nlpia/data')\n>>> url= DATA_DIR + '/toxic_comment_small.csv'\n>>>\n>>> comments = pd.read_csv(url)\n>>> index = ['comment{}{}'.format(i, '!'*j) for (i,j) in\n...          zip(range(len(comments)), comments.toxic)\n...         ]  # #2\n>>> comments = pd.DataFrame(\n...     comments.values, columns=comments.columns, index=index)\n>>> mask = comments.toxic.astype(bool).values\n>>> comments['toxic'] = comments.toxic.astype(int)\n>>> len(comments)\n5000\n>>> comments.toxic.sum()\n650\n>>> comments.head(6)\n                                                        text  toxic\ncomment0   you have yet to identify where my edits violat...      0\ncomment1   \"\\n as i have already said,wp:rfc or wp:ani. (...      0\ncomment2   your vote on wikiquote simple english when it ...      0\ncomment3   your stalking of my edits i've opened a thread...      0\ncomment4!  straight from the smear site itself. the perso...      1\ncomment5   no, i can't see it either - and i've gone back...      0\n```", "```py\n>>> from sklearn.feature_extraction.text import TfidfVectorizer\n>>> import spacy\n>>> nlp = spacy.load(\"en_core_web_sm\")\n>>>\n>>> def spacy_tokenize(sentence):\n...    return [token.text for token in nlp(sentence.lower())]\n>>>\n>>> tfidf_model = TfidfVectorizer(tokenizer=spacy_tokenize)\n>>> tfidf_docs = tfidf_model.fit_transform(\\\n...     raw_documents=comments.text).toarray()\n>>> tfidf_docs.shape\n(5000, 19169)\n```", "```py\n>>> mask = comments.toxic.astype(bool).values  # #1\n>>> toxic_centroid = tfidf_docs[mask].mean(axis=0)  # #2\n>>> nontoxic_centroid = tfidf_docs[~mask].mean(axis=0)  # #3\n```", "```py\n>>> centroid_axis = toxic_centroid - nontoxic_centroid\n>>> toxicity_score = tfidf_docs.dot(centroid_axis)  # #1\n>>> toxicity_score.round(3)\narray([-0.008, -0.022, -0.014, ..., -0.025, -0.001, -0.022])\n```", "```py\n>>> from sklearn.preprocessing import MinMaxScaler\n>>> comments['manual_score'] = MinMaxScaler().fit_transform(\\\n...     toxicity_score.reshape(-1,1))\n>>> comments['manual_predict'] = (comments.manual_score > .5).astype(int)\n>>> comments['toxic manual_predict manual_score'.split()].round(2).head(6)\n           toxic  manual_predict  manual_score\ncomment0       0               0          0.41\ncomment1       0               0          0.27\ncomment2       0               0          0.35\ncomment3       0               0          0.47\ncomment4!      1               0          0.48\ncomment5       0               0          0.31\n```", "```py\n>>> (1 - (comments.toxic - comments.manual_predict).abs().sum()\n...     / len(comments))\n0.895...\n```", "```py\n>>> from sklearn import discriminant_analysis\n>>> lda_tfidf = discriminant_analysis.LinearDiscriminantAnalysis\n>>> lda_tfidf = lda_tfidf.fit(tfidf_docs, comments['toxic'])\n>>> comments['tfidf_predict'] = lda_tfidf.predict(tfidf_docs)\n>>> float(lda_tfidf.score(tfidf_docs, comments['toxic']))\n0.999...\n```", "```py\n>>> from sklearn.model_selection import train_test_split\n>>> X_train, X_test, y_train, y_test = train_test_split(tfidf_docs,\\\n...     comments.toxic.values, test_size=0.5, random_state=271828)\n>>> lda_tfidf = LDA(n_components=1)\n>>> lda = lda_tfidf.fit(X_train, y_train)  # #1\n>>> round(float(lda.score(X_train, y_train)), 3)\n0.999\n>>> round(float(lda.score(X_test, y_test)), 3)\n0.554\n```", "```py\n>>> from sklearn.metrics import confusion_matrix\n>>> confusion_matrix(y_test, lda.predict(X_test))\narray([[1261,  913],\n       [ 201,  125]], dtype=int64)\n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> from sklearn.metrics import plot_confusion_matrix\n>>> plot_confusion_matrix(lda,X_test, y_test, cmap=\"Greys\",\n...                display_labels=['non-toxic', 'toxic'], colorbar=False)\n>>> plt.show()\n```", "```py\n>>> import pandas as pd\n>>> from sklearn.decomposition import PCA\n>>> import seaborn\n>>> from matplotlib import pyplot as plt\n\n>>> DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/'\n...             '-/raw/master/src/nlpia/data')\n\n>>> df = pd.read_csv(DATA_DIR + '/pointcloud.csv.gz', index_col=0)\n>>> pca = PCA(n_components=2)  # #1\n>>> df2d = pd.DataFrame(pca.fit_transform(df), columns=list('xy'))\n>>> df2d.plot(kind='scatter', x='x', y='y')\n>>> plt.show()\n```", "```py\n>>> tfidf_docs.shape\n(5000, 19169)\n```", "```py\n>>> from sklearn.decomposition import TruncatedSVD\n>>>\n>>> svd = TruncatedSVD(n_components=16, n_iter=100)  # #1\n>>> columns = ['topic{}'.format(i) for i in range(svd.n_components)]\n>>> svd_topic_vectors = svd.fit_transform(tfidf_docs)  # #2\n>>> svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns,\\\n...     index=index)\n>>> svd_topic_vectors.round(3).head(6)\n           topic0  topic1  topic2  ...  topic13  topic14  topic15\ncomment0    0.121  -0.055   0.036  ...   -0.038    0.089    0.011\ncomment1    0.215   0.141  -0.006  ...    0.079   -0.016   -0.070\ncomment2    0.342  -0.200   0.044  ...   -0.138    0.023    0.069\ncomment3    0.130  -0.074   0.034  ...   -0.060    0.014    0.073\ncomment4!   0.166  -0.081   0.040  ...   -0.008    0.063   -0.020\ncomment5    0.256  -0.122  -0.055  ...    0.093   -0.083   -0.074\n```", "```py\n>>> list(tfidf_model.vocabulary_.items())[:5]  # #1\n[('you', 18890),\n ('have', 8093),\n ('yet', 18868),\n ('to', 17083),\n ('identify', 8721)]\n>>> column_nums, terms = zip(*sorted(zip(tfidf.vocabulary_.values(),\n...     tfidf.vocabulary_.keys())))  # #2\n>>> terms[:5]\n('\\n', '\\n ', '\\n \\n', '\\n \\n ', '\\n  ')\n```", "```py\n>>> topic_term_matrix = pd.DataFrame(\n...     svd.components_, columns=terms,\n...     index=['topic{}'.format(i) for i in range(16)])\n>>> pd.options.display.max_columns = 8\n>>> topic_term_matrix.sample(5, axis='columns',\n...     random_state=271828).head(4)  # #1\n...\n        littered  unblock.(tâ€¢c  orchestra  flanking  civilised\ntopic0  0.000268      0.000143   0.000630  0.000061   0.000119\ntopic1  0.000297     -0.000211  -0.000830 -0.000088  -0.000168\ntopic2 -0.000367      0.000157  -0.001457 -0.000150  -0.000133\ntopic3  0.000147     -0.000458   0.000804  0.000127   0.000181\n```", "```py\n>>> pd.options.display.max_columns = 8\n>>> toxic_terms = topic_term_matrix[\n...     'pathetic crazy stupid idiot lazy hate die kill'.split()\n...     ].round(3) * 100  # #1\n...\n>>> toxic_terms\n         pathetic  crazy  stupid  idiot  lazy  hate  die  kill\ntopic0        0.3    0.1     0.7    0.6   0.1   0.4  0.2   0.2\ntopic1       -0.2    0.0    -0.1   -0.3  -0.1  -0.4 -0.1   0.1\ntopic2        0.7    0.1     1.1    1.7  -0.0   0.9  0.6   0.8\ntopic3       -0.3   -0.0    -0.0    0.0   0.1  -0.0  0.0   0.2\ntopic4        0.7    0.2     1.2    1.4   0.3   1.7  0.6   0.0\ntopic5       -0.4   -0.1    -0.3   -1.3  -0.1   0.5 -0.2  -0.2\ntopic6        0.0    0.1     0.8    1.7  -0.1   0.2  0.8  -0.1\n...\n>>> toxic_terms.T.sum()\ntopic0     2.4\ntopic1    -1.2\ntopic2     5.0\ntopic3    -0.2\ntopic4     5.9\ntopic5    -1.8\ntopic6     3.4\ntopic7    -0.7\ntopic8     1.0\ntopic9    -0.1\ntopic10   -6.6\n...\n```", "```py\n>>> tfidf_docs = tfidf_docs - tfidf_docs.mean()\n```", "```py\n>>> X_train_16d, X_test_16d, y_train_16d, y_test_16d = train_test_split(\n...     svd_topic_vectors, comments.toxic.values, test_size=0.5,\n...     random_state=271828)\n>>> lda_lsa = LinearDiscriminantAnalysis(n_components=1)\n>>> lda_lsa = lda_lsa.fit(X_train_16d, y_train_16d)\n>>> round(float(lda_lsa.score(X_train_16d, y_train_16d)), 3)\n0.881\n>>> round(float(lda_lsa.score(X_test_16d, y_test_16d)), 3)\n0.88\n```", "```py\n>>> from sklearn.metrics import f1_score\n>>> f1_score(y_test_16d, lda_lsa.predict(X_test_16d).round(3)\n0.342\n```", "```py\n>>> hparam_table = pd.DataFrame()\n>>> tfidf_performance = {'classifier': 'LDA',\n...                      'features': 'tf-idf (spacy tokenizer)',\n...                      'train_accuracy': 0.99 ,\n...                      'test_accuracy': 0.554,\n...                      'test_precision': 0.383 ,\n...                      'test_recall': 0.12,\n...                      'test_f1': 0.183}\n>>> hparam_table = hparam_table.append(\n...     tfidf_performance, ignore_index=True)  # #1\n```", "```py\n>>> def hparam_rec(model, X_train, y_train, X_test, y_test,\n...                model_name, features):\n...     return {\n...         'classifier': model_name,\n...         'features': features,\n...         'train_accuracy': float(model.score(X_train, y_train)),\n...         'test_accuracy': float(model.score(X_test, y_test)),\n...         'test_precision':\n...             precision_score(y_test, model.predict(X_test)),\n...         'test_recall':\n...             recall_score(y_test, model.predict(X_test)),\n...         'test_f1': f1_score(y_test, model.predict(X_test))\n...         }\n>>> lsa_performance = hparam_rec(lda_lsa, X_train_16d, y_train_16d,\n...        X_test_16d,y_test_16d, 'LDA', 'LSA (16 components)'))\n>>> hparam_table = hparam_table.append(lsa_performance)\n>>> hparam_table.T  # #1\n                                       0          1\nclassifier                           LDA        LDA\nfeatures        tf-idf (spacy tokenizer)  LSA (16d)\ntrain_accuracy                      0.99     0.8808\ntest_accuracy                      0.554       0.88\ntest_precision                     0.383        0.6\ntest_recall                         0.12   0.239264\ntest_f1                            0.183   0.342105\n```", "```py\n>>> def evaluate_model(X,y, classifier, classifier_name, features):\n...     X_train, X_test, y_train, y_test = train_test_split(\n...         X, y, test_size=0.5, random_state=271828)\n...     classifier = classifier.fit(X_train, y_train)\n...     return hparam_rec(classifier, X_train, y_train, X_test,y_test,\n...                       classifier_name, features)\n```", "```py\n>>> total_corpus_len = 0\n>>> for document_text in comments.text:\n...     total_corpus_len += len(spacy_tokenize(document_text))\n>>> mean_document_len = total_corpus_len / len(sms)\n>>> round(mean_document_len, 2)\n21.35\n```", "```py\n>>> sum([len(spacy_tokenize(t)) for t in comments.text]\n...     ) * 1\\. / len(comments.text)\n21.35\n```", "```py\n>>> from sklearn.feature_extraction.text import CountVectorizer\n>>>\n>>> counter = CountVectorizer(tokenizer=spacy_tokenize)\n>>> bow_docs = pd.DataFrame(counter.fit_transform(\nraw_documents=comments.text)\\\n...     .toarray(), index=index)\n>>> column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n...     counter.vocabulary_.keys())))\n>>> bow_docs.columns = terms\n```", "```py\n>>> comments.loc['comment0'].text\n'you have yet to identify where my edits violated policy.\n 4 july 2005 02:58 (utc)'\n>>> bow_docs.loc['comment0'][bow_docs.loc['comment0'] > 0].head()\n         1\n(        1\n)        1\n.        1\n02:58    1\nName: comment0, dtype: int64\n```", "```py\n>>> from sklearn.decomposition import LatentDirichletAllocation as LDiA\n\n>>> ldia = LDiA(n_components=16, learning_method='batch')\n>>> ldia = ldia.fit(bow_docs)  # #1\n>>> ldia.components_.shape\n(16, 19169)\n```", "```py\n>>> pd.set_option('display.width', 75)\n>>> term_topic_matrix = pd.DataFrame(ldia.components_, index=terms,\\\n...     columns=columns)  # #1\n>>> term_topic_matrix.round(2).head(3)\n                          topic0  topic1  ...  topic14  topic15\na                         21.853   0.063  ...    0.063  922.515\naaaaaaaaaahhhhhhhhhhhhhh   0.063   0.063  ...    0.063    0.063\naalst                      0.063   0.063  ...    0.063    0.063\naap                        0.063   0.063  ...    2.062    0.062\n```", "```py\n>>> toxic_terms= components.loc['pathetic crazy stupid lazy idiot hate die kill'.split()].round(2)\n>>> toxic_terms\n          topic0  topic1  topic2  ...  topic13  topic14  topic15\npathetic    1.06    0.06   32.35  ...     0.06     0.06     9.47\ncrazy       0.06    0.06    3.82  ...     1.17     0.06     0.06\nstupid      0.98    0.06    4.58  ...     8.29     0.06    35.80\nlazy        0.06    0.06    1.34  ...     0.06     0.06     3.97\nidiot       0.06    0.06    6.31  ...     0.06     1.11     9.91\nhate        0.06    0.06    0.06  ...     0.06   480.06     0.06\ndie         0.06    0.06   26.17  ...     0.06     0.06     0.06\nkill        0.06    4.06    0.06  ...     0.06     0.06     0.06\n```", "```py\n>>> non_trivial_terms = [term for term in components.index\n                            if term.isalpha() and len(term)>3]\ncomponents.topic14.loc[non_trivial_terms].sort_values(ascending=False)[:10]\nhate         480.062500\nkilled        14.032799\nexplosion      7.062500\nwitch          7.033359\njune           6.676174\nwicked         5.062500\ndead           3.920518\nyears          3.596520\nwake           3.062500\narrived        3.062500\n```", "```py\n>>> ldia16_topic_vectors = ldia.transform(bow_docs)\n>>> ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors,\\\n...     index=index, columns=columns)\n>>> ldia16_topic_vectors.round(2).head()\n           topic0  topic1  topic2  ...  topic13  topic14  topic15\ncomment0      0.0     0.0    0.00  ...     0.00      0.0      0.0\ncomment1      0.0     0.0    0.28  ...     0.00      0.0      0.0\ncomment2      0.0     0.0    0.00  ...     0.00      0.0      0.0\ncomment3      0.0     0.0    0.00  ...     0.95      0.0      0.0\ncomment4!     0.0     0.0    0.07  ...     0.00      0.0      0.0\n```", "```py\n>>> model_ldia16 = LinearDiscriminantAnalysis()\n>>> ldia16_performance=evaluate_model(ldia16_topic_vectors,\n       comments.toxic,model_ldia16, 'LDA', 'LDIA (16 components)')\n>>> hparam_table = hparam_table.append(ldia16_performance,\n...    ignore_index = True)\n>>> hparam_table.T\n                                       0          1          2\nclassifier                           LDA        LDA        LDA\nfeatures        tf-idf (spacy tokenizer)  LSA (16d) LDIA (16d)\ntrain_accuracy                      0.99     0.8808     0.8688\ntest_accuracy                      0.554       0.88     0.8616\ntest_precision                     0.383        0.6   0.388889\ntest_recall                         0.12   0.239264   0.107362\ntest_f1                            0.183   0.342105   0.168269\n```", "```py\n>>> ldia32 = LDiA(n_components=32, learning_method='batch')\n>>> ldia32 = ldia32.fit(bow_docs)\n>>> model_ldia32 = LinearDiscriminantAnalysis()\n>>> ldia32_performance =evaluate_model(ldia32_topic_vectors,\n...          comments.toxic, model_ldia32, 'LDA', 'LDIA (32d)')\n>>> hparam_table = hparam_table.append(ldia32_performance,\n...           ignore_index = True)\n>>> hparam_table.T\n                                       0          1          2           3\nclassifier                           LDA        LDA        LDA         LDA\nfeatures        tf-idf (spacy tokenizer)  LSA (16d) LDIA (16d)  LDIA (32d)\ntrain_accuracy                      0.99     0.8808     0.8688      0.8776\ntest_accuracy                      0.554       0.88     0.8616      0.8796\ntest_precision                     0.383        0.6   0.388889    0.619048\ntest_recall                         0.12   0.239264   0.107362    0.199387\ntest_f1                            0.183   0.342105   0.168269    0.301624\n```", "```py\n>>> import sklearn\n>>> sklearn.__file__\n'/Users/hobs/anaconda3/envs/conda_env_nlpia/lib/python3.6/site-packages/skl\nearn/__init__.py'\n>>> from sklearn.discriminant_analysis\\\n...     import LinearDiscriminantAnalysis as LDA\n>>> LDA??\nInit signature: LDA(solver='svd', shrinkage=None, priors=None, n_components\n=None, store_covariance=False, tol=0.0001)\nSource:\nclass LinearDiscriminantAnalysis(BaseEstimator, LinearClassifierMixin,\n                                 TransformerMixin):\n    \"\"\"Linear Discriminant Analysis\n\n    A classifier with a linear decision boundary, generated by fitting\n    class conditional densities to the data and using Bayes' rule.\n\n    The model fits a Gaussian density to each class, assuming that all\n    classes share the same covariance matrix.\"\"\"\n...\n```", "```py\n'cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan', 'braycurtis',\n'canberra', 'chebyshev', 'correlation', 'dice', 'hamming', 'jaccard',\n'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto',\n'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n'yule'\n```", "```py\n>>> similarity = 1\\. / (1\\. + distance)\n>>> distance = (1\\. / similarity) - 1.\n```", "```py\n>>> similarity = 1\\. - distance\n>>> distance = 1\\. - similarity\n```", "```py\n>>> import math\n>>> angular_distance = math.acos(cosine_similarity) / math.pi\n>>> distance = 1\\. / similarity - 1.\n>>> similarity = 1\\. - distance\n```", "```py\n>>> REPO_URL = 'https://gitlab.com/tangibleai/qary/-/raw/master'\n>>> FAQ_DIR = 'src/qary/data/faq'\n>>> FAQ_FILENAME = 'short-faqs.csv'\n>>> DS_FAQ_URL = '/'.join([REPO_URL, FAQ_DIR, FAQ_FILENAME])\n\n>>> df = pd.read_csv(DS_FAQ_URL)\n```", "```py\n>>> vectorizer = TfidfVectorizer()\n>>> vectorizer.fit(df['question'])\n>>> tfidfvectors = vectorizer.transform(df['question'])\n>>> svd = TruncatedSVD(n_components=16, n_iterations=100)\n>>> tfidfvectors_16d = svd.fit_transform(tfidfvectors)\n>>>\n>>> def bot_reply(question):\n...       question_tfidf = vectorizer.transform([question]).todense()\n...       question_16d = svd.transform(question_tfidf)\n...       idx = question_16d.dot(tfidfvectors_16d.T).argmax()\n...       print(\n...            f\"Your question:\\n  {question}\\n\\n\"\n...            f\"Most similar FAQ question:\\n  {df['question'][idx]}\\n\\n\"\n...            f\"Answer to that FAQ question:\\n  {df['answer'][idx]}\\n\\n\"\n...           )\n```", "```py\n>>> bot_reply(\"What's overfitting a model?\")\nYour question:\n  What's overfitting a model?\nMost similar FAQ question:\n  What is overfitting?\nAnswer to that FAQ question:\n  When your test set accuracy is significantly lower than your training\n   set accuracy.\n```", "```py\n>>> bot_reply(\"How do I decrease overfitting for Logistic Regression?\")\nYour question:\n  How do I decrease overfitting for Logistic Regression?\nMost similar FAQ question:\n  How to reduce overfitting and improve test set accuracy for a\n   LogisticRegression model?\nAnswer to that FAQ question:\n  Decrease the C value, this increases the regularization strength.\n```"]