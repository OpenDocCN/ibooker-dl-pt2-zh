["```py\ndef forrester_1d(x):                                              ❶\n    y = -((x + 1) ** 2) * torch.sin(2 * x + 2) / 5 + 1            ❶\n    return y.squeeze(-1)                                          ❶\n\nbound = 5                                                         ❷\n\nxs = torch.linspace(-bound, bound, bound * 100 + 1).unsqueeze(1)  ❷\nys = forrester_1d(xs)                                             ❷\n```", "```py\nclass GPModel(gpytorch.models.ExactGP,\n  botorch.models.gpytorch.GPyTorchModel):  ❶\n    num_outputs = 1                        ❶\n\n    def __init__(self, train_x, train_y, likelihood):\n        super().__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ConstantMean()\n        self.covar_module = gpytorch.kernels.ScaleKernel(\n            gpytorch.kernels.RBFKernel()\n        )\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n```", "```py\ndef fit_gp_model(train_x, train_y, num_train_iters=500):\n    noise = 1e-4                                     ❶\n\n    likelihood = gpytorch.likelihoods\n    ➥.GaussianLikelihood()                          ❷\n    model = GPModel(train_x, train_y, likelihood)    ❷\n    model.likelihood.noise = noise                   ❷\n\n    optimizer = torch.optim.Adam(model.parameters(),\n    ➥lr=0.01)                                       ❸\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood\n    ➥(likelihood, model)                            ❸\n\n    model.train()                                    ❸\n    likelihood.train()                               ❸\n\n    for i in tqdm(range(num_train_iters)):           ❸\n        optimizer.zero_grad()                        ❸\n\n        output = model(train_x)                      ❸\n        loss = -mll(output, train_y)                 ❸\n\n        loss.backward()                              ❸\n        optimizer.step()                             ❸\n\n    model.eval()                                     ❸\n    likelihood.eval()                                ❸\n\n    return model, likelihood\n```", "```py\ndef visualize_gp_belief_and_policy(\n    model, likelihood, policy=None, next_x=None\n):\n    with torch.no_grad():\n        predictive_distribution = likelihood(model(xs))  ❶\n        predictive_mean = predictive_distribution.mean   ❶\n        predictive_upper, predictive_lower =             ❶\n          ➥predictive_distribution.confidence_region()  ❶\n\n        if policy is not None:                           ❷\n            acquisition_score = policy(xs.unsqueeze(1))  ❷\n\n    ...                                                  ❸\n```", "```py\n    if policy is None:\n        plt.figure(figsize=(8, 3))\n\n        plt.plot(xs, ys, label=\"objective\", c=\"r\")         ❶\n        plt.scatter(train_x, train_y, marker=\"x\", c=\"k\",\n            label=\"observations\")                          ❷\n\n        plt.plot(xs, predictive_mean, label=\"mean\")        ❸\n        plt.fill_between(                                  ❸\n            xs.flatten(),                                  ❸\n            predictive_upper,                              ❸\n            predictive_lower,                              ❸\n            alpha=0.3,                                     ❸\n            label=\"95% CI\",                                ❸\n        )                                                  ❸\n\n        plt.legend()\n        plt.show()\n```", "```py\n    else:\n        fig, ax = plt.subplots(\n            2,\n            1,\n            figsize=(8, 6),\n            sharex=True,\n            gridspec_kw={\"height_ratios\": [2, 1]}\n        )\n\n        ...                                                    ❶\n\n        if next_x is not None:                                 ❷\n            ax[0].axvline(next_x, linestyle=\"dotted\", c=\"k\")   ❷\n\n        ax[1].plot(xs, acquisition_score, c=\"g\")               ❸\n        ax[1].fill_between(                                    ❸\n          xs.flatten(),                                        ❸\n          acquisition_score,                                   ❸\n          0,                                                   ❸\n          color=\"g\",                                           ❸\n          alpha=0.5                                            ❸\n        )                                                      ❸\n\n        if next_x is not None:                                 ❷\n            ax[1].axvline(next_x, linestyle=\"dotted\", c=\"k\")   ❷\n\n        ax[1].set_ylabel(\"acquisition score\")\n\n        plt.show()\n```", "```py\nnext_x, acq_val = botorch.optim.optimize_acqf(\n    policy,\n    bounds=torch.tensor([[-bound * 1.0], [bound * 1.0]]),\n    q=1,\n    num_restarts=20,\n    raw_samples=50,\n)\n```", "```py\nnum_queries = 10                                         ❶\n\nfor i in range(num_queries):\n    print(\"iteration\", i)\n    print(\"incumbent\", train_x[train_y.argmax()], train_y.max())\n\n    model, likelihood = fit_gp_model(train_x, train_y)   ❷\n\n    policy = ...                                         ❸\n\n    next_x, acq_val = botorch.optim.optimize_acqf(       ❹\n        policy,                                          ❹\n        bounds=torch.tensor([[-bound * 1.0],             ❹\n        ➥[bound * 1.0]]),                               ❹\n        q=1,                                             ❹\n        num_restarts=20,                                 ❹\n        raw_samples=50,                                  ❹\n    )                                                    ❹\n\n    visualize_gp_belief_and_policy(model, likelihood, policy,\n        next_x=next_x)                                   ❺\n\n    next_y = forrester_1d(next_x)                        ❻\n\n    train_x = torch.cat([train_x, next_x])               ❻\n    train_y = torch.cat([train_y, next_y])               ❻\n```", "```py\ntrain_x = torch.tensor([\n    [1.],\n    [2.]\n])\ntrain_y = forrester_1d(train_x)\n\nmodel, likelihood = fit_gp_model(train_x, train_y)\n\nprint(torch.hstack([train_x, train_y.unsqueeze(1)]))\n```", "```py\ntensor([[1.0000, 1.6054],\n        [2.0000, 1.5029]])\n```", "```py\nwith torch.no_grad():\n    predictive_distribution = likelihood(model(torch.tensor([[0.]])))\n    predictive_mean = predictive_distribution.mean     ❶\n    predictive_sd = predictive_distribution.stddev     ❷\n```", "```py\nnormal = torch.distributions.Normal(predictive_mean, predictive_sd)\n```", "```py\n>>> 1 - normal.cdf(train_y.max())\n\ntensor([0.8305])\n```", "```py\npolicy = botorch.acquisition.analytic.ProbabilityOfImprovement( ❶\n    model, best_f=train_y.max()                                 ❶\n)                                                               ❶\n\nwith torch.no_grad():                                           ❷\n    scores = policy(xs.unsqueeze(1))                            ❷\n```", "```py\nnext_x, acq_val = botorch.optim.optimize.optimize_acqf(\n    policy,\n    bounds=torch.tensor([[-bound], [bound]], dtype=torch.float),\n    q=1,\n    num_restarts=10,\n    raw_samples=20,\n)\n```", "```py\n>>> next_x, acq_val\n\n(tensor([[0.5985]]), tensor(0.9129))\n```", "```py\nnum_queries = 10\n\nfor i in range(num_queries):\n    print(\"iteration\", i)\n    print(\"incumbent\", train_x[train_y.argmax()], train_y.max())\n\n    model, likelihood = fit_gp_model(train_x, train_y)\n\n    policy = botorch.acquisition.analytic.ProbabilityOfImprovement( ❶\n        model, best_f=train_y.max()                                 ❶\n    )                                                               ❶\n\n    next_x, acq_val = botorch.optim.optimize_acqf(\n    ...                                                             ❷\n```", "```py\nRuntimeWarning: Optimization failed in\n`gen_candidates_scipy` with the following warning(s):\n[OptimizationWarning('Optimization failed within `scipy.optimize.minimize`\nwith status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\nTrying again with a new set of initial conditions.\n  warnings.warn(first_warn_msg, RuntimeWarning)\n```", "```py\nwith warnings.catch_warnings():\n    warnings.filterwarnings('ignore', category=RuntimeWarning)\n    next_x, acq_val = botorch.optim.optimize_acqf(...)\n```", "```py\npolicy = botorch.acquisition.analytic.ExpectedImprovement(\n    model, best_f=train_y.max()\n)\n```"]