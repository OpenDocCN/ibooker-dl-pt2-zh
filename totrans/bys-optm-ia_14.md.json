["```py\ndef objective1(x):                                     ❶\n    return -((x + 1) ** 2) * torch.sin(2 * x + 2)\n    ➥/ 5 + 1 + x / 20                                 ❶\n\ndef objective2(x):                                     ❷\n    return (0.1 * objective1(x) + objective1(x - 4))\n    ➥/ 3 - x / 3 + 0.5                                ❷\n\ndef joint_objective(x):                                ❸\n    y1 = objective1(x)                                 ❸\n    y2 = objective2(x)                                 ❸\n    return torch.vstack([y1.flatten(), y2.flatten()])  ❸\n    ➥.transpose(-1, -2)                               ❸\n\nlb = -5                                                ❹\nub = 5                                                 ❹\nbounds = torch.tensor([[lb], [ub]], dtype=torch.float) ❹\n```", "```py\nfrom botorch.utils.multi_objective\n➥.box_decompositions.dominated import                ❶\n➥DominatedPartitioning                               ❶\n\ndominated_part = DominatedPartitioning\n➥(ref_point, train_y)                                ❷\nvolume = dominated_part.compute_hypervolume().item()  ❷\n```", "```py\nmodel1, likelihood1 = fit_gp_model(train_x, train_y[:, 0])\nmodel2, likelihood2 = fit_gp_model(train_x, train_y[:, 1])\n```", "```py\nfrom botorch.acquisition.multi_objective\n➥.analytic import                                    ❶\n➥ExpectedHypervolumeImprovement                      ❶\nfrom botorch.utils.multi_objective.box_decompositions\n➥.non_dominated import                               ❶\n➥FastNondominatedPartitioning                        ❶\nfrom botorch.models.model_list_gp_regression import ModelListGP\n\npolicy = ExpectedHypervolumeImprovement(\n    model=ModelListGP(model1, model2),                ❷\n    ref_point=ref_point,                              ❸\n    partitioning=FastNondominatedPartitioning\n    ➥(ref_point, train_y)                            ❹\n)\n```", "```py\nnext_x, acq_val = optimize_acqf(\n    policy,\n    bounds=bounds,\n    q=1,\n    num_restarts=20,\n    raw_samples=50\n)\n```", "```py\nfor i in range(num_queries):\n    if i % 2 == 0:                        ❶\n        model = model1                    ❶\n        best_f = train_y[:, 0].max()      ❶\n    else:                                 ❷\n        model = model2                    ❷\n        best_f = train_y[:, 1].max()      ❷\n\n    policy = ExpectedImprovement(model=model,\n    ➥best_f=best_f)                      ❸\n```", "```py\nhypervolumes = torch.zeros((num_repeats, num_queries))   ❶\n\nfor trial in range(num_repeats):\n  torch.manual_seed(trial)                               ❷\n  train_x = bounds[0] + (bounds[1] - bounds[0]) * torch  ❷\n  ➥.rand(1, 1)                                          ❷\n  train_y = joint_objective(train_x)                     ❷\n  for i in range(num_queries):\n    dominated_part = DominatedPartitioning(ref_point,\n    ➥train_y)                                           ❸\n    hypervolumes[trial, i] = dominated_part\n    ➥.compute_hypervolume().item()                      ❸\n\n    ...                                                  ❹\n```"]