- en: 8 Understanding Stuff Better with Generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using GPT to replace large data analytics operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using GPT to replace sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since GPT burst into all of our lives, most of our interactions with AI - and
    most of the book until this point - have focused on generating content of one
    sort or another. After all, "generate" *is* in the name. But not everything is
    about *creating* new things. There’s also *understanding* old things better.
  prefs: []
  type: TYPE_NORMAL
- en: It is true that all the way back in chapter 5 we did use the `GPTVectorStoreIndex`
    Python library to better understand some of our own data. But here’s where we
    take that a bit further and deeper. We’ll do that by using AI to help us find
    patterns and key details within large datasets (data analytics) and measuring
    population-scale public opinion using thousands of social media posts (sentiment
    analysis).
  prefs: []
  type: TYPE_NORMAL
- en: Until now, such tools and insights were normally available only to data professionals.
    Here we’ll see how they can now be accessed by just about anyone.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Using GPT to replace analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Absorbing and then summarizing very large quantities of content in just a few
    seconds truly is a big deal. Just last night I received a link to the recording
    of an important 90 minute business video conference that I’d missed a few hours
    before. The reason I’d missed the live version was because I had no time (I was,
    if you must know, rushing to write this book before the universe pops out of existence…​or
    at least before they release GPT-58). Well, a half a dozen hours later I still
    had no time for the video. Inexplicably, the book was still not finished.
  prefs: []
  type: TYPE_NORMAL
- en: 'So here’s how I resolved the conflict the GPT way:'
  prefs: []
  type: TYPE_NORMAL
- en: I used OpenAI Whisper (already seen in chapter 7) to generate a transcript based
    on the audio from the recording
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I exported the transcript to a PDF file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I uploaded the PDF to ChatPDF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I prompted ChatPDF for summaries connected to the specific topics that interested
    me
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Total time to "download" the key moments from the 90 minute call: 10 minutes.
    That’s 10 minutes to convert a dataset made up of around 15,000 spoken words to
    a machine-readable format, and to then digest, analyse, and summarize it.'
  prefs: []
  type: TYPE_NORMAL
- en: But all that’s old news by now. The *next-level* level will solve the problem
    of business analytics. Ok. So what *is* the "problem with business analytics"?
    It’s the hard work of building sophisticated code that parses large datasets`
    to make them consistently machine readable (also known as "data wrangling") and
    then applies complex algorithms to tease out useful insights. The figure below
    broadly outlines the process.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 Using data analytics to derive insights from raw data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 8 1](images/gai-8-1.png)'
  prefs: []
  type: TYPE_IMG
- en: A lot of the code that fits that description is incredibly complicated, not
    to mention clever. Inspiring clever data engineers to write that clever code can,
    of course, cost organizations many, many fortunes. The "problem" then, is the
    cost. So solving that problem would involve laying off the quarter-million-dollar-a-year
    engineers and replacing them with a few hundred dollars worth of large language
    model (LLM) API charges. Here’s how I plan to illustrate that.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll need a busy spreadsheet to work with, right? The best place I know for
    good data is the Kaggle website. Kaggle is an online platform for hosting datasets
    (and data science competitions). It’s become in important resource for data scientists,
    machine learning practitioners, and researchers, allowing them to showcase their
    skills, learn from others, and collaborate on projects. The platform offers a
    wide range of public and private datasets, as well as tools and features to support
    data exploration and modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '[The "Investing Program Type Prediction" dataset associated with this code](snassimr.html)
    should work perfectly. From what I can tell, this was data aggregated by a bank
    somewhere in the world that represents its customers'' behavior. Everything has
    been anonymized, of course, so there’s no way for us to know which bank we’re
    talking about, who the customers were, or even where in the world all this was
    happening. In fact, I’m not even 100% sure what each column of data represents.
    What *is* clear is that each customer’s age and neighborhood are there. Although
    the locations have been anonymized as `C1`, `C2`, `C3` etc. Some of the remaining
    columns clearly contain financial information.'
  prefs: []
  type: TYPE_NORMAL
- en: Based on those assumptions, my ultimate goal is to search for statistically
    valid relationships between columns. For instance, are there specific demographic
    features (income, neighborhood, age) that predict a greater likelihood of a customer
    purchasing additional banking products? For this specific example I’ll see if
    I can identify the geographic regions within the data whose average household
    wealth is the highest.
  prefs: []
  type: TYPE_NORMAL
- en: 'For normal uses such vaguely described data would be worthless. But since we’re
    just looking to demonstrate the process it’ll do just fine. I’ll *make up* column
    headers that more or less fit the shape of their data. Here’s how I named them:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer age
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geographic location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Branch visits per year
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total household assets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total household debt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total investments with bank
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The column names need to be very descriptive because those will be the only
    clues I’ll give GPT to help it understand the data. I did have to add my own customer
    IDs to that first column (they didn’t originally exist). The fastest way I could
    think of to do that was to insert the `=(RAND())` formula into the top data cell
    in that column (with the file loaded into spreadsheet software like Excel, Google
    Sheets, or LibreOffice Calc) and then apply the formula to the rest of the rows
    of data. When that’s done, all the 1,000 data rows will have unique IDs, albeit
    IDs between 0 and 1 with many decimal places.
  prefs: []
  type: TYPE_NORMAL
- en: 'With my data prepared, I’ll use our old friend LlamaIndex (first seen back
    in chapter 5) to get to work analysing the numbers. As before, the code I’m going
    to execute will:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the necessary functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add my OpenAI API key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read the data file that’s in the directory called `data`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build the nodes from which we’ll populate our index
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, I’ll send my prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here it is again in a format that’s easier on the eyes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Based on the data, which 5 geographic regions had the highest household net
    wealth?*'
  prefs: []
  type: TYPE_NORMAL
- en: I asked this question primarily to confirm that GPT understood the data. It’s
    always good to test your model just to see if the responses you’re getting seem
    to resonably reflect what you already know about the data. To answer properly,
    GPT would need to figure out what each of the column headers means and the relationships
    *between* columns. In other words, it would need to know how to calculate net
    worth for each row (account ID) from the values in the `Total household assets`,
    `Total household debt`, and `Total investments with bank` columns. It would then
    need to aggregate all the net worth numbers that it generated by `Geographic location`,
    calculate averages for each location and, finally, compare all the averages and
    rank them.
  prefs: []
  type: TYPE_NORMAL
- en: The result? I *think* GPT nailed it. After a minute or two of deep and profound
    thought (and around $0.25 in API charges), I was shown five location codes (G0,
    G90, G96, G97, G84, in case you’re curious). This tells me that GPT understands
    the location column the same way I did and is at least attempting to infer relationships
    between location and demographic features.
  prefs: []
  type: TYPE_NORMAL
- en: What did I mean "I think"? Well I never actually checked to confirm that the
    numbers made sense. For one thing, this isn’t real data anyway and, for all I
    know, I guessed the contents of each column incorrectly. But also because *every*
    data analysis needs checking against the real world so, in that sense, GPT-generated
    analysis is no different. In other words, whenever you’re working with data that’s
    supposed to represent the real world, you should always find a way to calibrate
    your data using known values to confirm that the whole thing isn’t a happy fantasy.
  prefs: []
  type: TYPE_NORMAL
- en: 'I then asked a second question that reflects a real-world query that would
    interest any bank:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Based on their age, geographic location, number of annual visits to bank branch,
    and total current investments, who are the ten customers most likely to invest
    in a new product offering? Show me only the value of the `customer ID` columns
    for those ten customers.*'
  prefs: []
  type: TYPE_NORMAL
- en: Once again GPT spat back a response that at least *seemed* to make sense. This
    question was also designed to test GPT on its ability to correlate multiple metrics
    and submit them to a complex assessment ("…​most likely to invest in a new product
    offering").
  prefs: []
  type: TYPE_NORMAL
- en: I’ll rate that as another successful experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: GPT - and other LLMs - are capable of independently parsing, analysing, and
    deriving insights from large data sets. While that greatly simplifies the process,
    success still depends on understanding the real-world context of your data and
    coming up with specific and clever prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Using GPT to replace sentiment analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Spoiler alert: this experiment won’t end quite so happily as some of the others
    we’ve seen here. But it’s really about the lessons learned along the way, isn’t
    it?'
  prefs: []
  type: TYPE_NORMAL
- en: Ok, so what is sentiment analysis and why should I want to do it?
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.1 Some background to sentiment analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sentiment analysis, also known as opinion mining, is a technique used to determine
    the sentiment or subjective tone expressed in a piece of text, such as a social
    media post, customer review, or news article. It generally involves analyzing
    the text to classify it as positive, negative, or neutral. It’s primary purpose
    is to understand the opinions, attitudes, and emotions of individuals or groups
    toward a particular topic, product, service, or event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sentiment analysis can help businesses and organizations:'
  prefs: []
  type: TYPE_NORMAL
- en: Gain insights into how their customers perceive their brand, products, or services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Track mentions of their brand or products to monitor and manage their online
    reputation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand market trends, consumer preferences, and emerging patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze customer feedback at scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gauge public sentiment and monitor discussions around political events, social
    issues, or public campaigns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor market sentiment and detect potential investment risks or opportunities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditionally, effective sentiment analysis requires analytics code that’ll
    put your data through a series of steps to try to correctly guess the sentiment
    expressed. The core tool involves assessing the *polarity* of each data unit (typically
    a brief survey response or social media post). That’s done by looking for key
    words that indicate whether the post is positive, negative, or neutral. Analysis
    might then look for words or phrases indicating more precise moods, like anger,
    appreciation, or surprise). Software would then compile a big-picture statistical
    profile of the dataset to suggest trends. The figure below offers examples.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 Using sentiment analysis to infer the underlying mood (or sentiment)
    of short-form content
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 8 2](images/gai-8-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Once again, the "problem" is that building effective sentiment analysis software
    from scratch will be complicated and expensive. And buying it won’t be cheap either.
  prefs: []
  type: TYPE_NORMAL
- en: Which is where AI comes in. Getting it done the GPT way will first involve preprocessing
    the text by removing any irrelevant information, such as punctuation, special
    characters, and stopwords (commonly used words like "and," "the," "is," etc.).
    The text may also be converted to lowercase to ensure consistent analysis. Next,
    relevant features or words from the text are extracted to represent the sentiment.
    This can be done using techniques like *bag-of-words*, where the frequency of
    occurrence of each word in the text is counted and used as a feature.
  prefs: []
  type: TYPE_NORMAL
- en: The extracted features are then used to classify the sentiment of the text.
    This can be done through various approaches, including "rule-based" methods that
    use predefined dictionaries that associate words or phrases with sentiment labels,
    and machine learning algorithms that have been trained on labeled datasets where
    each text is manually annotated with its corresponding sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the sentiment analysis results can be further analyzed and interpreted
    based on the specific needs of the application. This may involve visualizing sentiment
    trends over time, identifying key topics or entities associated with sentiment,
    or comparing sentiment across different sources or demographics.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that sentiment analysis is a challenging task due to
    the complexity of language, including sarcasm, irony, and context-dependent sentiment.
    It can also be expensive, as doing it right will often require customizations
    for the specific dataset you’re working with.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.2 Testing sentiment analysis through GPT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Which brings us back to generative AI. What LLMs generally bring to the table
    is simplicity. That is, most of the things they do can be done using different
    tools, but LLMs can do them with *a lot* less complex coding and environment configuration.
    That was nicely demonstrated by the analytics prompts we just saw.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, if we can provide GPT with a large dataset of comments and - without
    us having to manually direct the process or define our own sentiment dictionary
    - GPT can quickly spit out reliably-accurate sentiment rankings, then we’ll be
    ahead of the game. The trick is to see whether GPT delivers results that are similar
    to or at least close to the traditional methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test this, I downloaded a set of 1,000 Twitter messages that contained product
    or service reviews for various companies. The messages are all pre-labelled (meaning,
    the sentiment is already included). Here are a couple of rows so you can see how
    they look:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Company | Sentiment | Comment |'
  prefs: []
  type: TYPE_TB
- en: '| Microsoft | Negative | @Microsoft Why do I pay for WORD when it functions
    so poorly on my @SamsungUS Chromebook? |'
  prefs: []
  type: TYPE_TB
- en: '| MaddenNFL | Positive | Thank you @EAMaddenNFL!! |'
  prefs: []
  type: TYPE_TB
- en: My goal is to get GPT to generate its own sentiment labels without extensive
    preparations which I’ll compare with the existing set. That’ll show me how close
    GPT is to replacing the traditional sentiment analysis methodologies. I’ll test
    this using both the GPT-3 and GPT-3.5 engines.
  prefs: []
  type: TYPE_NORMAL
- en: While experimenting with various various formulations of API requests, I experienced
    some problems accessing the GPT API. The first setback in my plans came from an
    unexpected `RateLimitError` message. Trying to assess all 1,000 tweets consistently
    failed, with each failure costing me about $0.40.
  prefs: []
  type: TYPE_NORMAL
- en: Even when I dropped 950 of the messages from the CSV file (leaving only 50),
    I still hit the `RateLimitError` nearly as often as not. If nothing else, this
    gives us another strong use-case for the build-your-own LLM servers we’ll discuss
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In any case, I adapted the Python code for this experiment from [this excellent
    Sentiment Analysis project on GitHub](main.html). I begin by loading all the necessary
    libraries, passing my API key, and reading my .CSV spreadsheet file. Nothing new
    there.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Next, I’ll create two functions. The first (`analyze_gpt35(text)`) will set
    up a context and the prompt we’ll apply to each comment for the GPT-3.5 model.
    The context takes the form of a *system* role that tells GPT how it should act
    as an analyst. The actual prompt, which is a *user* role, consists of our specific
    instructions, asking GPT to perform sentiment analysis. The request writes the
    GPT completion to a variable called `response_text` using the `gpt-3.5-turbo`
    engine.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The second function does pretty much the same thing as the first, but for the
    older GPT-3 model. The goal here is to eventually be able to compare the accuracy
    of the two models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember: we created a data frame called `df` containing the original data
    we downloaded. Now we’re ready to actually run those two functions against each
    row of the `Comment` column in that data frame and write the analysis to new columns
    (which the code will create). If you run into that rate limit error, you can try
    running just one of those two commands at a time.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'With a nicely-populated data frame waiting for us, let’s compare the results
    of GPT-3, GPT-3.5 with the pre-existing labels. I’ll use `value_counts()` - which
    counts the incidents of each value in a data frame column - for that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'What came out the other end represents the number of times each possible combination
    of results occurred. So, for instance, the most common outcome (occurring 12 times)
    was a negative rating for each of the training data ("Label"), the GPT-3 model,
    and the GPT-3.5 model. There were ten instances where all three models delivered
    positive ratings. Here’s the full output as a chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Label | predicted_gpt3 | predicted_gpt35 | Frequency |'
  prefs: []
  type: TYPE_TB
- en: '| Negative | negative | negative | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| Positive | positive | positive | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| Neutral | negative | negative | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| Irrelevant | negative | negative | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Neutral | positive | positive | 2 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | not sure | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Negative | positive | positive | 2 |'
  prefs: []
  type: TYPE_TB
- en: '|  | negative | negative | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Irrelevant | positive | positive | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Negative | positive | positive | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Neutral |  | negative | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Irrelevant | neutral | not sure | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Neutral |  | positive | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Positive | negative | negative | 1 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | negative | 1 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | not sure | 1 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | positive | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Neutral | neutral | not sure | 1 |'
  prefs: []
  type: TYPE_TB
- en: Of our 50 comments, both GPT-3 and GPT-3.5 successfully matched the original
    label only 22 times (12 instances where all three scored "negative" and ten where
    all three scored "positive"). For all intents and purposes, the two GPT models
    also performed pretty much identically to each other.
  prefs: []
  type: TYPE_NORMAL
- en: A 44% success rate isn’t great, but it is probably good enough for at least
    some use-cases. Perhaps successfully running this against a much larger dataset
    would have given us better results. But I can imagine projects where you’re looking
    for broad trends rather than absolute accuracy. There’s certainly still some more
    work to do here.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used llama_index to analyse large datasets to deliver sophisticated financial
    and consumer insights into likely consumer behavior. We showed how results can
    (and must) be checked against the real world to confirm that our LLM isn’t making
    stuff up.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With mixed results, we used GPT to execute sentiment analysis against comments
    on consumer products and services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8.4 Try this for yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that GPT-4 is widely available, why not try it out on our sentiment analysis
    experiment and see if you get better results. Also, look for different data sources
    - and let us know what you discover.
  prefs: []
  type: TYPE_NORMAL
