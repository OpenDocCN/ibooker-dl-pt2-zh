["```py\nfrom tensorflow.keras.datasets.mnist import load_data\n(x_train, y_train), (x_test, y_test) = load_data()\n```", "```py\nprint(x_train)\nprint('x_train has shape: {}'.format(x_train.shape))\n```", "```py\n[[[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n ...\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]]\n\nx_train has shape: (60000, 28, 28)\n```", "```py\nprint(y_train)\nprint('y_train has shape: {}'.format(y_train.shape))\n```", "```py\n[5 0 4 ... 5 6 8]\n\ny_train has shape: (60000,)\n```", "```py\nnorm_x_train = ((x_train - 128.0)/128.0).reshape([-1,784])\n```", "```py\nimport numpy as np\n\ndef generate_masked_inputs(x, p, seed=None):\n    if seed:\n        np.random.seed(seed)\n    mask = np.random.binomial(n=1, p=p, size=x.shape).astype('float32')\n    return x * mask\n\nmasked_x_train = generate_masked_inputs(norm_x_train, 0.5)\n```", "```py\nfrom tensorflow.keras import layers, models\n\nautoencoder = models.Sequential(\n    [layers.Dense(64, activation='relu', input_shape=(784,)),  ❶\n    layers.Dense(32, activation='relu'),                       ❶\n    layers.Dense(64, activation='relu'),                       ❶\n    layers.Dense(784, activation='tanh')]                      ❶\n)\nautoencoder.compile(loss='mse', optimizer='adam')              ❷\nautoencoder.summary()                                          ❸\n```", "```py\nhistory = autoencoder.fit(masked_x_train, norm_x_train, batch_size=64, epochs=10)\n```", "```py\nTrain on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 4s 72us/sample - loss: 0.1496\nEpoch 2/10\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.0992\nEpoch 3/10\n...\n60000/60000 [==============================] - 4s 66us/sample - loss: 0.0821\nEpoch 8/10\n60000/60000 [==============================] - 4s 66us/sample - loss: 0.0801\nEpoch 9/10\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.0787\nEpoch 10/10\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.0777\n```", "```py\nx_train_sample = x_train[:10]\ny_train_sample = y_train[:10]\n\nmasked_x_train_sample = generate_masked_inputs(x_train_sample, 0.5, seed=2048)\nnorm_masked_x = ((x_train - 128.0)/128.0).reshape(-1, 784)\n\ny_pred = autoencoder.predict(norm_masked_x)\n```", "```py\nprint(y_pred)\nprint('y_pred has shape: {}'.format(y_pred.shape))\n```", "```py\n[[-0.99999976 -0.99999976 -0.99999976 ... -0.99999976 -0.99999976\n  -0.99999976]\n [-0.99999976 -0.99999976 -0.99999976 ... -0.99999976 -0.99999976\n  -0.99999976]\n [-0.99999976 -0.99999976 -0.99999976 ... -0.99999976 -0.99999976\n  -0.99999976]\n ...\n [-0.99999976 -0.99999976 -0.9999996  ... -0.99999946 -0.99999976\n  -0.99999976]\n [-0.99999976 -0.99999976 -0.99999976 ... -0.99999976 -0.99999976\n  -0.99999976]\n [-0.99999976 -0.99999976 -0.99999976 ... -0.99999976 -0.99999976\n  -0.99999976]]\n\ny_pred has shape: (60000, 784)\n```", "```py\nimport tensorflow_datasets as tfds\ndata = tfds.load('cifar10')\n```", "```py\n{'test': <PrefetchDataset \n➥ shapes: {id: (), image: (32, 32, 3), label: ()}, \n➥ types: {id: tf.string, image: tf.uint8, label: tf.int64}>, 'train': <PrefetchDataset \n➥ shapes: {id: (), image: (32, 32, 3), label: ()}, \n➥ types: {id: tf.string, image: tf.uint8, label: tf.int64}>}\n```", "```py\nimport tensorflow as tf\n\ndef format_data(x, depth):\n    return (tf.cast(x[\"image\"], 'float32'), tf.one_hot(x[\"label\"], depth=depth))\n```", "```py\ntr_data = data[\"train\"].map(lambda x: format_data(x, depth=10)).batch(32)\n```", "```py\nfor d in tr_data.take(1):\n    print(d)\n```", "```py\n(\n    <tf.Tensor: shape=(32, 32, 32, 3), dtype=float32, numpy=\n    array(\n        [[[[143.,  96.,  70.],\n           [141.,  96.,  72.],\n           [135.,  93.,  72.],\n           ...,     \n           [ 52.,  34.,  31.],\n           [ 91.,  74.,  59.],\n           [126., 110.,  88.]]]], \n        dtype=float32)\n    >, \n    <tf.Tensor: shape=(32, 10), dtype=float32, numpy=\n    array(\n        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n         ... \n         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], \n        dtype=float32)\n    >\n)\n```", "```py\nfrom tensorflow.keras import layers, models\nimport tensorflow.keras.backend as K\n\nK.clear_session()                                                          ❶\ncnn = models.Sequential(\n    [layers.Conv2D(\n        filters=16, kernel_size= (9,9), strides=(2,2), activation='relu',  ❷\n           padding=’valid’, input_shape=(32,32,3)\n        ),                                                                 ❷\n     layers.Conv2D(\n         filters=32, kernel_size= (7,7), activation='relu', padding=’valid’\n     ), \n     layers.Conv2D(\n         filters=64, kernel_size= (7,7), activation='relu', padding=’valid’\n     ), \n     layers.Flatten(),                                                     ❸\n     layers.Dense(64, activation='relu'),                                  ❹\n     layers.Dense(10, activation='softmax')]                               ❺\n)\n```", "```py\nlayers.Conv2D(filters=16,kernel_size=(9,9), strides=(2,2), activation='relu', input_shape=(32,32,3))\n```", "```py\n---------------------------------------------------------------------------\n...\n\nInvalidArgumentError: Negative dimension size caused by subtracting 7 from 6 for 'conv2d_2/Conv2D' (op: 'Conv2D') with input shapes: [?,6,6,32], [7,7,32,64].\n```", "```py\nlayers.Conv2D(16,(9,9), strides=(2,2), activation='relu', padding=’valid’, input_shape=(32,32,3))\n```", "```py\n(⌊(32 - 9) / 2⌋ + 1 = 12\n```", "```py\n     layers.Conv2D(32, (7,7), activation='relu', padding=’valid’)\n```", "```py\n12 - 7 + 1 = 6\n```", "```py\n     layers.Conv2D(64, (7,7), activation='relu', padding=’valid’), \n```", "```py\nfrom tensorflow.keras import layers, models\nimport tensorflow.keras.backend as K\n\nK.clear_session()\n\ncnn = models.Sequential([\n     layers.Conv2D(                                                      ❶\n         filters=16,kernel_size=(3,3), strides=(2,2), activation='relu', ❶\n         padding='same', input_shape=(32,32,3)),                         ❶\n     layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),   ❷\n     layers.Conv2D(32, (3,3), activation='relu', padding='same'),        ❸\n     layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),   ❹\n     layers.Flatten(),                                                   ❺\n     layers.Dense(64, activation='relu'),                                ❻\n     layers.Dense(32, activation='relu'),                                ❻\n     layers.Dense(10, activation='softmax')]                             ❼\n)\n```", "```py\ncnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n```", "```py\nhistory = cnn.fit(tr_data,epochs=25)\n```", "```py\nEpoch 1/25\n1563/1563 [==============================] - 23s 15ms/step - loss: 2.0566 - acc: 0.3195\nEpoch 2/25\n1563/1563 [==============================] - 13s 8ms/step - loss: 1.4664 - acc: 0.4699\n...\nEpoch 24/25\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.8070 - acc: 0.7174\nEpoch 25/25\n1563/1563 [==============================] - 13s 8ms/step - loss: 0.7874 - acc: 0.7227\n```", "```py\nfrom tensorflow.keras import layers, models\n\nmodels.Sequential([\nlayers.Conv2D(                                                     \n         filters=16, kernel_size=(5,5), padding='valid', input_shape=(64,64,3)\n),                        \nlayers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same'),  \nlayers.Conv2D(32, (3,3), activation='relu', padding='same'),       \nlayers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),  \nlayers.Conv2D(32, (3,3), strides=(2,2), activation='relu', padding='same')\n])       \n```", "```py\nimport requests\nimport os\n\ndef download_data():\n    \"\"\" This function downloads the CO2 data from \n    https:/ /datahub.io/core/co2-ppm/r/co2-mm-gl.csv\n    if the file doesn't already exist\n    \"\"\"\n    save_dir = \"data\"\n    save_path = os.path.join(save_dir, 'co2-mm-gl.csv')\n\n    # Create directories if they are not there\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n\n    # Download the data and save\n    if not os.path.exists(save_path):\n        url = \"https:/ /datahub.io/core/co2-ppm/r/co2-mm-gl.csv\"\n        r = requests.get(url)\n        with open(save_path, 'wb') as f:\n            f.write(r.content)\n    else:\n        print(\"co2-mm-gl.csv already exists. Not downloading.\")\n    return save_path\n\n# Downloading the data\nsave_path = download_data()\n```", "```py\nimport pandas as pd\ndata = pd.read_csv(save_path)\n```", "```py\ndata.head()\n```", "```py\ndata = data.set_index('Date')\n```", "```py\ndata[[\"Average\"]].plot(figsize=(12,6))\n```", "```py\ndata[\"Average Diff\"]=data[\"Average\"] - data[\"Average\"].shift(1).fillna(method='bfill')\n```", "```py\nimport numpy as np\n\ndef generate_data(co2_arr,n_seq):\n    x, y = [],[]\n    for i in range(co2_arr.shape[0]-n_seq):\n        x.append(co2_arr[i:i+n_seq-1])         ❶\n        y.append(co2_arr[i+n_seq-1:i+n_seq])   ❷\n    x = np.array(x)                            ❸\n    y = np.array(y)                            ❸\n    return x,y\n```", "```py\nfrom tensorflow.keras import layers, models\n\nrnn = models.Sequential([\n    layers.SimpleRNN(64),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n])\n```", "```py\nrnn.compile(loss='mse', optimizer='adam')\n```", "```py\nx, y = generate_data(data[“Average Diff”], n_seq=13)\nrnn.fit(x, y, shuffle=True, batch_size=64, epochs=25)\n```", "```py\nValueError: \n➥ Input 0 of layer sequential_1 is incompatible with the layer: \n➥ expected ndim=3, found ndim=2\\. Full shape received: [None, 12]\n```", "```py\nimport numpy as np\n\ndef generate_data(co2_arr,n_seq):\n    x, y = [],[]                              ❶\n    for i in range(co2_arr.shape[0]-n_seq):   ❷\n        x.append(co2_arr[i:i+n_seq-1])        ❸\n        y.append(co2_arr[i+n_seq-1:i+n_seq])  ❸\n    x = np.array(x).reshape(-1,n_seq-1,1)     ❹\n    y = np.array(y) \n    return x,y\n```", "```py\nx, y = generate_data(data[“Average Diff”], n_seq=13)\nrnn.fit(x, y, shuffle=True, batch_size=64, epochs=25)\n```", "```py\nTrain on 429 samples\nEpoch 1/25\n429/429 [==============================] - 1s 2ms/sample - loss: 0.4951\nEpoch 2/25\n429/429 [==============================] - 0s 234us/sample - loss: 0.0776\n...\nEpoch 24/25\n429/429 [==============================] - 0s 234us/sample - loss: 0.0153\nEpoch 25/25\n429/429 [==============================] - 0s 234us/sample - loss: 0.0152\n```", "```py\nhistory = data[\"Average Diff\"].values[-12:].reshape(1,-1,1)     ❶\ntrue_vals = []\nprev_true = data[\"Average\"].values[-1]                          ❷\nfor i in range(60):                                             ❸\n    p_diff = rnn.predict(history).reshape(1,-1,1)               ❹\n    history = np.concatenate((history[:,1:,:],p_diff),axis=1)   ❺\n    true_vals.append(prev_true+p_diff[0,0,0])                   ❻\n    prev_true = true_vals[-1]                                   ❼\n```", "```py\nhistory = data[\"Average Diff\"].values[-12:].reshape(1,-1,1)\n```", "```py\nprev_true = data[\"Average\"].values[-1]\n```", "```py\nhistory = np.concatenate((history[:,1:,:],p_diff),axis=1)\n```", "```py\ntrue_vals.append(prev_true+p_diff[0,0,0])\n```", "```py\nprev_true = true_vals[-1]\n```", "```py\nautoencoder = models.Sequential(\n    [layers.Dense(32, activation='sigmoid', input_shape=(512,)),\n    layers.Dense(16, activation='sigmoid'),\n    layers.Dense(512, activation='sigmoid')]\n)\n```", "```py\nrnn = models.Sequential([\n    layers.SimpleRNN(64, input_shape=(12, 2)),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(2)\n])\n```"]