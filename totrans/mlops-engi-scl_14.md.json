["```py\ndef objective(trial):                          ❶\n  hparams = {\n    \"seed\": trial.suggest_int('seed',\n                0,\n                pt.iinfo(pt.int32).max - 1),   ❷\n    \"num_features\": \"8\",\n    ...                                        ❸\n  }\n  model, trainer = build(DcTaxiModel(**hparams),\n    train_glob = \"https://raw.githubusercontent.com/osipov/smlbook/\n➥     master/train.csv\",\n    val_glob = \"https://raw.githubusercontent.com/osipov/smlbook/\n➥     master/valid.csv\")\n\n  return (trainer\n          .callback_metrics['train_val_rmse']\n          .item())                             ❹\n```", "```py\nx = pt.linspace(1, 1_000, 300)\n#prints the 1s, 10s, 100s\nprint(pt.count_nonzero(x[(x > 0) & (x < 10) ]).item(),\n    pt.count_nonzero(x[(x > 10) & (x < 100) ]).item(),\n    pt.count_nonzero(x[(x > 100) & (x < 1_000) ]).item())\n```", "```py\n3 27 269\n```", "```py\ny = pt.logspace(pt.log10(pt.tensor(1)),\n                pt.log10(pt.tensor(1_000)),  300)\n\n#prints the 1s, 10s, 100s\nprint(pt.count_nonzero(y[(y > 0) & (y < 10) ]).item(),\n    pt.count_nonzero(y[(y > 10) & (y < 100) ]).item(),\n    pt.count_nonzero(y[(y > 100) & (y < 1_000) ]).item())\n```", "```py\n100 100 99\n```", "```py\nhparams = {\n...\n\"lr\": trial.suggest_loguniform('lr', 0.001, 0.1),    ❶\n...\n}\n```", "```py\nhparams = {\n...\n\"optimizer\": \\\n  trial.suggest_categorical('optimizer',\n                            ['Adam', 'SGD']),    ❶\n...\n}\n```", "```py\nhparams = {\n  ...\n  \"batch_size\": \\\n    trial.suggest_categorical('batch_size',\n                  [2 ** i for i in range(16, 22)]),    ❶\n  ...\n}\n```", "```py\nhparams = {\n  ...\n  \"num_hidden_neurons\": \\                                            ❶\n    [trial.suggest_categorical(f\"num_hidden_layer_{layer}_neurons\",\n                              [7, 11, 13, 19, 23]) for layer in \\\n                              range(trial.suggest_categorical('num_layers',\n                                                       [11, 13, 17, 19]))],\n  ...\n}\n```", "```py\ndef objective(trial):\n  hparams = {\n    \"seed\": trial.suggest_int('seed', 0, pt.iinfo(pt.int32).max - 1),\n    \"num_features\": \"8\",\n    \"optimizer\": trial.suggest_categorical('optimizer', ['Adam', 'SGD']),\n    \"lr\": trial.suggest_loguniform('lr', 0.009, 0.07),\n    \"num_hidden_neurons\": \\\n      str([trial\n➥           .suggest_categorical(f\"num_hidden_layer_{layer}_neurons\",\n            [7, 11]) for layer in \\\n              range(trial.suggest_categorical('num_layers', [2, 3]))]),\n    \"batch_size\": trial.suggest_int('batch_size', 30, 50, log = True),\n    \"max_batches\": trial.suggest_int('max_batches', 30, 50, log = True)\n    \"batch_norm_linear_layers\": \\\n      str(trial.suggest_int('batch_norm_linear_layers', 0, 1)),\n  }\n  model, trainer = build(DcTaxiModel(**hparams),\n    train_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥     master/train.csv',\n    val_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥     master/valid.csv')\n\n  return trainer.callback_metrics['train_val_rmse'].item()\n```", "```py\ndef build_hidden_layers(self, num_hidden_neurons, activation):\n  linear_layers = \\                                            ❶\n    [ pt.nn.Linear(num_hidden_neurons[i],\n      num_hidden_neurons[i+1]) for i in range(len(num_hidden_neurons) - 1) ]\n\n  classes = \\                                                  ❷\n    [activation.__class__] * len(num_hidden_neurons)\n\n  activation_instances = \\                                     ❸\n    list(map(lambda x: x(), classes))\n\n  hidden_layer_activation_tuples = \\                           ❹\n    list(zip(linear_layers, activation_instances))\n\n  hidden_layers = \\                                            ❺\n    [i for sublist in hidden_layer_activation_tuples for i in sublist]\n\n  return hidden_layers\n```", "```py\nimport json\nimport torch as pt\nimport pytorch_lightning as pl\nclass DcTaxiModel(pl.LightningModule):\n  def __init__(self, hparams = None):\n    super().__init__()\n    self.hparams = hparams\n\n    pt.manual_seed(self.hparams['seed'])\n\n    num_hidden_neurons = \\                           ❶\n      json.loads(self.hparams.num_hidden_neurons)\n\n    self.layers = \\                                  ❷\n      pt.nn.Sequential(\n        pt.nn.Linear(int(self.hparams.num_features), num_hidden_neurons[0]),\n        pt.nn.ReLU(),\n        *self.build_hidden_layers(num_hidden_neurons, pt.nn.ReLU()),\n        pt.nn.Linear(num_hidden_neurons[-1], 1)\n    )\n\nmodel = build(DcTaxiModel(**{\n        \"seed\": \"1686523060\",\n        \"num_features\": \"8\",\n        \"num_hidden_neurons\": \"[3, 5, 8]\",           ❸\n        \"optimizer\": \"Adam\",\n        \"lr\": \"0.03\",\n        \"max_batches\": \"100\",\n        \"batch_size\": \"100\",}),\n  train_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/train.csv',\n  val_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥               master/valid.csv',\n  test_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥               master/train.csv')\n```", "```py\ndef batch_norm_linear(self, layers):\n  idx_linear = \\                                                   ❶\n    list(filter(lambda x: type(x) is int,\n      [idx if issubclass(layer.__class__, pt.nn.Linear) else None \\\n        for idx, layer in enumerate(layers)]))\n\n  idx_linear.append(sys.maxsize)                                   ❷\n\n  layer_lists = \\                                                  ❸\n    [list(iter(layers[s:e])) \\\n      for s, e in zip(idx_linear[:-1], idx_linear[1:])]\n\n  batch_norm_layers = \\                                            ❹\n    [pt.nn.BatchNorm1d(layer[0].in_features) for layer in layer_lists]\n\n  batch_normed_layer_lists = \\                                     ❺\n    [ [bn, *layers] for bn, layers in \\\n      list(zip(batch_norm_layers, layer_lists)) ]\n\n  result = \\                                                       ❻\n    pt.nn.Sequential(*[layer for nested_layer in \\\n      batch_normed_layer_lists for layer in nested_layer ])\n\n  return result\n```", "```py\nfrom distutils.util import strtobool\n\ndef __init__(self, **kwargs):\n  super().__init__()\n  self.save_hyperparameters()\n\n  self.step = 0\n  self.start_ts = time.perf_counter()\n  self.train_val_rmse = pt.tensor(0.)\n\n  pt.manual_seed(int(self.hparams.seed))\n  #create a list of hidden layer neurons, e.g. [3, 5, 8]\n  num_hidden_neurons = json.loads(self.hparams.num_hidden_neurons)\n\n  self.layers = pt.nn.Sequential(\n      pt.nn.Linear(int(self.hparams.num_features), num_hidden_neurons[0]),\n      pt.nn.ReLU(),\n      *self.build_hidden_layers(num_hidden_neurons, pt.nn.ReLU()),\n      pt.nn.Linear(num_hidden_neurons[-1], 1)\n  )\n\n  if 'batch_norm_linear_layers' in self.hparams \\          ❶\n    and strtobool(self.hparams.batch_norm_linear_layers):\n    self.layers = self.batch_norm_linear(self.layers)\n```", "```py\nimport sys\nimport json\nimport time\nimport torch as pt\nimport pytorch_lightning as pl\nfrom distutils.util import strtobool\nfrom torch.utils.data import DataLoader\nfrom kaen.torch import ObjectStorageDataset as osds\npt.set_default_dtype(pt.float64)\n\nclass DcTaxiModel(pl.LightningModule):\n    def __init__(self, **kwargs):\n      super().__init__()\n      self.save_hyperparameters()\n\n      self.step = 0\n      self.start_ts = time.perf_counter()\n      self.train_val_rmse = pt.tensor(0.)\n\n      pt.manual_seed(int(self.hparams.seed))\n      #create a list of hidden layer neurons, e.g. [3, 5, 8]\n      num_hidden_neurons = json.loads(self.hparams.num_hidden_neurons)\n\n      self.layers = \\\n        pt.nn.Sequential(\n          pt.nn.Linear(int(self.hparams.num_features),\n                              num_hidden_neurons[0]),\n          pt.nn.ReLU(),\n          *self.build_hidden_layers(num_hidden_neurons, pt.nn.ReLU()),\n          pt.nn.Linear(num_hidden_neurons[-1], 1)\n        )\n\n      if 'batch_norm_linear_layers' in self.hparams \\\n        and strtobool(self.hparams.batch_norm_linear_layers):\n        self.layers = self.batch_norm_linear(self.layers)\n\n    def build_hidden_layers(self, num_hidden_neurons, activation):\n      linear_layers = [ pt.nn.Linear(num_hidden_neurons[i],\n          num_hidden_neurons[i+1]) for i in \\\n            range(len(num_hidden_neurons) - 1) ]\n\n      classes = [activation.__class__] * len(num_hidden_neurons)\n\n      activation_instances = list(map(lambda x: x(), classes))\n\n      hidden_layer_activation_tuples = \\\n        list(zip(linear_layers, activation_instances))\n\n      hidden_layers = \\\n        [i for sublist in hidden_layer_activation_tuples for i in sublist]\n\n      return hidden_layers\n\n    def batch_norm_linear(self, layers):\n      idx_linear = \\\n        list(filter(lambda x: type(x) is int,\n        [idx if issubclass(layer.__class__, pt.nn.Linear) else None \\\n          for idx, layer in enumerate(layers)]))\n\n      idx_linear.append(sys.maxsize)\n      layer_lists = \\\n        [list(iter(layers[s:e])) \\\n          for s, e in zip(idx_linear[:-1], idx_linear[1:])]\n      batch_norm_layers = \\\n        [pt.nn.BatchNorm1d(layer[0].in_features) for layer in layer_lists]\n      batch_normed_layer_lists = \\\n        [ [bn, *layers] for bn, layers in \\\n          list(zip(batch_norm_layers, layer_lists)) ]\n\n      return \\\n        pt.nn.Sequential(*[layer \\\n          for nested_layer in batch_normed_layer_lists \\\n          for layer in nested_layer ])\n\n    def batchToXy(self, batch):\n      batch = batch.squeeze_()\n      X, y = batch[:, 1:], batch[:, 0]\n      return X, y\n\n    def forward(self, X):\n      y_est = self.layers(X)\n      return y_est.squeeze_()\n\n    def training_step(self, batch, batch_idx):\n        self.step += 1\n\n        X, y = self.batchToXy(batch) #unpack batch into features and label\n\n        y_est = self.forward(X)\n\n        loss = pt.nn.functional.mse_loss(y_est, y)\n\n        for k,v in {\n\n          \"train_mse\": loss.item(),\n          \"train_rmse\": loss.sqrt().item(),\n          \"train_steps_per_sec\": \\\n            self.step / (time.perf_counter() - self.start_ts),\n\n        }.items():\n          self.log(k, v, on_step=True, on_epoch=True,\n                          prog_bar=True, logger=True)\n\n        self.train_val_rmse = loss.sqrt().item()\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n      X, y = self.batchToXy(batch)\n\n      with pt.no_grad():\n          loss = pt.nn.functional.mse_loss(self.forward(X), y)\n\n      for k,v in {\n        \"val_mse\": loss.item(),\n        \"val_rmse\": loss.sqrt().item(),\n        \"train_val_rmse\": self.train_val_rmse + loss.sqrt().item(),\n      }.items():\n        self.log(k, v, on_step=True, on_epoch=True,\n                        prog_bar=True, logger=True)\n      return loss\n\n    def test_step(self, batch, batch_idx):\n      X, y = self.batchToXy(batch)\n\n      with pt.no_grad():\n          loss = pt.nn.functional.mse_loss(self.forward(X), y)\n\n      for k,v in {\n          \"test_mse\": loss.item(),\n          \"test_rmse\": loss.sqrt().item(),\n      }.items():\n          self.log(k, v, on_step=True, on_epoch=True,\n                          prog_bar=True, logger=True)\n\n    def configure_optimizers(self):\n        optimizers = {'Adam': pt.optim.AdamW,\n                      'SGD': pt.optim.SGD}\n        optimizer = optimizers[self.hparams.optimizer]\n\n        return optimizer(self.layers.parameters(),\n                            lr = float(self.hparams.lr))\n\ndef build(model, train_glob, val_glob, test_glob = None):\n  csvLog = CSVLogger(save_dir = \"logs\",\n                    name = \"dctaxi\",\n                    version = f\"seed_{model.hparams.seed}\")\n\n  trainer = pl.Trainer(gpus = pt.cuda.device_count() \\\n                                if pt.cuda.is_available() else 0,\n    max_epochs = 1,\n    limit_train_batches = int( model.hparams.max_batches ) \\\n                                if 'max_batches' in model.hparams else 1,\n    limit_val_batches = 1,\n    num_sanity_val_steps = 1,\n    val_check_interval = min(20, int( model.hparams.max_batches ) ),\n    limit_test_batches = 1,\n    log_every_n_steps = 1,\n    logger = csvLog,\n    gradient_clip_val=0.5,\n    progress_bar_refresh_rate = 0,\n    weights_summary = None,)\n\n  train_dl = \\\n    DataLoader(osds(train_glob,\n                    batch_size = int(model.hparams.batch_size) ),\n               pin_memory = True)\n\n  val_dl = \\\n    DataLoader(osds(val_glob,\n                    batch_size = int(model.hparams.batch_size) ),\n               pin_memory = True)\n  trainer.fit(model,\n              train_dataloaders = train_dl,\n              val_dataloaders = val_dl)\n\n  if test_glob is not None:\n    test_dl = \\\n      DataLoader(osds(test_glob,\n                      batch_size = int(model.hparams.batch_size) ),\n                pin_memory = True)\n\n    trainer.test(model,\n                dataloaders=test_dl)\n\n  return model, trainer\n\nmodel, trainer = build(DcTaxiModel(**{\n        \"seed\": \"1686523060\",\n        \"num_features\": \"8\",\n        \"num_hidden_neurons\": \"[3, 5, 8]\",\n        \"batch_norm_linear_layers\": \"1\",\n        \"optimizer\": \"Adam\",\n        \"lr\": \"0.03\",\n        \"max_batches\": \"100\",\n        \"batch_size\": \"100\",}),\n\n  train_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/train.csv',\n  val_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/valid.csv',\n  test_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                 master/train.csv')\n```", "```py\ndef objective(trial):\n  hparams = {\n    \"seed\": trial.suggest_int('seed', 0, pt.iinfo(pt.int32).max - 1),\n\n    \"num_features\": \"8\",\n\n    \"batch_norm_linear_layers\": \\\n      str(trial.suggest_int('batch_norm_linear_layers', 0, 1)),\n\n    \"optimizer\": trial.suggest_categorical('optimizer', ['Adam', 'SGD']),\n\n    \"lr\": trial.suggest_loguniform('lr', 0.009, 0.07),\n\n    \"num_hidden_neurons\": \\\n      str([trial.suggest_categorical(f\"num_hidden_layer_{layer}_neurons\",\n            [7, 11]) for layer in \\\n              range(trial.suggest_categorical('num_layers', [2, 3]))]),\n\n    \"batch_size\": trial.suggest_int('batch_size', 30, 50, log = True),\n\n    \"max_batches\": trial.suggest_int('max_batches', 30, 50, log = True)\n  }\n  model, trainer = build(DcTaxiModel(**hparams),\n    train_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                   master/train.csv',\n    val_glob = 'https://raw.githubusercontent.com/osipov/smlbook/\n➥                   master/valid.csv')\n\n  return trainer.callback_metrics['train_val_rmse'].item()\n\nimport optuna\nfrom optuna.samplers import TPESampler                       ❶\nstudy = \\\n  optuna.create_study(direction = 'minimize',                ❷\n                      sampler = TPESampler( seed = 42 ),)\n\nstudy.optimize(objective, n_trials = 100)                    ❸\n```", "```py\nstudy_df = study.trials_dataframe().sort_values(by='value',\n                                                ascending = True)\nstudy_df[:5][['number', 'value', 'params_seed']],\n```", "```py\noptuna.visualization.plot_param_importances(study)\n```", "```py\noptuna.visualization.plot_parallel_coordinate(study,\n    params=[\"lr\", \"batch_size\", \"num_hidden_layer_0_neurons\"])\n```", "```py\noptuna.visualization.plot_contour(study, params=[\"batch_size\", \"lr\"])\n```"]