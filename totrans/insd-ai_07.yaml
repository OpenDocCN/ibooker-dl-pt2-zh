- en: 7 AI doesn’t turn data into intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The difference between data, information, and intelligence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The limited reusability of AI models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The vulnerability of AI to unexpected data inputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will explain that regardless of how extensive the dataset
    or advanced the algorithms, an AI program faces a substantial challenge in inferring
    intelligence from data due to the semantic gap, as AI algorithms can process data
    but struggle to grasp its deeper meanings. Even for simpler tasks, such as recognizing
    handwritten numbers, where AI models excel, they still lack the capability to
    grasp the context surrounding these numbers. For instance, an AI system might
    correctly identify a handwritten 9 as the numeric symbol 9, but it remains unable
    to infer that this number more likely represents a child’s age on a birthday card.
  prefs: []
  type: TYPE_NORMAL
- en: The Farmer-Wolf-Goat-Cabbage riddle, previously discussed in chapter 4, serves
    as a prime example illustrating the constraints of AI when confronted with problems
    that demand logical reasoning and strategic planning. Traditional machine learning
    models primarily depend on statistical patterns and data-driven training, rendering
    them unsuitable for tasks that necessitate deductive reasoning, forward planning,
    and a deep comprehension of specific constraints, as exemplified by this simple
    problem. In this puzzle, the farmer must safely transport the wolf, goat, and
    cabbage across a river, ensuring that neither the wolf eats the goat nor the goat
    consumes the cabbage. While AI excels in domains such as natural language understanding,
    image recognition, and game playing, these domains typically involve activities
    based on pattern recognition and optimization, drawing from historical data. In
    contrast, solving the Farmer-Wolf-Goat-Cabbage riddle calls for symbolic reasoning
    or symbolic AI techniques, reliant on explicit rules and logic to determine the
    correct sequence of actions while adhering to predefined constraints. Real progress
    in AI will require the development of innovative techniques, such as smart agents,
    that extend beyond the confines of learning solely from data.
  prefs: []
  type: TYPE_NORMAL
- en: Let us elaborate further by referring to medical diagnosis, where many believe
    that AI possesses the capability to acquire “intelligence” from data. However,
    AI systems trained on data are insufficient for conducting accurate medical diagnoses.
    One fundamental limitation is the absence of medical understanding. AI programs
    trained on data can identify statistical patterns and correlations, but they lack
    an inherent grasp of the underlying medical concepts, disease mechanisms, and
    the complexity of the human body. Medical diagnosis often demands an understanding
    of biology, pathology, and clinical expertise that cannot be inferred from data.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, a visit to a doctor’s office, unless it’s an emergency, begins
    with an information-sharing process. Questions are posed and answered during appointment
    scheduling, intake forms are completed, health histories are updated, and sometimes
    questionnaires are necessary. Before the patient even sees the doctor, a nurse
    often records height, weight, temperature, and blood pressure, along with conducting
    preliminary tests.
  prefs: []
  type: TYPE_NORMAL
- en: Once the doctor enters the examination room, they commence the process of information
    filtration and reasoning. In addition to the patient’s records and the preliminary
    data collected, the doctor takes into account the patient’s physical appearance
    and demeanor. They conduct visual examinations of the patient’s eyes, ears, nose,
    and throat; listen to the heartbeat; and palpate the abdomen. They engage the
    patient in discussions about their symptoms, asking targeted questions to gather
    specific information. In some cases, they might perform specialized diagnostic
    procedures or request blood or urine samples for laboratory tests.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, nearly any detail from the patient’s life story or even their relatives’
    stories could be relevant to a diagnosis. However, discerning what to consider
    and what to disregard is a skill, and in most cases, the majority of available
    information is irrelevant to the immediate situation. If finding the right diagnosis
    sometimes feels like finding a needle in a haystack, adding more data only increases
    the haystack’s size, creating a hindrance rather than assistance.
  prefs: []
  type: TYPE_NORMAL
- en: Much of a doctor’s reasoning occurs instinctively and subconsciously, drawing
    from experience with similar cases and familiarity with the patient. Over time,
    doctors have developed the ability to deal with uncertainty and incomplete information.
    For instance, they must interpret the patient’s description of symptom severity
    in light of the patient’s overall health. Their line of questioning adapts in
    real-time based on the patient’s responses and their intuition. Sometimes, they
    intuitively know to inquire about family history or pre-existing conditions, while
    in other cases, curiosity prompts them to ask about sleep quality or emotional
    stress.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, doctors need to extrapolate, draw analogies, and rely on intuition.
    Their task isn’t about amassing as much information as possible but about obtaining
    the right information and interpreting it correctly. How could an AI model, no
    matter the size of the data sets on which it was trained, replicate the multifaceted
    reasoning of a medical professional?
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Machines defeating world champions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two of the most widely publicized “AI events” in history were IBM’s Deep Blue
    defeating chess champion Gary Kasparov in 1997 and AlphaGo’s victory over Go champion
    Lee Sedol in 2016\. Both instances received extensive media coverage, showcasing
    the apparent “intelligence” of these programs and generating anticipation for
    even more advanced technology in the future. However, these popular interpretations
    often missed the mark. These demonstrations primarily highlighted the machines’
    formidable computing power and sophisticated specialized algorithms. Instead of
    demonstrating genuine intelligence or understanding, they highlighted the stark
    contrast between human and machine approaches to generating game moves. By analyzing
    the methods employed by computers to play human games, we can gain a better understanding
    of AI systems reliant on data and computation.
  prefs: []
  type: TYPE_NORMAL
- en: In the game of chess, the board consists of eight rows and eight columns, with
    32 squares initially occupied by pieces. Each side begins with a collection of
    pieces, including eight pawns, two rooks, two knights, two bishops, one queen,
    and one king (figure 7.1). Each type of piece possesses its own distinctive movement
    rules. For example, a pawn typically moves one square forward at a time, except
    for its first move, where it has the option to advance one or two squares. Players
    take turns, with white pieces making the first move. A piece captures an opponent’s
    piece by moving to the square occupied by that piece. The goal of the game is
    to put the opponent’s king in a position where it can’t escape capture, which
    is called checkmate.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 The starting position in chess (French Louvre collections of art)
    [1]
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The white player in a chess game faces an initial choice of 20 possible moves,
    and their opponent has an equal number of potential responses. However, as the
    game progresses, the number of possible board positions increases significantly.
    Just after the second pair of moves, we reach 197,742 potential board configurations.
    After three pairs of moves, this number skyrockets to over 121 million. To provide
    some perspective, consider that a typical position in chess allows for approximately
    30 legal moves to choose from. With the average chess game extending to about
    40 move pairs, the total number of possible game positions can be estimated to
    be around 10120\.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE This monumental figure is known as the Shannon number, named in honor of
    the mathematician and electrical engineer Claude Shannon. It serves as a metric
    in chess to estimate the complexity of the game tree. Shannon published a groundbreaking
    paper titled “Programming a Computer for Playing Chess.” In this paper, he introduced
    the notion of a game tree, comprising nodes that represent different game states
    and edges connecting them to nodes reachable by legal moves.
  prefs: []
  type: TYPE_NORMAL
- en: In chess, each move by a player leads to a multitude of possible responses by
    the opponent, creating a branching structure known as the game tree. The Shannon
    number attempts to quantify the vast number of possible chess games. This number
    provides a lower bound on the game-tree complexity of chess. It is an estimation
    of the minimum number of possible chess games, taking into account legal moves
    and positions. The calculation involves considering the average branching factor
    (average number of possible moves at each turn) and the average game length.
  prefs: []
  type: TYPE_NORMAL
- en: While the exact number is difficult to pinpoint due to the immense complexity
    of chess, the Shannon number serves as a theoretical measure to illustrate the
    extraordinary depth and intricacy of the game. It highlights the intricate and
    expansive nature of chess, emphasizing the difficulties in encompassing all potential
    legal positions and moves.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional method for programming turn-based games, as seen in the development
    of IBM’s Deep Blue for chess, involves storing the game tree in computer memory.
    In this approach, the system assesses the desirability of positions at the endpoints
    of branches, systematically adds more nodes to the tree for a deeper search, and
    prunes less promising branches. The computer then selects its move based on the
    positions with the highest evaluations. Competitive turn-based games often come
    with time limits. Each player is initially allocated a specific amount of time,
    which decreases when it’s their turn to make a move. If a player’s time runs out,
    they typically lose the game. Consequently, a computer must rely on heuristics
    to determine how much time to allocate for computations and when to make a move.
    Just like human players, it needs to strike a balance between spending time to
    find potentially better moves and conserving time for future turns, avoiding rapid
    decisions that could lead to a disadvantageous position.
  prefs: []
  type: TYPE_NORMAL
- en: To compete effectively against skilled chess players, a program must analyze
    sequences involving a large number of moves, a task that would be impractical
    without pruning. Alpha-beta pruning is a specific algorithm used to reduce the
    number of nodes that need to be evaluated in this process. Chess programs also
    include subroutines that apply heuristics and rules of thumb to assess the relative
    advantages of each side in various positions. These assessments are translated
    into numerical scores, weighted, and combined to produce an overall evaluation
    score, taking into account their relative importance. Additionally, programs like
    Deep Blue have access to databases containing complete grandmaster games, opening
    sequences, and an endgame database that includes full game trees for positions
    with only a few remaining pieces on the board.
  prefs: []
  type: TYPE_NORMAL
- en: Switching gears to the game of Go, it is played on a 1…9 grid with black and
    white stones. The objective is to capture the most territory by surrounding it
    with one’s own stones. Computer Go programs have taken various approaches over
    the years, with early efforts like Albert Zobrist’s 1968 program [2] relying on
    traditional programming. In contrast, the Symbiotic Adaptive Neuro-Evolution (SANE)
    approach introduced in 1998 at the University of Texas at Austin [3] utilized
    neural networks and genetic algorithms to teach the program to play on a nine-by-nine
    board without preprogrammed Go knowledge. AlphaGo, however, employed extensive
    reference databases, grandmaster knowledge, and highly sophisticated deep learning.
    The program was trained using positions from both human- and computer-played games,
    incorporating board positions, the best moves, and winning percentages. Subsequently,
    AlphaGo played millions of games against itself to refine its strategies.
  prefs: []
  type: TYPE_NORMAL
- en: The computer-based approach differs from human players, who rely on intuition
    and experience. Human players calculate move sequences and evaluate positions,
    but their process is neither systematic nor numerical. Renowned chess grandmaster
    Magnus Carlsen mentioned that he can occasionally calculate 15 to 20 moves ahead,
    but the challenge lies in evaluating the positions at the end of these lines [4].
    Humans also depend heavily on intuition, strategy, and anticipating their opponents’
    plans, sometimes choosing moves that may not have the highest numerical score
    but are psychologically challenging for their opponents.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Lack of generalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numerous AI projects primarily serve marketing purposes, with resulting programs
    typically having limited utility beyond their ability to beat humans in specific
    games. These projects often demand substantial investments in terms of both cost
    and resources. While they may initially capture media attention, as exemplified
    by the widespread coverage of Deep Blue, they frequently fade into obscurity over
    time. In contrast, human experts in games like chess or Go can transfer their
    skills to play other games reasonably well. Given a brief period to familiarize
    themselves with the rules of a new game, they can effectively apply their systematic
    and strategic thinking abilities. AI systems, on the other hand, struggle to adapt
    to rule changes in their designated games, let alone apply their knowledge to
    different domains.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, when evaluating a computer’s apparent intelligence, it’s important
    to consider that individuals capable of playing chess at a master level can also
    handle tasks such as writing articles on chess strategy. However, despite their
    impressive game-playing abilities, systems like Deep Blue are limited in their
    competency beyond their specialized tasks. For example, AlphaGo employs advanced
    techniques to navigate complex state spaces and analyze extensive data, but it
    can only do so because it operates with complete and perfect information. These
    systems encounter difficulties when confronted with real-world scenarios that
    feature incomplete information and uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the 1950s, individuals who could perform fast and accurate mental calculations
    were deemed “intelligent” because this skill was highly valuable in an era before
    the widespread use of calculating machines. Today, affordable handheld calculators
    surpass human abilities in manipulating mathematical formulas and performing calculations.
    Yet, we don’t attribute intelligence to calculators. This raises the question:
    Why do we often characterize game-playing programs as intelligent simply because
    they excel in rapid calculations and data processing?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s conclude this chapter with a historical case example that underscores
    the significant challenges AI systems face when attempting to replicate counterintuitive
    intelligence. During World War II, mathematician Abraham Wald proposed a counterintuitive
    but highly effective strategy for reinforcing planes against enemy fire. Instead
    of reinforcing the parts of planes that received the most damage, as suggested
    by the records, he recommended reinforcing the parts that received the least damage
    [5]. His insight was crucial: the planes that returned to base were surviving
    the damage they accumulated, and the records highlighted the areas that, if damaged,
    would lead to the plane’s loss. Wald’s remarkable demonstration of counterintuitive
    intelligence was made possible by his cognitive abilities, such as abstract reasoning,
    creativity, and a deep understanding of context, which allowed him to conceptualize
    and reason about concepts that may not have had direct precedents in his knowledge
    and past experiences. Furthermore, his ability to apply common-sense reasoning,
    creativity, and imagination enabled him to formulate innovative solutions to problems
    that defied conventional logic and showcased his counterintuitive intelligence.'
  prefs: []
  type: TYPE_NORMAL
- en: In stark contrast, AI models lack the capability to grasp the underlying principles
    or concepts behind data. They also lack common-sense reasoning, which is essential
    for comprehending counterintuitive scenarios that may not conform to standard
    rules or patterns. In essence, AI’s inability to infer counterintuitive intelligence
    underscores the divide between data-driven machine learning and the nuanced, context-dependent
    reasoning that humans often employ in complex, unconventional situations.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Relying solely on an AI program learning from data alone may not be sufficient
    for performing many tasks, especially those that require reasoning or common-sense
    knowledge.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI models that rely on data to learn are often limited to a single domain because
    their knowledge and capabilities are derived solely from the data they are trained
    on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI models lack the capacity for context-based reasoning and critical thinking.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
