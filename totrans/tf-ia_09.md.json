["```py\ndata_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False, samplewise_center=False,\n    featurewise_std_normalization=False, samplewise_std_normalization=False,\n    zca_whitening=False, rotation_range=0, width_shift_range=0.0,\n    height_shift_range=0.0, brightness_range=None, shear_range=0.0, \n➥ zoom_range=0.0,\n    channel_shift_range=0.0, horizontal_flip=False, \n    vertical_flip=False, fill_mode=”nearest”, rescale=None,\n    preprocessing_function=None, validation_split=0.0\n)\n```", "```py\nimage_gen_aug = ImageDataGenerator(                     ❶\n        samplewise_center=False,                        ❷\n        rotation_range=30,                              ❸\n        width_shift_range=0.2, height_shift_range=0.2,  ❸\n        brightness_range=(0.5,1.5),                     ❸\n        shear_range=5,                                  ❸\n        zoom_range=0.2,                                 ❸\n        horizontal_flip=True,                           ❸\n        fill_mode='reflect',                            ❸\n        validation_split=0.1                            ❹\n)\nimage_gen = ImageDataGenerator(samplewise_center=False) ❺\n```", "```py\npartial_flow_func = partial(                                ❶\n        image_gen_aug.flow_from_directory, \n        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n        target_size=target_size, classes=None,\n        class_mode='categorical', batch_size=batch_size, \n        shuffle=True, seed=random_seed\n)\n\ntrain_gen = partial_flow_func(subset='training')            ❷\n\nvalid_gen = partial_flow_func(subset='validation')          ❸\n\ntest_df = get_test_labels_df(                               ❹\n        os.path.join('data','tiny-imagenet-200',  'val', \n➥ 'val_annotations.txt')\n)\ntest_gen = image_gen.flow_from_dataframe(                   ❺\n        test_df, directory=os.path.join('data','tiny-imagenet-200',  'val', \n➥ 'images'),\n        target_size=target_size, classes=None,\n        class_mode='categorical', batch_size=batch_size, shuffle=False\n)\n```", "```py\nimage_gen.flow_from_directory (\n    directory=<directory where the images are>, \n    target_size=<height and width or target image>, \n    classes=None,\n    class_mode=<type of targets generated such as one hot encoded, sparse, etc.>,\n    batch_size=<size of a single batch>, \n    shuffle=<whether to shuffle data or not>, \n    seed=<random seed to be used in shuffling>, \n    subset=<set to training or validation>\n)\n```", "```py\ndef data_gen_augmented_inceptionnet_v1(gen, random_gamma=False, \n➥ random_occlude=False):                                                  ❶\n    for x,y in gen: \n        if random_gamma:                                                   ❷\n            # Gamma correction\n            # Doing this in the image process fn doesn't help improve \n➥ performance\n            rand_gamma = np.random.uniform(0.9, 1.08, (x.shape[0],1,1,1))  ❸\n            x = x**rand_gamma                                              ❸\n\n        if random_occlude:                                                 ❹\n            # Randomly occluding sections in the image\n            occ_size = 10\n            occ_h, occ_w = np.random.randint(0, x.shape[1]-occ_size), \n➥ np.random.randint(0, x.shape[2]-occ_size)                               ❺\n            x[:,occ_h:occ_h+occ_size,occ_w:occ_w+occ_size,:] = \n➥ np.random.choice([0.,128.,255.])                                        ❻\n\n        # Image centering\n        x -= np.mean(x, axis=(1,2,3), keepdims=True)                       ❼\n\n        yield x,(y,y,y)                                                    ❽\n\ntrain_gen_aux = data_gen_augmented_inceptionnet_v1(\n    train_gen, random_gamma=True, random_occlude=True                      ❾\n)\nvalid_gen_aux = data_gen_augmented_inceptionnet_v1(valid_gen)              ❿\ntest_gen_aux = data_gen_augmented_inceptionnet_v1(test_gen)                ❿\n```", "```py\ndense1 = Dropout(0.7)(dense1)\n```", "```py\ndef aux_out(inp,name=None):    \n    avgpool1 = AvgPool2D((5,5), strides=(3,3), padding='valid')(inp)\n    conv1 = Conv2D(128, (1,1), activation='relu', padding='same')(avgpool1)\n    flat = Flatten()(conv1)\n    dense1 = Dense(1024, activation='relu')(flat) \n    dense1 = Dropout(0.7)(dense1)                     ❶\n    aux_out = Dense(200, activation='softmax', name=name)(dense1)\n    return aux_out\n```", "```py\nflat_out = Dropout(0.4)(flat_out)\n```", "```py\navgpool1 = AvgPool2D((7,7), strides=(1,1), padding='valid')(inc_5b)\n\nflat_out = Flatten()(avgpool1)\nflat_out = Dropout(0.4)(flat_out)\nout_main = Dense(200, activation='softmax', name='final')(flat_out)\n```", "```py\ndef get_steps_per_epoch(n_data, batch_size):\n    \"\"\" Given the data size and batch size, gives the number of steps to \n➥ travers the full dataset \"\"\"\n    if n_data%batch_size==0:\n        return int(n_data/batch_size)\n    else:\n        return int(n_data*1.0/batch_size)+1\n```", "```py\n# Create a directory called eval which stores model performance\nif not os.path.exists('eval'):\n    os.mkdir('eval')\n# Logging the performance metrics to a CSV file\ncsv_logger = CSVLogger(os.path.join('eval','2_eval_data_aug_early_stopping.log'))\n```", "```py\n# Early stopping callback\nes_callback = EarlyStopping(monitor='val_loss', patience=5)\n```", "```py\nhistory = model.fit(\n    train_gen_aux, validation_data=valid_gen_aux, \n    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)),batch_size),\n    validation_steps=get_steps_per_epoch(int(0.1*(500*200)),batch_size),\n    epochs=50, callbacks=[es_callback, csv_logger]\n)\n```", "```py\nTrain for 703 steps, validate for 78 steps\nEpoch 1/50\nWARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, \n➥ dropout() uses dropout rate instead of keep_prob. Please ensure that \n➥ this is intended.                                                      ❶\nWARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, \n➥ dropout() uses dropout rate instead of keep_prob. Please ensure that \n➥ this is intended.                                                      ❶\nWARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, \n➥ dropout() uses dropout rate instead of keep_prob. Please ensure that \n➥ this is intended.                                                      ❶\n703/703 [==============================] - 196s 279ms/step - loss: 15.4462 \n➥ - final_loss: 5.1507 - aux1_loss: 5.1369 - aux2_loss: 5.1586 - \n➥ final_accuracy: 0.0124 - aux1_accuracy: 0.0140 - aux2_accuracy: 0.0119 \n➥ - val_loss: 14.8221 - val_final_loss: 4.9696 - val_aux1_loss: 4.8943 - \n➥ val_aux2_loss: 4.9582 - val_final_accuracy: 0.0259 - val_aux1_accuracy: \n➥ 0.0340 - val_aux2_accuracy: 0.0274\n...\nEpoch 38/50\n703/703 [==============================] - 194s 276ms/step - loss: \n➥ 9.4647 - final_loss: 2.8825 - aux1_loss: 3.3037 - aux2_loss: 3.2785 - \n➥ final_accuracy: 0.3278 - aux1_accuracy: 0.2530 - aux2_accuracy: 0.2572 \n➥ - val_loss: 9.7963 - val_final_loss: 3.1555 - val_aux1_loss: 3.3244 - \n➥ val_aux2_loss: 3.3164 - val_final_accuracy: 0.2940 - val_aux1_accuracy: \n➥ 0.2599 - val_aux2_accuracy: 0.2590\n```", "```py\nmodel = tf.keras.models.Sequential([\ntf.keras.layers.Dense(100, activation=’relu’, input_shape=(250,)),\ntf.keras.layers.Dropout(0.5), \ntf.keras.layers.Dense(10, activation=’softmax’)\n])\nmodel.compile\n    (loss=’categorical_crossentropy’, optimizer=’adam’, metrics=[‘accuracy’])\nmodel.fit(X, y, epochs=25)\n```", "```py\ndense1_bn = BatchNormalization()(dense1)\n```", "```py\ndef stem(inp, activation='relu', bn=True):                              ❶\n\n    conv1_1 = Conv2D(\n        32, (3,3), strides=(2,2), activation=None,                      ❷\n        kernel_initializer=init, padding='same'\n    )(inp) #62x62\n    if bn:\n        conv1_1 = BatchNormalization()(conv1_1)                         ❸\n    conv1_1 = Activation(activation)(conv1_1)                           ❹\n\n    conv1_2 = Conv2D(\n        32, (3,3), strides=(1,1), activation=None,                      ❷\n        kernel_initializer=init, padding='same'\n    )(conv1_1) # 31x31\n    if bn:\n        conv1_2 = BatchNormalization()(conv1_2)\n    conv1_2 = Activation(activation)(conv1_2)\n\n    conv1_3 = Conv2D(\n        64, (3,3), strides=(1,1), activation=None,                      ❷\n           kernel_initializer=init, padding='same'\n       )(conv1_2) # 31x31\n    if bn:\n        conv1_3 = BatchNormalization()(conv1_3)\n    conv1_3 = Activation(activation)(conv1_3)\n\n    maxpool2_1 = MaxPool2D((3,3), strides=(2,2), \n➥ padding='same')(conv1_3)                                             ❺\n\n    conv2_2 = Conv2D(\n        96, (3,3), strides=(2,2), activation=None,\n        kernel_initializer=init, padding='same'\n    )(conv1_3)                  \n    if bn:\n        conv2_2 = BatchNormalization()(conv2_2)\n    conv2_2 = Activation(activation)(conv2_2)                           ❺\n\n    out2 = Concatenate(axis=-1)([maxpool2_1, conv2_2])                  ❻\n\n    conv3_1 = Conv2D(\n        64, (1,1), strides=(1,1), activation=None, \n        kernel_initializer=init, padding='same'\n    )(out2)                                                             ❼\n    if bn:\n        conv3_1 = BatchNormalization()(conv3_1)\n    conv3_1 = Activation(activation)(conv3_1)\n\n    conv3_2 = Conv2D(\n        96, (3,3), strides=(1,1), activation=None, \n        kernel_initializer=init, padding='same'\n    )(conv3_1)                                                          ❼\n    if bn:\n        conv3_2 = BatchNormalization()(conv3_2)\n    conv3_2 = Activation(activation)(conv3_2)\n\n    conv4_1 = Conv2D(\n        64, (1,1), strides=(1,1), activation=None, \n        kernel_initializer=init, padding='same'\n    )(out2)                                                             ❽\n    if bn:\n        conv4_1 = BatchNormalization()(conv4_1)\n    conv4_1 = Activation(activation)(conv4_1)\n\n    conv4_2 = Conv2D(\n        64, (7,1), strides=(1,1), activation=None, \n        kernel_initializer=init, padding='same'\n    )(conv4_1)                                                          ❽\n    if bn:\n        conv4_2 = BatchNormalization()(conv4_2)\n\n    conv4_3 = Conv2D(\n        64, (1,7), strides=(1,1), activation=None, \n        kernel_initializer=init, padding='same'\n    )(conv4_2)                                                          ❽\n    if bn:\n        conv4_3 = BatchNormalization()(conv4_3)\n    conv4_3 = Activation(activation)(conv4_3)\n\n    conv4_4 = Conv2D(\n        96, (3,3), strides=(1,1), activation=None, \n        kernel_initializer=init, padding='same'\n    )(conv4_3)                                                          ❽\n    if bn:\n        conv4_4 = BatchNormalization()(conv4_4)\n    conv4_4 = Activation(activation)(conv4_4)\n\n    out34 = Concatenate(axis=-1)([conv3_2, conv4_4])                    ❾\n\n    maxpool5_1 = MaxPool2D((3,3), strides=(2,2), padding='same')(out34) ❿\n    conv6_1 = Conv2D(\n        192, (3,3), strides=(2,2), activation=None,       \n        kernel_initializer=init, padding='same'\n    )(out34)                                                            ❿\n    if bn:\n        conv6_1 = BatchNormalization()(conv6_1)\n    conv6_1 = Activation(activation)(conv6_1)\n\n    out56 = Concatenate(axis=-1)([maxpool5_1, conv6_1])                 ❿\n\n    return out56\n```", "```py\nfrom tensorflow.keras.layers import Dense, Input, Add\n\ninp = Input(shape=(10,))\nd1 = Dense(20, activation='relu')(inp)\nd2 = Dense(20, activation='relu')(d1)\nd3 = Dense(20, activation='relu')(d2)\n```", "```py\nd4 = d3 + d1\n```", "```py\nd4 = Add()([d3, d1])\n```", "```py\ninp = Input(shape=(10,))\nd1 = Dense(20, activation='relu')(inp)\nd2 = Dense(20, activation='relu')(d1)\nd3 = Dense(30, activation='relu')(d2)\nd4 = Add()([d3, d1])\n```", "```py\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n...\n----> d4 = Add()([d3, d1])\n...\nValueError: Operands could not be broadcast together with shapes (30,) (20,)\n```", "```py\ninp = Input(shape=(10,))\nd1 = Dense(20, activation='relu')(inp)\nd2 = Dense(20, activation='relu')(d1)\nd3 = Dense(20, activation='relu')(d2)\nd4 = Add()([d3, d1])\n```", "```py\ndef inception_resnet_a(inp, n_filters, initializer, activation='relu', \n➥ bn=True, res_w=0.1):\n    out1_1 = Conv2D(\n        n_filters[0][0], (1,1), strides=(1,1), \n➥ activation=None, \n        kernel_initializer=initializer, \n➥ padding='same'\n    )(inp)                                                        ❶\n    if bn:\n        out1_1 = BatchNormalization()(out1_1)\n    out1_1 = Activation(activation)(out1_1)                       ❶\n\n    out2_1 = Conv2D(\n        n_filters[1][0], (1,1), strides=(1,1), \n➥ activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(inp)                                                        ❷\n    if bn:\n        out2_1 = BatchNormalization()(out2_1)\n    out2_1 = Activation(activation)(out2_1)                       ❷\n\n    out2_2 = Conv2D(\n        n_filters[1][1], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out2_1)                                                     ❷\n    if bn:\n        out2_2 = BatchNormalization()(out2_2)\n    out2_2 = Activation(activation)(out2_2)                       ❷\n\n    out2_3 = Conv2D(\n        n_filters[1][2], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out2_2)                                                     ❷\n\n    out3_1 = Conv2D(\n        n_filters[2][0], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(inp)                                                        ❸\n    if bn:\n        out3_1 = BatchNormalization()(out3_1)\n    out3_1 = Activation(activation)(out3_1)                       ❸\n\n    out3_2 = Conv2D(\n        n_filters[2][1], (3,3), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out3_1)                                                     ❸\n    if bn:\n        out3_2 = BatchNormalization()(out3_2)\n    out3_2 = Activation(activation)(out3_2)                       ❸\n\n    out3_3 = Conv2D(\n        n_filters[2][2], (3,3), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out3_2)                                                     ❸\n    if bn:\n        out3_3 = BatchNormalization()(out3_3)\n    out3_3 = Activation(activation)(out3_3)                       ❸\n\n    out3_4 = Conv2D(\n        n_filters[2][3], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out3_3)                                                     ❸\n    if bn:\n        out3_4 = BatchNormalization()(out3_4)\n    out3_4 = Activation(activation)(out3_4)                       ❸\n\n    out4_1 = Concatenate(axis=-1)([out1_1, out2_2, out3_4])       ❹\n    out4_2 = Conv2D(\n        n_filters[3][0], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out4_1)\n    if bn:\n        out4_2 = BatchNormalization()(out4_2)                               \n\n    out4_2 += res_w * inp                                         ❺\n    out4_2 = Activation(activation)(out4_2)                       ❺\n\n        return out4_2\n```", "```py\ndef inception_resnet_b(inp, n_filters, initializer, activation='relu', \n➥ bn=True, res_w=0.1):\n    out1_1 = Conv2D(\n        n_filters[0][0], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(inp)\n    if bn:\n        out1_1 = BatchNormalization()(out1_1) \n    out1_1 = Activation(activation)(out1_1)                      ❶\n\n    out2_1 = Conv2D(\n        n_filters[1][0], (1,1), strides=(1,1), activation=activation, \n        kernel_initializer=initializer, padding='same'\n    )(inp)\n    if bn:\n        out2_1 = BatchNormalization()(out2_1)\n    out2_1 = Activation(activation)(out2_1)                      ❷\n\n    out2_2 = Conv2D(\n        n_filters[1][1], (1,7), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out2_1)\n    if bn:\n        out2_2 = BatchNormalization()(out2_2)\n    out2_2 = Activation(activation)(out2_2)                      ❷\n\n    out2_3 = Conv2D(\n        n_filters[1][2], (7,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out2_2)\n    if bn:\n        out2_3 = BatchNormalization()(out2_3)\n    out2_3 = Activation(activation)(out2_3)                      ❷\n\n    out3_1 = Concatenate(axis=-1)([out1_1, out2_3])              ❸\n    out3_2 = Conv2D(\n        n_filters[2][0], (1,1), strides=(1,1), activation=None, \n        kernel_initializer=initializer, padding='same'\n    )(out3_1)\n    if bn:\n        out3_2 = BatchNormalization()(out3_2)                    ❹\n\n    out3_2 += res_w * inp                                        ❺\n    out3_2 = Activation(activation)(out3_2)\n\n    return out3_2\n```", "```py\ndef reduction(inp, n_filters, initializer, activation='relu', bn=True):\n    # Split to three branches\n    # Branch 1\n    out1_1 = Conv2D(\n        n_filters[0][0], (3,3), strides=(2,2), \n        kernel_initializer=initializer, padding='same'\n    )(inp)  \n    if bn:\n        out1_1 = BatchNormalization()(out1_1)\n    out1_1 = Activation(activation)(out1_1)                         ❶\n\n    out1_2 = Conv2D(\n        n_filters[0][1], (3,3), strides=(1,1), \n        kernel_initializer=initializer, padding='same'\n    )(out1_1)\n    if bn:\n        out1_2 = BatchNormalization()(out1_2)\n    out1_2 = Activation(activation)(out1_2)                         ❶\n\n    out1_3 = Conv2D(\n        n_filters[0][2], (3,3), strides=(1,1), \n        kernel_initializer=initializer, padding='same'\n    )(out1_2)\n    if bn:\n        out1_3 = BatchNormalization()(out1_3)\n    out1_3 = Activation(activation)(out1_3)                         ❶\n\n    # Branch 2\n    out2_1 = Conv2D(\n        n_filters[1][0], (3,3), strides=(2,2), \n        kernel_initializer=initializer, padding='same'\n    )(inp)\n    if bn:\n        out2_1 = BatchNormalization()(out2_1)\n    out2_1 = Activation(activation)(out2_1)                         ❷\n\n    # Branch 3\n    out3_1 = MaxPool2D((3,3), strides=(2,2), padding='same')(inp)   ❸\n\n    # Concat the results from 3 branches\n    out = Concatenate(axis=-1)([out1_3, out2_1, out3_1])            ❹\n\n    return out\n```", "```py\ninp = Input(shape=(64,64,3))\n```", "```py\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop, \n➥ RandomContrast\n# Cropping the image to a 56x56 sized image\ncrop_inp = RandomCrop(56, 56, seed=random_seed)(inp)\n# Provide a random contrast between 0.7 and 1.3 where 1.0 is the original \n➥ contrast\ncrop_inp = RandomContrast(0.3, seed=random_seed)(crop_inp)\n```", "```py\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, \n➥ AvgPool2D, Dense, Concatenate, Flatten, BatchNormalization, Activation\n➥ from tensorflow.keras.layers.experimental.preprocessing import RandomCrop, \n➥ RandomContrast\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n\ninp = Input(shape=(64,64,3))                                       ❶\n\ncrop_inp = RandomCrop(56, 56, seed=random_seed)(inp)               ❷\ncrop_inp = RandomContrast(0.3, seed=random_seed)(crop_inp)         ❸\n\nstem_out = stem(crop_inp)                                          ❹\n\ninc_a = inception_resnet_a(stem_out, [(32,),(32,32), (32, 48, 64, \n➥ 384),(384,)], initializer=init)                                 ❺\n\nred = reduction(inc_a, [(256,256,384),(384,)], initializer=init)   ❻\n\ninc_b1 = inception_resnet_b(red, [(192,),(128,160,192),(1152,)], \n➥ initializer=init)                                               ❼\ninc_b2 = inception_resnet_b(inc_b1,  [(192,),(128,160,192),(1152,)], \n➥ initializer=init)                                               ❼\n\navgpool1 = AvgPool2D((4,4), strides=(1,1), padding='valid')(inc_b2)\nflat_out = Flatten()(avgpool1)\ndropout1 = Dropout(0.5)(flat_out)\nout_main = Dense(200, activation='softmax',  kernel_initializer=init, \n➥ name='final')(flat_out)                                         ❽\n\nminception_resnet_v2 = Model(inputs=inp, outputs=out_main)         ❾\nminception_resnet_v2.compile(loss=’categorical_crossentropy’, \n➥ optimizer='adam', metrics=['accuracy'])                         ❿\n```", "```py\nimport time\nfrom tensorflow.keras.callbacks import EarlyStopping, CSVLogger\nfrom functools import partial\n\nn_epochs=50\n\nes_callback = EarlyStopping(monitor='val_loss', patience=10)              ❶\ncsv_logger = CSVLogger(os.path.join('eval','3_eval_minception.log'))      ❷\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'    ❸\n)\n\nhistory = model.fit(                                                      ❹\n    train_gen_aux, validation_data=valid_gen_aux, \n    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size),\n    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n    epochs=n_epochs, \n    callbacks=[es_callback, csv_logger, lr_callback]\n)\n```", "```py\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'\n)\n```", "```py\nTrain for 703 steps, validate for 78 steps\nEpoch 1/50\n703/703 [==============================] - 158s 224ms/step - loss: 4.9362 - \n➥ accuracy: 0.0544 - val_loss: 13.1802 - val_accuracy: 0.0246\n...\nEpoch 41/50\n702/703 [============================>.] - ETA: 0s - loss: 2.5830 - \n➥ accuracy: 0.6828\nEpoch 00041: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n703/703 [==============================] - 136s 194ms/step - loss: 2.5831 - \n➥ accuracy: 0.6827 - val_loss: 3.4446 - val_accuracy: 0.4316\n...\nEpoch 47/50\n702/703 [============================>.] - ETA: 0s - loss: 2.3371 - \n➥ accuracy: 0.7859\nEpoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n703/703 [==============================] - 139s 197ms/step - loss: 2.3372 - \n➥ accuracy: 0.7859 - val_loss: 3.2988 - val_accuracy: 0.4720\n...\nEpoch 50/50\n703/703 [==============================] - 137s 194ms/step - loss: 2.3124 - \n➥ accuracy: 0.7959 - val_loss: 3.3133 - val_accuracy: 0.4792\n```", "```py\nif not os.path.exists('models'):\n    os.mkdir(\"models\")\nmodel.save(os.path.join('models', 'minception_resnet_v2.h5'))\n```", "```py\n# Load the model from disk\nmodel = load_model(os.path.join('models','minception_resnet_v2.h5'))\n\n# Evaluate the model\ntest_res = model.evaluate(test_gen_aux, steps=get_steps_per_epoch(500*50, \n➥ batch_size))\n```", "```py\ndef my_conv_block(input, activation): \n    out_1 = tf.keras.layers.Conv2D(n_filters[0][2], (3,3), strides=(1,1), \n                    kernel_initializer=initializer, padding='same')(input)\n    out_final = tf.keras.layers.BatchNormalization()(out_1)\n    out_final = tf.keras.layers.Activation(activation)(out_final)\n    return out_final  \n```", "```py\n    InceptionResNetV2(include_top=False, pooling='avg')\n```", "```py\nfrom tensorflow.keras.applications import InceptionResNetV2   ❶\nfrom tensorflow.keras.models import Sequential                ❶\nfrom tensorflow.keras.layers import Input, Dense, Dropout     ❶\n\nmodel = Sequential([\n    Input(shape=(224,224,3)),                                 ❷\n    InceptionResNetV2(include_top=False, pooling='avg'),      ❸\n    Dropout(0.4),                                             ❹\n    Dense(200, activation='softmax')                          ❺\n])\n\nadam = tf.keras.optimizers.Adam(learning_rate=0.0001)         ❻\nmodel.compile(loss=’categorical_crossentropy’, optimizer=adam, \n➥ metrics=['accuracy'])\nmodel.summary()\n```", "```py\ndef get_train_valid_test_data_generators(batch_size, target_size):\n\n    image_gen_aug = ImageDataGenerator(\n        samplewise_center=False, rotation_range=30, width_shift_range=0.2,\n        height_shift_range=0.2, brightness_range=(0.5,1.5), shear_range=5, \n        zoom_range=0.2, horizontal_flip=True, validation_split=0.1\n    )                                                         ❶\n    image_gen = ImageDataGenerator(samplewise_center=False)   ❶\n\n    partial_flow_func = partial(                              ❷\n        image_gen_aug.flow_from_directory, \n        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n        target_size=target_size,                              ❸\n        classes=None,\n        class_mode='categorical', \n        interpolation='bilinear',                             ❹\n        batch_size=batch_size, \n        shuffle=True, \n        seed=random_seed)                                        \n\n    # Get the training data subset\n    train_gen = partial_flow_func(subset='training')          ❺\n    # Get the validation data subset\n    valid_gen = partial_flow_func(subset='validation')        ❺\n\n    # Defining the test data generator\n    test_df = get_test_labels_df(os.path.join('data','tiny-imagenet-200',  \n➥ 'val', 'val_annotations.txt'))                             ❻\n    test_gen = image_gen.flow_from_dataframe(\n        test_df, \n        directory=os.path.join('data','tiny-imagenet-200',  'val', 'images'), \n        target_size=target_size,                              ❼\n        classes=None,\n        class_mode='categorical', \n        interpolation='bilinear',                             ❼\n        batch_size=batch_size,  \n        shuffle=False\n    )\n    return train_gen, valid_gen, test_gen\n\nbatch_size = 32                                               ❽\ntarget_size = (224,224)                                       ❽\n\n# Getting the train,valid, test data generators\ntrain_gen, valid_gen, test_gen = \n➥ get_train_valid_test_data_generators(batch_size, target_size)\n\ntrain_gen_aux = data_gen_augmented(train_gen, random_gamma=True, \n➥ random_occlude=True)                                       ❾\n\nvalid_gen_aux = data_gen_augmented(valid_gen)                 ❾\ntest_gen_aux = data_gen_augmented(test_gen)                   ❾\n```", "```py\nfrom tensorflow.keras.callbacks import EarlyStopping, CSVLogger\nes_callback = EarlyStopping(monitor='val_loss', patience=10)\ncsv_logger = CSVLogger(os.path.join('eval','4_eval_resnet_pretrained.log'))\nn_epochs=30\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'\n)\n\nhistory = model.fit(\n    train_gen_aux, validation_data=valid_gen_aux, \n    steps_per_epoch=int(0.9*(500*200)/batch_size), validation_steps=int(0.1*(500*200)/batch_size),\n    epochs=n_epochs, callbacks=[es_callback, csv_logger, lr_callback]\n)\n```", "```py\nEpoch 1/50\n2813/2813 [==============================] - 1465s 521ms/step - loss: \n➥ 2.0031 - accuracy: 0.5557 - val_loss: 1.5206 - val_accuracy: 0.6418\n...\nEpoch 23/50\n2813/2813 [==============================] - ETA: 0s - loss: 0.1268 - \n➥ accuracy: 0.9644\nEpoch 00023: ReduceLROnPlateau reducing learning rate to \n➥ 9.999999974752428e-08.\n2813/2813 [==============================] - 1456s 518ms/step - loss: \n➥ 0.1268 - accuracy: 0.9644 - val_loss: 1.2681 - val_accuracy: 0.7420\n```", "```py\n# Evaluate the model\ntest_res = model.evaluate(test_gen_aux, steps=get_steps_per_epoch(500*50, \n➥ batch_size))\n```", "```py\nDefine: model (Trained Inception Resnet V2 model)\nDefine: probe_ds (A list of image, class(integer) tuples e.g. [(image, \n➥ class-int), (image, class-int), ...]) that we will use to interpret the model\nDefine: last_conv (Last convolution layer of the model - closest to the \n➥ prediction layer)\nLoad the model (inceptionnet_resnet_v2.h5)\n\nFor img, cls in probe_ds:\n\n    # Computing the gradient map and its associated weights\n    Compute the model’s final output (out) and last_conv layer’s output \n➥ (conv_out)\n    Compute the gradient d (out[cls]) / d (conv_out) and assign to grad\n    Compute channel weights by taking the mean of grad over width and \n➥ height dimensions (Results in a [batch size(=1), 1, 1, # channels in \n➥ last_conv] tensor)\n\n    # Creating the final gradient heatmap\n    grad = grad * weights # Multiply grad with weights\n    grad = tf.reduce_sum(grad, axis=-1) # Take sum over channels\n    grad = tf.nn.relu(grad) # Apply ReLU activation to obtain the gradient \n➥ heatmap\n\n    # Visualizing the gradient heatmap\n    Resize the gradient heatmap to a size of 224x224\n    Superimpose the gradient heatmap on the original image (img)\n    Plot the image and the image with the gradient heatmap superimposed \n➥ side by side\n```", "```py\n    model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(100, activation=’relu’, input_shape=(250,)), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(10, activation=’softmax’)\n    ])\n    model.compile(loss=’categorical_crossentropy’, optimizer=’adam’, \n    ➥ metrics=[‘accuracy’])\n    model.fit(X, y, epochs=25)\n    ```", "```py\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n    ➥ patience=5, min_delta=0.1)\n    model.fit(X, y, epochs=25, callbacks=[es_callback])\n    ```", "```py\ntf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5)\n```", "```py\ndef my_conv_block(input, activation): \n    out_1 = tf.keras.layers.Conv2D(n_filters[0][2], (3,3), strides=(1,1), \n                   kernel_initializer=initializer, activation=activation,\n                   padding='same')(input)\n\n    out_final = tf.keras.layers.BatchNormalization()(out_1)\n\n    out = out_final + out_1 \n    return out\n\n```", "```py\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=(224,224,3)),                                      \n    tf.keras.applications.VGG16(include_top=False, pooling='max'),\n    tf.keras.layers.Dense(100, activation=’relu’),                    \n    tf.keras.layers.Dense(50, activation='softmax') \n])\n```"]