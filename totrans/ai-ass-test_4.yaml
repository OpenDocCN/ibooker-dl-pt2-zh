- en: 4 AI-assisted testing for developers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Developing unit tests and production code with GitHub Copilot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing unit tests and production code with ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: According to a poll on dev ecosystems by JetBrains in 2022, 81% of respondents
    have a developer-to-QA ratio that is greater than 1-to-1\. Forty percent reported
    that they had “less than 1 QA per 10 developers,” and only 1% reported that they
    had “more QAs than developers.” (The poll can be found at [www.jetbrains.com/lp/devecosystem-2022/testing](devecosystem-2022.html).)
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and building in quality is essential to delivering value to our
    users, yet the ratio between development and testing is nearly always imbalanced,
    and for many reasons. Some organizational leaders choose to educate developers
    to build in quality with the support of quality coaches, and others simply don’t
    want to invest in roles that advocate for testing and quality. Either way, this
    situation puts pressure on everyone on a team to deliver high-quality applications.
    So how can AI tools help relieve this pressure?
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll focus specifically on how large language model (LLM)
    AIs, such as GitHub Copilot and ChatGPT, can help us developers build quality
    into our work. Rather than think of these AI tools as replacements for developers
    and testers, we’ll learn how they can guide us as we carry out activities that
    build in quality as we develop—as well as demonstrate how we can use AI tools
    to steer the direction toward improving quality and identifying risks when testing
    is a limited resource to take advantage of.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Examining the rise of the automated developer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In April of 2023, Similarweb, a market competition analysis company, reported
    that Stack Overflow’s traffic in the preceding month had dropped by 14%. The cause,
    according to Similarweb, was a rise in developers switching from Stack Overflow
    to tools such as GitHub’s Copilot and ChatGPT. (You can read the article at [www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt](ai-news.html)).
    Whether this is a sign of an ongoing trend of developers jumping ship or an anomaly
    that will eventually balance out, reports like this one demonstrate the sweeping
    changes that LLM-based AI tools (LLMs) are introducing to the role of a developer.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a tester, it’s an interesting change to witness. For many years, as test
    automation tools became more advanced, I would have discussions with developers
    about whether testing could be replaced by automated testing tools. Now, with
    LLMs that are trained against billions of lines of code from public and private
    repositories, conversations have turned toward whether developer roles can be
    automated. For example, a tool like ChatGPT can be sent a prompt such as this
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'and it will then use its billions of trained weights and balances to return
    a working code example like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: From just one basic prompt we can use LLMs to create workable code (updating
    the `apiUrl` to a real API returned a positive result). So it’s not surprising
    that there are tools appearing that combine prompts attempting to automate development
    work. Tools like [AutoGPT](Significant-Gravitas.html) and [MetaGPT](geekan.html)
    have appeared that work as autonomous agents, generating their own prompts based
    on initial questions to solve complex problems. Though these tools are in their
    infancy, it’s clear to see why the more hyperbolic claims of developers being
    automated out of their role are bandied about.
  prefs: []
  type: TYPE_NORMAL
- en: As someone who has spent much of his career explaining why test automation doesn’t
    serve as a suitable replacement, it’s tempting to enjoy the schadenfreude of seeing
    developers defending their roles in the same way, but instead it’s more valuable
    to learn from the experiences of testers and the topic of automation. Just as
    a tester’s role can’t be automated fully, neither can a developer’s role. A development
    role is more than just the code that is produced. The solutions that developers
    create are a product of analytical skills, problem-solving, and design thinking.
    These are skills that LLM tools give the impression of being capable of, but currently
    they are not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, developers find success with LLM tools by using them to enhance their
    own abilities, using tools like Copilot to quickly and effectively create code
    that they want built, or seeking advice from ChatGPT to solve issues or learn
    new APIs. These principles can also be applied to improving a developer’s ability
    to build quality into an application. By combining techniques such as test-driven
    design (TDD) or pairing with the power of LLMs, developers can increase their
    productivity while ensuring that their analytical and design skills lead the charge.
    To help demonstrate this symbiosis, let’s explore two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Using Copilot to rapidly generate unit checks and production code for TDD loops
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emulating pairing with a simulated developer, courtesy of ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Through these examples, we’ll learn to set up and use these LLM tools as well
    as appreciate the balance we can strike between the power of AI and the abilities
    of developers.
  prefs: []
  type: TYPE_NORMAL
- en: Experiences may vary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Given that Copilot relies on predictive algorithms that are frequently being
    trained on newly added code and updated APIs/libraries, it’s worth highlighting
    that the output and experience you have when following the upcoming examples may
    be different from what has been recorded. Keep in mind that the goal of this chapter
    is not to replicate the examples in this chapter 100%, but rather to become comfortable
    with using LLMs to assist our work in a way that helps us build in quality.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Pairing with LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve already spent time understanding that LLMs are probabilistic in nature,
    and as a result it can be useful to think of them as outputting simulations of
    roles, rather than inhabiting specific roles. An LLM has no more awareness of
    being a software tester than it does as a restauranteur. But with prompt engineering
    we can create prompts that frame an LLM’s probabilistic output to simulate a role,
    helping us to create rubber ducks to interact with. This can be useful in a development
    capacity when testing resources are limited in either availability or capability.
    So let’s take a look at a couple of sample prompts we can use to elicit feedback
    that can help us improve the quality of our work and our products.
  prefs: []
  type: TYPE_NORMAL
- en: Wait, what—rubber duck?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'When faced with a problem that we have no solution for, it can help to verbalize
    the problem to others to find an answer. By articulating the problem to another
    person, we sometimes experience that the solution presents itself to us. However,
    there isn’t always an opportunity to speak with colleagues; therefore; some developers
    will verbalize their issues to a rubber duck (or another item). Although we’re
    sharing our challenges with an inanimate object, the experience is the same: Verbalizing
    our challenges tricks our brains into finding solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Analyzing ideas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our first prompt is inspired by the shift-left mindset that some teams apply
    to help build quality into applications as early as possible. *Shift-left* means
    bringing testing analysis earlier into the development process, ideally around
    the point at which ideas are being discussed and details are being clarified.
    This process results in many questions being asked that help us to identify issues
    earlier, deliver valuable features, and improve the quality of our products. Shift-left
    activities are an invaluable for improving quality and should be encouraged regardless
    of the use of AI in the development process. But it doesn’t mean we can’t also
    use prompts to generate questions that might reveal assumptions or misunderstandings—or
    questions that we can simply disregard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a sample prompt that can be used to rapidly generate questions
    that might be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The prompt outlines instructions for an LLM to analyze a user story and acceptance
    criteria and return a list of questions for us to consider. Notice how we also
    provide context in the quality characteristics instruction. If we want to focus
    on different characteristics, we can update these as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Entering this prompt into ChatGPT returned the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Reading through the response, we can see that there is an interesting collection
    of questions ranging in quality. For example, consider this question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This is a helpful question that encourages us to consider in more detail the
    statement `Guests are asked to create an account to make a booking`, found in
    our user story. We could consider this question and think about how we would design
    the booking process to make it accessible for all types of users.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, other questions are perhaps not quite as good. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: What makes this question problematic is its reference to the quality characteristic
    `accuracy`. Typically, accuracy would be more focused on the accuracy of data
    that is processed or stored (think bank interest rate calculations). Instead,
    the phrase “accuracy of user access” feels like an odd way to describe the rules
    set around users and what they can access. Ultimately, it’s up to us to evaluate
    each question for suitability and use. Some questions can encourage us to build
    products that are more closely aligned with what a user wants and help us avoid
    errors—whereas other generated questions will either make little sense or cover
    topics already considered.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll come back to this prompt and how we might use it during the development
    of a feature, but first let’s look at how we can repurpose this prompt to review
    our code.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Analyzing code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Just as we can prompt an LLM to analyze written-down ideas, we can also have
    it review code and help us to identify risks. Using this prompt is akin to simulating
    the role of a developer or tester that you are pairing with, by having them analyze
    your work as you develop to offer suggestions for consideration. Let’s look at
    a prompt that could be of use for this type of activity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After I sent the prompt with the sample code and quality characteristics to
    ChatGPT, the following output was returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the previous prompt, which generated questions around written requirements,
    the quality of these different risks varies. For example, the risk `Performance
    - Message Posting` feels quite abstract, as we can see in its explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Suggesting risks around network communication or I/O operations feels vague
    because it might refer to a range of implementations, some of which might relate
    to our work and some that might not.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, other risks are more concrete and potentially useful—for example,
    `Security - Inadequate Authorization` in which it highlights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This risk feels more concrete because it refers to actions that are carried
    out in our method, and the absence of potentially important checks within it.
    Of course, we may carry out authorization checks elsewhere, but using the information
    it has given, it’s highlighted an explicit activity that we might need to discuss
    further to improve the security of our booking feature.
  prefs: []
  type: TYPE_NORMAL
- en: Generating more ideas
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: So far, we’ve looked at singular prompts to send to LLMs, which gives us useful
    responses to review. But what if we want to solicit more questions and risks?
    We simply ask by submitting an additional prompt, such as “Generate me more questions”
    or “Identify further risks.” Be wary, though, as this has diminishing returns.
    An LLM will try to fulfill our requests at the risk of increasing hallucinations.
    So, as options start to dry out, we may see more suggestions that are less and
    less connected to the ideas and code we wanted feedback on in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3 Recognizing that a simulation is better than nothing at all
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When testing is discussed, the focus typically tends to be on the production
    and execution of test cases. But a highly trained and experienced tester delivers
    value by using their critical and lateral thinking skills and asks questions that
    help us view solutions in new ways and reveal potential issues. The prompts we’ve
    looked at can offer a simulation of that process. But it’s important to remember
    that LLMs don’t have these critical and lateral thinking skills and that the questions
    and risks generated come from the instruction of our prompts. Instead, these types
    of prompts can offer a lightweight way to simulate the experience of pairing with
    testers or other developers when the opportunity to pair is unavailable. The key
    is to develop an eye for generated questions to determine which are of use and
    which are not.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Building in quality with AI assistance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we’ve looked at prompts as singular activities, but now let’s turn our
    attention to how the prompts we’ve recently learnt and other LLM assistant tools
    can be used in conjunction with TDD to help us build in quality.
  prefs: []
  type: TYPE_NORMAL
- en: Though TDD is not strictly a testing activity when compared against other testing
    activities, TDD that is carried out correctly helps guide developers to build
    quality into our products. To recap, the process of TDD is to use unit checking
    tools to first create failing checks and then create just enough production code
    to make the check *pass* (and fix any other checks that may have failed). Once
    all our checks are passing, we can refactor our production code while ensuring
    all our checks are green. Once that is complete, we start the loop again until
    our work is complete, as demonstrated in Figure 4.1.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 The red/green/refactor TDD cycle
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](images/04__image001.png)'
  prefs: []
  type: TYPE_IMG
- en: What’s all this about checks?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In our Automation in Testing training, Richard Bradshaw and I make a distinction
    between human-led testing and tool-led testing. We call the latter type *automated
    checking* because the tools can only assert explicit actions or data that we codify
    into our automation. This distinction helps us to better appreciate that automated
    tools like unit-checking frameworks are excellent at rapidly checking small, specific
    changes in a product, but are unable to tell us more about a system beyond its
    assertions. Humans, however, are slower and less deterministic in our testing,
    though we are much more efficient at identifying many events happening at the
    same time. Hence, this is why tools check and humans test. One is not better than
    the other, and, hopefully, this book demonstrates that we can have the best success
    when combining both.
  prefs: []
  type: TYPE_NORMAL
- en: This approach enables us to design products that are highly testable while ensuring
    we deliver what the business or end user desires.
  prefs: []
  type: TYPE_NORMAL
- en: Though its benefits are manifold, some developers find it hard to adopt the
    TDD approach because some believe that it slows down development as we create
    unit checks for each specific section of production code we add to our system.
    However, with the use of tools like Copilot, we can learn how to establish a balance
    in which the tools enable us to rapidly create unit checks and build in quality.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Creating our first TDD loop with LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To demonstrate, let’s undergo the process of creating part of a feature for
    a sample timesheet manager, which is described below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You can review the test and production code that was created as part of this
    example in the following GitHub repository: [https://github.com/mwinteringham/ai-assisted-testing/tree/main/chapter-4](main.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Copilot
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This chapter assumes that you have installed and configured the Copilot plugin
    within your IDE. If you haven’t already completed the setup process, you can find
    installation instructions in the appendix.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.1 Preparing the work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before starting to create my timesheet manager feature, I wanted to think about
    how I would go about building it. To help me with this process, and to encourage
    me to think about the solution from various angles, I took the first prompt we
    explored earlier in this chapter and entered my context into it. Specifically,
    I:'
  prefs: []
  type: TYPE_NORMAL
- en: Changed the quality characteristics to Accuracy and Consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Added the user story into the delimited section at the bottom of the prompt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this prompt to ChatGPT returned the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: What are quality characteristics?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Quality means very different things to different people and is a multifaceted
    concept. Therefore, when attempting to understand what quality means to a stakeholder
    or end user, we break out ways of thinking about it into different characteristics.
    For example, quality characteristics might include look and feel, usability, compliance,
    and much more. Different projects will have different quality characteristics
    that we prioritize, and it’s up to us as teams to identify what quality characteristics
    are a priority to us and our users.
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, I read through each of the questions sent back to me and noted the
    ones that stood out to me as raising points I hadn’t considered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: These two felt very similar to me, but they highlighted that I will, at some
    point, need to add date time handling into the code to prevent issues around invalid
    entries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It’s a good question, but not relevant to this work as I plan to just track
    the amount of time carried out and not when it was carried out (at least for now).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Connected to the previous question, I opted for simply tracking the amount of
    time that had elapsed and not specifically when it had occurred—meaning that the
    displaying of information is relatively straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: At this time, there is no multiple-user feature, though it might be introduced
    later, so I make a note of this to consider for future iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Many more questions could be asked and addressed, but what this process demonstrates
    is that, by generating different questions, I am required to think about various
    aspects of the design of this feature. Some I can choose to rule out, or shelve
    for later conversation, and some help me to improve the quality of my feature
    by raising my awareness to validation and date time formatting.
  prefs: []
  type: TYPE_NORMAL
- en: '4.4.2 Loop 1: Save a timesheet entry'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With the questions from the previous prompt in my mind, I start my first loop
    by creating an empty maven project within my IDE before heading to the `pom.xml`
    to add in my required dependencies. I require JUnit 5 to build my unit checks,
    so I entered the comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To be returned the suggested code block from Copilot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'At the time of writing the proposed version of `junit-jupiter-engine` is an
    older version so I update to `5.9.2` as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This required update is a good example of how data provenance can impact what
    is being suggested. Copilot, while constantly being trained on code that is being
    pushed to GitHub, runs the risk of lagging behind the latest versions of libraries
    and APIs. So we need to be vigilant when adding in dependencies via AI code assistants
    to ensure they are suggesting the version we want.
  prefs: []
  type: TYPE_NORMAL
- en: Also, what is demonstrated here is how the Copilot IDE plugin will take code
    (or in this case a code comment) I have written, add it to a prompt, and then
    send it to the Copilot LLM to process. The LLM then sends back to the IDE plugin
    a suggestion of what to enter next, and the plugin then presents me with the suggestion.
    I then have the option to either accept the suggestion by hitting Tab or continuing
    to write my own code.
  prefs: []
  type: TYPE_NORMAL
- en: Much like other LLMs, Copilot is triggered by prompts. But unlike a chat-based
    LLM (such as ChatGPT), Copilot is tuned to process code-based prompts rather than
    text-based prompts. This distinction is important to make because it highlights
    both the benefits of different types of fine-tuned LLMs for different activities
    as well as the need to write prompts that work for different types of prompts.
    This is why TDD and AI assistants are an interesting combination to work with.
    The unit checks we create not only frame the design of our work but also serve
    as prompts to inform how we want to implement features.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, for our first check, I prompt Copilot to create my first unit
    check for me by adding the following comment into a new class entitled `TimesheetTest`
    in `src/test/java`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at this suggested check, we see that it has the necessary details we
    require. It’s given the class I intend to build a sensible name of `Timesheet`
    and suggested the method `submitTimesheet` with the correct parameters of project
    name and hours. This check is enough of a prompt that when I create a new class
    `Timesheet` in `src/main/java`, Copilot suggests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The unit check served as a prompt to Copilot to create my production code and
    although what has been produced is not exactly exciting, the check has been fulfilled.
    We can also see that Copilot works by building prompts upon prompts to get to
    what we want. First I created a prompt in the form of a code comment to help Copilot
    suggest the code for the unit check, and then that unit check served as a prompt
    for the suggested production code. As the unit checks grow, so will the prompts
    and directions to Copilot on what to build. So now let’s look at how I used this
    process to build out the `submitTimesheet` method.
  prefs: []
  type: TYPE_NORMAL
- en: '4.4.3 Loop 2: Retrieve a timesheet entry'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With the first loop I created the skeleton of my project, but at the moment
    the actual production code bears little fruit. So with the second loop, I looked
    to add more features to the `Timesheet` class to help flesh out the `submitTimesheet`
    method. Again, I start by adding a new comment prompt to `TimesheetTest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'And upon creating a new line, Copilot returned the following check as a suggestion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the check created is using the `submitTimesheet` method to create
    some data that I can then check with the newly created `getTimesheets` method.
    So heading over to the `Timesheet` class, I use Copilot to generate the necessary
    `getTimesheets` method, which returns the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Though it’s helpful that it created the method signature for me, the internals
    of the method are not so useful. However, then I add the following to the top
    of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'and then return to the `submitTimesheet` method and remove `return true` from
    inside the method. When I enter the keyword `if` into the statement, Copilot returns
    the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This is a useful demonstration of how, when working with Copilot, a project
    requires a degree of warmup before the LLM can return more accurate suggestions.
    By returning to the `submitTimesheet` method, removing its contents, and then
    waiting for Copilot to respond, I get a refreshed response from Copilot based
    on the new details I’ve provided. Just as a prompt for a chat LLM requires a prompt
    with clear and explicit details, so too does Copilot. The initial stock methods
    that were returned from Copilot for `Timesheet` are likely because there is little
    context to work with. Essentially, the prompts sent to Copilot lack information.
    But as I create new unit checks and additional code to show our intent in our
    code, the suggestions become more useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is also demonstrated when I delete the `getTimesheets` method entirely.
    With the new `HashMap` added to the class, my updated code prompts Copilot to
    return an updated version of the method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Running both of my unit checks after this loop, I can see both checks are passing
    and I now have working code that is a bit more feature rich than when I started
    the loop.
  prefs: []
  type: TYPE_NORMAL
- en: '4.4.4 Loop 3: Calculating times for a project'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the final loop, I went back to the questions returned from ChatGPT and
    thought about the question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Though there is no functionality for multiple users at this point in the project,
    the question from ChatGPT did make me think about how to handle multiple timesheet
    submissions to the same project. So I created my third unit check to handle this
    scenario by once again creating a code comment to prompt Copilot for another unit
    check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Which returned me the following unit check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the suggested check is close, but I want the `Timesheet` class to
    return a total, not have a total processed within the unit check itself. So I
    opted to update the check to explicitly state there is a method for getting total
    timesheet hours:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Heading back over to `Timesheet` and waiting for Copilot, the LLM returns the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This allows the code to compile, but my new unit check fails because the project
    count isn’t being updated. Instead, because I am using a `HashMap`, the count
    is being overwritten. I need to update `submitTimesheet` to handle duplicate projects,
    which I do by dropping the following comment into `submitTimesheet` just after
    the initial if statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Which in the context of the `submitTimesheet` updates it to increase the duration
    of existing projects in a timesheet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: A final run of my three unit checks confirms that they are all passing and that
    I have all the features I want in my `Timesheet` class. However, the code is starting
    to become more complex, so I turn my attention to refactoring my code with the
    use of ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.5 Refactoring code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One benefit of pairing with others is the ability for a pair partner to see
    potential issues and risks that we might not see. However, in the absence of a
    pair partner, I chose to use the second of the prompts we explored earlier in
    this chapter—specifically, the prompt that analyzes code and returns suggestions.
    Taking the prompt from earlier and adding my code and the quality characteristics’
    accuracy and consistency, I sent this prompt to ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending the prompt returned the following risks that I might want to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike the questions prompt, this response appears to call out specific items
    of my code and gives reasons for how things might go wrong. With this response,
    I have the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: Review each risk on a case-by-case basis and then mitigate the ones I feel are
    important and ignore the others.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ignore the proposed risks entirely, or perhaps send another prompt to ChatGPT
    to see whether there are more risks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the response from ChatGPT as a prompt in and of itself to help me refactor
    my code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the purposes of this demonstration, I chose to go with the third option
    and send an additional prompt to ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how I used the time-to-think principle to get the LLM to check whether
    each risk has actually been mitigated by the refactored code it suggested. This
    helps increase the likelihood that the code that’s returned will be useful. Sending
    this prompt to ChatGPT returned the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: To check to see if these modifications hold up I copy the suggested code into
    `Timesheet`, modify `testCalculateTotalHoursWorked` to take a `long` instead of
    an `int` in `TimesheetTest` and discover that my checks still pass and I have
    refactored my code.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, has this actually improved my code? To confirm, I run the original
    code analysis prompt with my updated code again and this time receive new risks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'What is interesting in this response is I can confirm that some risks have
    been mitigated such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'But it appears that there are still some risks that haven’t. For example, in
    the first list of risks I received the following risk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Which was handled by ChatGPT implementing a `lowerCase` method to help sanitize
    the project name. However, on the second analysis I was returned the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This risk is very similar to the original, allegedly mitigated, risk. It feels
    like this additional risk around inconsistent data entry should have been handled
    properly when my code was refactored. I could once again ask the LLM to refactor
    my code for me, but instead given the potential for going round in circles with
    the LLM, it would be sensible for me to take the lead and fix the issues myself.
    This is an important skill to develop, when to rely on an LLM and when to take
    charge.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason this choice is important can be highlighted by one of the other
    suggested risks that came from the second round of analysis. Specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This sounds like a convincing risk, but it’s a demonstration of a hallucination.
    As the code stands, if the duration is 0 or less then method simply returns false
    and bails out of the timesheet storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: LLMs can be biased sometimes to prioritize giving an answer regardless of its
    quality. Meaning the more times we ask an LLM to analyze our code, the more likely
    it will start to generate hallucinations to give the impression that it’s producing
    useful results rather than returning with a response that no useful information
    can be shared. This is why we must keep careful tabs on when it’s useful to use
    an LLM and when it’s not.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, I chose to stop the use case as what we’ve covered demonstrates
    the way in which different types of LLMs can help me in different ways. Copilot
    offers the ability to rapidly generate code, but it requires code-based prompts
    to help it with its suggestions. The newer the project, the more likely we are
    to see hits and misses with Copilot, but we can aid this process through the use
    of unit checks. This helps not only guide Copilot in the building of our code,
    but gives us the benefits of TDD including well-designed, testable code.
  prefs: []
  type: TYPE_NORMAL
- en: With ChatGPT we’ve demonstrated that it can be a useful tool for analysis when
    prompted correctly. Building prompts that can analyze ideas and code and suggest
    risks and improvements can rapidly offer us alternative perspectives to consider,
    which we can then either action or reject. Utilizing the LLM as a simulation of
    role that advocates quality can help us to improve our work.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Improving documentation and communication with LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It might not seem so, but communicating the work we’ve done through code comments
    and release notes can be a big contributor to the quality of a product. By sharing
    new developments and changes to code bases, we can help fellow developers understand
    how our work impacts theirs, guide testers in what to focus on when testing our
    work, and even help how users view our products (For example, Slack’s early release
    notes helped market their tooling with their clear communication and humor).
  prefs: []
  type: TYPE_NORMAL
- en: Despite these benefits, documentation and release notes are sometimes left to
    languish at the end of a development cycle or are ignored entirely. This make
    senses, given the time required to write and maintain code comments and release
    notes that are useful and relevant, especially when there is time pressure to
    be constantly delivering new features. However, with the use of LLMs, we can reduce
    that time overhead while ensuring we create useful documentation that creates
    value for future readers. So let’s take a look at some useful prompts that can
    rapidly generate documentation for us.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5.1 Generating code comments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Though we should always be striving to create code that is arranged in a way
    that is fluent and easy to parse, regardless of experience with a code base, code
    comments can provide the extra detail that prevents misuse of code and speeds
    up development. This is doubly important if we’re releasing APIs that will be
    used by others. (I’ve on many occasions wasted time trying to understand how a
    library works from poorly documented API docs.) The challenge is to get the right
    balance in code comments: too few and the person reading your code is left to
    fend for themselves; too much and we create more work for ourselves in maintaining
    code and comments to ensure they align with one another.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So instead, let’s look at a prompt that can take care of the process of annotating
    our work with comments for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'In this prompt we use the usual delimiter tactic to provide our code that we
    would like to see commented, but we also want to ensure that the LLM doesn’t change
    our code to make it align with the comments it creates. So we also make it explicit
    within the prompt to check that no parts of the code have been changed before
    outputting the completed commented code. Sending this prompt with our example
    code from earlier to ChatGPT returned the following commented code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the methods and sections of code within them have now been annotated
    with comments to give us more detail. What stands out most is comments such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The comment provided not only references what the `ConcurrentHashMap` is used
    for but also highlights that all project names will be stored in lowercase, which
    is a reference to part of the code inside `submitTimesheet,` which does stand
    in contrast to comments like this, which feel a little unnecessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Once again the choice is ours as to what to use and what not to. Though the
    prompt we’ve used has provided us with comments, we’ve observed that some are
    probably more of use than others. So our role changes from being the author of
    comments to an editor, selecting and tweaking the comments that seem the most
    useful.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining code comments with prompts
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: What makes this process so useful is that when we inevitably come to a point
    in which our code changes and our comments need updating, we simply can run the
    prompt again with our updated code to regenerate our comments to incorporate our
    changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'A final observation is that although the comments can be useful for someone
    reading our code directly, what if we want to provide more structured documentation
    in the form of, say, Javadoc? In that instance, we can modify the prompt and use
    the structured data tactic to create a prompt like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this prompt with our example code to ChatGPT produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Using this prompt, we’ve improved the quality of some of the comments and also
    created JavaDoc-friendly comments that can be used to document our code for external
    users. All that would be left for us to do is to tweak and edit at the points
    we see fit.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5.2 Generating release notes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Just as we can use a LLM to modify our code to add comments, we can also use
    LLMs to transform our code base into release notes that can be consumed by others
    in the team and beyond. To do this, we create a new prompt with the following
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The prompt follows a similar pattern to the previous code comment focused prompt,
    but this time instead of asking it to inject comments into our code we instruct
    the code to be transformed in natural language release notes. For example, sending
    the prompt with the sample code to ChatGPT returned this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The result we get is a completely different format to our original code that
    attempts to detail what our code base does. Reviewing the output, it does feel
    quite technical, which makes sense considering we’ve asked for detailed notes
    on a small amount of code. However, even these release notes can be of use because
    we can adapt an earlier prompt for suggesting risks to analyse the release notes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this prompt in ChatGPT returned me the following suggested risks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Of course, this might be an unnecessary step if we can directly ask an LLM to
    suggest risks based on the code directly, but it does demonstrate the power of
    LLMs ability to transform data from one format to another.
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 Maintaining a balance with code assistants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The perspective on the value that tools like Copilot and ChatGPT offer depends
    on individuals. For some, it means the automation of development and the loss
    of many roles, and for others, it’s nothing but an advanced tool that randomly
    picks suggested code. What this chapter demonstrates is the ongoing theme that
    their worth and usefulness lie somewhere between those two extremes.
  prefs: []
  type: TYPE_NORMAL
- en: These models, trained on masses of data from Stack Overflow and GitHub repositories,
    are very sophisticated in what they suggest for both production and test code.
    But they still require direction from us humans—direction that is guided by our
    abilities to communicate with stakeholders, analyze requirements, and design implementation.
    How well we can use AI tools in development is dependent on honing our complementary
    skills, which can be summarized by using the area-of-effect model shown in Figure
    4.2.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 An area-of-effect model, updated to demonstrate the skills of a human
    and the ability of code assistant tools
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](images/04__image003.png)'
  prefs: []
  type: TYPE_IMG
- en: A balanced approach can help us to deliver features faster but still ensure
    that we build in quality. So our goal is to maintain that balance in situations
    in which we may need to rely on our own abilities or the features of our tools.
    Sometimes, code assistants won’t be able to suggest the correct implementation
    and we need to take charge. This gives us more control but does sacrifice speed.
    At other times, we can rely on code assistant tools to reference vast amounts
    of data to suggest new design ideas through unit checks or conversations. But
    we want to ensure that we keep our TDD loops focused on design and not on test
    coverage. Too many unit checks and we lose sight of our design and end up in a
    box-checking activity.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The majority of AI tools now on the market rely on large language models that
    are trained with vast amounts of data scraped from the internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are sophisticated algorithms that apply statistical analysis to our requests
    to determine what output it should respond with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copilot is a coding assistant tool that uses the OpenAI GPT-4 and is trained
    on code that is stored on GitHub.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copilot works within an IDE and reads your code as a prompt to suggest what
    to add next into test code and production code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools like Copilot can work well with the TDD red/green/refactor loop to help
    us rapidly create unit checks and production code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To help Copilot return code that is valuable, we need to guide it with prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Success with AI code assistants depends on our understanding our abilities and
    the features of code assistant tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A push-pull relationship exists between how much we are leading versus the tooling
    leading design.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We must be aware of the tradeoffs when the balance shifts from humans leading
    to tools leading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
