- en: 4 AI-assisted testing for developers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 AI辅助开发者测试
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章内容包括
- en: Developing unit tests and production code with GitHub Copilot
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GitHub Copilot开发单元测试和生产代码
- en: Developing unit tests and production code with ChatGPT
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ChatGPT开发单元测试和生产代码
- en: According to a poll on dev ecosystems by JetBrains in 2022, 81% of respondents
    have a developer-to-QA ratio that is greater than 1-to-1\. Forty percent reported
    that they had “less than 1 QA per 10 developers,” and only 1% reported that they
    had “more QAs than developers.” (The poll can be found at [www.jetbrains.com/lp/devecosystem-2022/testing](devecosystem-2022.html).)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 根据JetBrains于2022年进行的开发生态系统调查显示，81%的受访者的开发人员与QA的比例大于1：1。其中40%报告称他们的开发人员中“不到10名开发人员中有1名QA”，只有1%的受访者报告称他们拥有“比开发人员更多的QA”。（该调查可在[www.jetbrains.com/lp/devecosystem-2022/testing](devecosystem-2022.html)找到。）
- en: Understanding and building in quality is essential to delivering value to our
    users, yet the ratio between development and testing is nearly always imbalanced,
    and for many reasons. Some organizational leaders choose to educate developers
    to build in quality with the support of quality coaches, and others simply don’t
    want to invest in roles that advocate for testing and quality. Either way, this
    situation puts pressure on everyone on a team to deliver high-quality applications.
    So how can AI tools help relieve this pressure?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和建立质量至关重要，以向我们的用户提供价值，然而，开发和测试之间的比例几乎总是不平衡的，原因有很多。一些组织领导选择通过质量教练的支持来教育开发人员建立质量，而其他人则简单地不愿意投资于提倡测试和质量的角色。无论哪种情况，这种情况都给团队的每个人带来了交付高质量应用程序的压力。那么，AI工具如何帮助减轻这种压力呢？
- en: In this chapter, we’ll focus specifically on how large language model (LLM)
    AIs, such as GitHub Copilot and ChatGPT, can help us developers build quality
    into our work. Rather than think of these AI tools as replacements for developers
    and testers, we’ll learn how they can guide us as we carry out activities that
    build in quality as we develop—as well as demonstrate how we can use AI tools
    to steer the direction toward improving quality and identifying risks when testing
    is a limited resource to take advantage of.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于如何借助大型语言模型（LLM）AI，如GitHub Copilot和ChatGPT，帮助我们开发人员将质量融入我们的工作中。我们不应将这些AI工具视为开发人员和测试人员的替代品，而应学习它们如何指导我们在开发过程中进行质量建设的活动，以及如何利用AI工具引导改进质量并在测试资源有限时识别风险。
- en: 4.1 Examining the rise of the automated developer
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 探究自动化开发者的兴起
- en: In April of 2023, Similarweb, a market competition analysis company, reported
    that Stack Overflow’s traffic in the preceding month had dropped by 14%. The cause,
    according to Similarweb, was a rise in developers switching from Stack Overflow
    to tools such as GitHub’s Copilot and ChatGPT. (You can read the article at [www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt](ai-news.html)).
    Whether this is a sign of an ongoing trend of developers jumping ship or an anomaly
    that will eventually balance out, reports like this one demonstrate the sweeping
    changes that LLM-based AI tools (LLMs) are introducing to the role of a developer.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年4月，市场竞争分析公司Similarweb报告称，Stack Overflow在前一个月的流量下降了14%。根据Similarweb的说法，原因是开发人员从Stack
    Overflow转向GitHub的Copilot和ChatGPT等工具。 （您可以在[www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt](ai-news.html)阅读该文章。）无论这是否是开发人员跳槽的持续趋势，还是最终会达到平衡的异常情况，像这样的报道都显示了基于LLMs的AI工具（LLMs）对开发人员角色引入的巨大变化。
- en: 'As a tester, it’s an interesting change to witness. For many years, as test
    automation tools became more advanced, I would have discussions with developers
    about whether testing could be replaced by automated testing tools. Now, with
    LLMs that are trained against billions of lines of code from public and private
    repositories, conversations have turned toward whether developer roles can be
    automated. For example, a tool like ChatGPT can be sent a prompt such as this
    one:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为测试人员，见证这种变化是很有趣的。多年来，随着测试自动化工具的不断发展，我会与开发人员讨论是否可以通过自动化测试工具来替代测试工作。现在，随着针对来自公共和私人存储库的数十亿行代码进行训练的LLMs的出现，谈论的话题已经转向是否可以自动化开发人员的角色。例如，像ChatGPT这样的工具可以发送这样的提示：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'and it will then use its billions of trained weights and balances to return
    a working code example like this one:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它将利用其数十亿个训练权重和平衡来返回一个工作代码示例，就像这样：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: From just one basic prompt we can use LLMs to create workable code (updating
    the `apiUrl` to a real API returned a positive result). So it’s not surprising
    that there are tools appearing that combine prompts attempting to automate development
    work. Tools like [AutoGPT](Significant-Gravitas.html) and [MetaGPT](geekan.html)
    have appeared that work as autonomous agents, generating their own prompts based
    on initial questions to solve complex problems. Though these tools are in their
    infancy, it’s clear to see why the more hyperbolic claims of developers being
    automated out of their role are bandied about.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个基本提示我们可以使用 LLM 来创建可用的代码（将 `apiUrl` 更新为真实的 API 返回了积极的结果）。因此，出现了结合提示尝试自动化开发工作的工具并不奇怪。出现了像
    [AutoGPT](Significant-Gravitas.html) 和 [MetaGPT](geekan.html) 这样的工具，它们作为自治代理工作，根据最初的问题生成自己的提示来解决复杂的问题。尽管这些工具还处于萌芽阶段，但很明显可以理解为什么开发人员被自动化出他们的角色的夸张说法所困扰。
- en: As someone who has spent much of his career explaining why test automation doesn’t
    serve as a suitable replacement, it’s tempting to enjoy the schadenfreude of seeing
    developers defending their roles in the same way, but instead it’s more valuable
    to learn from the experiences of testers and the topic of automation. Just as
    a tester’s role can’t be automated fully, neither can a developer’s role. A development
    role is more than just the code that is produced. The solutions that developers
    create are a product of analytical skills, problem-solving, and design thinking.
    These are skills that LLM tools give the impression of being capable of, but currently
    they are not.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个大部分职业生涯都在解释为什么测试自动化不能作为合适替代品的人，很容易享受看到开发人员以同样的方式捍卫他们的角色的快感，但相反，从测试人员的经验和自动化的话题中学习更有价值。正如测试人员的角色不能完全自动化一样，开发人员的角色也不能。开发角色不仅仅是所产生的代码。开发人员创建的解决方案是分析技能、问题解决和设计思维的产物。这些是
    LLM 工具给人的印象能够做到的技能，但目前它们还不能。
- en: 'Instead, developers find success with LLM tools by using them to enhance their
    own abilities, using tools like Copilot to quickly and effectively create code
    that they want built, or seeking advice from ChatGPT to solve issues or learn
    new APIs. These principles can also be applied to improving a developer’s ability
    to build quality into an application. By combining techniques such as test-driven
    design (TDD) or pairing with the power of LLMs, developers can increase their
    productivity while ensuring that their analytical and design skills lead the charge.
    To help demonstrate this symbiosis, let’s explore two examples:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，开发人员通过使用 LLM 工具来增强他们自己的能力而取得成功，使用像 Copilot 这样的工具快速有效地创建他们想要构建的代码，或者向 ChatGPT
    寻求解决问题或学习新的 API。这些原则也可以应用于提高开发人员构建应用程序质量的能力。通过将诸如测试驱动设计（TDD）或与 LLM 强大的配对技术相结合，开发人员可以提高生产力，同时确保他们的分析和设计技能发挥主导作用。为了帮助证明这种共生关系，让我们探讨两个例子：
- en: Using Copilot to rapidly generate unit checks and production code for TDD loops
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Copilot 快速生成 TDD 循环的单元检查和生产代码
- en: Emulating pairing with a simulated developer, courtesy of ChatGPT
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 ChatGPT 的模拟开发人员模拟配对
- en: Through these examples, we’ll learn to set up and use these LLM tools as well
    as appreciate the balance we can strike between the power of AI and the abilities
    of developers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些示例，我们将学习设置和使用这些 LLM 工具，并欣赏我们可以在 AI 的力量和开发人员的能力之间取得的平衡。
- en: Experiences may vary
  id: totrans-19
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 经验可能有所不同
- en: Given that Copilot relies on predictive algorithms that are frequently being
    trained on newly added code and updated APIs/libraries, it’s worth highlighting
    that the output and experience you have when following the upcoming examples may
    be different from what has been recorded. Keep in mind that the goal of this chapter
    is not to replicate the examples in this chapter 100%, but rather to become comfortable
    with using LLMs to assist our work in a way that helps us build in quality.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于 Copilot 依赖于经常在新添加的代码和更新的 API/库上进行训练的预测算法，值得强调的是，遵循即将出现的示例时您所拥有的输出和体验可能与已记录的内容不同。请记住，本章的目标不是完全复制本章中的示例，而是让我们舒适地使用
    LLM 工具来协助我们的工作，从而帮助我们提高质量。
- en: 4.2 Pairing with LLMs
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 与 LLM 的配对
- en: We’ve already spent time understanding that LLMs are probabilistic in nature,
    and as a result it can be useful to think of them as outputting simulations of
    roles, rather than inhabiting specific roles. An LLM has no more awareness of
    being a software tester than it does as a restauranteur. But with prompt engineering
    we can create prompts that frame an LLM’s probabilistic output to simulate a role,
    helping us to create rubber ducks to interact with. This can be useful in a development
    capacity when testing resources are limited in either availability or capability.
    So let’s take a look at a couple of sample prompts we can use to elicit feedback
    that can help us improve the quality of our work and our products.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经花了时间了解到 LLM 具有概率性质，因此认为它们输出的是角色的模拟，而不是具体的角色。LLM 对于自己是软件测试员还是餐厅经营者并不更加清楚。但是通过提示工程，我们可以创建提示，将
    LLM 的概率输出框架化为模拟角色，帮助我们创建与之交互的橡皮鸭。当测试资源在可用性或能力上有限时，这在开发方面可能很有用。因此，让我们看看我们可以使用的几个示例提示，这些提示可以帮助我们改进我们的工作和产品的质量。
- en: Wait, what—rubber duck?
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 等等，什么——橡皮鸭？
- en: 'When faced with a problem that we have no solution for, it can help to verbalize
    the problem to others to find an answer. By articulating the problem to another
    person, we sometimes experience that the solution presents itself to us. However,
    there isn’t always an opportunity to speak with colleagues; therefore; some developers
    will verbalize their issues to a rubber duck (or another item). Although we’re
    sharing our challenges with an inanimate object, the experience is the same: Verbalizing
    our challenges tricks our brains into finding solutions.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 面对无解的问题时，向他人口头表达问题可能有助于找到答案。通过向他人表达问题，我们有时会发现解决方案呈现在我们面前。然而，并不总是有机会与同事交流；因此，一些开发人员会向橡皮鸭（或其他物品）表达他们的问题。尽管我们把挑战分享给了一个无生命的物体，但体验是相同的：口头表达我们的挑战会让我们的大脑找到解决方案。
- en: 4.2.1 Analyzing ideas
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 分析思想
- en: Our first prompt is inspired by the shift-left mindset that some teams apply
    to help build quality into applications as early as possible. *Shift-left* means
    bringing testing analysis earlier into the development process, ideally around
    the point at which ideas are being discussed and details are being clarified.
    This process results in many questions being asked that help us to identify issues
    earlier, deliver valuable features, and improve the quality of our products. Shift-left
    activities are an invaluable for improving quality and should be encouraged regardless
    of the use of AI in the development process. But it doesn’t mean we can’t also
    use prompts to generate questions that might reveal assumptions or misunderstandings—or
    questions that we can simply disregard.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个提示灵感来自于一些团队应用的左移思维，旨在尽早将测试分析引入开发过程中，理想情况下是在讨论想法和澄清细节的时候。左移意味着将测试分析尽早引入开发过程中，理想情况下是在讨论想法和澄清细节的时候。这个过程会引发许多问题，这些问题有助于我们更早地识别问题、交付有价值的功能并提高产品的质量。左移活动对于提高质量非常重要，应该鼓励，无论在开发过程中是否使用
    AI。但这并不意味着我们不能使用提示来生成可能揭示假设或误解的问题，或者我们可以简单地忽略的问题。
- en: 'Let’s look at a sample prompt that can be used to rapidly generate questions
    that might be useful:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个可以用来迅速生成可能有用的问题的示例提示：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The prompt outlines instructions for an LLM to analyze a user story and acceptance
    criteria and return a list of questions for us to consider. Notice how we also
    provide context in the quality characteristics instruction. If we want to focus
    on different characteristics, we can update these as well.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 提示概述了一个用于分析用户故事和验收标准的 LLM 的指令，并返回一个我们要考虑的问题列表。请注意，我们还在质量特征指令中提供了上下文。如果我们想要关注不同的特征，我们也可以更新这些特征。
- en: 'Entering this prompt into ChatGPT returned the following result:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将此提示输入 ChatGPT 返回了以下结果：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Reading through the response, we can see that there is an interesting collection
    of questions ranging in quality. For example, consider this question:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过阅读响应，我们可以看到有一个有趣的问题集合，质量参差不齐。例如，考虑这个问题：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is a helpful question that encourages us to consider in more detail the
    statement `Guests are asked to create an account to make a booking`, found in
    our user story. We could consider this question and think about how we would design
    the booking process to make it accessible for all types of users.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有帮助的问题，鼓励我们更详细地考虑`Guests are asked to create an account to make a booking`这一陈述，在我们的用户故事中发现。我们可以考虑这个问题，思考一下我们将如何设计预订流程，使其对所有类型的用户都可以访问。
- en: 'However, other questions are perhaps not quite as good. For example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，其他问题可能并不太好。例如：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What makes this question problematic is its reference to the quality characteristic
    `accuracy`. Typically, accuracy would be more focused on the accuracy of data
    that is processed or stored (think bank interest rate calculations). Instead,
    the phrase “accuracy of user access” feels like an odd way to describe the rules
    set around users and what they can access. Ultimately, it’s up to us to evaluate
    each question for suitability and use. Some questions can encourage us to build
    products that are more closely aligned with what a user wants and help us avoid
    errors—whereas other generated questions will either make little sense or cover
    topics already considered.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使这个问题变得棘手的是它对`accuracy`质量特征的引用。通常，准确性更侧重于处理或存储的数据的准确性（想想银行利率计算）。相反，“用户访问的准确性”这个短语感觉像是描述用户和他们可以访问的内容的规则集的奇怪方式。最终，我们需要评估每个问题的适用性和使用情况。一些问题可以鼓励我们构建更符合用户需求的产品，并帮助我们避免错误——而其他生成的问题要么没有意义，要么涵盖了已经考虑过的主题。
- en: We’ll come back to this prompt and how we might use it during the development
    of a feature, but first let’s look at how we can repurpose this prompt to review
    our code.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回到这个提示，以及我们在开发功能期间如何使用它，但首先让我们看看我们如何重新利用这个提示来审查我们的代码。
- en: 4.2.2 Analyzing code
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 分析代码
- en: 'Just as we can prompt an LLM to analyze written-down ideas, we can also have
    it review code and help us to identify risks. Using this prompt is akin to simulating
    the role of a developer or tester that you are pairing with, by having them analyze
    your work as you develop to offer suggestions for consideration. Let’s look at
    a prompt that could be of use for this type of activity:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们可以促使一个LLM分析书面的想法一样，我们也可以让它审查代码，并帮助我们识别风险。使用这个提示类似于模拟与你合作的开发人员或测试人员的角色，让他们在你开发时分析你的工作并提出建议供考虑。让我们看看一个可能对这种类型的活动有用的提示：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After I sent the prompt with the sample code and quality characteristics to
    ChatGPT, the following output was returned:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在我向ChatGPT发送了包含示例代码和质量特征的提示后，返回了以下输出：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Similar to the previous prompt, which generated questions around written requirements,
    the quality of these different risks varies. For example, the risk `Performance
    - Message Posting` feels quite abstract, as we can see in its explanation:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个提示类似，它围绕书面需求产生了问题，这些不同风险的质量也不同。例如，风险`Performance - Message Posting`感觉相当抽象，正如我们在其解释中看到的那样：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Suggesting risks around network communication or I/O operations feels vague
    because it might refer to a range of implementations, some of which might relate
    to our work and some that might not.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕网络通信或I/O操作提出风险建议感觉模糊，因为它可能涉及一系列实现，其中一些可能与我们的工作有关，而另一些可能不相关。
- en: 'However, other risks are more concrete and potentially useful—for example,
    `Security - Inadequate Authorization` in which it highlights:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，其他风险更具体，可能更有用，例如，`Security - Inadequate Authorization`，其中它强调了：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This risk feels more concrete because it refers to actions that are carried
    out in our method, and the absence of potentially important checks within it.
    Of course, we may carry out authorization checks elsewhere, but using the information
    it has given, it’s highlighted an explicit activity that we might need to discuss
    further to improve the security of our booking feature.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个风险感觉更具体，因为它涉及到我们方法中执行的操作，以及其中缺少的可能重要的检查。当然，我们可能会在其他地方进行授权检查，但使用它所提供的信息，它强调了一个明确的活动，我们可能需要进一步讨论以改进我们的预订功能的安全性。
- en: Generating more ideas
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成更多的想法
- en: So far, we’ve looked at singular prompts to send to LLMs, which gives us useful
    responses to review. But what if we want to solicit more questions and risks?
    We simply ask by submitting an additional prompt, such as “Generate me more questions”
    or “Identify further risks.” Be wary, though, as this has diminishing returns.
    An LLM will try to fulfill our requests at the risk of increasing hallucinations.
    So, as options start to dry out, we may see more suggestions that are less and
    less connected to the ideas and code we wanted feedback on in the first place.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经查看了发送给 LLM 的单个提示，这使我们有用的反馈进行了审查。但是如果我们想要索取更多的问题和风险怎么办？我们只需提交额外的提示，例如“生成更多问题”或“识别更多风险”。但要小心，因为这会有递减的回报。LLM
    将尝试满足我们的要求，从而增加幻觉的风险。因此，随着选项开始枯竭，我们可能会看到更多与我们最初希望反馈的想法和代码不相关的建议。
- en: 4.2.3 Recognizing that a simulation is better than nothing at all
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.3 认识到模拟总比什么都没有好
- en: When testing is discussed, the focus typically tends to be on the production
    and execution of test cases. But a highly trained and experienced tester delivers
    value by using their critical and lateral thinking skills and asks questions that
    help us view solutions in new ways and reveal potential issues. The prompts we’ve
    looked at can offer a simulation of that process. But it’s important to remember
    that LLMs don’t have these critical and lateral thinking skills and that the questions
    and risks generated come from the instruction of our prompts. Instead, these types
    of prompts can offer a lightweight way to simulate the experience of pairing with
    testers or other developers when the opportunity to pair is unavailable. The key
    is to develop an eye for generated questions to determine which are of use and
    which are not.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论测试时，重点通常集中在测试用例的制作和执行上。但是，一个经过高度培训和经验丰富的测试人员通过使用其批判性和横向思维技能提供价值，并提出有助于我们以新的方式查看解决方案并揭示潜在问题的问题。我们看过的提示可以提供该过程的模拟。但重要的是要记住，LLMs
    没有这些批判性和横向思维技能，而生成的问题和风险来自我们提示的指示。相反，这些类型的提示可以提供一种轻量级的方式来模拟与测试人员或其他开发人员配对的经验，当无法配对时。关键是培养一种识别生成问题的眼光，以确定哪些是有用的，哪些是没有用的。
- en: 4.3 Building in quality with AI assistance
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 利用 AI 辅助构建质量
- en: So far, we’ve looked at prompts as singular activities, but now let’s turn our
    attention to how the prompts we’ve recently learnt and other LLM assistant tools
    can be used in conjunction with TDD to help us build in quality.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经将提示视为单一活动，但现在让我们将注意力转向我们最近学到的提示以及其他 LLM 辅助工具如何与 TDD 结合使用，帮助我们构建质量。
- en: Though TDD is not strictly a testing activity when compared against other testing
    activities, TDD that is carried out correctly helps guide developers to build
    quality into our products. To recap, the process of TDD is to use unit checking
    tools to first create failing checks and then create just enough production code
    to make the check *pass* (and fix any other checks that may have failed). Once
    all our checks are passing, we can refactor our production code while ensuring
    all our checks are green. Once that is complete, we start the loop again until
    our work is complete, as demonstrated in Figure 4.1.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 TDD 与其他测试活动相比并不严格是一种测试活动，但正确执行的 TDD 可以帮助开发人员将质量融入我们的产品中。简而言之，TDD 的过程是使用单元检查工具首先创建失败的检查，然后创建足够的生产代码使检查*通过*（并修复可能失败的任何其他检查）。一旦我们的所有检查都通过了，我们可以在确保所有检查都是绿色的同时重构我们的生产代码。完成后，我们重新开始循环，直到工作完成，如图4.1所示。
- en: Figure 4.1 The red/green/refactor TDD cycle
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1 红绿重构 TDD 循环
- en: '![](images/04__image001.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](images/04__image001.png)'
- en: What’s all this about checks?
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 所有这些检查是什么意思？
- en: In our Automation in Testing training, Richard Bradshaw and I make a distinction
    between human-led testing and tool-led testing. We call the latter type *automated
    checking* because the tools can only assert explicit actions or data that we codify
    into our automation. This distinction helps us to better appreciate that automated
    tools like unit-checking frameworks are excellent at rapidly checking small, specific
    changes in a product, but are unable to tell us more about a system beyond its
    assertions. Humans, however, are slower and less deterministic in our testing,
    though we are much more efficient at identifying many events happening at the
    same time. Hence, this is why tools check and humans test. One is not better than
    the other, and, hopefully, this book demonstrates that we can have the best success
    when combining both.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试自动化培训中，Richard Bradshaw 和我区分了人工测试和工具测试。我们称后者为*自动化检查*，因为工具只能断言我们编码到自动化中的显式操作或数据。这种区别帮助我们更好地理解，像单元检查框架这样的自动化工具非常擅长快速检查产品中的小型、具体的变化，但不能告诉我们有关系统的更多信息。然而，人类在测试中更慢且不确定性更大，尽管我们在识别同时发生的许多事件时效率更高。因此，这就是为什么工具检查而人类测试。一个并不比另一个更好，希望这本书能证明当我们结合两者时，我们能取得最好的成功。
- en: This approach enables us to design products that are highly testable while ensuring
    we deliver what the business or end user desires.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法使我们能够设计出高度可测试的产品，同时确保我们提供了业务或最终用户所期望的内容。
- en: Though its benefits are manifold, some developers find it hard to adopt the
    TDD approach because some believe that it slows down development as we create
    unit checks for each specific section of production code we add to our system.
    However, with the use of tools like Copilot, we can learn how to establish a balance
    in which the tools enable us to rapidly create unit checks and build in quality.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它的好处多多，但一些开发人员发现很难采用 TDD 方法，因为有些人认为它会减慢开发速度，因为我们为系统中添加的每个特定的生产代码部分创建单元检查。然而，通过使用像
    Copilot 这样的工具，我们可以学会如何建立一个平衡，在这个平衡中，工具使我们能够快速创建单元检查并构建质量。
- en: 4.4 Creating our first TDD loop with LLMs
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 使用 LLMs 创建我们的第一个 TDD 循环
- en: 'To demonstrate, let’s undergo the process of creating part of a feature for
    a sample timesheet manager, which is described below:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示，让我们来完成为示例工时管理器的一部分功能的过程，该功能如下所述：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can review the test and production code that was created as part of this
    example in the following GitHub repository: [https://github.com/mwinteringham/ai-assisted-testing/tree/main/chapter-4](main.html).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下 GitHub 存储库中查看作为示例一部分创建的测试和生产代码：[https://github.com/mwinteringham/ai-assisted-testing/tree/main/chapter-4](main.html)。
- en: Setting up Copilot
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 设置 Copilot
- en: This chapter assumes that you have installed and configured the Copilot plugin
    within your IDE. If you haven’t already completed the setup process, you can find
    installation instructions in the appendix.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章假设您已经在您的集成开发环境中安装并配置了 Copilot 插件。如果您尚未完成设置过程，您可以在附录中找到安装说明。
- en: 4.4.1 Preparing the work
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 准备工作
- en: 'Before starting to create my timesheet manager feature, I wanted to think about
    how I would go about building it. To help me with this process, and to encourage
    me to think about the solution from various angles, I took the first prompt we
    explored earlier in this chapter and entered my context into it. Specifically,
    I:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始创建我的工时管理器功能之前，我想先考虑一下如何构建它。为了帮助我进行这个过程，并鼓励我从各个角度考虑解决方案，我将本章前面探索的第一个提示输入到其中。具体来说，我：
- en: Changed the quality characteristics to Accuracy and Consistency
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将质量特性更改为准确性和一致性
- en: Added the user story into the delimited section at the bottom of the prompt
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将用户故事添加到提示底部的分隔部分中
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Sending this prompt to ChatGPT returned the following response:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将此提示发送给 ChatGPT 返回了以下响应：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: What are quality characteristics?
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 什么是质量特性？
- en: Quality means very different things to different people and is a multifaceted
    concept. Therefore, when attempting to understand what quality means to a stakeholder
    or end user, we break out ways of thinking about it into different characteristics.
    For example, quality characteristics might include look and feel, usability, compliance,
    and much more. Different projects will have different quality characteristics
    that we prioritize, and it’s up to us as teams to identify what quality characteristics
    are a priority to us and our users.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 质量对不同的人意味着完全不同的事情，是一个多方面的概念。因此，当试图理解质量对利益相关者或最终用户意味着什么时，我们将其思考方式分解成不同的特征。例如，质量特征可能包括外观和感觉、可用性、合规性等等。不同的项目将有不同的质量特征，我们要优先考虑哪些质量特征是我们和我们的用户的重点，这取决于我们作为团队的选择。
- en: 'From here, I read through each of the questions sent back to me and noted the
    ones that stood out to me as raising points I hadn’t considered:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，我阅读了每个发送给我的问题，并注意到那些引起我注意的问题，因为它们提出了我没有考虑过的观点：
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: These two felt very similar to me, but they highlighted that I will, at some
    point, need to add date time handling into the code to prevent issues around invalid
    entries.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这两者感觉非常相似，但它们强调了在某个时候，我需要将日期时间处理加入代码中，以防止无效输入引起的问题。
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It’s a good question, but not relevant to this work as I plan to just track
    the amount of time carried out and not when it was carried out (at least for now).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的问题，但与这项工作无关，因为我打算只跟踪执行的时间，而不是执行的时间点（至少目前是这样）。
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Connected to the previous question, I opted for simply tracking the amount of
    time that had elapsed and not specifically when it had occurred—meaning that the
    displaying of information is relatively straightforward.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个问题相关联，我选择简单地跟踪经过的时间，而不是具体时间点——这意味着信息的显示相对简单。
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: At this time, there is no multiple-user feature, though it might be introduced
    later, so I make a note of this to consider for future iterations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 目前还没有多用户功能，尽管它可能稍后会被引入，所以我做个记录，以便未来的迭代考虑。
- en: Many more questions could be asked and addressed, but what this process demonstrates
    is that, by generating different questions, I am required to think about various
    aspects of the design of this feature. Some I can choose to rule out, or shelve
    for later conversation, and some help me to improve the quality of my feature
    by raising my awareness to validation and date time formatting.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多问题可以提出和解决，但这个过程所展示的是，通过生成不同的问题，我被要求思考该功能设计的各个方面。有些问题我可以选择排除，或者暂时搁置以后的讨论，有些问题则帮助我提高功能的质量，提高我对验证和日期时间格式化的认识。
- en: '4.4.2 Loop 1: Save a timesheet entry'
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 循环 1：保存时间表条目
- en: 'With the questions from the previous prompt in my mind, I start my first loop
    by creating an empty maven project within my IDE before heading to the `pom.xml`
    to add in my required dependencies. I require JUnit 5 to build my unit checks,
    so I entered the comment:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我脑海中有来自前一个提示的问题后，我开始我的第一个循环，通过在我的 IDE 中创建一个空的 Maven 项目，然后前往 `pom.xml` 添加所需的依赖项。我需要
    JUnit 5 来构建我的单元检查，所以我输入了注释：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To be returned the suggested code block from Copilot:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Copilot 返回建议的代码块：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'At the time of writing the proposed version of `junit-jupiter-engine` is an
    older version so I update to `5.9.2` as shown here:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写时，`junit-jupiter-engine` 的建议版本是旧版本，所以我更新到 `5.9.2`，如下所示：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This required update is a good example of how data provenance can impact what
    is being suggested. Copilot, while constantly being trained on code that is being
    pushed to GitHub, runs the risk of lagging behind the latest versions of libraries
    and APIs. So we need to be vigilant when adding in dependencies via AI code assistants
    to ensure they are suggesting the version we want.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这次必要的更新是数据来源如何影响建议的一个很好的例子。 Copilot 虽然不断地在 GitHub 上推送的代码上进行训练，但存在落后于最新版本库和 API
    的风险。因此，在通过 AI 代码助手添加依赖项时，我们需要保持警惕，以确保它们提供的是我们想要的版本。
- en: Also, what is demonstrated here is how the Copilot IDE plugin will take code
    (or in this case a code comment) I have written, add it to a prompt, and then
    send it to the Copilot LLM to process. The LLM then sends back to the IDE plugin
    a suggestion of what to enter next, and the plugin then presents me with the suggestion.
    I then have the option to either accept the suggestion by hitting Tab or continuing
    to write my own code.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这里演示了Copilot IDE插件将我编写的代码（或在本例中是代码注释），添加到提示中，然后发送给Copilot LLM进行处理。LLM然后向IDE插件发送一个建议，提示我输入下一个内容。然后我可以选择通过按Tab键接受建议，或继续编写自己的代码。
- en: Much like other LLMs, Copilot is triggered by prompts. But unlike a chat-based
    LLM (such as ChatGPT), Copilot is tuned to process code-based prompts rather than
    text-based prompts. This distinction is important to make because it highlights
    both the benefits of different types of fine-tuned LLMs for different activities
    as well as the need to write prompts that work for different types of prompts.
    This is why TDD and AI assistants are an interesting combination to work with.
    The unit checks we create not only frame the design of our work but also serve
    as prompts to inform how we want to implement features.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 像其他LLMs一样，Copilot是通过提示触发的。但与基于聊天的LLM（如ChatGPT）不同，Copilot被调整为处理基于代码而不是文本的提示。这个区别很重要，因为它突显了为不同类型的活动调优LLMs的不同类型的好处，以及编写适用于不同类型提示的必要性。这就是为什么TDD和AI助手是一个有趣的组合来共同使用的原因。我们创建的单元检查不仅构成了我们工作的设计框架，还作为提示来告知我们如何实现功能。
- en: 'For example, for our first check, I prompt Copilot to create my first unit
    check for me by adding the following comment into a new class entitled `TimesheetTest`
    in `src/test/java`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于我们的第一个检查，我提示Copilot为我创建第一个单元检查，方法是将以下注释添加到一个名为`TimesheetTest`的新类中，该类位于`src/test/java`中：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Looking at this suggested check, we see that it has the necessary details we
    require. It’s given the class I intend to build a sensible name of `Timesheet`
    and suggested the method `submitTimesheet` with the correct parameters of project
    name and hours. This check is enough of a prompt that when I create a new class
    `Timesheet` in `src/main/java`, Copilot suggests:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这个建议的检查，我们看到它具备我们需要的必要细节。它为我打算构建的类起了一个合理的名字`Timesheet`，并建议了正确的参数项目名称和工时的方法`submitTimesheet`。这个检查足够提示，当我在`src/main/java`创建一个新的类`Timesheet`时，Copilot建议：
- en: '[PRE21]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The unit check served as a prompt to Copilot to create my production code and
    although what has been produced is not exactly exciting, the check has been fulfilled.
    We can also see that Copilot works by building prompts upon prompts to get to
    what we want. First I created a prompt in the form of a code comment to help Copilot
    suggest the code for the unit check, and then that unit check served as a prompt
    for the suggested production code. As the unit checks grow, so will the prompts
    and directions to Copilot on what to build. So now let’s look at how I used this
    process to build out the `submitTimesheet` method.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 单元检查作为提示，促使Copilot创建我的生产代码，虽然产生的东西并不是非常激动人心，但检查已经完成。我们还可以看到Copilot通过建立提示来获取我们想要的。首先，我创建了一个形式为代码注释的提示，以帮助Copilot建议单元检查的代码，然后该单元检查作为建议生产代码的提示。随着单元检查的增加，Copilot的提示和指导将增加。现在让我们看看我如何使用这个过程来完善`submitTimesheet`方法。
- en: '4.4.3 Loop 2: Retrieve a timesheet entry'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.3 循环2：检索时间表条目
- en: 'With the first loop I created the skeleton of my project, but at the moment
    the actual production code bears little fruit. So with the second loop, I looked
    to add more features to the `Timesheet` class to help flesh out the `submitTimesheet`
    method. Again, I start by adding a new comment prompt to `TimesheetTest`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通过第一个循环，我创建了项目的骨架，但目前实际的生产代码几乎没有成果。因此，在第二个循环中，我试图添加更多功能到`Timesheet`类以帮助完善`submitTimesheet`方法。同样，我首先在`TimesheetTest`中添加了一个新的注释提示：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And upon creating a new line, Copilot returned the following check as a suggestion:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建新行时，Copilot返回了以下检查作为建议：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This time, the check created is using the `submitTimesheet` method to create
    some data that I can then check with the newly created `getTimesheets` method.
    So heading over to the `Timesheet` class, I use Copilot to generate the necessary
    `getTimesheets` method, which returns the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，创建的检查是使用`submitTimesheet`方法创建一些数据，然后我可以使用新创建的`getTimesheets`方法进行检查。所以，转到`Timesheet`类，我使用Copilot生成必要的`getTimesheets`方法，它返回以下内容：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Though it’s helpful that it created the method signature for me, the internals
    of the method are not so useful. However, then I add the following to the top
    of the class:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它为我创建了方法签名，但方法的内部并不那么有用。然而，然后我在类的顶部添加了以下内容：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'and then return to the `submitTimesheet` method and remove `return true` from
    inside the method. When I enter the keyword `if` into the statement, Copilot returns
    the following result:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后返回`submitTimesheet`方法，并从方法内部删除`return true`。当我将关键字`if`输入到语句中时，Copilot返回以下结果：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This is a useful demonstration of how, when working with Copilot, a project
    requires a degree of warmup before the LLM can return more accurate suggestions.
    By returning to the `submitTimesheet` method, removing its contents, and then
    waiting for Copilot to respond, I get a refreshed response from Copilot based
    on the new details I’ve provided. Just as a prompt for a chat LLM requires a prompt
    with clear and explicit details, so too does Copilot. The initial stock methods
    that were returned from Copilot for `Timesheet` are likely because there is little
    context to work with. Essentially, the prompts sent to Copilot lack information.
    But as I create new unit checks and additional code to show our intent in our
    code, the suggestions become more useful.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有用的演示，说明了当使用Copilot时，项目需要一定的预热时间，LLM才能返回更准确的建议。返回`submitTimesheet`方法，清空其内容，然后等待Copilot的响应，我得到了来自Copilot的基于我提供的新详细信息的更新响应。就像对话LLM需要明确和明确的详细信息提示一样，Copilot也是如此。最初从Copilot返回的标准方法可能是因为缺乏要处理的上下文。基本上，发送给Copilot的提示缺乏信息。但是随着我创建新的单元检查和额外的代码来展示我们在代码中的意图，建议变得更加有用。
- en: 'This is also demonstrated when I delete the `getTimesheets` method entirely.
    With the new `HashMap` added to the class, my updated code prompts Copilot to
    return an updated version of the method:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当我完全删除`getTimesheets`方法时，这也得到了证实。随着添加到类中的新`HashMap`，我的更新代码促使Copilot返回方法的更新版本：
- en: '[PRE27]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Running both of my unit checks after this loop, I can see both checks are passing
    and I now have working code that is a bit more feature rich than when I started
    the loop.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个循环之后运行我的两个单元检查，我可以看到两个检查都通过了，现在我有了一个比我开始循环时更丰富一些的工作代码。
- en: '4.4.4 Loop 3: Calculating times for a project'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.4 循环3：计算项目的时间
- en: 'For the final loop, I went back to the questions returned from ChatGPT and
    thought about the question:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后一个循环，我回到了ChatGPT返回的问题，并考虑了这个问题：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Though there is no functionality for multiple users at this point in the project,
    the question from ChatGPT did make me think about how to handle multiple timesheet
    submissions to the same project. So I created my third unit check to handle this
    scenario by once again creating a code comment to prompt Copilot for another unit
    check:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然目前项目中没有多用户功能，但ChatGPT的问题让我思考如何处理对同一项目的多次工时提交。因此，我创建了第三个单元检查来处理这种情况，再次创建代码注释以提示Copilot进行另一个单元检查：
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Which returned me the following unit check:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 返回给我的是以下单元检查：
- en: '[PRE30]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This time, the suggested check is close, but I want the `Timesheet` class to
    return a total, not have a total processed within the unit check itself. So I
    opted to update the check to explicitly state there is a method for getting total
    timesheet hours:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，建议的检查接近，但我希望`Timesheet`类返回一个总数，而不是在单元检查本身中处理总数。因此，我选择更新检查，明确说明有一个方法可以获取总工时：
- en: '[PRE31]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Heading back over to `Timesheet` and waiting for Copilot, the LLM returns the
    following code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到`Timesheet`并等待Copilot，LLM返回以下代码：
- en: '[PRE32]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This allows the code to compile, but my new unit check fails because the project
    count isn’t being updated. Instead, because I am using a `HashMap`, the count
    is being overwritten. I need to update `submitTimesheet` to handle duplicate projects,
    which I do by dropping the following comment into `submitTimesheet` just after
    the initial if statement:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得代码可以编译，但我的新单元检查失败了，因为项目计数没有被更新。相反，因为我使用了`HashMap`，计数被覆盖了。我需要更新`submitTimesheet`以处理重复的项目，我在`submitTimesheet`中刚开始的if语句之后添加了以下注释：
- en: '[PRE33]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Which in the context of the `submitTimesheet` updates it to increase the duration
    of existing projects in a timesheet:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在`submitTimesheet`的上下文中，更新它以增加工时表中现有项目的持续时间：
- en: '[PRE34]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: A final run of my three unit checks confirms that they are all passing and that
    I have all the features I want in my `Timesheet` class. However, the code is starting
    to become more complex, so I turn my attention to refactoring my code with the
    use of ChatGPT.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我的三个单元测试的最后一次运行确认它们都通过了，我在`Timesheet`类中拥有了我想要的所有功能。然而，代码开始变得更加复杂，所以我把注意力转向了使用ChatGPT来重构我的代码。
- en: 4.4.5 Refactoring code
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.5 重构代码
- en: 'One benefit of pairing with others is the ability for a pair partner to see
    potential issues and risks that we might not see. However, in the absence of a
    pair partner, I chose to use the second of the prompts we explored earlier in
    this chapter—specifically, the prompt that analyzes code and returns suggestions.
    Taking the prompt from earlier and adding my code and the quality characteristics’
    accuracy and consistency, I sent this prompt to ChatGPT:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 与他人合作的一个好处是合作伙伴能够看到我们可能没有看到的潜在问题和风险。然而，在没有合作伙伴的情况下，我选择使用本章早些时候探讨过的第二个提示——具体地分析代码并返回建议的提示。将之前的提示与我的代码和质量特征的准确性和一致性相结合，我将这个提示发送给ChatGPT：
- en: '[PRE35]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Sending the prompt returned the following risks that I might want to consider:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 发送提示返回了以下我可能想考虑的风险：
- en: '[PRE36]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Unlike the questions prompt, this response appears to call out specific items
    of my code and gives reasons for how things might go wrong. With this response,
    I have the following options:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 与问题提示不同，这个回复似乎指出了我的代码的具体项目，并说明了事情可能出错的原因。有了这个回复，我有以下几个选择：
- en: Review each risk on a case-by-case basis and then mitigate the ones I feel are
    important and ignore the others.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逐个检查每个风险，然后减轻我认为重要的风险并忽略其他风险。
- en: Ignore the proposed risks entirely, or perhaps send another prompt to ChatGPT
    to see whether there are more risks.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完全忽略所提出的风险，或者也许发送另一个提示给ChatGPT，看看是否还有更多的风险。
- en: Use the response from ChatGPT as a prompt in and of itself to help me refactor
    my code.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将ChatGPT的回复本身作为提示，帮助我重构代码。
- en: 'For the purposes of this demonstration, I chose to go with the third option
    and send an additional prompt to ChatGPT:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示的目的，我选择了第三个选项，并向ChatGPT发送了一个额外的提示：
- en: '[PRE37]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Notice how I used the time-to-think principle to get the LLM to check whether
    each risk has actually been mitigated by the refactored code it suggested. This
    helps increase the likelihood that the code that’s returned will be useful. Sending
    this prompt to ChatGPT returned the following code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我是如何运用思考时间原则来让LLM检查每个风险是否确实被它建议的重构代码所减轻的。这有助于增加返回的代码实际上会有用的可能性。将此提示发送给ChatGPT返回了以下代码：
- en: '[PRE38]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: To check to see if these modifications hold up I copy the suggested code into
    `Timesheet`, modify `testCalculateTotalHoursWorked` to take a `long` instead of
    an `int` in `TimesheetTest` and discover that my checks still pass and I have
    refactored my code.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查这些修改是否有效，我将建议的代码复制到`Timesheet`中，修改`TimesheetTest`中的`testCalculateTotalHoursWorked`以接受一个`long`而不是`int`，并发现我的检查仍然通过了，我已经重构了我的代码。
- en: 'However, has this actually improved my code? To confirm, I run the original
    code analysis prompt with my updated code again and this time receive new risks:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这实际上改进了我的代码吗？为了确认，我再次用我的更新后的代码运行原始代码分析提示，这一次收到了新的风险：
- en: '[PRE39]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'What is interesting in this response is I can confirm that some risks have
    been mitigated such as:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个回应中有趣的是，我可以确认一些风险已经得到了减轻，比如：
- en: '[PRE40]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'But it appears that there are still some risks that haven’t. For example, in
    the first list of risks I received the following risk:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 但似乎仍然有一些风险还没有被减轻。例如，在我收到的第一个风险清单中，我收到了以下风险：
- en: '[PRE41]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Which was handled by ChatGPT implementing a `lowerCase` method to help sanitize
    the project name. However, on the second analysis I was returned the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT通过实现一个`lowerCase`方法来帮助清理项目名称来处理这个风险。然而，在第二次分析中，我收到了以下内容：
- en: '[PRE42]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This risk is very similar to the original, allegedly mitigated, risk. It feels
    like this additional risk around inconsistent data entry should have been handled
    properly when my code was refactored. I could once again ask the LLM to refactor
    my code for me, but instead given the potential for going round in circles with
    the LLM, it would be sensible for me to take the lead and fix the issues myself.
    This is an important skill to develop, when to rely on an LLM and when to take
    charge.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这个风险与原始的、据称已经减轻的风险非常相似。感觉这个关于不一致数据输入的额外风险应该在我的代码重构时得到妥善处理。我可以再次要求LLM为我重构代码，但考虑到与LLM打转的潜力，对我来说更明智的做法是自己主导并修复问题。这是一个重要的技能要发展，何时依赖于LLM，何时主导。
- en: 'The reason this choice is important can be highlighted by one of the other
    suggested risks that came from the second round of analysis. Specifically:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 选择重要的原因可以通过第二轮分析提出的其他建议风险之一来突出显示。具体地说：
- en: '[PRE43]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This sounds like a convincing risk, but it’s a demonstration of a hallucination.
    As the code stands, if the duration is 0 or less then method simply returns false
    and bails out of the timesheet storage:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来像是一个令人信服的风险，但这只是一种幻觉的示范。就目前的代码而言，如果持续时间为0或更少，则该方法只需返回false并退出时间表存储：
- en: '[PRE44]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: LLMs can be biased sometimes to prioritize giving an answer regardless of its
    quality. Meaning the more times we ask an LLM to analyze our code, the more likely
    it will start to generate hallucinations to give the impression that it’s producing
    useful results rather than returning with a response that no useful information
    can be shared. This is why we must keep careful tabs on when it’s useful to use
    an LLM and when it’s not.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，LLMs可能会存在偏见，优先考虑提供答案，而不考虑其质量。这意味着我们越多次要求LLM分析我们的代码，它就越有可能开始产生幻觉，以给出它正在产生有用结果的印象，而不是返回一个没有有用信息可分享的响应。这就是为什么我们必须仔细掌握何时使用LLM何时不使用的原因。
- en: At this point, I chose to stop the use case as what we’ve covered demonstrates
    the way in which different types of LLMs can help me in different ways. Copilot
    offers the ability to rapidly generate code, but it requires code-based prompts
    to help it with its suggestions. The newer the project, the more likely we are
    to see hits and misses with Copilot, but we can aid this process through the use
    of unit checks. This helps not only guide Copilot in the building of our code,
    but gives us the benefits of TDD including well-designed, testable code.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我选择停止使用案例，因为我们所涵盖的内容展示了不同类型的LLMs如何在不同方面帮助我。Copilot提供了快速生成代码的能力，但它需要基于代码的提示来帮助它提出建议。项目越新，我们越有可能在Copilot中看到命中和未命中，但我们可以通过单元检查来帮助这个过程。这不仅有助于指导Copilot构建我们的代码，而且给我们带来了TDD的好处，包括良好设计的可测试代码。
- en: With ChatGPT we’ve demonstrated that it can be a useful tool for analysis when
    prompted correctly. Building prompts that can analyze ideas and code and suggest
    risks and improvements can rapidly offer us alternative perspectives to consider,
    which we can then either action or reject. Utilizing the LLM as a simulation of
    role that advocates quality can help us to improve our work.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通过ChatGPT，我们已经证明了它可以是一个有用的分析工具，当正确提示时。构建可以分析思想和代码并提出风险和改进建议的提示可以迅速为我们提供不同的考虑角度，然后我们可以采取行动或拒绝。利用LLM作为倡导质量角色的模拟可以帮助我们改进工作。
- en: 4.5 Improving documentation and communication with LLMs
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 改进与LLMs的文档和沟通
- en: It might not seem so, but communicating the work we’ve done through code comments
    and release notes can be a big contributor to the quality of a product. By sharing
    new developments and changes to code bases, we can help fellow developers understand
    how our work impacts theirs, guide testers in what to focus on when testing our
    work, and even help how users view our products (For example, Slack’s early release
    notes helped market their tooling with their clear communication and humor).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看起来可能不是那么重要，但通过代码注释和发布说明来传达我们所做工作的方式对产品质量的贡献可能很大。通过分享新的发展和对代码库的更改，我们可以帮助其他开发人员了解我们的工作如何影响他们的工作，指导测试人员在测试我们的工作时应该关注什么，甚至帮助用户了解我们的产品（例如，Slack早期的发布说明通过其清晰的沟通和幽默帮助市场推广他们的工具）。
- en: Despite these benefits, documentation and release notes are sometimes left to
    languish at the end of a development cycle or are ignored entirely. This make
    senses, given the time required to write and maintain code comments and release
    notes that are useful and relevant, especially when there is time pressure to
    be constantly delivering new features. However, with the use of LLMs, we can reduce
    that time overhead while ensuring we create useful documentation that creates
    value for future readers. So let’s take a look at some useful prompts that can
    rapidly generate documentation for us.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些好处，文档和发布说明有时会被放置在开发周期的最后阶段，或者完全被忽略。考虑到编写和维护有用和相关的代码注释和发布说明所需的时间，尤其是当有时间压力不断交付新功能时，这是有道理的。然而，通过使用LLMs，我们可以减少这种时间开销，同时确保我们创建有用的文档，为未来的读者创造价值。所以让我们看一些可以迅速为我们生成文档的有用提示。
- en: 4.5.1 Generating code comments
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.1 生成代码注释
- en: 'Though we should always be striving to create code that is arranged in a way
    that is fluent and easy to parse, regardless of experience with a code base, code
    comments can provide the extra detail that prevents misuse of code and speeds
    up development. This is doubly important if we’re releasing APIs that will be
    used by others. (I’ve on many occasions wasted time trying to understand how a
    library works from poorly documented API docs.) The challenge is to get the right
    balance in code comments: too few and the person reading your code is left to
    fend for themselves; too much and we create more work for ourselves in maintaining
    code and comments to ensure they align with one another.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们应该始终努力创建以流畅易读的方式排列的代码，无论对于代码库的经验如何，代码注释可以提供额外的细节，以防止代码的误用并加快开发速度。如果我们发布的API将被他人使用，这一点尤为重要。（我曾多次因为API文档记录不足而浪费时间，试图理解一个库的工作原理。）挑战在于在代码注释中取得正确的平衡：太少了，读你代码的人将不得不自行解决；太多了，我们将为自己增加更多的工作量，以确保代码和注释保持一致。
- en: 'So instead, let’s look at a prompt that can take care of the process of annotating
    our work with comments for us:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们看一个可以为我们处理注释工作的提示：
- en: '[PRE45]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In this prompt we use the usual delimiter tactic to provide our code that we
    would like to see commented, but we also want to ensure that the LLM doesn’t change
    our code to make it align with the comments it creates. So we also make it explicit
    within the prompt to check that no parts of the code have been changed before
    outputting the completed commented code. Sending this prompt with our example
    code from earlier to ChatGPT returned the following commented code:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个提示中，我们使用通常的分隔符策略提供我们希望看到注释的代码，但我们也希望确保LLM不会改变我们的代码，以使其与它创建的注释保持一致。所以我们在提示中也明确表示，在输出完成的注释代码之前，检查代码的任何部分是否已更改。将此提示与我们之前的示例代码发送到ChatGPT返回了以下注释代码：
- en: '[PRE46]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'As we can see, the methods and sections of code within them have now been annotated
    with comments to give us more detail. What stands out most is comments such as:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，现在方法和其中的代码段都已经被注释以提供更多细节。最引人注目的是诸如：
- en: '[PRE47]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The comment provided not only references what the `ConcurrentHashMap` is used
    for but also highlights that all project names will be stored in lowercase, which
    is a reference to part of the code inside `submitTimesheet,` which does stand
    in contrast to comments like this, which feel a little unnecessary:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的注释不仅提到了`ConcurrentHashMap`的用途，还强调了所有项目名称将以小写形式存储，这是对`submitTimesheet`内部代码的一个参考，与此相比，像这样的注释感觉有点多余：
- en: '[PRE48]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Once again the choice is ours as to what to use and what not to. Though the
    prompt we’ve used has provided us with comments, we’ve observed that some are
    probably more of use than others. So our role changes from being the author of
    comments to an editor, selecting and tweaking the comments that seem the most
    useful.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以自行选择使用什么，不使用什么。虽然我们使用的提示已经为我们提供了注释，但我们观察到有些可能比其他更有用。因此，我们的角色从注释的作者变为编辑，选择并调整看起来最有用的注释。
- en: Maintaining code comments with prompts
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用提示维护代码注释
- en: What makes this process so useful is that when we inevitably come to a point
    in which our code changes and our comments need updating, we simply can run the
    prompt again with our updated code to regenerate our comments to incorporate our
    changes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程如此有用的原因在于，当我们不可避免地遇到代码变化和我们的注释需要更新的时候，我们只需简单地运行带有我们更新代码的提示，以重新生成我们的注释，以整合我们的变化。
- en: 'A final observation is that although the comments can be useful for someone
    reading our code directly, what if we want to provide more structured documentation
    in the form of, say, Javadoc? In that instance, we can modify the prompt and use
    the structured data tactic to create a prompt like so:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的观察是，尽管注释对于直接阅读我们的代码的人可能很有用，但如果我们想以结构化文档的形式（例如Javadoc）提供更多的文档怎么办？在那种情况下，我们可以修改提示，并使用结构化数据策略来创建一个如下所示的提示：
- en: '[PRE49]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Sending this prompt with our example code to ChatGPT produces:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 将此提示与我们的示例代码一起发送给ChatGPT产生以下结果：
- en: '[PRE50]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Using this prompt, we’ve improved the quality of some of the comments and also
    created JavaDoc-friendly comments that can be used to document our code for external
    users. All that would be left for us to do is to tweak and edit at the points
    we see fit.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个提示，我们改进了一些注释的质量，并创建了可以用于为外部用户文档化我们的代码的JavaDoc友好的注释。我们需要做的就是在适当的地方进行微调和编辑。
- en: 4.5.2 Generating release notes
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.2 生成发布说明
- en: 'Just as we can use a LLM to modify our code to add comments, we can also use
    LLMs to transform our code base into release notes that can be consumed by others
    in the team and beyond. To do this, we create a new prompt with the following
    details:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们可以使用LLM修改我们的代码以添加注释一样，我们也可以使用LLM将我们的代码库转换为可以由团队和更广泛的人员消费的发布说明。为此，我们创建一个具有以下详细信息的新提示：
- en: '[PRE51]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The prompt follows a similar pattern to the previous code comment focused prompt,
    but this time instead of asking it to inject comments into our code we instruct
    the code to be transformed in natural language release notes. For example, sending
    the prompt with the sample code to ChatGPT returned this:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示遵循了与以前的代码注释为重点的提示类似的模式，但这次我们不是要求它将注释注入我们的代码，而是要求将代码转换为自然语言发布说明。例如，将带有示例代码的提示发送给ChatGPT返回了以下结果：
- en: '[PRE52]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The result we get is a completely different format to our original code that
    attempts to detail what our code base does. Reviewing the output, it does feel
    quite technical, which makes sense considering we’ve asked for detailed notes
    on a small amount of code. However, even these release notes can be of use because
    we can adapt an earlier prompt for suggesting risks to analyse the release notes:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的结果是完全不同于我们原始代码的格式，试图详细说明我们的代码库做了什么。回顾输出，它确实感觉非常技术化，这是有道理的，因为我们要求对少量代码进行详细说明。然而，即使是这些发布说明也可以派上用场，因为我们可以修改先前的提示以建议分析发布说明的风险：
- en: '[PRE53]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Using this prompt in ChatGPT returned me the following suggested risks:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个提示在ChatGPT中返回了以下建议的风险：
- en: '[PRE54]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Of course, this might be an unnecessary step if we can directly ask an LLM to
    suggest risks based on the code directly, but it does demonstrate the power of
    LLMs ability to transform data from one format to another.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果我们可以直接要求LLM根据代码直接提出风险，这可能是一个不必要的步骤，但它确实展示了LLM将数据从一种格式转换为另一种格式的能力。
- en: 4.6 Maintaining a balance with code assistants
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 与代码助手保持平衡
- en: The perspective on the value that tools like Copilot and ChatGPT offer depends
    on individuals. For some, it means the automation of development and the loss
    of many roles, and for others, it’s nothing but an advanced tool that randomly
    picks suggested code. What this chapter demonstrates is the ongoing theme that
    their worth and usefulness lie somewhere between those two extremes.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像Copilot和ChatGPT这样的工具所提供的价值观取决于个人。对于一些人来说，这意味着开发的自动化和许多角色的流失，对于其他人来说，它只是一个随机选择建议代码的先进工具。本章展示的持续主题是它们的价值和用处在这两个极端之间。
- en: These models, trained on masses of data from Stack Overflow and GitHub repositories,
    are very sophisticated in what they suggest for both production and test code.
    But they still require direction from us humans—direction that is guided by our
    abilities to communicate with stakeholders, analyze requirements, and design implementation.
    How well we can use AI tools in development is dependent on honing our complementary
    skills, which can be summarized by using the area-of-effect model shown in Figure
    4.2.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型是在大量来自Stack Overflow和GitHub存储库的数据上进行训练的，它们对于生产和测试代码提出了非常复杂的建议。但是它们仍然需要我们人类的指导
    - 这种指导是由我们与利益相关者沟通的能力、分析需求和设计实施所引导的。我们能够多好地使用AI工具来进行开发取决于我们如何完善我们的辅助技能，这可以通过使用图4.2所示的区域效应模型进行总结。
- en: Figure 4.2 An area-of-effect model, updated to demonstrate the skills of a human
    and the ability of code assistant tools
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.2 一个区域效应模型，更新以展示人类技能和代码助手工具的能力
- en: '![](images/04__image003.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](images/04__image003.png)'
- en: A balanced approach can help us to deliver features faster but still ensure
    that we build in quality. So our goal is to maintain that balance in situations
    in which we may need to rely on our own abilities or the features of our tools.
    Sometimes, code assistants won’t be able to suggest the correct implementation
    and we need to take charge. This gives us more control but does sacrifice speed.
    At other times, we can rely on code assistant tools to reference vast amounts
    of data to suggest new design ideas through unit checks or conversations. But
    we want to ensure that we keep our TDD loops focused on design and not on test
    coverage. Too many unit checks and we lose sight of our design and end up in a
    box-checking activity.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 平衡的方法可以帮助我们更快地交付功能，但仍然确保我们建立质量。因此，我们的目标是在需要依赖我们自己的能力或代码助手工具的情况下保持平衡。有时，代码助手无法提供正确的实现建议，我们需要掌控。这可以给我们更多的控制，但会牺牲速度。在其他时候，我们可以依赖代码助手工具参考大量数据来通过单元测试或对话来提出新的设计理念。但我们希望确保我们的
    TDD 循环专注于设计，而不是测试覆盖率。过多的单元测试会使我们失去设计的视野，最终陷入一个钩钩检查的活动中。
- en: 4.7 Summary
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 总结
- en: The majority of AI tools now on the market rely on large language models that
    are trained with vast amounts of data scraped from the internet.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前市场上大多数的人工智能工具都依赖于从互联网上采集的大量数据进行训练的大型语言模型。
- en: LLMs are sophisticated algorithms that apply statistical analysis to our requests
    to determine what output it should respond with.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 是一种先进的算法，通过对我们的请求应用统计分析来确定应该回应的输出内容。
- en: Copilot is a coding assistant tool that uses the OpenAI GPT-4 and is trained
    on code that is stored on GitHub.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Copilot 是一个使用 OpenAI GPT-4 并训练于存储在 GitHub 上的代码的编码助手工具。
- en: Copilot works within an IDE and reads your code as a prompt to suggest what
    to add next into test code and production code.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Copilot 在 IDE 中工作，通过读取您的代码作为提示来建议添加到测试代码和生产代码中的内容。
- en: Tools like Copilot can work well with the TDD red/green/refactor loop to help
    us rapidly create unit checks and production code.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像 Copilot 这样的工具可以很好地与 TDD 红/绿/重构循环配合使用，帮助我们快速创建单元测试和生产代码。
- en: To help Copilot return code that is valuable, we need to guide it with prompts.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了帮助 Copilot 返回有价值的代码，我们需要通过提示对其进行引导。
- en: Success with AI code assistants depends on our understanding our abilities and
    the features of code assistant tools.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功地使用人工智能代码助手取决于我们对自己的能力以及代码助手工具的功能的了解。
- en: A push-pull relationship exists between how much we are leading versus the tooling
    leading design.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的主导程度与工具主导设计之间存在一种推拉关系。
- en: We must be aware of the tradeoffs when the balance shifts from humans leading
    to tools leading.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当平衡从人类主导转变为工具主导时，我们必须意识到其中的权衡。
