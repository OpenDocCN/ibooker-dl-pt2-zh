- en: Chapter 7\. Visualizing data and models
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第7章 数据和模型的可视化
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章内容*'
- en: How to use tfjs-vis to perform custom data visualization
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用tfjs-vis执行自定义数据可视化
- en: How to peek at the internal workings of models after they are trained and gain
    useful insights
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在模型训练后查看内部工作并获得有用的见解
- en: Visualization is an important skill for machine-learning practitioners because
    it is involved in every phase of the machine-learning workflow. Before we build
    models, we examine our data by visualizing it; during model engineering and training,
    we monitor the training process through visualization; after the model is trained,
    we use visualization to get a sense about how it works.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化对于机器学习从业者来说是一项重要的技能，因为它涉及到机器学习工作流的每个阶段。在我们构建模型之前，我们通过可视化来检查数据；在模型工程和训练期间，我们通过可视化来监测训练过程；模型训练完毕后，我们使用可视化来了解其工作原理。
- en: In [chapter 6](kindle_split_018.html#ch06), you learned the benefits of visualizing
    and understanding data before applying machine learning on it. We described how
    to use Facets, a browser-based tool that helps you get a quick, interactive look
    at your data. In this chapter, we will introduce a new tool, tfjs-vis, which helps
    you visualize your data in custom, programmatic ways. The benefit of doing so,
    versus just looking at the data in its raw format or using off-the-shelf tools
    such as Facets, is the more flexible and versatile visualization paradigm and
    the deeper understanding of data that it leads to.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](kindle_split_018.html#ch06)中，你了解到在应用机器学习之前，可视化和了解数据的好处。我们介绍了如何使用Facets，这是一个基于浏览器的工具，可以帮助你快速、交互式地查看数据。在本章中，我们将介绍一个新工具tfjs-vis，它可以帮助你以自定义、程序化的方式可视化数据。这样做的好处，相较于只看数据的原始格式或使用Facets等现成工具，是更灵活、多样的可视化范式以及更深入理解数据的可能性。
- en: In addition to the visualization of data, we will show how visualization can
    be used on deep-learning models *after* they are trained. We will use the fascinating
    examples of peeking into the “black boxes” of neural networks by visualizing their
    internal activations and computing the patterns that maximally “excite” layers
    of a convnet. This will complete the story of how visualization goes hand-in-hand
    with deep learning in each and every stage of it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据可视化外，我们还会展示如何在深度学习模型*训练后*使用可视化。我们将使用深入的例子，通过可视化内部激活和计算卷积神经网络层最大程度“激发”的模式，来窥视神经网络“黑盒”的潜力。这将完整展现可视化如何在每个阶段与深度学习相辅相成的故事。
- en: By the end of this chapter, you should know why visualization is an indispensable
    part of any machine-learning workflow. You should also be familiar with the standard
    ways in which data and models are visualized in the framework of TensorFlow.js
    and be able to apply them to your own machine-learning problems.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你应该知道为什么可视化是任何机器学习工作流不可或缺的一部分。你还应该熟悉在TensorFlow.js框架中可视化数据和模型的标准方式，并能够将它们应用到自己的机器学习问题中。
- en: 7.1\. Data visualization
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1数据可视化
- en: Let’s start from the visualization of data, because that’s the first thing a
    machine-learning practitioner does when laying hands on a new problem. We assume
    that the visualization task is more advanced than what can be covered by Facets
    (for instance, the data isn’t in a small CSV file). For that, we will first introduce
    a basic charting API that helps you create simple and widely used types of plots,
    including line charts, scatter plots, bar charts, and histograms, in the browser.
    After we’ve covered the basic examples using hand-coded data, we will put things
    together by using an example involving the visualization of an interesting real
    dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从数据可视化开始，因为这是机器学习实践者在解决新问题时首先做的事情。我们假设可视化任务比Facets能够覆盖的更高级（例如，数据不在一个小的CSV文件中）。因此，我们首先会介绍一个基本的图表API，它可以帮助你在浏览器中创建简单且广泛使用的绘图类型，包括折线图、散点图、条形图和直方图。在完成使用手工编写的数据的基本示例后，我们将通过一个涉及可视化有趣真实数据集的示例将事物整合起来。
- en: 7.1.1\. Visualizing data using tfjs-vis
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1使用tfjs-vis可视化数据
- en: tfjs-vis is a visualization library closely integrated with TensorFlow.js. Among
    its many features that this chapter will cover is a lightweight charting API under
    its `tfvis.render.*` namespace.^([[1](#ch07fn1)]) This simple and intuitive API
    allows you to make charts in the browser, with a focus on the types of charts
    most frequently used in machine learning. To help you get started with `tfvis.render`,
    we will give you a tour of the CodePen at [https://codepen.io/tfjs-book/pen/BvzMZr](https://codepen.io/tfjs-book/pen/BvzMZr),
    which showcases how to use `tfvis.render` to create various types of basic data
    plots.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: tfjs-vis 是一个与 TensorFlow.js 紧密集成的可视化库。本章将介绍其许多功能之一，即其 `tfvis.render.*` 命名空间下的轻量级图表
    API。这个简单直观的 API 允许你在浏览器中制作图表，重点关注机器学习中最常用的图表类型。为了帮助你开始使用 `tfvis.render`，我们将给你介绍一个
    CodePen，地址为 [https://codepen.io/tfjs-book/pen/BvzMZr](https://codepen.io/tfjs-book/pen/BvzMZr)，该
    CodePen 展示了如何使用 `tfvis.render` 创建各种基本数据图。
- en: ¹
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This charting API is built on top of the Vega visualization library: [https://vega.github.io/vega/](https://vega.github.io/vega/).'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此绘图 API 是建立在 Vega 可视化库之上的：[https://vega.github.io/vega/](https://vega.github.io/vega/)。
- en: Basics of tfjs-vis
  id: totrans-15
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: tfjs-vis 的基础知识
- en: 'First, note that tfjs-vis is separate from the main TensorFlow.js library.
    You can see this from how the CodePen imports tfjs-vis with a `<script>` tag:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，注意 tfjs-vis 是独立于主要的 TensorFlow.js 库的。你可以从 CodePen 如何用 `<script>` 标签导入 tfjs-vis
    来看出这一点：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is different from how the main TensorFlow.js library is imported:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这与导入主要的 TensorFlow.js 库的方式不同：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The same distinction applies to the npm packages of tfjs-vis and TensorFlow.js
    (`@tensorflow/tfjs-vis` and `@tensorflow/tfjs`, respectively). In a web page or
    JavaScript program that depends on both TensorFlow.js and tfjs-vis, the two dependencies
    must both be imported.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: tfjs-vis 和 TensorFlow.js 的 npm 包有所不同（分别是 `@tensorflow/tfjs-vis` 和 `@tensorflow/tfjs`）。在一个依赖于
    TensorFlow.js 和 tfjs-vis 的网页或 JavaScript 程序中，这两个依赖都必须被导入。
- en: Line charts
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 线图
- en: The most commonly used type of chart is perhaps the *line chart* (a curve that
    plots a quantity against an ordered quantity). A line chart has a horizontal axis
    and a vertical axis, which are often referred to as the *x-axis* and *y-axis*,
    respectively. This type of visualization is seen everywhere in life. For example,
    we can plot how the temperature changes over the course of a day with a line chart
    in which the horizontal axis is the time of day and the vertical axis is the reading
    of a thermometer. The horizontal axis of a line chart can also be something other
    than time. For instance, we can use a line chart to show the relation between
    the therapeutic effect of a high-blood-pressure medication (how much it reduces
    blood pressure) and the dose (how much of the medication is used per day). Such
    a plot is referred to as a *dose-response curve*. Another good example of a nontemporal
    line chart is the ROC curve we discussed in [chapter 3](kindle_split_014.html#ch03).
    There, neither the x- nor y-axis has to do with time (they are the false and true
    positive rates of a binary classifier).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的图表类型可能是 *线图*（一个曲线，将一个数量绘制成有序数量）。线图有一个水平轴和一个垂直轴，通常分别称为 *x 轴* 和 *y 轴*。这种类型的可视化在生活中随处可见。例如，我们可以通过线图将一天中温度的变化情况绘制出来，其中水平轴是一天中的时间，垂直轴是温度计的读数。线图的水平轴也可以是其他东西。例如，我们可以使用线图来显示高血压药物的治疗效应（它降低了多少血压）与剂量（每天使用多少药物）之间的关系。这样的绘图被称为
    *剂量-反应曲线*。另一个非时间线图的很好的例子是我们在[第三章](kindle_split_014.html#ch03)中讨论的 ROC 曲线。那里，x
    轴和 y 轴都与时间无关（它们是二元分类器的假阳性和真阳性率）。
- en: 'To create a line chart with `tfvis.render`, use the `linechart()` function.
    As the first example in the CodePen (also [listing 7.1](#ch07ex01)) shows, the
    function takes three arguments:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `tfvis.render` 创建线图，可以使用 `linechart()` 函数。正如 CodePen 的第一个示例（也是[清单 7.1](#ch07ex01)）所示，该函数需要三个参数：
- en: The first argument is the HTML element in which the chart will be drawn. An
    empty `<div>` element suffices.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个参数是用于绘制图表的 HTML 元素。可以使用空的 `<div>` 元素。
- en: The second argument is the values of the data points in the chart. This is a
    plain old JavaScript object (POJO) with the `value` field pointing to an array.
    The array consists of a number of x-y value pairs, each of which is represented
    by a POJO with fields named `x` and `y`. The `x` and `y` values are, of course,
    the x- and y-coordinates of the data points, respectively.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个参数是图表中数据点的值。这是一个包含`value`字段并指向一个数组的普通JavaScript对象（POJO）。数组由多个x-y值对组成，每个值对由一个包含名为`x`和`y`字段的POJO表示。`x`和`y`值分别是数据点的x和y坐标。
- en: The third argument, which is optional, contains additional configuration fields
    for the line chart. In this example, we use the `width` field to specify the width
    of the resultant chart (in pixels). You will see more configuration fields in
    the coming examples.^([[2](#ch07fn2)])
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三个参数（可选）包含线图的其他配置字段。在这个例子中，我们使用`width`字段来指定结果图的宽度（以像素为单位）。在后面的例子中您将看到更多的配置字段。^([[2](#ch07fn2)])
- en: ²
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ²
- en: ''
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[https://js.tensorflow.org/api_vis/latest/](https://js.tensorflow.org/api_vis/latest/)
    contains the full documentation of the tfjs-vis API, where you can find information
    about other configuration fields of this function.'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://js.tensorflow.org/api_vis/latest/](https://js.tensorflow.org/api_vis/latest/)
    包含 tfjs-vis API 的完整文档，在这里您可以找到关于此函数的其他配置字段的信息。'
- en: Listing 7.1\. Making a simple line chart using `tfvis.render.linechart()`
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单7.1\. 使用`tfvis.render.linechart()`创建一个简单的折线图
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '***1*** The data series is an array of x-y pairs.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 数据系列是一个包含x-y对的数组。'
- en: '***2*** The first argument is an HTML element in which the chart will be drawn.
    Here, ‘plot1’ is the ID of an empty div.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 第一个参数是将绘制图表的HTML元素。这里的''plot1''是一个空的div的ID。'
- en: '***3*** The second argument is an Object containing the key “value.”'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** 第二个参数是一个包含键“值”的对象。'
- en: '***4*** Custom configuration is passed as the third argument. In this case,
    we configure only the width of the plot.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** 自定义配置作为第三个参数传递。在这种情况下，我们只配置了图的宽度。'
- en: The line chart created by the code in [listing 7.1](#ch07ex01) is shown in the
    left panel of [figure 7.1](#ch07fig01). This is a simple curve with only four
    data points. But the `linechart()` function can support curves with many more
    data points (for example, thousands). However, you will eventually run into the
    browser’s resource restrictions if you try to plot too many data points at once.
    The limit is browser- and platform-dependent and should be discovered empirically.
    In general, it is good practice to limit the size of the data to be rendered in
    interactive visualizations for the sake of a smooth and responsive UI.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由[清单7.1](#ch07ex01)中的代码创建的折线图显示在[图7.1](#ch07fig01)的左侧面板中。这是一个只有四个数据点的简单曲线。但是，`linechart()`函数可以支持更多数据点的曲线（例如，数千个）。然而，如果你尝试一次绘制太多数据点，你最终会遇到浏览器的资源限制。限制与浏览器和平台相关，应当通过实证方法来确定。一般来说，为了使用户界面流畅响应，限制图表中可呈现的数据大小是一个好习惯。
- en: 'Figure 7.1\. Line charts created using `tfvis.render.linechart()`. Left: a
    single series, made using the code in [listing 7.1](#ch07ex01). Right: two series
    in the same axes, made using the code in [listing 7.2](#ch07ex02).'
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.1\. 使用`tfvis.render.linechart()`创建的折线图。左侧：使用[清单7.1](#ch07ex01)中的代码创建的单个系列。右侧：使用[清单7.2](#ch07ex02)中的代码在同一个坐标轴上创建的两个系列。
- en: '![](06fig07_alt.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig07_alt.jpg)'
- en: Sometimes you want to plot two curves in the same chart in order to show the
    relation between them (for instance, to contrast them with each other). You can
    make these sorts of plots with `tfvis.render.linechart()`. An example is shown
    in the right panel of [figure 7.1](#ch07fig01) and the code in [listing 7.2](#ch07ex02).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您想在同一张图中绘制两条曲线，以显示它们之间的关系（例如相互比较）。您可以使用`tfvis.render.linechart()`制作这些类型的图表。示例显示在图7.1的右侧面板中，代码在[清单7.2](#ch07ex02)中。
- en: These are known as *multiseries* charts, and each line is called a *series*.
    To create a multiseries chart, you must include an additional field, `series`,
    in the first argument to `linechart()`. The value of the field is an array of
    strings. The strings are the names given to the series and will be rendered as
    a legend in the resulting chart. In the example code, we call our series `'My
    series 1'` and `'My series 2'`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些被称为*多系列*图表，每条线称为*系列*。要创建多系列图表，必须在传递给`linechart()`的第一个参数中包括一个附加字段`series`。该字段的值是一个字符串数组。这些字符串是系列的名称，并将作为图表中的图例呈现。在示例代码中，我们将系列称为`'My
    series 1'`和`'My series 2'`。
- en: The `value` field of the first argument also needs to be specified properly
    for a multiseries chart. For our first example, we provided an array of points,
    but for multiseries plots, we must provide an array of arrays. Each element of
    the nested array is the data points of a series and has the same format as the
    values array we saw in [listing 7.1](#ch07ex01) when we plotted a single-series
    chart. Therefore, the length of the nested array must match the length of the
    `series` array, or an error will occur.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多系列图表，第一个参数的`value`字段也需要恰当地指定。对于我们的第一个示例，我们提供了一个点数组，但是对于多系列图表，我们必须提供一个数组的数组。嵌套数组的每个元素都是一个系列的数据点，并且具有与我们在[清单7.1](#ch07ex01)中绘制单系列图表时看到的值数组相同的格式。因此，嵌套数组的长度必须与`series`数组的长度匹配，否则将出现错误。
- en: The chart created by [listing 7.2](#ch07ex02) is shown in the right panel of
    [figure 7.1](#ch07fig01). As you can see in the chart in electronic versions of
    this book, tfjs-vis has picked two different colors (blue and orange) to render
    the two curves in. This default coloring scheme works well in general because
    blue and orange are easy to tell apart. If there are more series to render, other
    new colors will be selected automatically.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由[清单 7.2](#ch07ex02)创建的图表显示在[图 7.1](#ch07fig01)的右侧面板中。如您在本书的电子版本中图表中所见，tfjs-vis选择两种不同的颜色（蓝色和橙色）来渲染两条曲线。这种默认的着色方案通常很有效，因为蓝色和橙色很容易区分。如果有更多的系列需要呈现，其他新颜色将自动选择。
- en: The two series in this example chart are a little special in the sense that
    they have exactly the same set of x-coordinate values (1, 2, 3, and 4). However,
    in general, the x-coordinate values of different series in a multiseries chart
    don’t have to be identical. You are encouraged to try this in exercise 1 at the
    end of this chapter. But, be aware that it is not always a good idea to plot two
    curves in the same chart. For example, if the two curves have very different and
    nonoverlapping y-value ranges, plotting them in the same line chart will make
    the variation in each curve harder to see. In such cases, it is better to plot
    them in separate line charts.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例图表中的两个系列在x坐标的值（1、2、3和4）完全相同。但是，在多系列图表中，不同系列的x坐标值不一定相同。您可以尝试在本章末尾的练习1中尝试这种情况。但是，需要注意的是，将两条曲线绘制在同一个线条图表中并不总是明智的做法。例如，如果两条曲线具有非常不同并且不重叠的y值范围，则将它们绘制在同一个线条图表中会使每个曲线的变化更难以看到。在这种情况下，最好将它们绘制在单独的线条图表中。
- en: Another thing worth pointing out in [listing 7.2](#ch07ex02) is the custom labels
    for the axes. We use the `xLabel` and `yLabel` fields in the configuration object
    (the third argument passed to `linechart()`) in order to label the x- and y-axis
    as custom strings of our choice. In general, it is good practice to always label
    your axes, as it makes the charts more self-explanatory. tfjs-vis will always
    label your axes as `x` and `y` if you don’t specify `xLabel` and `yLabel`, which
    is what happened in [listing 7.1](#ch07ex01) and the left panel of [figure 7.1](#ch07fig01).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在[清单 7.2](#ch07ex02)中还值得指出的是轴的自定义标签。 我们使用配置对象中的`xLabel`和`yLabel`字段（传递给`linechart（）`的第三个参数）来标记我们选择的自定义字符串的x和y轴。
    通常，标记轴是一种良好的实践，因为它使图表更易于理解。 如果您没有指定`xLabel`和`yLabel`，tfjs-vis将始终将您的轴标记为`x`和`y`，这就是[清单
    7.1](#ch07ex01)和[图 7.1](#ch07fig01)的左面板所发生的。
- en: Listing 7.2\. Making a line chart with two series using `tfvis.render.linechart()`
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单7.2。使用 `tfvis.render.linechart（）`制作带有两个系列的线条图表
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '***1*** To show multiple series in the same axes, make values an array consisting
    of multiple arrays of x-y pairs.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 为了在相同的轴上显示多个系列，使值成为由多个x-y对数组组成的数组。'
- en: '***2*** Series names must be provided when plotting multiple series.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 在绘制多个系列时，必须提供系列名称。'
- en: '***3*** Overrides the default x- and y-axis labels'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** 覆盖默认的 x 和 y 坐标轴标签。'
- en: Scatter plots
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 散点图
- en: '*Scatter* *plots* are another type of chart you can create with `tfvis.render`.
    The most salient difference between a scatter plot and a line chart is the fact
    that a scatter plot doesn’t connect the data points with line segments. This makes
    scatter plots suitable for cases in which the ordering among data points is unimportant.
    For example, a scatter plot may plot the population of a few countries against
    their per-capita GDPs. In such a plot, the primary piece of information is the
    relation between the x- and y-values, not an ordering among the data points.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*散点图* 是您可以使用 `tfvis.render` 创建的另一种图表类型。散点图与折线图最显著的区别在于，散点图不使用线段连接数据点。这使得散点图适用于数据点间顺序不重要的情况。例如，散点图可以将几个国家的人口与人均国内生产总值进行绘制。在这样的图中，主要信息是
    x 值和 y 值之间的关系，而不是数据点之间的顺序。'
- en: In `tfvis.render`, the function that lets you create scatter plots is `scatterplot()`.
    As the example in [listing 7.3](#ch07ex03) shows, `scatterplot()` can render multiple
    series, just like `linechart()`. In fact, the APIs of `scatterplot()` and `linechart()`
    are practically identical, as you can see by comparing [listing 7.2](#ch07ex02)
    with [listing 7.3](#ch07ex03). The scatter plot created by [listing 7.3](#ch07ex03)
    is shown in [figure 7.2](#ch07fig02).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `tfvis.render` 中，让您创建散点图的函数是 `scatterplot()`。正如 [清单 7.3](#ch07ex03) 中的示例所示，`scatterplot()`
    可以呈现多个系列，就像 `linechart()` 一样。事实上，`scatterplot()` 和 `linechart()` 的 API 实际上是相同的，您可以通过比较
    [清单 7.2](#ch07ex02) 和 [清单 7.3](#ch07ex03) 来了解。[清单 7.3](#ch07ex03) 创建的散点图显示在 [图
    7.2](#ch07fig02) 中。
- en: Figure 7.2\. A scatter plot that contains two series, made with the code in
    [listing 7.3](#ch07ex03).
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.2\. 包含两个系列的散点图，使用 [清单 7.3](#ch07ex03) 中的代码制作。
- en: '![](07fig02_alt.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig02_alt.jpg)'
- en: Listing 7.3\. Making a scatter plot using `tfvis.render.scatterplot()`
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单 7.3\. 使用 `tfvis.render.scatterplot()` 制作散点图
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***1*** As in linechart(), uses an array of x-y pair arrays to show multiple
    series in a scatter plot'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 与 linechart() 一样，使用 x-y 对数组的数组来在散点图中显示多个系列'
- en: '***2*** Always remember to label your axes.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 记得始终标记你的轴。'
- en: Bar charts
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 柱状图
- en: As its name indicates, a *bar chart* uses bars to show the magnitude of quantities.
    Such bars usually start from zero at the bottom so that the ratios between the
    quantities can be read from the relative heights of the bars. Therefore, bar charts
    are a good choice when the ratio between quantities is of importance. For example,
    it is natural to use a bar chart to show the annual revenue of a company over
    a few years. In this case, the relative heights of the bars give the viewer an
    intuitive sense of how the revenue changes from one quarter to another in terms
    of the ratio between them. This makes bar charts distinct from line charts and
    scatter plots, in which the values are not necessarily “anchored” at zero.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名称所示，*柱状图* 使用柱形显示数量的大小。这些柱通常从底部的零开始，以便可以从柱形的相对高度读取数量之间的比率。因此，当数量之间的比率很重要时，柱状图是一个不错的选择。例如，自然而然地使用柱状图来显示公司几年来的年收入。在这种情况下，柱形的相对高度使观众对收入在季度之间的变化情况有直观的感觉。这使得柱状图与折线图和散点图有所不同，因为这些值不一定“锚定”在零点上。
- en: To create a bar chart with `tfvis.render`, use `barchart()`. You can find an
    example in [listing 7.4](#ch07ex04). The bar chart created by the code is shown
    in [figure 7.3](#ch07fig03). The API of `barchart()` is similar to those of `linechart()`
    and `scatterplot()`. However, an important difference should be noted. The first
    argument passed to `barchart()` is not an object consisting of a `value` field.
    Instead, it is a simple array of index-value pairs. The horizontal values are
    not specified with a field called `x`, but are instead specified with a field
    called `index`. Similarly, the vertical values are not specified with a field
    called `y`, but are instead associated with a field called `value`. Why this difference?
    It is because the horizontal values of a bar in a bar chart don’t have to have
    a number. Instead, they can be either strings or numbers, as is shown by our example
    in [figure 7.3](#ch07fig03).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`tfvis.render`创建条形图，请使用`barchart()`。您可以在[代码清单7.4](#ch07ex04)中找到一个示例。代码创建的条形图显示在[图7.3](#ch07fig03)中。`barchart()`的API类似于`linechart()`和`scatterplot()`的API。但是，应该注意一个重要的区别。传递给`barchart()`的第一个参数不是由`value`字段组成的对象。相反，它是一个简单的索引-值对数组。水平值不是用一个叫做`x`的字段指定的，而是用一个叫做`index`的字段指定的。同样，垂直值不是用一个叫做`y`的字段指定的，而是与一个叫做`value`的字段关联的。为什么有这种区别？这是因为条形图中条形的水平值不一定是一个数字。相反，它们可以是字符串或数字，正如我们在[图7.3](#ch07fig03)的示例中所示。
- en: Figure 7.3\. A bar chart consisting of both string- and numeric-named bars,
    made with the code in [listing 7.4](#ch07ex04)
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.3\. 由[代码清单7.4](#ch07ex04)生成的包含字符串和数字命名条的条形图
- en: '![](07fig03_alt.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig03_alt.jpg)'
- en: Listing 7.4\. Creating a bar chart using `tfvis.render.barchart()`
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码清单7.4\. 使用`tfvis.render.barchart()`创建条形图
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '***1*** Notice how the index of a bar chart can be numeric or a string. Note
    that the order of the elements matters.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 请注意条形图的索引可以是数字或字符串。请注意元素的顺序很重要。'
- en: Histograms
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 直方图
- en: The three types of plots described previously let you plot the values of a certain
    quantity. Sometimes, the detailed quantitative values are not as important as
    the *distribution* of the values. For example, consider an economist looking at
    the annual household income data from the result of a national census. To the
    economist, the detailed income values are not the most interesting piece of information.
    They contain too much information (yes, sometimes too much information can be
    a bad thing!). Instead, the economist wants a more succinct summary of the income
    values. They’re interested in how such values are distributed—that is, how many
    of them fall below US$20,000, how many of them are between $20,000 and $40,000,
    or between $40,000 and $60,000, and so forth. *Histograms* are a type of chart
    suited for such a visualization task.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 先前描述的三种图表类型允许您绘制某个数量的值。有时，详细的定量值并不像值的*分布*那样重要。例如，考虑一位经济学家查看国家普查结果中的年度家庭收入数据。对于经济学家来说，详细的收入数值并不是最有趣的信息。它们包含了太多信息（是的，有时候太多信息可能是一件坏事！）。相反，经济学家想要更简洁的收入数值摘要。他们对这些值是如何分布感兴趣——即有多少个值低于2万美元，有多少个值介于2万美元和4万美元之间，或者介于4万美元和6万美元之间，等等。*直方图*是一种适合这种可视化任务的图表类型。
- en: A histogram assigns the values into *bins*. Each bin is simply a continuous
    range for the value, with a lower bound and an upper bound. The bins are chosen
    to be adjacent to each other so as to cover all possible values. In the prior
    example, the economist may use bins such as 0 ~ 20k, 20k ~ 40k, 40k ~ 60k, and
    so forth. Once such a set of `N` bins is chosen, you can write a program to count
    the number of individual data points that fall into each of the bins. Executing
    this program will give you *N* numbers (one for each bin). You can then plot the
    numbers using vertical bars. This gives you a histogram.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图将值分配到*区间*中。每个区间只是一个值的连续范围，有一个下界和一个上界。区间被选择为相邻的，以覆盖所有可能的值。在前面的例子中，经济学家可能使用诸如0
    ~ 20k、20k ~ 40k、40k ~ 60k等的区间。一旦选择了这样一组`N`个区间，您就可以编写一个程序来计算落入每个区间的单个数据点的数量。执行此程序将给您*N*个数字（每个区间一个）。然后，您可以使用垂直条形图绘制这些数字。这就给您一个直方图。
- en: '`tfvis.render.histogram()` does all these steps for you. This saves you the
    effort of determining the bounds of the bins and counting the examples by the
    bins. To invoke `histogram()`, simply pass an array of numbers, as shown in the
    following listing. These numbers don’t need to be sorted in any order.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfvis.render.histogram()` 会为您执行所有这些步骤。这样可以省去您确定箱界限并按箱计数示例的麻烦。要调用 `histogram()`，只需传递一个数字数组，如下面的列表所示。这些数字不需要按任何顺序排序。'
- en: Listing 7.5\. Visualizing a value distribution using `tfvis.render.histogram()`
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第 7.5 节。使用 `tfvis.render.histogram()` 可视化值分布。
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***1*** Uses automatically generated bins'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 使用自动生成的箱。'
- en: '***2*** Specifies the number of bins explicitly'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 指定了明确的箱数。'
- en: In [listing 7.5](#ch07ex05), there are two slightly different `histogram()`
    calls. The first call doesn’t specify any custom options beyond the width of the
    plot. In this case, `histogram()` uses its built-in heuristics to calculate the
    bins. This results in seven bins –4 ~ –2, –2 ~ 0, 0 ~ 2, . . ., 8 ~ 10, as shown
    in the left panel of [figure 7.4](#ch07fig04). When divided among these seven
    bins, the histogram shows the highest value in the bin 4 ~ 6, which contains a
    count of 4 because four of the values in the data array are 5\. Three bins of
    the histogram (–2 ~ 0, 2 ~ 4, and 6 ~ 8) have zero value because none of the elements
    of the data points falls into any of these three bins.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [列表 7.5](#ch07ex05) 中，有两个略有不同的 `histogram()` 调用。第一个调用除了绘图宽度之外没有指定任何自定义选项。在这种情况下，`histogram()`
    使用其内置的启发式方法来计算箱。结果是七个箱：–4 ～ –2，–2 ～ 0，0 ～ 2，...，8 ～ 10，如[图 7.4](#ch07fig04) 的左面板所示。在这七个箱中，直方图显示在
    4 ～ 6 箱中具有最高值，其中包含 4 个计数，因为数据数组中的四个值为 5。直方图的三个箱（–2 ～ 0，2 ～ 4 和 6 ～ 8）的值为零，因为数据点的元素都没有落入这三个箱中。
- en: Figure 7.4\. Histograms of the same data, plotted with the automatically calculated
    bins (left) and an explicitly specified number of bins (right). The code that
    generates these histograms is in [listing 7.5](#ch07ex05).
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.4。相同数据的直方图，使用自动计算的箱（左）和明确指定的箱数（右）绘制。生成这些直方图的代码在 [列表 7.5](#ch07ex05) 中。
- en: '![](07fig04_alt.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](07fig04_alt.jpg)'
- en: Hence, we can argue that the default heuristics end up with too many bins for
    our particular data points. If there are fewer bins, then it will be less likely
    that any of them will end up empty. You can use the configuration field `maxBins`
    to override the default binning heuristics and limit the number of bins. This
    is what’s done by the second `histogram()` call in [listing 7.5](#ch07ex05), the
    result of which is shown on the right in [figure 7.4](#ch07fig04). You can see
    that by limiting the number of bins to three, all the bins become nonempty.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以认为默认的启发式方法对于我们特定的数据点来说生成了太多的箱。如果箱数较少，那么不太可能会有任何箱是空的。您可以使用配置字段 `maxBins`
    来覆盖默认的箱子启发式方法并限制箱子数量。这就是[列表 7.5](#ch07ex05) 中第二个 `histogram()` 调用所做的，其结果在[图 7.4](#ch07fig04)
    中右侧显示。您可以看到通过将箱数限制为三个，所有箱都变得非空。
- en: Heatmaps
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 热图
- en: A *heatmap* displays a 2D array of numbers as a grid of colored cells. The color
    of each cell reflects the relative magnitude of the elements of the 2D array.
    Traditionally, “cooler” colors such as blue and green are used to represent lower
    values, while “warmer” colors such as orange and red are used to show higher ones.
    This is why these plots are called heatmaps. Perhaps the most frequently encountered
    examples of heatmaps in deep learning are confusion matrices (see the iris-flower
    example in [chapter 3](kindle_split_014.html#ch03)) and attention matrices (see
    the date-conversion example in [chapter 9](kindle_split_021.html#ch09)). tfjs-vis
    provides the function `tfvis.render.heatmap()` to support the rendering of this
    type of visualization.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*热图* 将数字的 2D 数组显示为彩色单元格的网格。每个单元格的颜色反映了 2D 数组元素的相对大小。传统上，“较冷”的颜色（如蓝色和绿色）用于表示较低的值，而“较暖”的颜色（如橙色和红色）则用于表示较高的值。这就是为什么这些图被称为热图。在深度学习中最常见的热图例子可能是混淆矩阵（参见[第
    3 章](kindle_split_014.html#ch03)中的鸢尾花示例）和注意力矩阵（参见[第 9 章](kindle_split_021.html#ch09)中的日期转换示例）。tfjs-vis
    提供了函数 `tfvis.render.heatmap()` 来支持此类可视化的渲染。'
- en: '[Listing 7.6](#ch07ex06) shows how to make a heatmap to visualize a made-up
    confusion matrix involving three classes. The value of the confusion matrix is
    specified in the `values` field of the second input argument. The names of the
    classes, which are used to label the columns and rows of the heatmap, are specified
    as `xTickLabels` and `yTickLabels`. Do not confuse these tick labels with `xLabel`
    and `yLabel` in the third argument, which are for labeling the entire x- and y-axes.
    [Figure 7.5](#ch07fig05) shows the resulting heatmap plot.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 7.6](#ch07ex06) 展示了如何制作一个热图来可视化涉及三个类别的虚构混淆矩阵。混淆矩阵的值在第二个输入参数的 `values` 字段中指定。类别的名称，用于标记热图的列和行，是作为
    `xTickLabels` 和 `yTickLabels` 指定的。不要将这些刻度标签与第三个参数中的 `xLabel` 和 `yLabel` 混淆，后者用于标记整个
    x 和 y 轴。[图 7.5](#ch07fig05) 展示了生成的热图绘图。'
- en: Figure 7.5\. The heatmap rendered by the code in [listing 7.6](#ch07ex06). It
    shows an imaginary confusion matrix involving three classes.
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.5\. 由 [列表 7.6](#ch07ex06) 中的代码渲染的热图。它展示了一个涉及三个类别的虚构混淆矩阵。
- en: '![](07fig05_alt.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig05_alt.jpg)'
- en: Listing 7.6\. Visualizing 2D tensors using `tfvis.render.heatmap()`
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.6\. 使用 `tfvis.render.heatmap()` 可视化 2D 张量
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '***1*** The values passed to heatmap() can be a nested JavaScript array (as
    shown here) or a 2D tf.Tensor.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 传递给 heatmap() 的值可以是嵌套的 JavaScript 数组（如此处所示）或 2D tf.Tensor。'
- en: '***2*** xTickLabels is used to label the individual columns along the x-axis.
    Don’t confuse it with xLabel. Likewise, yTickLabels is used to label the individual
    rows along the y-axis.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** xTickLabels 用于标记沿 x 轴的单个列。不要与 xLabel 混淆。同样，yTickLabels 用于标记沿 y 轴的单个行。'
- en: '***3*** xLabel and yLabel are used to label the entire axes, unlike xTickLabel
    and yTickLabel.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** xLabel 和 yLabel 用于标记整个坐标轴，不同于 xTickLabel 和 yTickLabel。'
- en: '***4*** Apart from the ‘blues’ color map shown here, there are also ‘greyscale’
    and ‘viridian’.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** 除了这里展示的“蓝色”色图外，还有“灰度”和“翠绿”。'
- en: This concludes our quick tour of four major types of charts supported by `tfvis.render`.
    If your future work involves data visualization using tfjs-vis, odds are that
    you will use these charts a lot. [Table 7.1](#ch07table01) provides a brief summary
    of the chart types in order to help you decide which one to use for a given visualization
    task.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们对 `tfvis.render` 支持的四种主要图表类型的快速介绍。如果你未来的工作涉及使用 tfjs-vis 进行数据可视化，很有可能会经常使用这些图表。[表
    7.1](#ch07table01) 提供了图表类型的简要摘要，以帮助您决定在给定的可视化任务中使用哪种图表。
- en: Table 7.1\. A summary of the five major types of charts supported by tfjs-vis
    under the `tfvis.render` namespace
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.1\. tfjs-vis 在 `tfvis.render` 命名空间下支持的五种主要图表类型的摘要
- en: '| Name of chart | Corresponding function in tfjs-vis | Suitable visualization
    tasks and machine-learning examples |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 图表名称 | tfjs-vis 中对应的函数 | 适合的可视化任务和机器学习示例 |'
- en: '| --- | --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Line chart | tfvis.render.linechart() | A scalar (y-value) varying with another
    scalar (x-value) that has an intrinsic ordering (time, dose, and so on). Multiple
    series can be plotted in the same axes: for example, metrics from the training
    and validation sets, each of which is plotted against training-epoch number. |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 折线图 | tfvis.render.linechart() | 一个标量（y 值）随另一个具有固有顺序（时间、剂量等）的标量（x 值）变化。多个系列可以在同一坐标轴上绘制：例如，来自训练集和验证集的指标，每个指标都根据训练轮次数量绘制。
    |'
- en: '| Scatter plot | tfvis.render.scatterplot() | x-y scalar value pairs that do
    not have an intrinsic ordering, such as the relation between two numeric columns
    of a CSV dataset. Multiple series can be plotted in the same axes. |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 散点图 | tfvis.render.scatterplot() | x-y 标量值对，没有固有的顺序，例如 CSV 数据集的两个数值列之间的关系。多个系列可以在同一坐标轴上绘制。
    |'
- en: '| Bar chart | tfvis.render.barchart() | A set of values belonging to a small
    number of categories, such as accuracies (as percent numbers) achieved by several
    models on the same classification problem. |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 条形图 | tfvis.render.barchart() | 一组属于少数类别的值，例如几个模型在相同分类问题上实现的准确率（以百分比数字表示）。
    |'
- en: '| Histogram | tfvis.render.histogram() | A set of values of which the distribution
    is of primary interest, such as the distribution of parameter values in the kernel
    of a dense layer. |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 直方图 | tfvis.render.histogram() | 分布的主要兴趣是一组值，例如密集层内核中参数值的分布。 |'
- en: '| Heatmap | tfvis.render.heathmap() | A 2D array of numbers to be visualized
    as a 2D grid of cells, each element of which is color-coded to reflect the magnitude
    of the corresponding value: for example, confusion matrix of a multiclass classifier
    ([section 3.3](kindle_split_014.html#ch03lev1sec3)); attention matrix of a sequence-to-sequence
    model ([section 9.3](kindle_split_021.html#ch09lev1sec3)). |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 热力图 | tfvis.render.heathmap() | 一种二维数字数组，以2D网格单元格的形式进行可视化，每个元素的颜色用于反映对应值的大小：例如，多类别分类器的混淆矩阵（[3.3节](kindle_split_014.html#ch03lev1sec3)）；序列到序列模型的注意力矩阵（[9.3节](kindle_split_021.html#ch09lev1sec3)）。'
- en: '7.1.2\. An integrative case study: Visualizing weather data with tfjs-vis'
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2\. 一个综合案例研究：使用tfjs-vis可视化天气数据
- en: The CodePen examples in the previous section used small, hand-coded data. In
    this section, we will show how to use the charting features of tfjs-vis on a much
    larger and more interesting real dataset. This will demonstrate the true power
    of the API and make a case for the value of such data visualization in the browser.
    This example will also highlight some of the nuances and gotchas you may run into
    when using the charting API on real problems.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节的CodePen示例使用的是小型的手动编码数据。在本节中，我们将展示如何在更大更有趣的真实数据集上使用tfjs-vis的图表功能。这将展示出API的真正强大之处，并且为在浏览器中进行数据可视化的价值提供论据。这个示例还将突出一些在解决实际问题时可能遇到的微妙之处和陷阱。
- en: The data we will use is the Jena-weather-archive dataset. It includes the measurements
    collected with a variety of meteorological instruments at a location in Jena,
    Germany, over a course of eight years (between 2009 and 2017). The dataset, which
    can be downloaded from the Kaggle page (see [www.kaggle.com/pankrzysiu/weather-archive-jena](http://www.kaggle.com/pankrzysiu/weather-archive-jena)),
    comes in a 42MB CSV file. It consists of 15 columns. The first column is a timestamp,
    while the remaining columns are weather data such as temperature (`T deg(C)`),
    air pressure (`p (mbar)`), relative humidity (`rh (%s)`), wind velocity (`wv (m/s)`),
    and so on. If you examine the timestamps, you can see that they have a 10-minute
    spacing, reflecting the fact that the measurements were made every 10 minutes.
    This is a rich dataset to visualize, explore, and try machine learning on. In
    the following sections, we will try making weather forecasts using various machine-learning
    models. In particular, we will predict the temperature of the next day using the
    weather data from the 10 preceding days. But before we embark on this exciting
    weather forecasting task, let’s follow the principle of “always look at your data
    before trying machine learning on it” and see how tfjs-vis can be used to plot
    the data in a clear and intuitive fashion.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据是Jena-weather-archive数据集。它包括在德国耶拿（Jena）地区的一个位置上使用各种气象仪器收集的数据，涵盖了八年的时间（2009年至2017年）。可以从Kaggle页面上下载该数据集（参见[www.kaggle.com/pankrzysiu/weather-archive-jena](http://www.kaggle.com/pankrzysiu/weather-archive-jena)），它以一个42MB的CSV文件的形式提供。它包含15列，第一列是时间戳，其余列是气象数据，如温度（`T
    deg(C)`）、气压（`p (mbar)`）、相对湿度（`rh (%s)`）、风速（`wv (m/s)`）等。如果你检查时间戳，你会发现它们之间有10分钟的间隔，反映出测量是每隔10分钟进行一次。这是一个丰富的数据集，可以进行可视化、探索和尝试机器学习。在接下来的章节中，我们将尝试使用不同的机器学习模型进行天气预报。特别是，我们将使用前10天的天气数据来预测第二天的温度。但在我们开始这个令人兴奋的天气预测任务之前，让我们遵循“在尝试机器学习之前，始终查看数据”的原则，看看tfjs-vis如何以清晰直观的方式绘制数据。
- en: 'To download and run the Jena-weather example, use the following commands:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载和运行Jena-weather示例，请使用以下命令：
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Limiting the amount of data for efficient and effective visualization
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 限制数据量以进行高效有效的可视化
- en: 'The Jena-weather dataset is quite large. At a file size of 42 MB, it is bigger
    than all the CSV or tabular datasets you’ve seen in this book so far. This leads
    to two challenges:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Jena-weather数据集相当大。文件大小为42MB，比迄今为止本书中看到的所有CSV或表格数据集都要大。这导致了两个挑战：
- en: 'The first challenge is for the computer: if you plot all the data from the
    eight years at once, the browser tab will run out of resources, become unresponsive,
    and probably crash. Even if you limit yourself to only 1 of the 14 columns, there
    are still about 420,000 data points to show. This is more than what tfjs-vis (or
    any JavaScript plotting library, for that matter) can safely render at a time.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个挑战是对计算机而言：如果一次绘制八年的所有数据，浏览器选项卡将耗尽资源，变得无响应，并可能崩溃。即使你仅限制在14列中的1列，仍然有大约42万个数据点需要显示。这比tfjs-vis（或任何JavaScript绘图库）能够安全渲染的量要多。
- en: 'The second challenge is for the user: it is hard for a human to look at a large
    amount of data at once and make sense out of it. For instance, how is someone
    supposed to look at all 420,000 data points and extract useful information from
    them? Just like the computer, the human brain has limited information-processing
    bandwidth. The job of a visualization designer is to present the most relevant
    and informative aspects of the data in an efficient way.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个挑战是对用户而言：一次查看大量数据并从中提取有用信息是困难的。例如，有人应该如何查看所有420,000个数据点并从中提取有用信息？就像计算机一样，人类大脑的信息处理带宽是有限的。可视化设计师的工作是以高效的方式呈现数据的最相关和最有信息量的方面。
- en: 'We use three tricks to address these challenges:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用三种技巧来解决这些挑战：
- en: Instead of plotting the data from the whole eight years at once, we let the
    user choose what time range to plot using an interactive UI. This is the purpose
    of the Time Span drop-down menu in the UI (see the screenshots in [figures 7.6](#ch07fig06)
    and [7.7](#ch07fig07)). The time-span options include Day, Week, 10 Days, Month,
    Year, and Full. The last one corresponds to the whole eight years. For any of
    the other time spans, the UI allows the user to go back and forth in time. This
    is what the left-arrow and right-arrow buttons are for.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不是一次性绘制整个八年的数据，而是让用户使用交互式用户界面选择要绘制的时间范围。这就是用户界面中时间跨度下拉菜单的目的（请参见 [图7.6](#ch07fig06)
    和 [7.7](#ch07fig07) 中的截屏）。时间跨度选项包括Day、Week、10 Days、Month、Year和Full。最后一个对应于整个八年。对于任何其他时间跨度，用户界面允许用户在时间上前后移动。这就是左箭头和右箭头按钮的作用。
- en: 'Figure 7.6\. Line charts of temperature (`T (degC)`) and air pressure (`p (mbar)`)
    from the Jena-weather-archive dataset, plotted at two different time scales. Top:
    10-day time span. Notice the daily cycle in the temperature curve. Bottom: 1-year
    time span. Notice the annual cycle in the temperature curve and the slight tendency
    for air pressure to be more stable during spring and summer than during other
    seasons.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.6\. 展示了Jena气象档案数据集中温度（`T（degC）`）和气压（`p（mbar）`）的折线图，分别以两种不同的时间尺度绘制。顶部：10天时间跨度。注意温度曲线中的日常周期。底部：1年时间跨度。注意温度曲线中的年度周期以及春季和夏季期间气压相对其他季节更稳定的轻微倾向。
- en: '![](07fig06_alt.jpg)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](07fig06_alt.jpg)'
- en: Figure 7.7\. An example scatter plot from the Jena-weather demo. The plot shows
    the relation between air density (rho, vertical axis) and temperature (T, horizontal)
    over a time period of 10 days, where a negative correlation can be seen.
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.7\. Jena气象演示的散点图示例。该图显示了空气密度（rho，纵轴）和温度（T，横轴）之间的关系，时间跨度为10天，可以看到负相关性。
- en: '![](07fig07_alt.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](07fig07_alt.jpg)'
- en: For any time span longer than a week, we *downsample* the time series before
    plotting them on the screen. For example, consider the time span Month (30 days).
    The full data for this time span contains about 30 * 24 * 6 = 4.32k data points.
    In the code in [listing 7.7](#ch07ex07), you can see that we only plot every sixth
    data point when showing the data from a month. This cuts the number of plotted
    data points down to 0.72k, a significant reduction in the rendering cost. But
    to human eyes, this six-fold reduction in the data-point count barely makes a
    difference.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于任何超过一周的时间跨度，我们在将时间序列绘制到屏幕上之前进行*降采样*。例如，考虑时间跨度为一个月（30天）。这个时间跨度的完整数据包含约30 *
    24 * 6 = 4.32k个数据点。在 [清单7.7](#ch07ex07) 中的代码中，您可以看到我们在显示一个月的数据时仅绘制每六个数据点。这将绘制的数据点数量减少到0.72k，大大降低了渲染成本。但对于人眼来说，数据点数量的六倍减少几乎没有什么差别。
- en: Similar to what we did with the Time Span drop-down menu, we include a drop-down
    menu in the UI so that the user can choose what weather data to plot at any given
    time. Notice the drop-down menus labeled Data Series 1 and Data Series 2\. By
    using them, the user may plot any 1 or any 2 of the 14 columns as line charts
    on the screen, in the same axes.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与我们在时间跨度下拉菜单中所做的类似，我们在用户界面中包含一个下拉菜单，以便用户可以选择在任何给定时间绘制什么天气数据。注意标有Data Series
    1和Data Series 2的下拉菜单。通过使用它们，用户可以在同一坐标轴上将任何1或任何2个14列中的数据作为折线图绘制到屏幕上。
- en: '[Listing 7.7](#ch07ex07) shows the code responsible for making the charts like
    the ones in [figure 7.6](#ch07fig06). Despite the fact that the code calls `tfvis.render.linechart()`
    just like the CodePen example in the previous section, it is much more abstract
    compared to the code in the previous listings. This is because in our web page,
    we need to defer the decision of what quantities to plot according to the UI state.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[7.7 节的示例](#ch07ex07)展示了负责制作与[图 7.6](#ch07fig06)类似的图表的代码。尽管代码调用了`tfvis.render.linechart()`，与前一节中的
    CodePen 示例相似，但与前面列表中的代码相比，它要抽象得多。这是因为在我们的网页中，我们需要根据 UI 状态延迟决定要绘制的数量。'
- en: Listing 7.7\. Weather data as a multiseries line chart (in jena-weather/index.js)
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 7.7 节。Jena 天气数据作为多系列折线图（在 jena-weather/index.js 中）
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '***1*** jenaWeatherData is an object that helps us organize and retrieve the
    weather data from the CSV file. See jena-weather/data.js.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** jenaWeatherData 是一个帮助我们组织和检索来自 CSV 文件的天气数据的对象。请参阅 jena-weather/data.js。'
- en: '***2*** Specifies the time span for visualization'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 指定可视化的时间跨度'
- en: '***3*** Chooses the appropriate stride (downsampling factor)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** 选择适当的步幅（降采样因子）'
- en: '***4*** Takes advantage of the fact that tfjs-vis’s line chart supports multiple
    series'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** 利用了 tfjs-vis 的折线图支持多系列的特性。'
- en: '***5*** Always label the axes.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** 总是标记轴。'
- en: 'You are encouraged to explore the data-visualization UI. It contains a lot
    of interesting patterns you can discover about weather. For example, the top panel
    of [figure 7.6](#ch07fig06) shows how the normalized temperature (`T (degC)`)
    and normalized air pressure (`p (mbar)`) vary over a time period of 10 days. In
    the temperature curve, you can see a clear daily cycle: the temperature tends
    to peak around the middle of the day and bottom out shortly after midnight. On
    top of the daily cycle, you can also see a more global trend (a gradual increase)
    over the 10-day period. By contrast, the air-pressure curve doesn’t show a clear
    pattern. The bottom panel of the same figure shows the same measurements over
    the time span of a year. There, you can see the annual cycle of temperature: it
    peaks around August and reaches the bottom around January. The air pressure again
    shows a less clear-cut pattern than temperature at this time scale. The pressure
    can vary in a somewhat chaotic fashion over the entire year, although there appears
    to be a tendency for it to be less variable around summer than in winter. By looking
    at the same measurements at different time scales, we can notice various interesting
    patterns. All these patterns are nearly impossible to notice if we look at just
    the raw data in the numerical CSV format.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励您探索数据可视化界面。它包含许多有趣的天气模式，您可以发现。例如，[图 7.6](#ch07fig06)的顶部面板显示了在 10 天内温度（`T (degC)`）和标准化气压（`p
    (mbar)`）是如何变化的。在温度曲线中，您可以看到一个明显的日循环：温度倾向于在中午左右达到峰值，并在午夜后不久达到最低点。在日循环之上，您还可以看到在这
    10 天期间的一个更全局的趋势（逐渐增加）。相比之下，气压曲线在这个时间尺度上没有显示出明显的模式。同一图的底部面板显示了一年时间跨度内的相同测量值。在那里，您可以看到温度的年循环：它在八月左右达到峰值，并在一月左右达到最低点。气压再次显示出一个不太清晰的模式，比起温度，在这个时间尺度上。压力在整个年份内可能以一种略微混沌的方式变化，尽管在夏季周围，似乎有一个较少变化的倾向，而在冬季则相反。通过在不同的时间尺度上查看相同的测量值，我们可以注意到各种有趣的模式。如果我们只看数字
    CSV 格式的原始数据，所有这些模式几乎是不可能注意到的。
- en: One thing you might have noticed in the charts in [figure 7.6](#ch07fig06) is
    that they show normalized values of temperature and air pressure instead of their
    absolute values, which is due to the fact that the Normalize Data check box in
    the UI was checked when we made these plots. We briefly mentioned normalization
    when discussing the Boston-housing model back in [chapter 2](kindle_split_013.html#ch02).
    The normalization there involved subtracting the mean and dividing the result
    by the standard deviation. We did this in order to improve model training. The
    normalization we performed here is exactly the same. However, it is not just for
    the accuracy of our machine-learning model (to be covered in the next section)
    but is also for visualization. Why? If you try unchecking the Normalize Data check
    box when the chart shows temperature and air pressure, you’ll immediately see
    the reason. The temperature measurement varies in the range between –10 and 40
    (on the Celsius scale), while the air pressure resides in the range between 980
    and 1,000\. When plotted in the same axes without normalization, the two quantities
    with vastly different ranges force the y-axis to expand to a very large range,
    causing both curves to look like basically flat lines with tiny variations. Normalization
    avoids this problem by mapping all measurements to a distribution of zero mean
    and unit standard deviation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图7.6](#ch07fig06)中的图表中，你可能已经注意到它们显示的是温度和气压的归一化值，而不是它们的绝对值，这是因为我们在生成这些图表时勾选了UI中的“Normalize
    Data”复选框。我们在[第2章](kindle_split_013.html#ch02)中讨论波士顿房价模型时简单提到了归一化。那里的归一化涉及将平均值减去，然后除以标准差的结果。我们这里进行的归一化完全相同。然而，这不仅仅是为了我们机器学习模型的准确性（下一节将介绍），还是为了可视化。为什么呢？如果你尝试在图表显示温度和气压时取消勾选“Normalize
    Data”复选框，你会立即看到原因。温度测量值的范围在-10到40之间（摄氏度），而气压的范围在980到1,000之间。在没有归一化的情况下，具有非常不同范围的两个变量会导致y轴扩展到非常大的范围，使得两条曲线看起来基本上是平的，并且只有微小的变化。通过归一化，可以避免这个问题，将所有测量值映射到零平均值和单位标准差的分布。
- en: '[Figure 7.7](#ch07fig07) shows an example of plotting two weather measurements
    against each other as a scatter plot, a mode you can activate by checking the
    Plot Against Each Other check box and making sure that neither of the Data Series
    drop-down menus is set to None. The code for making such scatter plots is similar
    to the `makeTimeSerieChart()` function in [listing 7.7](#ch07ex07) and is therefore
    omitted here for conciseness. You can study it in the same file (jena-weather/index.js)
    if you are interested in the details.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7.7](#ch07fig07)展示了一个将两个气象测量值绘制为散点图的示例，你可以通过勾选“Plot Against Each Other”复选框并确保两个“Data
    Series”下拉菜单都不是“None”来激活此模式。制作这样的散点图的代码与[清单7.7](#ch07ex07)中的`makeTimeSerieChart()`函数相似，因此这里为了简洁起见省略了。如果你对细节感兴趣，可以在相同的文件（jena-weather/index.js）中进行研究。'
- en: 'The example scatter plot shows the relation between the normalized air density
    (y-axis) and normalized temperature (x-axis). Here, you can spot a fairly strong
    negative correlation between the two quantities: the air density gets lower as
    the temperature increases. This example plot uses the 10-day time span, but you
    can verify that the trend largely holds at other time spans as well. This kind
    of correlation between variables is easy to visualize with scatter plots but much
    harder to discover by just looking at the text-format data. This is another example
    of the value afforded by data visualization.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例散点图展示了归一化空气密度（y轴）和归一化温度（x轴）之间的关系。在这里，你可以发现两个变量之间存在较强的负相关性：随着温度的升高，空气密度将降低。这个示例图表使用了10天的时间跨度，但你可以验证这种趋势在其他时间跨度下也基本保持不变。这种变量之间的相关性可以通过散点图轻松地可视化，但只通过文本格式的数据很难发现。这再次展示了数据可视化的强大价值。
- en: 7.2\. Visualizing models after training
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 训练后的模型可视化
- en: In the previous sections, we showed how visualization can be useful for data.
    In this section, we will show you how to visualize various aspects of models after
    they are trained in order to gain useful insight. To this end, we will focus primarily
    on convnets that take images as inputs, because they are used widely and produce
    interesting visualization results.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们展示了可视化对数据的有用之处。在本节中，我们将展示如何在模型训练后可视化模型的各个方面，以获得有用的洞察力。为此，我们将主要关注以图像为输入的卷积神经网络（convnet），因为它们被广泛使用且产生有趣的可视化结果。
- en: 'You may have heard the remark that deep neural networks are “black boxes.”
    Don’t let this remark mislead you into thinking that it’s hard to get any information
    from the inside of a neural network during its inference or training. To the contrary,
    it is fairly easy to peek at what each layer is doing inside a model written in
    TensorFlow.js.^([[3](#ch07fn3)]) Furthermore, as far as convnets are concerned,
    the internal representations they learn are highly amenable to visualization,
    in large part because they are representations of visual concepts. Since 2013,
    a wide array of techniques has been developed for visualizing and interpreting
    these representations. Since it’s impractical to cover all the interesting techniques,
    we’ll cover three of the most basic and useful ones:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过深度神经网络是“黑盒子”。不要让这个说法让你误以为在推理或训练神经网络时很难从内部获取任何信息。相反，查看 TensorFlow.js 中编写的模型的每个层在内部做了什么是相当容易的。此外，就卷积神经网络而言，它们学习的内部表示非常适合可视化，主要是因为它们是视觉概念的表示。自
    2013 年以来，已经开发了各种各样的技术来可视化和解释这些表示。由于涵盖所有有趣的技术是不切实际的，我们将介绍三种最基本和最有用的技术：
- en: ³
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ³
- en: ''
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What that remark really means is that the large number of mathematical operations
    that occur in a deep neural network, even if they can be accessed, are harder
    to describe in layperson’s terms as compared with certain other types of machine-learning
    algorithms, such as decision trees and logistic regression. For example, with
    a decision tree, you can walk down the branching points one by one and explain
    why a certain branch is chosen by verbalizing the reason as a simple sentence
    like “because factor X is greater than 0.35.” That problem is referred to as *model
    interpretability* and is a different matter from what we are covering in this
    section.
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个说法实际上意味着，深度神经网络中发生的大量数学运算，即使可以访问，也比起某些其他类型的机器学习算法，如决策树和逻辑回归，更难以用 layperson
    的术语描述。例如，对于决策树，你可以逐个沿着分支点走下去，并解释为什么选择了某个分支，通过用一句简单的句子如“因为因子 X 大于 0.35”来用语言化的方式解释原因。这个问题被称为*模型可解释性*，与我们在本节中涵盖的内容不同。
- en: '*Visualizing the outputs of intermediate layers (intermediate activations)
    of a convnet*—This is useful for understanding how successive convnet layers transform
    their inputs, and for getting a first idea of the visual features learned by individual
    convnet filters.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可视化 convnet 中间层（中间激活）的输出* —— 这有助于理解连续 convnet 层如何转换其输入，并且可以初步了解单个 convnet
    滤波器学习的视觉特征。'
- en: '*Visualizing convnet filters by finding input images that maximally activate
    them*—This is useful for understanding what visual pattern or concept each filter
    is sensitive to.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过找到最大化激活它们的输入图像来可视化 convnet 滤波器* —— 这有助于理解每个滤波器对哪种视觉模式或概念敏感。'
- en: '*Visualizing heatmaps of class activation in an input image*—This helps in
    understanding which parts of an input image play the most important role in causing
    the convnet to generate the final classification result, which can also be useful
    for interpreting how a convnet reaches its output and for “debugging” incorrect
    outputs.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可视化输入图像中类激活的热图* —— 这有助于理解输入图像的哪些部分在导致 convnet 生成最终分类结果时起着最重要的作用，这也可以有助于解释
    convnet 如何达到其输出和“调试”不正确的输出。'
- en: 'The code we will use to showcase these techniques is in the visualize-convnet
    example from the tfjs-examples repo. To run the example, use these commands:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的代码来展示这些技术是来自 tfjs-examples 仓库的 visualize-convnet 示例。要运行示例，请使用以下命令：
- en: '[PRE10]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `yarn visualize` command is different from the `yarn watch` command you’ve
    seen in previous examples. In addition to building and launching the web page,
    it performs some additional steps outside the browser. First, it installs some
    required Python libraries, followed by downloading and converting the VGG16 model
    (a well-known and widely used deep convnet) into TensorFlow.js format. The VGG16
    model has been pretrained on the large-scale ImageNet dataset and is available
    as a Keras application. Once the model conversion is complete, `yarn visualize`
    performs a series of analyses on the converted model in tfjs-node. Why are these
    steps carried out in Node.js instead of the browser? Because VGG16 is a relatively
    large convnet.^([[4](#ch07fn4)]) As a result, several of the steps are computationally
    heavy and run much faster in the less resource-restricted environment in Node.js.
    The computation can be further speeded up if you use tfjs-node-gpu instead of
    the default tfjs-node (this requires a CUDA-enabled GPU with the required driver
    and libraries installed; see [appendix A](kindle_split_027.html#app01)):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`yarn visualize`命令与您在先前示例中看到的`yarn watch`命令不同。除了构建和启动网页之外，它还在浏览器外执行一些额外的步骤。首先，它安装一些所需的Python库，然后下载并转换VGG16模型（一个知名且广泛使用的深度卷积网络）为TensorFlow.js格式。VGG16模型已经在大规模的ImageNet数据集上进行了预训练，并作为Keras应用程序提供。一旦模型转换完成，`yarn
    visualize`在tfjs-node中对转换后的模型进行一系列分析。为什么这些步骤在Node.js中而不是浏览器中执行？因为VGG16是一个相对较大的卷积网络。^([[4](#ch07fn4)])
    因此，其中的一些步骤计算量很大，在Node.js中的资源限制较少的环境中运行得更快。如果您使用tfjs-node-gpu而不是默认的tfjs-node，计算速度可以进一步加快（这需要具有所需驱动程序和库的CUDA启用GPU；请参阅[附录A](kindle_split_027.html#app01)）：'
- en: ⁴
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁴
- en: ''
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To get an idea of how large VGG16 is, realize that its total weight size is
    528 MB, as compared to the <10MB weight size of MobileNet.
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要了解VGG16有多大的概念，请意识到其总重量大小为528 MB，而MobileNet的重量大小小于10MB。
- en: '[PRE11]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Once the computationally heavy steps are completed in Node.js, they will generate
    a set of image files in the dist/folder. As its last step, `yarn visualize` will
    compile and launch a web server for a set of static web files including those
    images, in addition to opening the index page in your browser.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在Node.js中完成了计算密集的步骤，它们将生成一组图像文件在dist/folder中。作为最后一步，`yarn visualize`将编译并启动一个Web服务器，用于一组静态Web文件，包括那些图像，除了在浏览器中打开索引页。
- en: 'The `yarn visualize` command contains a few additional configurable flags.
    For example, by default, it performs computation and visualization on eight filters
    per convolutional layer of interest. You can change the number of filters by using
    the `--filters` flag: for example, `yarn visualize --filters 32`. Also, the default
    input image used by `yarn visualize` is the cat.jpg image that comes with the
    source code. You can use other image files by using the `--image` flag.^([[5](#ch07fn5)])
    Now let’s look at the visualization results based on the cat.jpg image and 32
    filters.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`yarn visualize`命令包含一些额外可配置的标志。例如，默认情况下，它对感兴趣的每个卷积层执行八个过滤器的计算和可视化。您可以使用`--filters`标志更改过滤器的数量：例如，`yarn
    visualize --filters 32`。此外，`yarn visualize`使用的默认输入图像是随源代码提供的cat.jpg图像。您可以使用`--image`标志使用其他图像文件。^([[5](#ch07fn5)])
    现在让我们基于cat.jpg图像和32个过滤器查看可视化结果。'
- en: ⁵
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁵
- en: ''
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Most common image formats, including JPEG and PNG, are supported.
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最常见的图像格式，包括JPEG和PNG，都受支持。
- en: 7.2.1\. Visualizing the internal activations of a convnet
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.1\. 可视化卷积神经网络内部激活
- en: Here, we compute and display the feature map generated by various convolutional
    layers of the VGG16 model given an input image. These feature maps are called
    *internal* activation because they are not the model’s final output (the model’s
    final output is a length-1,000 vector that represents the probability scores for
    the 1,000 ImageNet classes). Instead, they are the intermediate steps of the model’s
    computation. These internal activations give us a view into how the input is decomposed
    into different features learned by the network.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们计算并显示了给定输入图像的VGG16模型的各种卷积层生成的特征图。这些特征图被称为*内部*激活，因为它们不是模型的最终输出（模型的最终输出是一个长度为1,000的向量，表示1,000个ImageNet类别的概率分数）。相反，它们是模型计算的中间步骤。这些内部激活使我们能够了解输入是如何被网络学习的不同特征分解的。
- en: 'Recall from [chapter 4](kindle_split_015.html#ch04) that the output of a convolutional
    layer has the NHWC shape `[numExamples, height, width, channels]`. Here, we are
    dealing with a single input image, so `numExamples` is 1\. We want to visualize
    the output of each convolutional layer along three remaining dimensions: height,
    width, and channels. The height and width of a convolutional layer’s output are
    determined by its filter size, padding, and strides, as well as the height and
    width of the layer’s input. In general, they get smaller and smaller as you go
    deeper into a convnet. On the other hand, the value of `channels` generally gets
    larger as you go deeper, as the convnet extracts a larger and larger number of
    features through successive layers of representation transformation. These channels
    of convolutional layers cannot be interpreted as different color components. Instead,
    they are the learned feature dimensions. This is why our visualization breaks
    them into separate panels and draws them in grayscale. [Figure 7.8](#ch07fig08)
    shows the activations from five convolutional layers of VGG16 given the cat.jpg
    input image.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[第四章](kindle_split_015.html#ch04)，卷积层的输出具有NHWC形状`[numExamples, height, width,
    channels]`。在这里，我们正在处理单个输入图像，因此`numExamples`为1。我们想要可视化每个卷积层输出的剩余三个维度：高度、宽度和通道。卷积层输出的高度和宽度由其滤波器大小、填充、步长以及图层输入的高度和宽度确定。一般来说，随着深入到卷积神经网络中，它们会变得越来越小。另一方面，随着深入，`channels`的值通常会变得越来越大，因为卷积神经网络通过一系列层的表示转换逐渐提取越来越多的特征。卷积层的这些通道不能解释为不同的颜色分量。相反，它们是学习到的特征维度。这就是为什么我们的可视化将它们分成单独的面板并以灰度绘制的原因。[图7.8](#ch07fig08)展示了给定cat.jpg输入图像的VGG16的五个卷积层的激活。
- en: Figure 7.8\. Internal activation from several convolutional layers of VGG16
    performing inference on the cat.jpg image. The original input image is shown on
    the left, together with the top three classes output by the model and their associated
    probability scores. The five layers visualized are the layers named `block1_conv1`,
    `block2_conv1`, `block3_conv2`, `block4_conv2`, and `block5_conv3`. They are ordered
    by their depth in the VGG16 model from top to bottom. That is, `block1_conv1`
    is the closest to the input layer, while `block5_conv1` is the closest to the
    output layer. Note that all internal-activation images are scaled to the same
    size for visualization purposes, even though the activations have smaller sizes
    (lower resolution) in the later layers due to successive convolution and pooling.
    This can be seen in the coarse pixel patterns in the later layers.
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.8。VGG16对cat.jpg图像执行推理的几个卷积层的内部激活。左侧显示原始输入图像，以及模型输出的前三个类别和它们关联的概率分数。可视化的五个层分别是命名为`block1_conv1`、`block2_conv1`、`block3_conv2`、`block4_conv2`和`block5_conv3`的层。它们按照在VGG16模型中的深度从顶部到底部的顺序排序。也就是说，`block1_conv1`是最靠近输入层的，而`block5_conv1`是最靠近输出层的。请注意，出于可视化目的，所有内部激活图像都缩放到相同的大小，尽管由于连续的卷积和池化，后续层的激活具有较小的尺寸（较低的分辨率）。这可以从后续层中的粗略像素模式中看出。
- en: '![](07fig08_alt.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig08_alt.jpg)'
- en: The first thing you may notice in the internal activations is that they look
    increasingly different from the original input as you go deeper in the network.
    The earlier layers (such as `block1_conv1`) appear to encode relatively simple
    visual features such as edges and colors. For example, the arrow labeled “A” points
    at an internal activation that seems to respond to the yellow and pink colors.
    The arrow labeled “B” points at an internal activation that seems to be about
    edges along certain orientations in the input image.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在内部激活中你可能注意到的第一件事是随着网络的深入，它们与原始输入的差异越来越大。较早的层（例如`block1_conv1`）似乎编码相对简单的视觉特征，例如边缘和颜色。例如，标记为“A”的箭头指向一个似乎响应黄色和粉色的内部激活。标记为“B”的箭头指向一个似乎与输入图像中某些方向的边缘有关的内部激活。
- en: 'But the later layers (such as `block4_conv2` and `block5_conv3`) show activation
    patterns that are more and more removed from simple pixel-level features in the
    input image. For example, the arrow labeled “C” in [figure 7.8](#ch07fig08) points
    at a filter in `block4_ conv2` that seems to encode the cat’s facial features,
    including the ears, eyes, and nose. This is a concrete example of the incremental
    feature extraction that we showed schematically in [figure 4.6](kindle_split_015.html#ch04fig06)
    of [chapter 4](kindle_split_015.html#ch04). However, note that not all filters
    in later layers can be explained verbally in a straightforward way. Another interesting
    observation is that the “sparsity” of the activation maps also increases with
    the depth of the layer: in the first layer shown in [figure 7.8](#ch07fig08),
    all filters are activated (show a nonconstant pixel pattern) by the input image;
    however, in the last layer, some of the layers become blank (constant pixel pattern;
    for example, see the last row in the right panel of [figure 7.8](#ch07fig08)).
    This means the features encoded by those blank filters are absent from this particular
    input image.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，后面的层（比如`block4_conv2`和`block5_conv3`）显示出越来越多地与输入图像中简单的像素级特征不相关的激活模式。例如，[图
    7.8](#ch07fig08) 中标记为“C”的箭头指向`block4_ conv2`中的一个滤波器，它似乎对猫的面部特征进行编码，包括耳朵、眼睛和鼻子。这是我们在[第
    4 章](kindle_split_015.html#ch04)的[图 4.6](kindle_split_015.html#ch04fig06)中用示意图展示的逐渐特征提取的具体示例。但请注意，并非所有后续层中的滤波器都能用简单的方式用语言解释清楚。另一个有趣的观察是，激活图的“稀疏性”也随着层的深度增加而增加：在[图
    7.8](#ch07fig08)中显示的第一层中，所有滤波器都被输入图像激活（显示出非常量像素模式）；然而，在最后一层中，一些滤波器变为空白（常量像素模式；例如，参见[图
    7.8](#ch07fig08)右面板的最后一行）。这意味着由那些空白滤波器编码的特征在这个特定的输入图像中是不存在的。
- en: 'You just witnessed an important universal characteristic of the representations
    learned by deep convnets: the features extracted by a layer become increasingly
    more abstract with the depth of the layer. The activations of deeper layers carry
    less and less information about the details in the input, and more and more information
    about the target (in this case, which of the 1,000 ImageNet classes the image
    belongs to). So, a deep neural network effectively acts as an *information distillation
    pipeline*, with raw data going in and being repeatedly transformed so that aspects
    in the input that are irrelevant to the task are filtered out, and aspects that
    are useful for the task are gradually magnified and refined. Even though we showed
    this through a convnet example, this characteristic holds for other deep neural
    networks (such as MLPs) as well.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您刚刚目睹了深度卷积神经网络学习到的表示的一个重要的普遍特征：通过层提取的特征随着层的深度越来越抽象。深层的激活承载着越来越少关于输入细节的信息，越来越多关于目标的信息（在本例中是图像属于
    1,000 个 ImageNet 类别中的哪一个）。因此，深度神经网络有效地充当着一个 *信息蒸馏管道*，原始数据进入并被重复地转换，以便过滤掉任务无关的方面，并逐渐放大和精炼对任务有用的方面。即使我们通过一个卷积神经网络的例子展示了这一点，但这个特征对其他深度神经网络（如
    MLPs）也是成立的。
- en: The aspects of input images that a convnet finds useful might be different from
    what the human visual system finds useful. The convnet training is driven by data
    and hence is prone to biases in the training data. For instance, the paper by
    Marco Ribeiro and colleagues listed in the “[Materials for further reading and
    exploration](#ch07lev1sec3)” section at the end of the chapter points out a case
    in which the image of a dog got misclassified as a wolf due to the presence of
    snow in the background, presumably because the training images contained instances
    of wolves against snowy backgrounds but no dogs against similar backgrounds.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络发现有用的输入图像方面可能与人类视觉系统发现的有用方面不同。卷积神经网络的训练受到数据驱动，因此容易受到训练数据的偏见影响。例如，在本章末尾“[进一步阅读和探索材料](#ch07lev1sec3)”部分列出的
    Marco Ribeiro 和同事的论文指出了一个案例，在这个案例中，由于背景中有雪的存在，一张狗的图像被误分类为狼，这可能是因为训练图像中包含了狼在雪地背景下的实例，但没有包含类似背景下的狗的实例。
- en: These are the useful insights we gained by visualizing the internal activation
    patterns of a deep convnet. The following subsection describes how to write code
    in TensorFlow.js to extract these internal activations.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过可视化深度卷积神经网络的内部激活模式，我们获得了这些有用的见解。下一小节描述了如何在 TensorFlow.js 中编写代码来提取这些内部激活。
- en: Deep dive into how internal activations are extracted
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 深入了解如何提取内部激活
- en: The steps for extracting the internal activations are encapsulated in the `writeInternalActivationAndGetOutput()`
    function ([listing 7.8](#ch07ex08)). It takes as its input a TensorFlow.js model
    object that has already been constructed or loaded and the names of the layers
    in question (`layerNames`). The key step is creating a new model object (`compositeModel`)
    with multiple outputs, including the output of the specified layers and the output
    of the original model. `compositeModel` is constructed with the `tf.model()` API,
    as you saw in the Pac-Man and simple-object-detection examples in [chapter 5](kindle_split_016.html#ch05).
    The nice thing about `compositeModel` is that its `predict()` method returns all
    the layers’ activations, along with the model’s final prediction (see the `const`
    named `outputs`). The rest of the code in [listing 7.8](#ch07ex08) (from visualize-convnet/main.js)
    is about the more mundane task of splitting the layers’ outputs into individual
    filters and writing them to files on disk.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 提取内部激活的步骤封装在 `writeInternalActivationAndGetOutput()` 函数中（[清单 7.8](#ch07ex08)）。它以已经构建或加载的
    TensorFlow.js 模型对象和相关层的名称（`layerNames`）作为输入。关键步骤是创建一个新的模型对象（`compositeModel`），其中包括指定层的输出和原始模型的输出。
    `compositeModel` 使用 `tf.model()` API 构建，就像你在 [第 5 章](kindle_split_016.html#ch05)
    的 Pac-Man 和简单物体检测示例中看到的一样。关于 `compositeModel` 的好处在于它的 `predict()` 方法返回所有层的激活，以及模型的最终预测（参见名为
    `outputs` 的 `const`）。[清单 7.8](#ch07ex08) 中的其余代码（来自 visualize-convnet/main.js）是关于将层的输出拆分为单独的滤波器并将它们写入磁盘文件的更加平凡的任务。
- en: Listing 7.8\. Calculating the internal activation of a convnet in Node.js
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单 7.8\. 在 Node.js 中计算卷积神经网络的内部激活
- en: '[PRE12]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***1*** Constructs a model that returns all the desired internal activations,
    in addition to the final output of the original model'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 构建一个模型，返回所有期望的内部激活，以及原始模型的最终输出'
- en: '***2*** outputs is an array of tf.Tensor’s, including the internal activations
    and the final output.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 输出是包含内部激活和最终输出的 tf.Tensor 数组。'
- en: '***3*** Splits the activation of the convolutional layer by filter'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** 将卷积层的激活按滤波器进行拆分'
- en: '***4*** Formats activation tensors and writes them to disk'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** 格式化激活张量并将其写入磁盘'
- en: '7.2.2\. Visualizing what convolutional layers are sensitive to: Maximally-
    y activating images'
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.2\. 可视化卷积层对哪些内容敏感：最大激活图像
- en: Another way to illustrate what a convnet learns is by finding the input images
    that its various internal layers are sensitive to. What we mean by a filter being
    sensitive to a certain input image is a maximal activation in the filter’s output
    (averaged across its output height and width dimensions) under the input image.
    By looking at such maximally activating inputs for various layers of the convnet,
    we can infer what each layer is trained to respond to.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种说明卷积网络学习内容的方式是找到其各种内部层对哪些输入图像敏感。我们所说的对某个输入图像敏感是指在输入图像下，滤波器输出的最大激活（在其输出高度和宽度维度上取平均）。
- en: 'The way in which we find the maximally activating images is through a trick
    that flips the “normal” neural network training process on its head. Panel A of
    [figure 7.9](#ch07fig09) shows schematically what happens when we train a neural
    network with `tf.Model.fit()`. We freeze the input data and allow the weights
    of the model (such as the kernels and biases of all the trainable layers) to be
    updated from the loss function^([[6](#ch07fn6)]) via backpropagation. However,
    there is no reason why we can’t swap the roles of the input and the weights: we
    can freeze the weights and allow the *input* to be updated through backpropagation.
    In the meantime, we tweak the loss function so that it causes the backpropagation
    to nudge the input in a way that maximizes the output of a certain convolutional
    filter when averaged across its height and width dimensions. This process is schematically
    shown in panel B of [figure 7.9](#ch07fig09) and is called *gradient ascent in
    input space*, as opposed to the *gradient descent in weight space* that underlies
    typical model training. The code that implements gradient descent in input space
    is shown in the next subsection and can be studied by interested readers.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到最大激活图像的方式是通过一种将“正常”的神经网络训练过程颠倒过来的技巧。[图 7.9](#ch07fig09)的面板 A 简要显示了当我们使用
    `tf.Model.fit()` 训练神经网络时会发生什么。我们冻结输入数据，并允许模型的权重（例如所有可训练层的核和偏差）通过反向传播从损失函数更新。但是，我们完全可以交换输入和权重的角色：我们可以冻结权重，并允许*输入*通过反向传播进行更新。同时，我们调整损失函数，使其导致反向传播以一种方式来微调输入，该方式最大化了某个卷积滤波器的输出，当在其高度和宽度维度上平均时。该过程在[图
    7.9](#ch07fig09)的面板 B 中示意，被称为*输入空间中的梯度上升*，与 typica 模型训练的基于*权重空间中的梯度下降*相对应。实现输入空间中的梯度下降的代码将在下一小节中展示，并可以供感兴趣的读者研究。
- en: ⁶
  id: totrans-170
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁶
- en: ''
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This diagram can be viewed as a simplified version of [figure 2.9](kindle_split_013.html#ch02fig09),
    which we used to introduce backpropagation back in [chapter 2](kindle_split_013.html#ch02).
  id: totrans-172
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个图可以看作是[图 2.9](kindle_split_013.html#ch02fig09)的简化版本，我们在[第二章](kindle_split_013.html#ch02)中用它来介绍反向传播。
- en: 'Figure 7.9\. A schematic diagram showing the basic idea behind how the maximally
    activating image for a convolutional filter is found through gradient ascent in
    input space (panel B) and how that differs from the normal neural network training
    process based on gradient descent in weight space (panel A). Note that this figure
    differs from some of the model diagrams shown previously in that it breaks the
    weights out from the model. This is for highlighting the two sets of quantities
    that can be updated through backpropagation: the weights and the input.'
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.9\. 示意图显示了通过输入空间中的梯度上升找到卷积滤波器的最大激活图像的基本思想（面板 B）以及与基于权重空间中的梯度下降的正常神经网络训练过程（面板
    A）不同的地方。请注意，该图与先前显示的某些模型图有所不同，因为它将权重从模型中分离出来。这是为了突出两组可以通过反向传播更新的量：权重和输入。
- en: '![](07fig09_alt.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig09_alt.jpg)'
- en: '[Figure 7.10](#ch07fig10) shows the result of performing the gradient-ascent-in-input-space
    process on four convolutional layers of the VGG16 model (the same model that we
    used to show internal activations). As in the previous illustration, the depth
    of the layers increases from the top to the bottom of the figure. A few interesting
    patterns can be gleaned from these maximally activating input images:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7.10](#ch07fig10)展示了在 VGG16 模型的四个卷积层上执行梯度上升输入空间过程的结果（与我们用来展示内部激活的相同模型）。与先前的插图一样，图层的深度从图的顶部到底部逐渐增加。从这些最大激活输入图像中可以得到一些有趣的模式：'
- en: 'First, these are color images instead of the grayscale internal activations
    like the ones in the previous section. This is because they are in the format
    of the convnet’s actual input: an image consisting of three (RGB) channels. Hence,
    they can be displayed in color.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，这些是彩色图像，而不是前面部分的灰度内部激活图像。这是因为它们的格式是卷积网络的实际输入：由三个（RGB）通道组成的图像。因此，它们可以显示为彩色。
- en: The shallowest layer (`block1_conv1`) is sensitive to simple patterns such as
    global color values and edges with certain orientations.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最浅的层（`block1_conv1`）对全局颜色值和带有特定方向的边缘等简单模式敏感。
- en: The intermediate-depth layers (such as `block2_conv1`) respond maximally to
    simple textures made from combining different edge patterns.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间深度层（如`block2_conv1`）对由不同边缘模式组合而成的简单纹理做出最大响应。
- en: The filters in deeper layers begin to respond to more complex patterns that
    show some resemblance to visual features in natural images (from the ImageNet
    training data, of course), such as grains, holes, colorful stripes, feathers,
    waves, and so forth.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在较深层的滤波器开始响应更复杂的模式，这些模式在某种程度上与自然图像中的视觉特征（当然是来自ImageNet训练数据）相似，例如颗粒、孔洞、彩色条纹、羽毛、波纹等。
- en: Figure 7.10\. Maximally activating input images for four layers of the VGG16
    deep convnet. These images are computed through 80 iterations of gradient ascent
    in input space.
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.10. VGG16深度卷积网络四个层的最大激活输入图像。这些图像是通过在输入空间中进行 80 次梯度上升计算得出来的。
- en: '![](07fig10_alt.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig10_alt.jpg)'
- en: In general, as the depth of the layer increases, the patterns get more and more
    removed from the pixel level and become more and more large-scale and complex.
    This reflects the layer-by-layer distillation of features by the deep convnet,
    composing patterns of patterns. Looking at the filters of the same layer, even
    though they share similar levels of abstraction, there is considerable variability
    in the detail patterns. This highlights the fact that each layer comes up with
    multiple representations of the same input in mutually complementary ways in order
    to capture the largest possible amount of useful information for solving the task
    that the network is trained to solve.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，随着层级的加深，模式从像素级逐渐变得更加复杂和大规模。这反映了深度卷积网络逐层对特征进行提炼，组合出各种模式。在分析同一层的滤波器时，尽管它们具有类似的抽象级别，但在详细模式上存在相当大的变化。这突显了每一层以互补的方式提出了同一输入的多种表示，以捕获尽可能多的有用信息，从而解决网络训练的任务。
- en: Deep dive into gradient ascent in input space
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 深入了解输入空间中的梯度上升
- en: In the visualize-convnet example, the core logic for gradient ascent in input
    space is in the `inputGradientAscent()` function in main.js and is shown in [listing
    7.9](#ch07ex09). The code runs in Node.js due to its time- and memory-consuming
    nature.^([[7](#ch07fn7)]) Note that even though the basic idea behind gradient
    ascent in input space is analogous to model training based on gradient descent
    in weight space (see [figure 7.10](#ch07fig10)), we cannot reuse `tf.Model.fit()`
    directly because that function is specialized to freeze the input and update the
    weights. Instead, we need to define a custom function that calculates a “loss”
    given an input image. This is the function defined by the line
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在可视化卷积网络的例子中，在 main.js 中的 `inputGradientAscent()` 函数中实现了输入空间中的梯度上升的核心逻辑，并且在
    [列表 7.9](#ch07ex09) 中进行了展示。由于其耗时和占用内存，该代码运行在 Node.js 中。^([[7](#ch07fn7)]) 注意，尽管梯度上升在输入空间中的基本思想类似于基于权重空间的梯度下降的模型训练（参见
    [图 7.10](#ch07fig10)），但我们不能直接重用 `tf.Model.fit()`，因为该函数专门冻结输入并更新权重。相反，我们需要定义一个自定义函数，该函数计算给定输入图像的“损失”。这就是该行定义的函数
- en: ⁷
  id: totrans-185
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁷
- en: ''
  id: totrans-186
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For convnets smaller than VGG16 (such as MobileNet and MobileNetV2), it is possible
    to run this algorithm within a reasonable amount of time in the web browser.
  id: totrans-187
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于小于VGG16的卷积网络（如MobileNet和MobileNetV2），可以在合理的时间内在Web浏览器中运行该算法。
- en: '[PRE13]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, `auxModel` is an auxiliary model object created with the familiar `tf.model()`
    function. It has the same input as the original model but outputs the activation
    of a given convolutional layer. We invoke the `apply()` method of the auxiliary
    model in order to obtain the value of the layer’s activation. `apply()` is similar
    to `predict()` in that it executes a model’s forward path. However, `apply()`
    provides finer-grained control, such as setting the `training` option to `true`,
    as is done in the prior line of code. Without setting `training` to `true`, backpropagation
    would not be possible because the forward pass disposes intermediate layer activations
    for memory efficiency by default. The `true` value in the `training` flag lets
    the `apply()` call preserve those internal activations and therefore enable backpropagation.
    The `gather()` call extracts a specific filter’s activation. This is necessary
    because the maximally activating input is calculated on a filter-by-filter basis,
    and the results differ between filters even of the same layer (see the example
    results in [figure 7.10](#ch07fig10)).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`auxModel`是一个使用熟悉的`tf.model()`函数创建的辅助模型对象。它具有与原始模型相同的输入，但输出给定卷积层的激活。我们调用辅助模型的`apply()`方法，以获得层激活的值。`apply()`类似于`predict()`，因为它执行模型的前向路径。但是，`apply()`提供了更细粒度的控制，例如将`training`选项设置为`true`，就像代码中前一行所做的那样。如果不将`training`设置为`true`，则不可能进行反向传播，因为默认情况下，前向传播会为内存效率而处置中间层激活。`training`标志中的`true`值使`apply()`调用保留这些内部激活，从而启用反向传播。`gather()`调用提取特定滤波器的激活。这是必要的，因为最大激活输入是根据每个过滤器逐个过滤器计算的，并且即使是相同层的过滤器之间的结果也会有所不同（请参见[图7.10](#ch07fig10)中的示例结果）。
- en: 'Once we have the custom loss function, we pass it to `tf.grad()` in order to
    obtain a function that gives us the gradient of the loss with respect to the input:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了自定义损失函数，我们就将其传递给`tf.grad()`，以便获得一个给出损失相对于输入的梯度的函数：
- en: '[PRE14]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The important thing to realize here is that `tf.grad()` doesn’t give us the
    gradient values directly; instead, it gives us a function (`gradFunction` in the
    prior line) that will return the gradient values when invoked.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这里要注意的重要事情是，`tf.grad()`不直接给出梯度值；相反，它会在调用时返回一个函数（在前一行中称为`gradFunction`），该函数在调用时会返回梯度值。
- en: 'Once we have this gradient function, we invoke it in a loop. In each iteration,
    we use the gradient value it returns to update the input image. An important nonobvious
    trick here is to normalize the gradient values before adding them to the input
    image, which ensures that the update in each iteration has a consistent magnitude:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这个梯度函数，我们就在一个循环中调用它。在每次迭代中，我们使用它返回的梯度值来更新输入图像。这里的一个重要的不明显的技巧是在将梯度值加到输入图像之前对其进行归一化，这确保了每次迭代中的更新具有一致的大小：
- en: '[PRE15]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This iterative update to the input image is performed 80 times, giving us the
    results shown in [figure 7.10](#ch07fig10).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迭代更新输入图像的过程重复执行了80次，得到了我们在[图7.10](#ch07fig10)中展示的结果。
- en: Listing 7.9\. Gradient ascent in input space (in Node.js, from visualize-convnet/main.js)
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.9\. 输入空间中的梯度上升（在Node.js中，来自visualize-convnet/main.js）
- en: '[PRE16]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '***1*** Creates an auxiliary model for which the input is the same as the original
    model, but the output is the convolutional layer of interest'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** 为原始模型创建一个辅助模型，其输入与原模型相同，但输出为感兴趣的卷积层'
- en: '***2*** This function calculates the value of the convolutional layer’s output
    at the designated filter index.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** 这个函数计算指定过滤器索引处的卷积层输出的值。'
- en: '***3*** This function calculates the gradient of the convolutional filter’s
    output with respect to the input image.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** 这个函数计算卷积滤波器输出相对于输入图像的梯度。'
- en: '***4*** Generates a random image as the starting point of the gradient ascent'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** 生成一个随机图像作为梯度上升的起始点'
- en: '***5*** Important trick: scales the gradient with the magnitude (norm) of the
    gradient'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** 重要技巧：将梯度与梯度的大小（范数）相乘'
- en: '***6*** Performs one step of gradient ascent: updates the image along the direction
    of the gradient'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*** 执行一步梯度上升：沿着梯度方向更新图像'
- en: 7.2.3\. Visual interpretation of a convnet’s classification result
  id: totrans-204
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.3\. 卷积神经网络分类结果的视觉解释
- en: The last post-training convnet visualization technique we will introduce is
    the *class activation map* (CAM) algorithm. The question that CAM aims to answer
    is “which parts of the input image play the most important roles in causing the
    convnet to output its top classification decision?” For instance, when the cat.jpg
    image was passed to the VGG16 network, we got a top class of “Egyptian cat” with
    a probability score of 0.89\. But by looking at just the image input and the classification
    output, we can’t tell which parts of the image are important for this decision.
    Surely some parts of the image (such as the cat’s head) must have played a greater
    role than other parts (for example, the white background). But is there an objective
    way to quantify this for any input image?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍的最后一个后训练卷积神经网络可视化技术是*类激活映射*（CAM）算法。CAM旨在回答的问题是“输入图像的哪些部分对于导致卷积神经网络输出其顶部分类决策起到最重要的作用？”例如，当将cat.jpg图像传递给VGG16网络时，我们得到了一个“埃及猫”的顶级类别，概率分数为0.89。但仅凭图像输入和分类输出，我们无法确定图像的哪些部分对于这个决定是重要的。肯定图像的某些部分（如猫的头部）必须比其他部分（例如白色背景）起到更重要的作用。但是否有一种客观的方法来量化任何输入图像的这一点？
- en: 'The answer is yes! There are multiple ways of doing this, and CAM is one of
    them.^([[8](#ch07fn8)]) Given an input image and a classification result from
    a convnet, CAM gives you a heat map that assigns importance scores to different
    parts of the image. [Figure 7.11](#ch07fig11) shows such CAM-generated heat maps
    overlaid on top of three input images: a cat, an owl, and two elephants. In the
    cat result, we see that the outline of the cat’s head has the highest values in
    the heat map. We can make the post hoc observation that this is because the outline
    reveals the shape of the animal’s head, which is a distinctive feature for a cat.
    The heat map for the owl image also meets our expectation because it highlights
    the head and wing of the animal. The result from the image with two elephants
    is interesting because the image differs from the other two images in that it
    contains two individual animals instead of one. The heat map generated by CAM
    assigns high importance scores to the head regions of both elephants in the image.
    There is a clear tendency for the heat map to focus on the trunks and ears of
    the animals, which may reflect the fact that the length of the trunk and the size
    of the ears are important in telling African elephants (the top class from the
    network) apart from Indian elephants (the third class from the network).'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是肯定的！有多种方法可以做到这一点，CAM就是其中之一。^([[8](#ch07fn8)])给定一个输入图像和一个卷积神经网络的分类结果，CAM会给出一个热图，为图像的不同部分分配重要性分数。[图7.11](#ch07fig11)展示了这样的CAM生成的热图叠加在三个输入图像上：一只猫，一只猫头鹰和两只大象。在猫的结果中，我们看到猫头的轮廓在热图中具有最高的值。我们可以事后观察到，这是因为轮廓揭示了动物头部的形状，这是猫的一个独特特征。猫头鹰图像的热图也符合我们的预期，因为它突出显示了动物的头部和翅膀。具有两只大象的图像的结果很有趣，因为该图像与其他两个图像不同，它包含了两只个体动物而不是一只。CAM生成的热图为图像中的两只大象的头部区域分配了高重要性分数。热图明显倾向于聚焦于动物的鼻子和耳朵，这可能反映了长鼻子的长度和耳朵的大小对于区分非洲象（网络的顶级类别）和印度象（网络的第三类别）的重要性。
- en: ⁸
  id: totrans-207
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁸
- en: ''
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The CAM algorithm was first described in Bolei Zhou et al., “Learning Deep Features
    for Discriminative Localization,” 2016, [http://cnnlocalization.csail.mit.edu/](http://cnnlocalization.csail.mit.edu/).
    Another well-known method is Local Interpretable Model-Agnostic Explanations (LIME).
    See [http://mng.bz/yzpq](http://mng.bz/yzpq).
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: CAM算法首次描述于Bolei Zhou等人的“为判别定位学习深度特征”，2016年，[http://cnnlocalization.csail.mit.edu/](http://cnnlocalization.csail.mit.edu/)。另一个知名的方法是局部可解释的模型无关解释（LIME）。见[http://mng.bz/yzpq](http://mng.bz/yzpq)。
- en: Figure 7.11\. Class activation maps (CAMs) for three input images to the VGG16
    deep convnet. The CAM heat maps are overlaid on the original input images.
  id: totrans-210
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.11。VGG16深度卷积神经网络的三个输入图像的类激活映射（CAMs）。CAM热图叠加在原始输入图像上。
- en: '![](07fig11_alt.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](07fig11_alt.jpg)'
- en: Technical side of the CAM algorithm
  id: totrans-212
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: CAM算法的技术方面
- en: 'As powerful as the CAM algorithm is, the idea behind it is actually not complicated.
    In a nutshell, each pixel in a CAM map shows how much the probability score of
    the winning class will change if the pixel value is increased by a unit amount.
    To go into the details a little more, the following steps are involved in CAM:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: CAM 算法虽然强大，但其背后的思想实际上并不复杂。简而言之，CAM 图中的每个像素显示了如果增加该像素值一单位量，获胜类别的概率分数将发生多大变化。下面稍微详细介绍了
    CAM 中涉及的步骤：
- en: Find the last (that is, deepest) convolutional layer of the convnet. In VGG16,
    this layer is named `block5_conv3`.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到卷积神经网络中最后一个（即最深的）卷积层。在 VGG16 中，这一层的名称为 `block5_conv3`。
- en: Compute the gradient of the network’s output probability for the winning class
    with respect to the output of the convolutional layer.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算网络输出概率对于获胜类别相对于卷积层输出的梯度。
- en: The gradient has a shape of `[1, h, w, numFilters]`, where `h`, `w`, and `numFilters`
    are the layer’s output height, width, and filter count, respectively. We then
    average the gradient across the example, height, and width dimensions, which gives
    us a tensor of shape `[numFilters]`. This is an array of importance scores, one
    for each filter of the convolutional layer.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度的形状为`[1, h, w, numFilters]`，其中`h`、`w`和`numFilters`分别是该层的输出高度、宽度和过滤器数量。然后，我们在示例、高度和宽度维度上对梯度进行平均，得到一个形状为`[numFilters]`的张量。这是一个重要性分数的数组，每个卷积层的过滤器都有一个。
- en: Take the importance-score tensor (of shape `[numFilters]`), and multiply it
    with the actual output value of the convolutional layer (of shape `[1, h, w, numFilters]`),
    with broadcasting (see [appendix B](kindle_split_030.html#app02), section B.2.2).
    This gives us a new tensor of shape `[1, h, w, numFilters]` and is an “importance-scaled”
    version of the layer’s output.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将重要性分数张量（形状为`[numFilters]`）与卷积层的实际输出值（形状为`[1, h, w, numFilters]`）进行乘法运算，并使用广播（参见
    [附录 B](kindle_split_030.html#app02)，第 B.2.2 节）。这给我们一个新的张量，形状为`[1, h, w, numFilters]`，是层输出的“重要性缩放”版本。
- en: Finally, average the importance-scaled layer output across the last (filter)
    dimension and squeeze out the first (example) dimension, which yields a grayscale
    image of shape `[h, w]`. The values in this image are a measure of how important
    each part of the image is for the winning classification result. However, this
    image contains negative values and is of smaller dimensions than the original
    input image (that is, 14 × 14 versus 224 × 224 in our VGG16 example). So, we zero
    out the negative values and up-sample the image before overlaying it on the input
    image.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，平均重要性缩放的层输出沿最后一维（过滤器）进行，并挤压掉第一维（示例），从而得到一个形状为`[h, w]`的灰度图像。该图像中的值是图像中每个部分对于获胜分类结果的重要程度的度量。然而，该图像包含负值，并且比原始输入图像的尺寸要小（例如，在我们的
    VGG16 示例中为 14 × 14，而原始输入图像为 224 × 224）。因此，我们将负值归零，并在覆盖输入图像之前对图像进行上采样。
- en: The detailed code is in the function named `gradClassActivationMap()` in visualize-convnet/main.js.
    Although this function runs in Node.js by default, the amount of computation it
    involves is significantly less than the gradient-ascent-in-input-space algorithm
    that we saw in the previous section. So, you should be able to run the CAM algorithm
    using the same code in the browser with acceptable speed.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 详细代码位于 visualize-convnet/main.js 中名为 `gradClassActivationMap()` 的函数中。尽管该函数默认在
    Node.js 中运行，但它所涉及的计算量明显少于前一节中我们看到的在输入空间中进行梯度上升的算法。因此，您应该能够在浏览器中使用相同的代码运行 CAM 算法，并且速度可接受。
- en: 'We talked about two things in this chapter: how to visualize data before it
    goes into training a machine-learning model and how to visualize a model after
    it’s trained. We intentionally skipped the important step in between—that is,
    visualization of the model *while* it’s being trained. This will be the focus
    of the next chapter. The reason why we single out the training process is that
    it is related to the concepts and phenomena of underfitting and overfitting, which
    are absolutely critical for any supervised-learning tasks and therefore deserve
    special treatment. Spotting and correcting underfitting and overfitting are made
    significantly easier by visualization. In the next chapter, we’ll revisit the
    tfjs-vis library we introduced in the first part of the chapter and see that it
    can be useful for showing how a model-training process is progressing, in addition
    to its data-visualization power discussed in this chapter.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了两个问题：在训练机器学习模型之前如何可视化数据，以及在训练完成后如何可视化模型。我们有意地跳过了其中一个重要步骤——也就是在模型训练*过程中*对模型进行可视化。这将成为下一章的重点。我们之所以单独提出训练过程，是因为它与欠拟合和过拟合的概念和现象有关，对于任何监督学习任务来说，这些概念和现象都是至关重要的，因此值得特别对待。通过可视化，我们可以更容易地发现和纠正欠拟合和过拟合问题。在下一章中，我们将重新讨论在本章第一部分介绍的
    tfjs-vis 库，并了解到它不仅可以用于数据可视化，还可以显示模型训练的进展情况。
- en: Materials for further reading and exploration
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步阅读和探索材料
- en: Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin, “Why Should I Trust
    You? Explaining the Predictions of Any Classifier,” 2016, [https://arxiv.org/pdf/1602.04938.pdf](https://arxiv.org/pdf/1602.04938.pdf).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin，“为什么我应该相信你？解释任何分类器的预测”，2016年，[https://arxiv.org/pdf/1602.04938.pdf](https://arxiv.org/pdf/1602.04938.pdf)。
- en: TensorSpace ([tensorspace.org](http://tensorspace.org)) uses animated 3D graphics
    to visualize the topology and internal activations of convnets in the browser.
    It is built on top of TensorFlow.js, three.js, and tween.js.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorSpace ([tensorspace.org](http://tensorspace.org)) 使用动画3D图形在浏览器中可视化卷积神经网络的拓扑和内部激活。它构建在
    TensorFlow.js、three.js 和 tween.js 之上。
- en: The TensorFlow.js tSNE library ([github.com/tensorflow/tfjs-tsne](http://github.com/tensorflow/tfjs-tsne))
    is an efficient implementation of the t-distributed Stochastic Neighbor Embedding
    (tSNE) algorithm based on WebGL. It can help you visualize high-dimensional datasets
    by projecting them to a 2D space while preserving the important structures in
    the data.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow.js tSNE 库 ([github.com/tensorflow/tfjs-tsne](http://github.com/tensorflow/tfjs-tsne))
    是基于 WebGL 的 t-distributed Stochastic Neighbor Embedding (tSNE) 算法的高效实现。它可以帮助您将高维数据集投影到2D空间中，同时保留数据中的重要结构。
- en: Exercises
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Experiment with the following features of `tfjs.vis.linechart()`:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用`tfjs.vis.linechart()`的以下功能：
- en: Modify the code in [listing 7.2](#ch07ex02) and see what happens when the two
    series being plotted have different sets of x-coordinate values. For example,
    try making the x-coordinate values 1, 3, 5, and 7 for the first series and 2,
    4, 6, and 8 for the second series. You can fork and modify the CodePen from [https://codepen.io/tfjs-book/pen/BvzMZr](https://codepen.io/tfjs-book/pen/BvzMZr).
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 [列表7.2](#ch07ex02) 中的代码，看看当要绘制的两个系列具有不同的x坐标值集合时会发生什么。例如，尝试将第一个系列的x坐标值设置为1、3、5和7，将第二个系列的x坐标值设置为2、4、6和8。您可以从
    [https://codepen.io/tfjs-book/pen/BvzMZr](https://codepen.io/tfjs-book/pen/BvzMZr)
    上分叉并修改 CodePen。
- en: The line charts in the example CodePen are all made with data series without
    duplicate x-coordinate values. Explore how the `linechart()` function handles
    data points with identical x-coordinate values. For example, in a data series,
    include two data points that both have x-value 0 but have different y-values (such
    as –5 and 5).
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在示例 CodePen 中的线图中，所有的数据系列都是由没有重复 x 坐标值的数据点组成的。了解一下 `linechart()` 函数如何处理具有相同
    x 坐标值的数据点。例如，在数据系列中，包括两个具有相同 x 值（例如-5和5）的数据点。
- en: In the visualize-convnet example, use the `--image` flag to the `yarn visualize`
    command to specify your own input image. Since we used only animal images in [section
    7.2](#ch07lev1sec2), explore other types of image content, such as people, vehicles,
    household items, and natural scenery. See what useful insights you can gain from
    the internal activations and CAMs.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 "visualize-convnet" 的例子中，使用 `yarn visualize` 命令的 `--image` 标志来指定自己的输入图片。由于我们在[第7.2节](#ch07lev1sec2)中仅使用了动物图片，请尝试探索其他类型的图片内容，例如人物、车辆、家居物品和自然风景。看看你能从内部激活和CAM中获得什么有用的见解。
- en: In the example in which we calculated the CAM of VGG16, we computed the gradients
    of the probability score for the *winning* class with respect to the last convolutional
    layer’s output. What if instead we compute the gradients for a *nonwinning* class
    (such as that of the lower probability)? We should expect the resulting CAM image
    to *not* highlight key parts that belong to the actual subject of the image. Confirm
    this by modifying the code of the visualize-convnet example and rerunning it.
    Specifically, the class index for which the gradients will be computed is specified
    as an argument to the function `gradClassActivationMap()` in visualize-convnet/cam.js.
    The function is called in visualize-convnet/main.js.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们计算 VGG16 的 CAM 的示例中，我们计算了相对于最后一个卷积层输出的 *胜利* 类别的概率分数的梯度。如果我们计算 *非胜利* 类别（例如较低概率的类别）的梯度会怎样？我们应该期望生成的
    CAM 图像 *不* 强调属于图像实际主题的关键部分。通过修改 visualize-convnet 示例的代码并重新运行确认这一点。具体来说，梯度将计算的类索引作为参数传递给
    `gradClassActivationMap()` 函数在 visualize-convnet/cam.js 中。该函数在 visualize-convnet/main.js
    中调用。
- en: Summary
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: We studied the basic usage of tfjs-vis, a visualization library tightly integrated
    with TensorFlow.js. It can be used to render basic types of charts in the browser.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们学习了 tfjs-vis 的基本用法，这是一个与 TensorFlow.js 紧密集成的可视化库。它可以用于在浏览器中呈现基本类型的图表。
- en: Visualizing data is an indispensable part of machine learning. Efficient and
    effective presentation of data can reveal patterns and provide insights that are
    otherwise hard to obtain, as we showed by using the Jena-weather-archive data.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可视化是机器学习不可或缺的一部分。对数据进行高效有效的呈现可以揭示模式并提供否则难以获得的见解，正如我们通过使用 Jena-weather-archive
    数据所展示的那样。
- en: Rich patterns and insights can be extracted from trained neural networks. We
    showed the steps and results of
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的模式和见解可以从训练好的神经网络中提取出来。我们展示了
- en: Visualizing the internal-layer activations of a deep convnet.
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化深度卷积网络的内部层激活。
- en: Calculating what the layers are maximally responsive to.
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算哪些层对最大程度响应。
- en: Determining which parts of an input image are most relevant to the convnet’s
    classification decision. These help us understand what is learned by the convnet
    and how it operates during inference.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定输入图像的哪些部分与 convnet 的分类决策最相关。这些帮助我们了解 convnet 学到了什么以及在推断过程中它是如何运作的。
