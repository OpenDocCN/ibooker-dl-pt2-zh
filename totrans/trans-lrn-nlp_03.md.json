["```py\npip install <package name>\n```", "```py\nimport numpy as np                      ❶\nimport pandas as pd                     ❷\n\nfilepath = \"../input/enron-email-dataset/emails.csv\"\n\nemails = pd.read_csv(filepath)          ❸\n\nprint(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0],  emails.shape[1]))                  ❹\nprint(emails.head(n=5))\n```", "```py\nSuccessfully loaded 517401 rows and 2 columns!\n\n                       file                                            message\n0     allen-p/_sent_mail/1\\.  Message-ID: <18782981.1075855378110.JavaMail.e...\n1    allen-p/_sent_mail/10\\.  Message-ID: <15464986.1075855378456.JavaMail.e...\n2   allen-p/_sent_mail/100\\.  Message-ID: <24216240.1075855687451.JavaMail.e...\n3  allen-p/_sent_mail/1000\\.  Message-ID: <13505866.1075863688222.JavaMail.e...\n4  allen-p/_sent_mail/1001\\.  Message-ID:<30922949.1075863688243.JavaMail.e...\n```", "```py\nprint(emails.loc[0][\"message\"])\n```", "```py\nMessage-ID: <18782981.1075855378110.JavaMail.evans@thyme>\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\nFrom: phillip.allen@enron.com\nTo: tim.belden@enron.com\nSubject: \nMime-Version: 1.0\nContent-Type: text/plain; charset=us-ascii\nContent-Transfer-Encoding: 7bit\nX-From: Phillip K Allen\nX-To: Tim Belden <Tim Belden/Enron@EnronXGate>\nX-cc: \nX-bcc: \nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\nX-Origin: Allen-P\nX-FileName: pallen (Non-Privileged).pst\n\nHere is our forecast\n```", "```py\nimport email\n\ndef extract_messages(df):\n    messages = []\n    for item in df[\"message\"]:\n        e = email.message_from_string(item)      ❶\n        message_body = e.get_payload()           ❷\n        messages.append(message_body)\n    print(\"Successfully retrieved message body from emails!\")\n    return messages\n```", "```py\nbodies = extract_messages(emails)\n```", "```py\nSuccessfully retrieved message body from emails!\n```", "```py\nbodies_df = pd.DataFrame(bodies)\nprint(bodies_df.head(n=5))\n```", "```py\n                                                  0\n0                 Here is our forecast\\n\\n \n1                Traveling to have a business meeting takes the...\n2                 test successful.  way to go!!!\n3                Randy,\\n\\n Can you send me a schedule of the s...\n4                Let's shoot for Tuesday at 11:45\\. \n```", "```py\nfilepath = \"../input/fraudulent-email-corpus/fradulent_emails.txt\"\nwith open(filepath, 'r',encoding=\"latin1\") as file:\n    data = file.read()\n\nfraud_emails = data.split(\"From r\")     ❶\n\nprint(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))\n```", "```py\nSuccessfully loaded 3978 spam emails!\n```", "```py\nfraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\nfraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\nprint(fraud_bodies_df.head())\n```", "```py\nSuccessfully retrieved message body from e-mails!\n                                                   0\n0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...\n1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...\n2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n4  Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ...\n```", "```py\nNsamp = 1000         ❶\nmaxtokens = 50       ❷\nmaxtokenlen = 20     ❸\n```", "```py\ndef tokenize(row):\n    if row in [None,'']:\n        tokens = \"\"\n    else:\n        tokens = str(row).split(\" \")[:maxtokens]    ❶\n    return tokens\n```", "```py\nimport re\ndef reg_expressions(row):\n    tokens = []\n    try:\n        for token in row:\n            token = token.lower()\n            token = re.sub(r'[\\W\\d]', \"\", token)    ❶\n            token = token[:maxtokenlen]             ❷\n            tokens.append(token)\n    except:\n        token = \"\"\n        tokens.append(token)\n    return tokens\n```", "```py\nimport nltk\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstopwords = stopwords.words('english')    \n\ndef stop_word_removal(row):\n    token = [token for token in row if token not in stopwords]    ❶\n    token = filter(None, token)                                   ❷\n    return token\n```", "```py\nimport random\n\nEnronEmails = bodies_df.iloc[:,0].apply(tokenize)              ❶\nEnronEmails = EnronEmails.apply(stop_word_removal)\nEnronEmails = EnronEmails.apply(reg_expressions)\nEnronEmails = EnronEmails.sample(Nsamp)                        ❷\n\nSpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\nSpamEmails = SpamEmails.apply(stop_word_removal)\nSpamEmails = SpamEmails.apply(reg_expressions)\nSpamEmails = SpamEmails.sample(Nsamp)\n\nraw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values  ❸\n```", "```py\nprint(\"Shape of combined data represented as NumPy array is:\")\nprint(raw_data.shape)\nprint(\"Data represented as NumPy array is:\")\nprint(raw_data)\n```", "```py\nShape of combined data represented as NumPy array is:\n(2000, )\nData represented as NumPy array is:\n'got' ... ]\n ['dear', 'friend' ' my' ...]\n ['private’, ‘confidential' 'friend', 'i' ... ]\n ...\n```", "```py\nCategories = ['spam','notspam']\nheader = ([1]*Nsamp)\nheader.extend(([0]*Nsamp))\n```", "```py\ndef assemble_bag(data):\n    used_tokens = []\n    all_tokens = []\n\n    for item in data:\n        for token in item:\n            if token in all_tokens:             ❶\n                if token not in used_tokens:\n                    used_tokens.append(token)\n            else:\n                all_tokens.append(token)\n\n    df = pd.DataFrame(0, index = np.arange(len(data)), columns = used_tokens)\n\n    for i, item in enumerate(data):             ❷\n        for token in item:\n            if token in used_tokens:\n                df.iloc[i][token] += 1    \n    return df\n```", "```py\nEnronSpamBag = assemble_bag(raw_data)\nprint(EnronSpamBag)\npredictors = [column for column in EnronSpamBag.columns]\n```", "```py\n     fails  report s  events   may   compliance  stephanie  \n0         0         0        0     0           0          0  \n1         0         0        0     0           0          0  \n2         0         0        0     0           0          0  \n3         0         0        0     0           0          0  \n4         0         0        0     0           0          0  \n...     ...       ...      ...   ...         ...        ...  \n1995      1         2        1     1           1          0  \n1996      0         0        0     0           0          0  \n1997      0         0        0     0           0          0  \n1998      0         0        0     0           0          1  \n1999      0         0        0     0           0          0  \n\n[2000 rows x 5469 columns]\n```", "```py\ndef unison_shuffle_data(data, header):\n    p = np.random.permutation(len(header))\n    data = data[p]\n    header = np.asarray(header)[p]\n    return data, header\n```", "```py\ndata, header = unison_shuffle_data(EnronSpamBag.values, header)\nidx = int(0.7*data.shape[0])       ❶\ntrain_x = data[:idx]\ntrain_y = header[:idx]\ntest_x = data[idx:]                ❷\ntest_y = header[idx:]\n```", "```py\n!wget -q \"http:/ /ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n!tar xzf aclImdb_v1.tar.gz\n```", "```py\ndef load_data(path):\n    data, sentiments = [], []\n    for folder, sentiment in (('neg', 0), ('pos', 1)):\n        folder = os.path.join(path, folder)\n        for name in os.listdir(folder):                        ❶\n            with open(os.path.join(folder, name), 'r') as reader:\n                  text = reader.read()\n            text = tokenize(text)                              ❷\n            text = stop_word_removal(text)\n            text = reg_expressions(text)\n            data.append(text)\n            sentiments.append(sentiment)                       ❸\n    data_np = np.array(data)                                   ❹\n    data, sentiments = unison_shuffle_data(data_np, sentiments)\n\n    return data, sentiments\n\ntrain_path = os.path.join('aclImdb', 'train')                  ❺\nraw_data, raw_header = load_data(train_path)\n```", "```py\nprint(raw_data.shape)\nprint(len(raw_header))\n```", "```py\n(25000,)\n25000\n```", "```py\nrandom_indices = np.random.choice(range(len(raw_header)),size=(Nsamp*2,),replace=False)\ndata_train = raw_data[random_indices]\nheader = raw_header[random_indices]\n```", "```py\nunique_elements, counts_elements = np.unique(header, return_counts=True)\nprint(\"Sentiments and their frequencies:\")\nprint(unique_elements)\nprint(counts_elements)\n```", "```py\nSentiments and their frequencies:\n[0 1]\n[1019  981]\n```", "```py\nMixedBagOfReviews = assemble_bag(data_train)\nprint(MixedBagOfReviews)\n```", "```py\n      ages  i  series         the  dream  the  movie  film  plays  ...  \\\n0        2  2       0     0     0      0    0      1     0      0  ...   \n1        0  0       0     0     0      0    0      0     0      1  ...   \n2        0  0       2     2     2      2    2      0     1      0  ...   \n3        0  2       0     1     0      0    0      1     1      1  ...   \n4        0  2       0     0     0      0    1      0     0      0  ...   \n...    ... ..     ...   ...   ...    ...  ...    ...   ...    ...  ...   \n1995     0  0       0     0     0      0    0      2     1      0  ...   \n1996     0  0       0     0     0      0    0      1     0      0  ...   \n1997     0  0       0     0     0      0    0      0     0      0  ...   \n1998     0  3       0     0     0      0    1      1     1      0  ...   \n1999     0  1       0     0     0      0    0      1     0      0  ... \n```", "```py\nfrom sklearn.linear_model import LogisticRegression\n\ndef fit(train_x,train_y):\n    model = LogisticRegression()      ❶\n\n    try:\n        model.fit(train_x, train_y)   ❷\n    except:\n        pass\n    return model\n```", "```py\nmodel = fit(train_x,train_y)\n```", "```py\npredicted_labels = model.predict(test_x)\nfrom sklearn.metrics import accuracy_score\nacc_score = accuracy_score(test_y, predicted_labels)\nprint(\"The logistic regression accuracy score is::\")\nprint(acc_score)\n```", "```py\nThe logistic regression accuracy score is::\n0.9766666666666667\n```", "```py\nThe logistic regression accuracy score is::\n0.715\n```", "```py\nimport time\nfrom sklearn.svm import SVC # Support Vector Classification model\n\nclf = SVC(C=1, gamma=\"auto\", kernel='linear',probability=False)     ❶\n\nstart_time = time.time()                                            ❷\nclf.fit(train_x, train_y)\nend_time = time.time()\nprint(\"Training the SVC Classifier took %3d seconds\"%(end_time-start_time))\n\npredicted_labels = clf.predict(test_x)                              ❸\nacc_score = accuracy_score(test_y, predicted_labels)\nprint(\"The SVC Classifier testing accuracy score is::\")\nprint(acc_score)\n```"]