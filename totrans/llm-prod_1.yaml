- en: '1 Word’s Awakening: Why Large Language Models Have Captured Attention'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 词语的觉醒：大型语言模型为何引起关注
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: What Large Language Models are and what they can and cannot do
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是大型语言模型，以及它们可以做什么和不能做什么
- en: When you should deploy your own Large Language Models and when should not
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么时候你应该部署自己的大型语言模型，以及什么时候不应该
- en: Large Language Model myths and the truths that lie behind them
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型的神话及其背后的真相
- en: '"Any sufficiently advanced technology is indistinguishable from magic."'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"任何足够先进的技术都与魔法无异。"'
- en: '- Arthur C. Clarke'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '- 阿瑟·克拉克'
- en: The year is 1450\. A sleepy corner of Mainz, Germany, unknowingly stands on
    the precipice of a monumental era. In Humbrechthof, a nondescript workshop shrouded
    in the town's shadows pulsates with anticipation. It is here that Johannes Gutenberg,
    a goldsmith and innovator, sweats and labors amidst the scents of oil, metal,
    and determination, silently birthing a revolution. In the late hours of the night,
    the peace is broken intermittently by the rhythmic hammering of metal on metal.
    In the lamp-lit heart of the workshop stands Gutenberg's decade-long labor of
    love—a contraption unparalleled in design and purpose.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是1450年。德国美因茨的一个寂静角落，在不知不觉中站在一个伟大时代的边缘。在Humbrechthof，这个隐藏在城镇阴影中的不起眼作坊里，空气中充满着油、金属和坚定决心的气味，约翰内斯·古腾堡，一位金匠和创新者，在这里辛苦劳作，无声地孕育着一场革命。在深夜的时刻，平静被金属与金属的节奏性敲打声不时打破。在作坊灯光明亮的中心，站立着古腾堡十年来的心血之作——一台设计和用途都独一无二的装置。
- en: This is no ordinary invention. Craftsmanship and creativity transform an assortment
    of moveable metal types, individually-cast characters born painstakingly into
    a matrix. The flickering light dances off the metallic insignias. The air pulsates
    with the anticipation of a breakthrough and the heady sweetness of oil-based ink,
    an innovation from Gutenberg himself. In the stillness of the moment, the master
    printer squares his shoulders and with unparalleled finesse, lays down a crisp
    sheet of parchment beneath the ink-loaded matrix and allows his invention to press
    firmly and stamp finely print onto the page. The room adjusts to the symphony
    of silence, bated breaths hanging heavily in the air. As the press is lifted,
    it creaks under its own weight, each screech akin to a war cry announcing an exciting
    new world.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一件普通的发明。工艺和创造力将一组可移动的金属类型、单个铸造的字符精心制造在模具中。跳跃的灯光在金属标志上闪烁。空气中充满了突破的期待和来自古腾堡自己的基于油的墨水的香甜。在这个瞬间的静寂中，主印刷师挺直了肩膀，用无与伦比的技艺，将一张干净的羊皮纸放在装满墨水的模具下面，让他的发明牢固地印在页面上。房间里调整到一片宁静的交响乐，屏住呼吸的空气显得沉重。当印刷机抬起时，它在自身重量下发出吱吱声，每个声响都像是一声战吼，宣告一个激动人心的新世界的到来。
- en: With a flurry of motion, Gutenberg pulls from the press the first printed page
    and slams it flat onto the wooden table carefully examining each character which
    are as bold and magnificent as the creator's vision. The room drinks in the sight,
    absolutely spellbound. A mere sheet of parchment has become a testament of transformation.
    As the night gives way to day, he looks upon his workshop with invigorated pride.
    His legacy is born, echoing in the annals of history and forever changing the
    way information would take wings. Johannes Gutenberg, now the man of the millennium,
    emerges from the shadows, an inventor who dared to dream. His name synonymous
    with the Printing Press which is not just a groundbreaking invention, but the
    catalyst of a modern world.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 古腾堡在一片忙碌中从印刷机上取下第一页印刷好的纸，并将其平放在木桌上，仔细检查每个字符，这些字符如他的愿景一样粗体且宏伟。整个房间都被这幅景象深深吸引。一张普通的羊皮纸已经成为了转变的见证。随着夜幕渐渐消散，他带着充满活力的自豪感审视他的作坊。他的遗产已经诞生，在历史的记载中回响，永远改变了信息传播的方式。约翰内斯·古腾堡，这个新的千年英雄，从阴影中走出来，这个敢于梦想的发明家。他的名字与印刷机紧密相连，这不仅是一个开创性的发明，更是现代世界的催化剂。
- en: As news of Gutenberg's achievement begins to flutter across the continent, scholars
    from vast disciplines are yet to appreciate the extraordinary tool at their disposal.
    Knowledge and learning, once coveted treasures, are now within the reach of the
    common man. There were varied and mixed opinions surrounding that newfound access.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着关于古腾堡成就的消息开始在欧洲大陆传播，来自各个学科的学者们尚未意识到他们手中掌握的这个非凡工具。知识和学习，曾经被珍视的宝藏，现在平民也可以轻松获得。而对于这种新发现的便利，意见却众说纷纭。
- en: “In our time, thanks to the talent and industry of those from the Rhine, books
    have emerged in lavish numbers. A book that once would’ve belonged only to the
    rich - nay, to a king - can now be seen under a modest roof. […] There is nothing
    nowadays that our children […] fail to know.”
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在我们这个时代，由于那些来自莱茵河的人才和工业，书籍数量激增。曾经只属于富人 - 不，属于国王的书籍现在可以在一个朴素的屋顶下见到。[…] 如今，我们的孩子们[…]无一不知。”
- en: '- Sebastian Brant'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '- 塞巴斯蒂安·布兰特'
- en: “Scholarly effort is in decline everywhere as never before. Indeed, cleverness
    is shunned at home and abroad. What does reading offer to pupils except tears?
    It is rare, worthless when it is offered for sale, and devoid of wit.”
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “学术努力从未像现在一样普遍衰退。事实上，聪明才智在国内外都受到厌恶。除了眼泪，阅读对学生有什么好处呢？很罕见，当它被出售时毫无价值，也没有智慧。”
- en: '- Egbert of Liege'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '- 列日的埃格伯特'
- en: 'People have had various opinions on books throughout history. One thing we
    can agree on, living in a time when virtual printing presses exist and books are
    ubiquitous: the printing press changed history. While we weren’t actually there
    when Gutenberg printed the first page using his printing press, we have watched
    many play with large language models (LLMs) for the first time. The astonishment
    on their face as they see it respond to their first prompt. The excitement they
    have when challenging it with a difficult question only to see it respond as if
    it was an expert in the field. The light bulb moment when they realize they can
    use this to simplify their life or make themselves wealthy. I imagine this wave
    of emotions were, but a fraction of those felt by Johannes Gutenberg. Being able
    to rapidly generate text and accelerate communication has always been valuable.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 人们对书籍有着各种各样的看法。有一点我们可以达成共识，在虚拟印刷厂存在且书籍无处不在的时代：印刷机改变了历史。尽管我们并不是真的在古腾堡使用印刷机打印第一页的时候在场，但我们已经看到很多人第一次尝试与大型语言模型（LLMs）互动。当他们看到它对他们的第一个提示做出回应时，他们脸上的惊讶。当他们挑战它的困难问题时，看到它像领域专家一样回应时，他们的兴奋。当他们意识到他们可以利用这一点来简化他们的生活或使自己富有时，他们的灵光一现。我想象这些情绪波动只是约翰内斯·古腾堡所感受到的一小部分。快速生成文本和加速沟通一直都是有价值的。
- en: 1.1 Large Language Models accelerating communication
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 大型语言模型加速沟通
- en: Every job has some level of communication. Oftentimes this communication is
    drudgery, bureaucratic, and political. I’ve often warned students and mentees
    that every job has its paperwork. Something that used to be a passion can easily
    be killed by the day to day tedium and menial work that comes with it when it
    becomes a job. In fact, when we talk about our professions we often talk them
    up, trying to improve our social standing, so you’ll rarely get the full truth.
    You won’t hear about the boring parts and the day-to-day grind gets conveniently
    forgotten.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 每一份工作都有一定程度的沟通。通常这种沟通是单调乏味的、官僚主义的和政治性的。我经常警告学生和门徒，每份工作都有它的文书工作。曾经是激情的东西很容易被日复一日的乏味和琐碎的工作所扼杀，当它变成一份工作时就会出现这种情况。事实上，当我们谈论我们的职业时，我们经常吹嘘它们，试图提高我们的社会地位，所以你很少会听到全部真相。你不会听到有关无聊的部分，日常的苦差事会方便地被遗忘。
- en: However, envision a world where we reduce the burden of monotonous work. A place
    where police officers no longer have to waste hours of each day filling out reports
    and could instead devote that time to community outreach programs. Or a world
    where teachers, no longer slaving late into the night grading homework and preparing
    lesson plans, instead being able to think about and prepare customized lessons
    for individual students. Or even a world where lawyers would no longer be stuck
    combing through legal documents for days, instead being free to take on charity
    cases for causes that inspire them? When the communication burden, the paperwork
    burden and the accounting burden, are taken away, the job becomes more akin to
    what we sell it as.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，想象一下一个减轻单调工作负担的世界。一个警察不再每天浪费数小时填写报告，而是可以把那些时间用在社区外展项目上的地方。或者一个世界，教师不再彻夜忙于批改作业和准备课程计划，而是可以考虑和准备针对个别学生的定制课程。甚至一个世界，律师们不再陷入为期数日的法律文件梳理之中，而是有自由去接受激励他们的慈善案件？当沟通负担、文书负担和会计负担消失时，工作更像是我们所说的那样。
- en: For this, LLMs are the most promising technology to come along since, well,
    the printing press. For starters, they have completely upended the role and relationship
    between humans and computers, transforming what we believed they were capable
    of. They have already passed medical exams[[1]](#_ftn1), the bar exam, and multiple
    theory of mind tests. They’ve passed both Google and Amazon coding interviews.
    They’ve gotten scores of at least 1410 out of 1600 on the SAT. One of the most
    impressive to the authors is that GPT-4 has even passed the Advanced Sommelier
    exam–which makes us wonder how they got past the practical wine tasting portion.
    Indeed, their unprecedented accomplishments are coming at breakneck speed and
    often make us mere mortals feeling a bit queasy and uneasy. What do you do with
    a technology that seems to be able to do anything?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一点，LLMs是自印刷术以来最有前途的技术。首先，它们彻底颠覆了人类和计算机之间的角色和关系，改变了我们认为它们有能力的东西。它们已经通过了医学考试[[1]](#_ftn1)，律师资格考试，以及多次心灵理论测试。它们已经通过了谷歌和亚马逊的编程面试。它们在SAT考试中至少获得了1600分中的1410分。其中最令作者印象深刻的是，GPT-4甚至通过了高级侍酒师考试-这让我们想知道它们是如何通过实际的品酒部分的。事实上，它们前所未有的成就以惊人的速度发展，往往让我们这些凡人感到有点不安和不安。对于一种似乎能做任何事情的技术，你会做什么呢？
- en: Passing tests is fun and all, but not exactly all that helpful unless our aim
    was to build the most expensive cheating machine ever, which we promise there’s
    better use of our time. What LLMs are good at is language, particularly, helping
    us improve and automate communication. This allows us to transform common bitter
    experiences into easy enjoyable experiences. For starters, imagine entering your
    home where you have your very own personal JARVIS, as if stepping into the shoes
    of Iron Man, an AI-powered assistant that adds an unparalleled dynamic to your
    routine. While not quite to the same artificial general intelligence (AGI) levels
    as those portrayed by JARVIS in the Marvel movies, LLMs are powering new user
    experiences from improving customer support to helping you shop for a loved one’s
    birthday. It knows to ask you about the person, learn about their interests and
    who they are, find out your budget, and then make specialized recommendations.
    While many of these assistants are being put to good work, many others are simply
    just chatbots that users can talk to and entertain themselves—which is important
    because even our imaginary friends are too busy these days. Jokes aside, these
    can create amazing experiences allowing you to meet your favorite fictional characters
    like Harry Potter, Sherlock Holmes, Anakin Skywalker or even Iron Man.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然通过考试很有趣，但除非我们的目标是建造史上最昂贵的作弊机器，否则并不是特别有帮助，我们承诺我们的时间有更好的利用。LLMs擅长的是语言，特别是帮助我们改善和自动化沟通。这使我们能够将常见的苦涩经验转化为轻松愉快的经验。首先，想象一下走进你的家门，你有自己的个人JARVIS，就好像踏入了钢铁侠的鞋子，这是一个为你的日常生活增添了无与伦比的活力的AI助手。虽然LLMs还没有达到漫威电影中JARVIS所表现出的人工智能（AGI）水平，但它们正在为改善客户支持到帮助你购物挑选爱人的生日礼物等新的用户体验提供动力。它懂得询问你关于这个人，了解他们的兴趣和身份，找出你的预算，然后给出专业的建议。尽管许多这些助手正在被很好地利用，但还有许多只是用户可以与之对话和娱乐的聊天机器人-这很重要，因为即使我们的想象朋友这些天也太忙了。开玩笑的，这些可以创造出惊人的体验，让你见到你最喜爱的虚构角色，比如哈利·波特，福尔摩斯，阿纳金·天行者或者钢铁侠。
- en: What we’re sure many readers are interested in though is programming assistants,
    because we all know Googling everything is actually one of the worst user experiences.
    Being able to write a few objectives in plain English and see a copilot write
    the code for you is exhilarating. I’ve personally used these tools to help me
    remember syntax, simplify and clean code, write tests, and learn a new programming
    language.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确信许多读者对编程助手感兴趣，因为我们都知道无所不Google实际上是最糟糕的用户体验之一。能够用简单的英语写下几个目标，然后看到助手帮你写代码是一种令人振奋的体验。我个人曾经使用这些工具来帮助我记住语法，简化和清理代码，编写测试，并学习一种新的编程语言。
- en: Video Gaming is another interesting field where we can expect LLMs to create
    a lot of innovation. Not only do they help the programmers create the game, but
    they are allowing designers to create more immersive experiences. For example,
    talking to NPC’s will have more depth and intriguing dialogue. Picture games like
    Animal Crossing or Stardew Valley having near infinite quests and conversations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 视频游戏是另一个有趣的领域，我们可以期待大型语言模型(LLM)带来许多创新。它们不仅帮助程序员创造游戏，还允许设计者创造更沉浸式的体验。例如，与NPC对话会更加深入和引人入胜。想象一下，像《动物之森》或《星露谷物语》这样的游戏会有几乎无穷无尽的任务和对话。
- en: Consider other industries, like Education where there just doesn’t seem to be
    enough teachers to go around meaning our kids aren’t getting the one on one attention
    they need. An LLM assistant can help save the teacher time doing manual chores
    as well as serve as a private tutor for the kids that are struggling. Corporate
    is looking into LLMs for talk-to-your-data jobs, tasks helping employees understand
    quarterly reports and data tables, essentially giving everyone their own personal
    analyst. Sales and Marketing divisions are guaranteed to take advantage of this
    marvelous innovation, for better or worse. The state of Search Engine Optimization
    (SEO) will change a lot too since currently it is mostly a game of generating
    content to hopefully make websites more popular, which is now super easy.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑其他行业，比如教育，似乎没有足够的老师满足需求，意味着我们的孩子没有得到他们需要的一对一关注。LLM助手可以帮助老师节省做手工事务的时间，同时为那些困难的孩子提供私人辅导。企业正在研究将LLM用于对话式数据工作，协助员工理解季度报告和数据表，基本上为每个人提供他们自己的个人分析师。销售和营销部门肯定会利用这一神奇的创新，无论好坏。搜索引擎优化（SEO）的状况也将发生很大变化，因为目前它主要是通过产生内容来希望使网站更受欢迎，而现在这变得非常容易。
- en: That list is just a few of the common examples I’ve seen where companies are
    interested in using them. People are using them for personal reasons too. Writing
    music, poetry, and even books, translating languages, summarizing legal documents
    or emails, and even using them for free therapy—which yes, is an awful idea since
    they are still dreadful at this. Just a personal preference, but we wouldn’t try
    to save a buck when our sanity is on the line. Of course, this leads us to the
    fact that people are already using them for darker purposes like cheating, scams,
    and fake news to skew elections. At this point, the list has become rather large
    and varied, but we’ve only begun to scratch the surface of the possible. Really,
    since LLMs help us with communication often, it’s better to think, “What can’t
    they do?” than “What can they do?”.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 那个清单只是我看到的一些常见例子，公司对使用它们感兴趣。人们也出于个人原因使用它们。创作音乐、诗歌，甚至写书，翻译语言，总结法律文件或电子邮件，甚至免费咨询——是的，这个主意很糟糕，因为它们在这方面还是很糟糕。个人偏好，但当我们的心智受到威胁时，我们不应该节省一分钱。当然，这导致了人们已经开始将它们用于欺骗、诈骗和伪造新闻以扭曲选举的黑暗目的。此时，清单已经变得相当大而且多样化，但我们只是开始挖掘其潜力的一角。实际上，由于大型语言模型（LLM）通常帮助我们进行沟通，所以更好的思考方式应该是，“它们做不到什么？”而不是“它们能做什么？”。
- en: Or better yet, “What shouldn’t they do?” Well, as a technology there are certain
    restrictions and constraints, for example, LLMs are kind of slow. Of course, slow
    is a relative term, but responsive times are often measured in seconds not milliseconds.
    We’ll dive deeper into this in Chapter 3, but as an example, we probably won’t
    see them being used in autocomplete tasks anytime soon which require blazingly
    fast inference in order to be useful. After all, autocomplete needs to be able
    to predict the word or phrase faster than someone types. In a similar fashion,
    LLMs are large complex systems, we don’t need them for such a simple problem anyway.
    Hitting an autocomplete problem with an LLM isn’t just hitting the nail with a
    sledgehammer, it’s hitting it with a full on wrecking ball. And just like it’s
    more expensive to rent a wrecking ball than buy a hammer, an LLM will cost you
    more to operate. There are a lot of similar tasks where we should consider the
    complexity of the problem we are trying to solve.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 或者更好的是，“它们不应该做什么？”嗯，作为一种技术，有一些限制和约束，例如，LLM速度有点慢。当然，慢是一个相对的词，但响应时间通常是以秒为单位而不是毫秒。我们将在第三章中更深入地探讨这个问题，但举个例子，我们可能不会很快看到它们用于自动完成任务，因为那需要非常快的推理才能有用。毕竟，自动完成需要能够比某人的打字速度更快地预测单词或短语。类似地，LLM是大型复杂系统，我们不需要它们来解决这样一个简单的问题。用LLM解决自动完成问题不仅仅是用锤子打钉子，而是用整个拆迁球撞击它。就像租用一颗拆迁球比买一把锤子更贵一样，运行LLM会花费你更多。有很多类似的任务，我们应该考虑解决的问题的复杂性。
- en: There are also many complex problems that are often poorly solved with LLMs
    such as predicting the future. No, we don’t mean with mystic arts, but forecasting
    problems, acts like predicting the weather or when high tide will hit on the ocean
    shore. These are actually problems we’ve solved, but we don’t necessarily have
    good ways to communicate how these have been solved. They are expressed through
    combinations of math solutions like Fourier transforms and harmonic analysis or
    through black box ML models. There are many problems that fit into this category,
    like outlier prediction, calculus, or finding the end of the roll of tape.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多复杂的问题通常很难用LLM解决，比如预测未来。不，我们不是指神秘的艺术，而是预测问题，比如预测天气或海滩上涨潮的时间。这些实际上是我们解决了的问题，但我们并没有一定好的方法来传达这些问题是如何解决的。它们通过数学解决方案的组合来表达，比如傅里叶变换和谐波分析，或者通过黑盒子ML模型。有很多问题符合这个类别，比如异常值预测，微积分，或者找到胶带卷的结尾。
- en: You also probably want to avoid using them for highly risky projects. LLMs aren’t
    infallible and make mistakes often. To increase creativity we often allow for
    a bit of randomness in LLMs which means you can ask an LLM the same question and
    get different answers. That’s risky. You can remove this randomness by doing what’s
    called turning down the temperature, but that might make it useless depending
    on your needs. For example, you might decide to use an LLM to categorize investment
    options as good or bad, but do you want it to then make actual investment decisions
    based on its output? Not without oversight, unless your goal is to create a meme
    video.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可能想要避免在高风险项目中使用它们。LLM并不是绝对可靠，经常会犯错误。为了增加创造力，我们通常允许LLM中有一点随机性，这意味着你可以问LLM同样的问题，得到不同的答案。这是有风险的。你可以通过降低温度来消除这种随机性，但根据你的需求，这可能会使它变得无用。例如，你可能决定使用LLM将投资选项分类为好或坏，但你是否希望它根据其输出做出实际的投资决策？除非你的目标是制作一个迷因视频，否则不要没有监督地这样做。
- en: Ultimately an LLM is just a model, it can’t be held accountable for losing your
    money, and really it didn’t lose your money you did by choosing to use it. Similar
    risky problems could include filling out tax forms or getting medical advice.
    While an LLM could do these things, it won’t protect you from heavy penalties
    in an IRS audit like hiring a certified CPA would. If you take bad medical advice
    from an LLM, there’s no doctor you could sue for malpractice. However, in all
    of these examples, the LLM could potentially largely help the practitioner better
    perform their job roles both reducing errors and improving speed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，LLM 只是一个模型，它不能对你的损失负责，而实际上是你选择使用它造成了损失。类似的风险问题可能包括填写税表或寻求医疗建议。虽然LLM可以做这些事情，但它不会像雇用经过认证的注册会计师那样保护你免受IRS审计的严重处罚。如果你从LLM那里得到错误的医疗建议，就没有医生可以告你医疗事故。然而，在所有这些例子中，LLM都有可能大大帮助从业者更好地执行他们的工作角色，减少错误并提高速度。
- en: When to use an LLM
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 何时使用LLM
- en: 'Use them for:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 用途包括：
- en: Generating content
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成内容
- en: Question and answering services
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatBots and AI assistants
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffusion (txt2img, txt23d, txt2vid, etc.)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Talk-to-your-data applications
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything that involves communication
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Avoid using them for:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Latency-sensitive workloads
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple projects
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems we don’t solve with words but with math or algorithm - forecasting,
    outlier prediction, calculus, etc.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Critical evaluations
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-risk projects
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language is not just a medium people use to communicate. It is the tool that
    made humans apex predators and gives every individual self-definition to their
    community. Every aspect of human existence, from arguing with your parents to
    graduating from college to reading this book is pervaded by our language. Language
    models are learning to harness one of the fundamental aspects of being human and
    have the ability, when used responsibly, to help us with each and every one of
    those tasks. They have the potential to unlock dimensions of understanding both
    of ourselves and others if we responsibly teach them how.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have captured the world’s attention since their potential allows imaginations
    to run wild. LLMs promise so much, but… where are all these solutions? Where are
    the video games that give us immersive experiences? Why don’t our kids have personal
    AI tutors yet? Why am I not Iron Man with my own personal assistant yet? These
    are the deep and profound questions that motivated us to write this book. Particularly
    that last one, it keeps me up at night. So while LLMs can do amazing things, not
    enough people know how to actually turn them into a product and that’s what we
    aim to share in this book.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/01__image001.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: This isn’t just a Machine Learning Operations book. There are a lot of gotchas
    and pitfalls involved with making an LLM work in production because LLMs just
    don’t work like traditional software solutions. To turn an LLM into a product
    that can interact coherently with your users will require an entire team and diverse
    set of skills. Depending on your use case you may need to train or finetune and
    then deploy your own model, or you may just need to access one from a vendor through
    an API.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of which LLM you use, if you want to take full advantage of the technology
    and build the best user experience, you will need to understand how they work.
    Not just on the math/tech side either, but on the soft side for how to make it
    a good experience for your users. In this book we’ll be covering everything you
    need to make LLMs work in production. We’ll talk about the best tools and infrastructure,
    how to maximize their utility with prompt engineering and other best practices
    like controlling costs. LLMs could be one step towards a greater equality, so
    if you are thinking, “I don’t feel like the person this book is for,” please reconsider.
    This book is for the whole team and anyone who will be interacting with LLMs in
    the future.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to hit on a practical level everything that you’ll need for collecting
    and creating a dataset, training or finetuning an LLM on consumer or industrial
    hardware, and deploying that model in various ways for customers to interact with.
    While we aren’t going to cover too much theory, we will be covering the process
    from end to end with real-world examples. At the end of this book you will know
    how to deploy LLMs with some viable experience to back it up.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在实践层面上涵盖您在收集和创建数据集、在消费者或工业硬件上训练或微调LLM，并以各种方式部署该模型供客户与之交互所需的一切。虽然我们不打算涉及太多理论，但我们将用真实的例子来覆盖从头到尾的过程。在本书结束时，您将知道如何部署LLM，并具有一些可行的经验来支持它。
- en: 1.2 Navigating between the Build and Buy decision with Large Language Models
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 在大型语言模型的构建与购买决策之间导航
- en: If you bought this book, you are likely already convinced of the overwhelming
    potential LLMs can have in your life and in your organization. Buying this book
    then is the first step to turning your dreams into a reality, because none of
    it is possible until we know how to put these models into production. After all,
    if you talk to any entrepreneur or investor out there they will tell you good
    ideas are a dime a dozen, what matters is execution and actually manifesting those
    ideas. What we need to do is get these models into production, where they are
    readily available to do actual work for you.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您购买了本书，那么您很可能已经相信LLM在您的生活和组织中具有巨大的潜力。那么购买本书就是将您的梦想变成现实的第一步，因为在我们知道如何将这些模型投入生产之前，这一切都是不可能的。毕竟，如果您与任何企业家或投资者交谈，他们都会告诉您，好的想法是大把的，重要的是执行和实现这些想法。我们需要做的是将这些模型投入生产，让它们随时可用于为您执行实际工作。
- en: There’s no getting around it and no need to sugar coat it either, deploying
    LLMs into production is hard. Often anything worth pursuing is. In this book we
    aim to teach you everything you need to know to do it as well as give you some
    practical hands-on experience. But because it is so hard, it is mighty tempting
    to take a shortcut. Large corporations like OpenAI and Google have some great
    offerings of models to choose from, why not just buy them? Let’s start by considering
    what they offer and if this may be a good choice, and then we’ll take a look at
    the other side of the coin where these offerings tend to fall flat.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何都无法避免，也没有必要美化，将LLM部署到生产环境中都很困难。通常，任何值得追求的事情都是如此。在本书中，我们旨在教您一切所需的知识，让您能够做到这一点，并提供一些实际的实践经验。但是因为它很困难，所以很容易想要走捷径。像OpenAI和Google这样的大型公司有一些很棒的模型选择，为什么不直接购买呢？让我们首先考虑一下它们提供了什么，以及这可能是一个好选择，然后我们将看看另一方面，这些提供通常存在的问题。
- en: '1.2.1 Buying: the beaten path'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 购买：被打的道路
- en: There are many great reasons to simply just buy access to an LLM. First and
    foremost is the speed and flexibility accessing an API provides. Working with
    an API is an incredibly easy and cheap way to build a prototype and get your hands
    dirty quickly. In fact, so easy you can see in listing 1.1 that it only takes
    a few lines of code to start connecting to OpenAI’s API and start using LLMs.
    Sure, there’s a lot that’s possible, but it would be a bad idea to heavily invest
    in LLMs only to find out they happen to fail in your specific domain. Working
    with an API allows you to fail fast. Building a prototype application to prove
    the concept and launching it with an API is a great place to get started.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地购买LLM访问权限有许多很好的理由。首先也是最重要的是，访问API提供的速度和灵活性。使用API是建立原型并迅速入手的一种非常简单和便宜的方法。事实上，如您在列表
    1.1 中所见，只需几行代码即可开始连接到OpenAI的API并开始使用LLM。当然，有很多可能性，但是过度投资于LLM，只是发现它们恰好在您特定的领域失败，这将是一个糟糕的主意。使用API可以让您快速失败。构建原型应用程序以证明概念，并通过API启动它是一个很好的起点。
- en: Listing 1.1 A simple app calling OpenAI’s API
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 1.1 调用OpenAI API的简单应用程序
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Oftentimes, buying access to a model can give you a competitive edge. In many
    cases it could very well be that the best model on the market is built by a company
    specializing in the domain who are using specialized datasets they have spent
    a fortune to curate. While you could try to compete and build your own, it may
    better serve your purposes to simply buy access to their model instead. Ultimately,
    whoever has the better domain specific data to finetune on is likely going to
    win, and that might not be you if this is a side project for your company. Curating
    data can be expensive after all. It can save you a lot of work to go ahead and
    buy it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Which leads to the next point, buying is a quick way to access expertise and
    support. For example, OpenAI has spent a lot of time making their models safe
    with plenty of filtering and controls to prevent the misuse of their LLMs. They’ve
    already encountered and covered a lot of the edge cases, so you don’t have to.
    Buying access to their model also gives you access to the system they’ve built
    around it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Not to mention, the LLM itself is only half the problem in deploying them to
    production. There’s still an entire application you need to build on top of it.
    Sometimes buying OpenAI’s model has thrived over its competitors in not a small
    part due to their UX and some tricks like making the tokens look like they’re
    being typed. We’ll take you through how you can start solving for the UX in your
    use case, along with some ways you can prototype to give you a major head start
    in this area.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.2 Building: the path less traveled'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using an API is easy, and in most cases, likely the best choice. However, there
    are many reasons why you should aim to own this technology and learn how to deploy
    it yourself instead. While this path might be harder, we’ll teach you how to do
    it. Let''s dive into several of those reasons starting with the most obvious:
    Control.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Control
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the first companies to truly adopt LLMs as a core technology is a small
    video game company called Latitude. Latitude specializes in Dungeon and Dragons
    like role playing games utilizing LLM chatbots, and they have faced challenges
    when working with them. This shouldn’t come off as criticizing this company for
    their missteps, as they contributed to our collective learning experience and
    were pioneers forging a new path. Nonetheless, their story is a captivating and
    intriguing one, like a train wreck that we personally couldn't help but keep watching.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Latitude's first release was a game called AI Dungeon. At inception, it utilized
    OpenAI’s GPT2 to create an interactive and dynamic storytelling experience. It
    quickly garnered a large gathering of players, who of course started to use it
    inappropriately. When OpenAI gave Latitude access to GPT3 it promised an upgrade
    to the gaming experience, instead, what it got was a nightmare.[[2]](#_ftn2)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: You see, with GPT3 they added Reinforcement Learning from Human Feedback (RLHF)
    which greatly helps improve functionality, but this also meant OpenAI contractors
    were now looking at the prompts. That’s the human feedback part. And these workers
    weren’t too thrilled to read the filth the game was creating. OpenAI's reps were
    quick to give Latitude an ultimatum. Either they needed to start censoring the
    players or they’d remove their access to the model—which would have essentially
    killed the game and the company. With no other option they quickly added some
    filters but the filtering system was too much a band-aid, a buggy and glitchy
    mess. Players were upset at how bad the system was and unnerved to realize Latitude’s
    developers were reading their stories, completely oblivious to the fact that OpenAI
    was already doing such. It was a PR nightmare. And it wasn’t over.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉你一个事，GPT3加入了人类反馈加强学习（RLHF）这个功能，这大大有助于提高功能，但这也意味着OpenAI的合同工现在正在查看提示。这就是人类反馈的部分。这些工作人员并不是太喜欢阅读游戏创建的淫秽内容。OpenAI的代表迅速向Latitude提出了最后通牒。要么他们需要开始审查玩家，否则他们将撤销他们对模型的访问——这将基本上扼杀了游戏和公司。由于没有其他选择，他们迅速添加了一些过滤器，但过滤系统却太过于是一个应急措施，一个漏洞和故障的混乱。玩家们对系统的糟糕程度感到不满，并且意识到Latitude的开发人员正在阅读他们的故事，完全不知道OpenAI已经在这方面做出了贡献。这是一场公关灾难。但这还没有结束。
- en: 'OpenAI decided the game studio wasn’t doing enough, stonewalled, they were
    forced to increase their safeguards, and so they started banning players. Here’s
    the twist, the reason so many of these stories turned to smut, was because the
    model had a preference for erotica. It would often unexpectedly transform harmless
    storylines into inappropriately risqué situations causing the player to be ejected
    and barred from the game. OpenAI was acting the paragon of purity, but it was
    their model that was the problem. Which led to one of the most ironic and unjust
    problems in gaming history: players were getting banned for what the game did.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI认为游戏工作室不够努力，一直在制造障碍，他们被迫增加保障措施，开始禁止玩家进入游戏。这里是因果转折，很多故事变得淫秽是因为这个模型有偏好于情色文学。它经常会将无害的情节意外地转化为不当的情挑状况，导致玩家被驱逐和禁止进入游戏。OpenAI又扮演起真理的楷模，但问题在于他们的模型。这让玩家们面临了游戏史上最具讽刺意味和不公正的问题：他们因游戏所传达的内容而被禁止进入游戏。
- en: So there they were, a young game studio just trying to make a fun game stuck
    between upset customers and a tech giant that pushed all the blame and responsibility
    onto them. If the company had more control over the technology they could have
    gone after a real solution, like fixing the model. Instead of having to throw
    makeup on a pig.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是一个年轻的游戏工作室，只是想制作一个有趣的游戏却陷入了挫败的客户和一个把所有责任都推到他们身上的技术巨头之间的困境。如果公司对技术拥有更多的控制权，他们可以采取真正的解决方案，比如修复模型，而不是只能把化妆品涂在猪身上。
- en: In this example, control may come off as your ability to finetune your mode
    and OpenAI now offers finetuning capabilities, but there are many fine-grained
    decisions that are still lost by using a service instead of rolling your own solution.
    For example, what training methodologies are used, what regions the model is deployed
    too, or what infrastructure it runs on. Control is also important for any customer
    or internal-facing tool. You don’t want to have a code generator accidentally
    output code that’s copyrighted or that creates a legal situation for your company.
    You also don’t want your customer-facing LLM to output factually incorrect information
    about your company or its processes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，控制可能表现为你微调模型的能力，而OpenAI现在提供了微调功能，但仍有许多细节的决策在使用服务而不是自己的解决方案时会丢失。例如，使用哪些训练方法，将模型部署到哪些区域，或者在哪种基础设施上运行。控制对于任何面向客户或内部的工具也很重要。你不希望代码生成器意外输出侵犯版权或为你的公司创建法律问题的代码。你也不希望你面向客户的LLM输出关于你的公司或其过程的事实不正确的信息。
- en: Control is your ability to direct and manage the operations, processes, and
    resources in a way that aligns with your goals, objectives, and values. If a model
    ends up becoming central to your product offering and the vendor unexpectedly
    raises their prices there’s little you can do but pay it. If the vendor decides
    their model should give more liberal or conservative answers that no longer align
    with your values, you are just as stuck.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 控制是你管理操作、过程、资源的能力，以便与你的目标、目的和价值观保持一致。如果一个模型最终成为你产品提供的核心，并且供应商意外提高了价格，你能做的很少。如果供应商决定他们的模型应该给出更自由或更保守的答案，而这不再与你的价值
- en: The more central a technology is to your business plan, the more important it
    is to control it. This is why McDonald's owns the real estate for its franchises
    and why Google, Microsoft, and Amazon all own their own cloud networks. Or even
    why so many entrepreneurs build online stores through Shopify versus just using
    other platforms like Etsy or Amazon Marketplace. Ultimately control is the first
    thing that’s lost when you buy someone else’s product. Keeping it will give you
    more options to solve future problems and will also give you a competitive edge.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 技术对你的业务计划越核心，控制它的重要性就越大。这就是为什么麦当劳拥有其特许经营的房地产，以及为什么谷歌、微软和亚马逊都拥有自己的云网络。甚至为什么那么多企业家通过Shopify建立在线商店，而不只是使用其他平台，比如Etsy或亚马逊市场。最终，当你购买别人的产品时，第一件失去的就是控制权。保持控制权将为你提供更多解决未来问题的选择，并且也将为你带来竞争优势。
- en: Competitive edge
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 竞争优势
- en: One of the most valuable aspects of deploying your own models is the competitive
    edge it gives you over your competition. Customization - train the model to be
    the best at one thing. For example, after the release of Bidirectional Encoder
    Representations from Transformers (BERT) in 2017, which is a transformer model
    architecture you could use to train your own model, there was a surge of researchers
    and businesses testing this newfound technology on their own data to worldwide
    success. At the time of writing, if you search the Hugging Face Hub for “BERT,”
    there are more than 13.7k models returned, all that people trained individually
    for their own purposes to be the best model for their task.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 部署自己模型最有价值的一个方面是它给你带来了竞争优势。定制化——训练模型成为最擅长的一件事。例如，在2017年发布了双向编码器表示来自变压器（BERT），这是一种你可以用来训练自己模型的变压器模型架构后，有一大批研究人员和企业开始测试这项新技术在他们自己的数据上取得全球成功。在撰写本文时，如果你在Hugging
    Face Hub搜索“BERT”，会返回超过13.7k个模型，所有这些模型都是人们为了自己的目的个别训练的，以成为他们任务的最佳模型。
- en: One of my personal experiences in this area was training SlovenBERTcina. After
    aggregating the largest (at-the-time) monolingual Slovak language dataset by scraping
    the Slovak National Corpus with permission, along with a whole bunch of other
    resources like the OSCAR project and the Europarl corpus. It never set any computational
    records, and has never appeared in any model reviews or generated partnerships
    for the company I worked for. It did, however, outperform every other model on
    the market on the tasks it trained on.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域的一个我个人的经验是训练斯洛文尼亚BERTcina。在征得许可的情况下，通过爬取斯洛伐克国家语料库等资源，我汇总了当时最大的（单语种斯洛伐克语）数据集，还包括像OSCAR项目和欧洲议会语料库等一大堆其他资源。它从未创造过任何计算记录，也从未出现在任何模型评论中或为我工作的公司产生合作伙伴关系。然而，在它训练的任务上，它确实胜过了市场上的其他任何模型。
- en: Chances are, neither you nor your company need AGI to generate relevant insights
    from your data, and in fact if you invented an actual self-aware AGI and planned
    to only ever use it to crunch some numbers, analyze data and generate visuals
    for PowerPoint slides once a week, that would definitely be reason enough for
    the AGI to eradicate humans. More than likely, you need exactly what I did when
    I made SlovenBERTcina, a large language model that performs the two to three tasks
    you need better than any other model on the market and doesn’t also share your
    data with Microsoft or other potential competitors. While some data is required
    to keep secret for security or legal reasons, a lot of data should be guarded
    simply because they are trade secrets.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，你和你的公司都不需要AGI（人工通用智能）来从你的数据中生成相关见解，实际上，如果你发明了一个真正自我意识的AGI，并计划仅仅将其用于每周一次为幻灯片制作一些数字、分析数据和生成可视化内容，那肯定足以成为AGI消灭人类的理由。更有可能的情况是，你需要的正是我制作斯洛文尼亚BERTcina时所需要的，一个大型语言模型，它在市场上执行的两到三个任务比其他任何模型都要好，并且不会将你的数据与微软或其他潜在竞争对手共享。虽然一些数据需要因安全或法律原因保密，但很多数据只是因为它们是商业机密而需要保护。
- en: There are hundreds of open source LLMs both for general intelligence, and for
    foundational expertise on a specific task. We’ll hit some of our favorites in
    Chapter 4\. Taking one of these open source alternatives and training it on your
    data to create a model that is the best in the world at that task will ensure
    you have a competitive edge in your market. It will also allow you to deploy the
    model your way and integrate it into your system to make the most impact.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Integrate anywhere
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s say you want to deploy an LLM as part of a choose your own adventure style
    game that uses a device’s GPS location to determine story plots. You know your
    users are often going to go on adventures into the mountains, out at sea, and
    generally to locations where they are likely to experience poor service and lack
    of internet access. Hitting an API just isn’t going to work. Now, don’t get me
    wrong, deploying LLMs onto edge devices like in this scenario is still an exploratory
    subject, but it is possible, and we will be showing you how in chapter 9\. Relying
    upon an API service is just not going to work for immersive experiences.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, using third party LLM and hitting an API adds integration and latency
    issues, requiring you to send data over the wire and wait for a response. APIs
    are great, but they are always slow and not always reliable. When latency is important
    to a project it’s much better to serve the service in-house. The previous section
    on Competitive Edge discussed two projects with edge computing as a priority,
    however many more exist. LLAMA.cpp and ALPACA.cpp are two of the first of such
    projects, and this space is innovating quicker than any others. Quantization into
    4-bit, Low-Rank Adaptation, and Parameter Efficient Finetuning are all methodologies
    recently created just to meet these needs, and we’ll be going over each of these
    starting in Chapter 3.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: When my team first started integrating with ChatGPT’s API, it was both an awe-inspiring
    and humbling experience. Awe-inspiring because it allowed us to quickly build
    some valuable tools. Humbling because as one engineer joked to me, “When you hit
    the end point you will get 503 errors, sometimes you get a text response as if
    the model was generating text, but I think that’s a bug.” Serving an LLM in a
    production environment, trying to meet the needs of so many clients, is no easy
    feat. However, deploying a model that’s integrated into your system allows you
    more control of the process affording higher availability and maintainability
    than you can currently find on the market.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Costs
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Considering costs is always important because it plays a pivotal role in making
    informed decisions and ensuring the financial health of a project or an organization.
    It helps you manage budgets efficiently and make sure that resources are allocated
    appropriately. Keeping costs under control allows you to maintain the viability
    and sustainability of your endeavors in the long run.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, considering costs is crucial for risk management. When you understand
    the different cost aspects, you can identify potential risks and exert better
    control over them. This way, you can avoid unnecessary expenditures and ensure
    that your projects are more resilient to unexpected changes in the market or industry.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑成本对于风险管理至关重要。当你了解不同的成本方面时，你可以识别潜在风险并更好地对其进行控制。这样，你可以避免不必要的支出，并确保你的项目对市场或行业的意外变化更具弹性。
- en: Finally, cost considerations are important for maintaining transparency and
    accountability. By monitoring and disclosing costs, organizations demonstrate
    their commitment to ethical and efficient operations to stakeholders, clients,
    and employees. This transparency can improve an organization's reputation and
    help build trust.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，成本考虑对于保持透明度和问责制是重要的。通过监控和披露成本，组织向利益相关者、客户和员工展示了他们对道德和高效运营的承诺。这种透明度可以提高组织的声誉并有助于建立信任。
- en: All of these apply as you consider building versus buying LLMs. It may seem
    immediately less costly to buy, as the most costly service widely used on the
    market currently is only $20 USD per month. Compared to an EC2 instance on AWS,
    just running that same model for inference (not even training) could run you up
    a bill for about $250k USD per year. This is where building has done its quickest
    innovation, however. If all you need is an LLM for a proof of concept, any of
    the projects mentioned in the Competitive Edge section will allow you to create
    a demo for only the cost of electricity to run on the computer you are demoing
    on, and spell out training easily enough to allow for significantly reduced costs
    to train a model on your own data, as low as $100 (yes, that’s the real number)
    for a model with 20 billion parameters. Another benefit is knowing that if you
    build your own, your cost will never go up, like it very much will when paying
    for a service.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑构建和购买LLM时，所有这些都适用。购买可能似乎立即较为廉价，因为目前市场上使用最多的服务每月只需20美元。但与在AWS上运行的EC2实例相比，仅仅运行同样的模型进行推理（甚至不是训练）每年可能会花费约25万美元。然而，这正是构建方面最快的创新所在。如果你只需要一个LLM来证明概念，文中竞争优势部分提到的任何项目都可以让你以运行演示计算机所需的电费为代价创建演示，并且中文文本处理后能很容易地解释出训练相关的内容，从而能够大大降低自己数据训练模型的成本，最低为100美元（是的，这个数字是真实的），可以训练包含200亿个参数的模型。另一个好处是，如果你自己构建，你的成本将永远不会增加，而支付服务的话，成本却很可能会大幅上涨。
- en: Security and privacy
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全性和隐私
- en: Consider the following case. You are a military staff member in charge of maintenance
    for the nuclear warheads in your arsenal. All the documentation is kept in a hefty
    manual. There’s so much information required to outline all the safety requirements
    and maintenance protocols cadets are known to forget important information despite
    their best efforts. They often cut the wires before first removing the fuse[[3]](#_ftn3).
    You decide to fine-tune an LLM model to be a personal assistant, giving directions
    and helping condense all that information giving soldiers exactly what they need
    when they need it. It’s probably not a good idea to upload those manuals to another
    company–understatement of the century–you're going to want to train something
    locally that’s kept secure and private.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑下面的情况。你是负责军事核弹头维护的军事人员。所有的文档都放在一本庞大的手册里。为了概述所有的安全要求和维护协议，学员们会因为遗忘重要信息而经常先剪掉保险丝再剪断导线。你决定调整一个LLM模型成为个人助手，给出指示，帮助压缩所有这些信息，为士兵在需要时提供精确所需的信息。将这些手册上传到另外一家公司显然不是个好主意——这是本世纪的轻描淡写——你需要在本地训练一些保持安全和隐私的东西。
- en: This scenario may sound farfetched, but when speaking to an expert working in
    analytics for a police department they echoed this exact concern. Talking with
    them, they expressed how cool ChatGPT is even having their whole team take a prompt
    engineering class to better take advantage of it, but lamented that there was
    no way for his team to use it for their most valuable work–the sort of work that
    literally saves lives–without exposing sensitive data and conversations. Anyone
    in similar shoes should be eager to learn how to deploy a model safely and securely.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况听起来可能很牵强，但当与一家警察局的分析专家交谈时，他们同样表达了这个问题。和他们交谈时，他们表达了ChatGPT有多酷，甚至让他们整个团队参加了一门提示工程课程，以更好地利用它，但他们抱怨说，没有办法让他们的团队在不暴露敏感数据和对话的情况下使用该模型进行最有价值的工作-那种可以拯救生命的工作。任何处于类似境地的人都应该热切学习如何安全、可靠地部署模型。
- en: You don’t have to be in the army or police force to handle sensitive data. Every
    company has important intellectual property and trade secrets that are best to
    keep a secret. Having worked in the semiconductor, healthcare, and finance industries
    we can tell you first hand, paranoia and corporate espionage are part of the culture
    in these industries. Because of this Samsung and other industry players at first
    locked down ChatGPT preventing employees from using it, later opening it up. Of
    course, it didn’t take long before several Samsung employees leaked confidential
    source code[[4]](#_ftn4). Because OpenAI uses RLHF, that code is retained and
    used to further train the model later on. Meaning with the right prompt injection,
    anyone could potentially pull the code out of the model.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 不用在军队或警察部门工作，也能处理敏感数据。每家公司都有重要的知识产权和商业机密，最好保守秘密。我们在半导体、医疗保健和金融行业工作过，可以亲身告诉你，偏执和企业间谍是这些行业文化的一部分。因此，三星和其他行业参与者最初锁定了ChatGPT，防止员工使用它，后来才开放了它。当然，不久之后，几名三星员工泄露了机密源代码[[4]](#_ftn4)。由于OpenAI使用了RLHF，这些代码被保留并用于以后进一步训练模型。这意味着只要有正确的提示注入，任何人都有可能从模型中提取代码。
- en: It’s not just code that can easily be lost. Business plans, meeting notes, confidential
    emails and even potential patent ideas are at risk. We unfortunately know of a
    few companies who have started sending confidential data to ChatGPT, using that
    model to clean and extract PII. If this strikes you as potential negligent misuse,
    you’d be right. This methodology directly exposes customer data, not just to Microsoft/OpenAI,
    but to any and all 3rd-party services that they use (including AWS Mechanical
    Turk, Fiverr, and Freelance workers) to perform the Human Feedback part of RLHF.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅代码容易丢失。商业计划、会议记录、机密电子邮件甚至潜在专利想法都有风险。我们很不幸地知道一些公司已经开始向ChatGPT发送机密数据，使用该模型清理和提取PII。如果您认为这可能是潜在的疏忽滥用，你是对的。这种方法直接暴露客户数据，不仅仅是给
    Microsoft/OpnAI，而是给他们使用的任何第三方服务（包括AWS Mechanical Turk、Fiverr和自由职业者）执行RLHF中的人类反馈部分。
- en: Wrapping up
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总结
- en: As you can see, there are lots of reasons why a company might want to own and
    build their own LLMs including having greater control, cutting costs, and meeting
    security and regulation requirements. Despite this we understand that buying is
    easy, and building is much more difficult so for many projects it makes sense
    to just buy, but before you do in figure 1.1 we share a flowchart of questions
    you should ask yourself first. Even though it’s the more difficult path, building
    can be much more rewarding.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，有很多原因使得公司想要拥有和构建自己的LLMs，包括更大的控制力、降低成本以及满足安全和监管要求。尽管如此，我们了解到购买很容易，建设却更加困难，因此对于许多项目来说，仅购买是有意义的，但在你这样做之前，在图1.1中，我们分享了一些你应该自问的问题的流程图。尽管这是更艰难的道路，但建设可能会更加有回报。
- en: Figure 1.1 Questions you should ask yourself before making that build vs buy
    decision.
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1在做出构建与购买决策之前你应该问自己的问题。
- en: '![](images/01__image002.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](images/01__image002.png)'
- en: 'One last point we think these build versus buy conversations never seem to
    hone in on enough is, “Porque no los dos?” Buying gets you all the things building
    is bad at: time-to-market, relatively low cost, and ease-of use. Building gets
    you all the things buying struggles with: privacy, control, and flexibility. Research
    and prototyping phases could very much benefit from buying a subscription to GPT4
    or Databricks for building something quick to help raise funding or get stakeholder
    buy-in. Production however, often isn’t an environment that lends itself to third-party
    solutions well.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, whether or not you plan to build or buy we wrote this book for you.
    Obviously if you plan to build it, there’s going to be a lot more you need to
    know about, so a majority of this book will be geared to these folks. In fact,
    we don’t need to belabor the point anymore, we’re going to teach you how to build
    in this book, but don’t let that stop you from doing the right thing for your
    company.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.3 A word of warning: embrace the future now'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: New technologies are like fire, they can provide warmth on cold nights and help
    cook our food, but they can also burn our homes and hurt us. In business, there’s
    no shortage of stories of companies failing because they failed to adapt to new
    technologies. We can learn a lot from their failures.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Borders Books first opened its doors in 1971\. After developing a comprehensive
    inventory management system that included advanced analytic capabilities it skyrocketed
    to become the second-largest Book retailer in the world, only behind Barnes &
    Noble. Using this new technology it disrupted the industry, allowing it to easily
    keep track of tens of thousands of books, opening large stores where patrons could
    peruse many more books than they could at smaller stores. The analytic capabilities
    helped it track which books were gaining popularity and gain better insights into
    their customers allowing it to make better business decisions. It dominated the
    industry for over two decades.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Borders however, failed to learn from its own history, going bankrupt in 2011,
    failing to adapt and being disrupted by technology this time; e-commerce. In 2001,
    instead of building their own platform and online store, they decided to outsource
    their online sales to Amazon.[[5]](#_ftn5) A decision many critics would say was
    akin to giving your competitors the key to your business. While not exactly handing
    over their secret sauce, it was a decision that gave up their competitive edge.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: For the next seven years they turned a blind eye to the growing online sector
    instead focusing on expanding their physical store presence, buying out competitors
    and securing a coveted Starbucks deal. When Amazon released the Kindle in 2007,
    the book retail landscape completely changed. Barnes & Noble having run their
    own online store quickly pivoted and released the Nook to compete, Borders however,
    did nothing, or in fact, could do nothing.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: By embracing e-commerce through a third party, they failed to develop the in-house
    expertise required to create a successful online sales strategy, leading to a
    substantial loss in market share. They eventually launched their own e-reader,
    Kobo, in late 2010, but it was too late to catch up. Their inability to fully
    understand and implement e-commerce technology effectively led to massive financial
    losses, store closures, and ultimately, the company filed for bankruptcy in 2011.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Borders Books is a cautionary tale, but there are hundreds more of similar companies
    who failed to adopt new technology to their own detriment. With a new technology
    as impactful as LLMs each company has to decide on which side of the fence they
    want to be on. Do they delegate implementation and deployment to large FAANG like
    corporations relegating to just hitting an API, or do they take charge preferring
    to master the technology and deploy it themselves?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: The biggest lesson we hope to impart from this story is that technologies build
    on top of one another. Ecommerce was built on top of the internet. Failing to
    build their own online store meant Borders failed to build the in-house technical
    expertise they needed to stay in the game when the landscape shifted. We see the
    same things with LLMs today because the companies that are best prepared to utilize
    them have already gathered expertise in machine learning and data science and
    have some idea of what they are doing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have a crystal ball that tells us the future, but many believe that
    LLMs are a revolutionary new technology like the internet or electricity before
    it. Learning how to deploy these models, or failing to do so, may very well be
    the defining moment for many companies. Not because doing so will make or break
    their company now, but in the future, when something even more valuable comes
    along that’s built on top of LLMs.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Foraying into this new world of deploying LLMs may be challenging but will help
    your company build the technical expertise to stay on top of the game. No one
    really knows where this technology will lead, but learning about this technology
    will likely be necessary to avoid mistakes like Borders Books’.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: There are many great reasons to buy your way to success, but there is at least
    one prevalent thought that is just absolutely wrong. It’s the myth that only large
    corporations can work in this field because it takes millions of dollars and thousands
    of GPUs to train these models. Creating this impenetrable moat of cash and resources
    the little guy can’t hope to cross. We’ll be talking about this more in the next
    section, but any company of any size can get started and there’s no better time
    than now to do so.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Debunking myths
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have all heard from large corporations and the current leaders in LLMs how
    incredibly difficult it is to train an LLM from scratch and how intense it is
    to try to finetune them. Whether from OpenAI, BigScience, or Google they discuss
    large investments and the need for strong data and engineering talent. But how
    much of this is true and how much of it is just a corporate attempt to create
    a technical moat?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Most of these barriers start with the premise that you will need to train an
    LLM from scratch if you hope to solve your problems. Simply put, you don’t! Open
    source models covering many dimensions of language models are constantly being
    released, so you more-than-likely don’t need to start from scratch. While what
    they say is true that training LLMs from scratch is supremely difficult, we are
    still constantly learning about how to do it and are able to more and more automate
    the repeatable portions. In addition, since this is an active field of research
    frameworks and libraries are being released or updated daily and will help you
    start from wherever you currently are. Frameworks like oobabooga’s Gradio will
    help you run LLMs and base models like Falcon 40B will be your starting point.
    All of it is covered. To add to this, memos have circulated at large companies
    addressing the lack of a competitive edge that any organization currently holds
    over the open source community at large.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: A friend once confided in me that, “I really want to get more involved in all
    this machine learning and data science stuff. It seems to be getting cooler every
    time I blink an eye. However, it feels like the only way to get involved is to
    go through a lengthy career change and go work for a FAANG. No, thank you. I’ve
    done my time at large companies, and they aren’t for me. But I hate feeling like
    I’m trapped on the outside.” This is the myth that inspired this book. We’re here
    to equip you with tools and examples to help you to stop feeling trapped on the
    outside. We’ll help you go through the language problems that we’re trying to
    solve with LLMs, along with machine learning operation strategies to account for
    the sheer size of the models.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Oddly enough, as many believe they are trapped on the outside, many others believe
    they can become experts in a weekend. Just get a GPT API key and that’s it, you’re
    done. This has led to a lot of fervor and hype with a cool new demo popping up
    on social media every day. But, most of these demos never become actual products
    and not because people don’t want them.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: To understand this, let’s discuss IBM’s Watson the world’s most advanced language
    model before GPT. Watson is a question and answering machine that went on to crush
    Jeopardy in 2011 against some of the best human contestants to ever appear on
    the show, Brad Rutter and Ken Jennings. Rutter the highest earning contestant
    ever to play the game show and Jennings a player so good he went on to win a whopping
    74 times in a row. Despite facing these legends, it wasn’t even close. Watson
    won in a landslide. Jennings in response to the loss responded with the famous
    quote, "I, for one, welcome our new computer overlords."[[6]](#_ftn6)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Watson was the first impressive foray into language modeling and many companies
    were clamoring to take advantage of its capabilities. Starting in 2013, Watson
    started being released for commercial use. One of the biggest applications involved
    many attempts trying to integrate it into healthcare to solve various problems.
    However, none of these solutions ever really worked the way they needed to and
    the business never became profitable. By 2022 Watson Health was sold off.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: What we find when solving language related problems is that building a prototype
    is easy, building a functioning product on the other hand is very, *very* difficult.
    There are just too many nuances to language. Many people wonder what made ChatGPT
    so explosive? Gaining over a million clients in just five days. Most of the answers
    I’ve heard would never satisfy an expert because ChatGPT wasn’t much more impressive
    than GPT3 or other LLMs which had been around for several years already. I heard
    Sam Altman of OpenAI himself say in an interview they didn’t think ChatGPT would
    get this much attention, they thought that would come with GPT4’s release.[[7]](#_ftn7)
    So why was it explosive? The magic in our opinion, is that it was the first product
    to truly productionize LLMs. To turn it from a demo into an actual product. It
    was something anyone could interact with and ask it tough questions, only to be
    amazed by how well it responded. A demo only has to work once, but the product
    has to work every time and even when millions of users are showing it to their
    friends saying, “Check this out!” That magic is exactly what you can hope to learn
    from reading this book.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: We’re excited about writing this book. We are excited about the possibilities
    of bringing this magic to you so you can bring it to the world. LLMs are at the
    intersection between so many fields such as linguistics, mathematics, computer
    science and more. While the more you know will help you, to be an expert isn’t
    required. Expertise in any of the individual parts only raises the skill ceiling,
    not the floor to get in. Consider an expert in physics or music theory, they won’t
    automatically have the skills for music production, but they will be more prepared
    to quickly learn. LLMs are a communication tool and communicating is a skill just
    about everyone needs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Like all other skills, your proximity and willingness to get involved are the
    two main blockers to knowledge, not a degree or ability to notate—these only shorten
    your journey towards being heard and understood. If you don’t have any experience
    in this area, it might be good to start by just developing an intuition around
    what an LLM is and needs by going and contributing to a project like OpenAssistant.
    If you’re a human, that’s exactly what they need. By volunteering, you can start
    understanding exactly what these models train on and why. If you fall anywhere
    from no knowledge up to being a professional machine learning engineer, we’ll
    be imparting the knowledge necessary to shorten your conversations along with
    your time to understanding considerably. If you’re not interested in learning
    the theoretical underpinnings of the subject, we’ve got plenty of hands-on examples
    and projects to get your hands dirty.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: We’ve all heard a story by now of LLM hallucinations, but LLMs don’t need to
    be erratic. Companies like Lakera are working daily to improve security, while
    others like LangChain are making it easier to provide models with pragmatic context
    which makes them more consistent and less likely to deviate. Techniques such as
    RLHF and Chain of Thought further allow our models to align themselves with negotiations
    we’ve already accepted as people and models should understand from the get-go,
    such as basic addition or the current date, both of which are conceptually arbitrary.
    We’ll help you increase your model stability from a linguistic perspective, so
    they’ll figure out not just what are the most likely outputs, but the most useful.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'Something to consider as you venture further down this path is not just the
    security of what goes into your model/code, but what comes out. LLMs can sometimes
    produce outdated, factually incorrect, or even copyrighted or licensed material,
    depending on what its training data contained. LLMs are unaware of any agreements
    people make about what is supposed to be a trade secret and what can be shared
    openly. That is, unless you tell it about those agreements during training or
    through careful prompting mechanisms during inference. Indeed, the challenges
    around prompt injection giving inaccurate information primarily arise due to two
    factors: firstly, users requesting information beyond the model''s understanding;
    and secondly, the model developers not fully predicting how users will interact
    with the models or the nature of their inquiries. If you had a resource that could
    help you get a head start on that second problem, it would be pretty close to
    invaluable, wouldn’t it?'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we don’t want to artificially or untruthfully inflate your sense of
    hope with LLMs. They are resource intensive to train and run. They are hard to
    understand, and they are harder to get working how you want. They are new and
    not well-understood. The good news is that these problems are being actively worked
    on, and we’ve put in a lot of work finding implementations that are concurrent
    with writing and actively lessen the burden on you to know everything about the
    entire deep learning architecture. From quantization to Kubernetes, we’ll help
    you figure out everything you need to know to do this now with what you have.
    Maybe we’ll inadvertently convince you that it’s too much, and you should just
    purchase from a vendor. Either way, we’ll help you every step of the way to help
    you get the results you need from this magical technology.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 1.4 Summary
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are exciting because they work with humans instead of against them
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Society has been built on language, so effective language models have limitless
    applications such as chatbots, programming assistants, video games, and AI assistants.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are excellent at many tasks and can even pass high-ranking medical and
    law exams
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are wrecking balls not hammers, and should be avoided for simple problems,
    problems that require low latency, and problems with high risks.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reasons to buy include:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly get up and running to conduct research and prototype use cases
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy access to highly optimized production models
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to vendors technical support and system
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reasons to build include:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting a competitive edge for your business use case
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping costs low and transparent
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring reliability of the model
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping your data safe
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling model output on sensitive or private topics
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no technical moat that is preventing you from competing with larger
    companies since open source frameworks and models provide the building blocks
    to pave your own path.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[[1]](#_ftnref1) Med-PaLM 2 has scored an 86.5% on the MedQA exam.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[[2]](#_ftnref2) WIRED, “It began as an AI-fueled dungeon game. Then it got
    much darker,” Ars Technica, May 08, 2021\. [https://arstechnica.com/gaming/2021/05/it-began-as-an-ai-fueled-dungeon-game-then-it-got-much-darker/](it-began-as-an-ai-fueled-dungeon-game-then-it-got-much-darker.html)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[[3]](#_ftnref3) M*A*S*H reference for those wondering: [https://youtu.be/UcaWQZlPXgQ](youtu.be.html)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[[4]](#_ftnref4) 이코노미스트, “[단독] 우려가 현실로…삼성전자, 챗GPT 빗장 풀자마자 ‘오남용’ 속출,” 이코노미스트,
    Mar. 30, 2023\. [https://economist.co.kr/article/view/ecn202303300057?s=31](view.html)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[[5]](#_ftnref5) A. Lowrey, “Borders bankruptcy: Done in by its own stupidity,
    not the Internet.,” Slate Magazine, Jul. 20, 2011\. [https://slate.com/business/2011/07/borders-bankruptcy-done-in-by-its-own-stupidity-not-the-internet.html](07.html)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[[6]](#_ftnref6) J. Best, “IBM Watson: The inside story of how the Jeopardy-winning
    supercomputer was born, and what it wants to do next,” TechRepublic, Sep. 09,
    2013\. [https://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/](ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next.html)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[[7]](#_ftnref7) “A conversation with OpenAI CEO Sam Altman | Hosted by Elevate,”
    May 18, 2023 [https://youtu.be/uRIWgbvouEw](youtu.be.html).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
