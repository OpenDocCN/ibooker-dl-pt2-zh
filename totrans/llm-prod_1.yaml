- en: '1 Word’s Awakening: Why Large Language Models Have Captured Attention'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What Large Language Models are and what they can and cannot do
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you should deploy your own Large Language Models and when should not
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large Language Model myths and the truths that lie behind them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"Any sufficiently advanced technology is indistinguishable from magic."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Arthur C. Clarke'
  prefs: []
  type: TYPE_NORMAL
- en: The year is 1450\. A sleepy corner of Mainz, Germany, unknowingly stands on
    the precipice of a monumental era. In Humbrechthof, a nondescript workshop shrouded
    in the town's shadows pulsates with anticipation. It is here that Johannes Gutenberg,
    a goldsmith and innovator, sweats and labors amidst the scents of oil, metal,
    and determination, silently birthing a revolution. In the late hours of the night,
    the peace is broken intermittently by the rhythmic hammering of metal on metal.
    In the lamp-lit heart of the workshop stands Gutenberg's decade-long labor of
    love—a contraption unparalleled in design and purpose.
  prefs: []
  type: TYPE_NORMAL
- en: This is no ordinary invention. Craftsmanship and creativity transform an assortment
    of moveable metal types, individually-cast characters born painstakingly into
    a matrix. The flickering light dances off the metallic insignias. The air pulsates
    with the anticipation of a breakthrough and the heady sweetness of oil-based ink,
    an innovation from Gutenberg himself. In the stillness of the moment, the master
    printer squares his shoulders and with unparalleled finesse, lays down a crisp
    sheet of parchment beneath the ink-loaded matrix and allows his invention to press
    firmly and stamp finely print onto the page. The room adjusts to the symphony
    of silence, bated breaths hanging heavily in the air. As the press is lifted,
    it creaks under its own weight, each screech akin to a war cry announcing an exciting
    new world.
  prefs: []
  type: TYPE_NORMAL
- en: With a flurry of motion, Gutenberg pulls from the press the first printed page
    and slams it flat onto the wooden table carefully examining each character which
    are as bold and magnificent as the creator's vision. The room drinks in the sight,
    absolutely spellbound. A mere sheet of parchment has become a testament of transformation.
    As the night gives way to day, he looks upon his workshop with invigorated pride.
    His legacy is born, echoing in the annals of history and forever changing the
    way information would take wings. Johannes Gutenberg, now the man of the millennium,
    emerges from the shadows, an inventor who dared to dream. His name synonymous
    with the Printing Press which is not just a groundbreaking invention, but the
    catalyst of a modern world.
  prefs: []
  type: TYPE_NORMAL
- en: As news of Gutenberg's achievement begins to flutter across the continent, scholars
    from vast disciplines are yet to appreciate the extraordinary tool at their disposal.
    Knowledge and learning, once coveted treasures, are now within the reach of the
    common man. There were varied and mixed opinions surrounding that newfound access.
  prefs: []
  type: TYPE_NORMAL
- en: “In our time, thanks to the talent and industry of those from the Rhine, books
    have emerged in lavish numbers. A book that once would’ve belonged only to the
    rich - nay, to a king - can now be seen under a modest roof. […] There is nothing
    nowadays that our children […] fail to know.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Sebastian Brant'
  prefs: []
  type: TYPE_NORMAL
- en: “Scholarly effort is in decline everywhere as never before. Indeed, cleverness
    is shunned at home and abroad. What does reading offer to pupils except tears?
    It is rare, worthless when it is offered for sale, and devoid of wit.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Egbert of Liege'
  prefs: []
  type: TYPE_NORMAL
- en: 'People have had various opinions on books throughout history. One thing we
    can agree on, living in a time when virtual printing presses exist and books are
    ubiquitous: the printing press changed history. While we weren’t actually there
    when Gutenberg printed the first page using his printing press, we have watched
    many play with large language models (LLMs) for the first time. The astonishment
    on their face as they see it respond to their first prompt. The excitement they
    have when challenging it with a difficult question only to see it respond as if
    it was an expert in the field. The light bulb moment when they realize they can
    use this to simplify their life or make themselves wealthy. I imagine this wave
    of emotions were, but a fraction of those felt by Johannes Gutenberg. Being able
    to rapidly generate text and accelerate communication has always been valuable.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Large Language Models accelerating communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every job has some level of communication. Oftentimes this communication is
    drudgery, bureaucratic, and political. I’ve often warned students and mentees
    that every job has its paperwork. Something that used to be a passion can easily
    be killed by the day to day tedium and menial work that comes with it when it
    becomes a job. In fact, when we talk about our professions we often talk them
    up, trying to improve our social standing, so you’ll rarely get the full truth.
    You won’t hear about the boring parts and the day-to-day grind gets conveniently
    forgotten.
  prefs: []
  type: TYPE_NORMAL
- en: However, envision a world where we reduce the burden of monotonous work. A place
    where police officers no longer have to waste hours of each day filling out reports
    and could instead devote that time to community outreach programs. Or a world
    where teachers, no longer slaving late into the night grading homework and preparing
    lesson plans, instead being able to think about and prepare customized lessons
    for individual students. Or even a world where lawyers would no longer be stuck
    combing through legal documents for days, instead being free to take on charity
    cases for causes that inspire them? When the communication burden, the paperwork
    burden and the accounting burden, are taken away, the job becomes more akin to
    what we sell it as.
  prefs: []
  type: TYPE_NORMAL
- en: For this, LLMs are the most promising technology to come along since, well,
    the printing press. For starters, they have completely upended the role and relationship
    between humans and computers, transforming what we believed they were capable
    of. They have already passed medical exams[[1]](#_ftn1), the bar exam, and multiple
    theory of mind tests. They’ve passed both Google and Amazon coding interviews.
    They’ve gotten scores of at least 1410 out of 1600 on the SAT. One of the most
    impressive to the authors is that GPT-4 has even passed the Advanced Sommelier
    exam–which makes us wonder how they got past the practical wine tasting portion.
    Indeed, their unprecedented accomplishments are coming at breakneck speed and
    often make us mere mortals feeling a bit queasy and uneasy. What do you do with
    a technology that seems to be able to do anything?
  prefs: []
  type: TYPE_NORMAL
- en: Passing tests is fun and all, but not exactly all that helpful unless our aim
    was to build the most expensive cheating machine ever, which we promise there’s
    better use of our time. What LLMs are good at is language, particularly, helping
    us improve and automate communication. This allows us to transform common bitter
    experiences into easy enjoyable experiences. For starters, imagine entering your
    home where you have your very own personal JARVIS, as if stepping into the shoes
    of Iron Man, an AI-powered assistant that adds an unparalleled dynamic to your
    routine. While not quite to the same artificial general intelligence (AGI) levels
    as those portrayed by JARVIS in the Marvel movies, LLMs are powering new user
    experiences from improving customer support to helping you shop for a loved one’s
    birthday. It knows to ask you about the person, learn about their interests and
    who they are, find out your budget, and then make specialized recommendations.
    While many of these assistants are being put to good work, many others are simply
    just chatbots that users can talk to and entertain themselves—which is important
    because even our imaginary friends are too busy these days. Jokes aside, these
    can create amazing experiences allowing you to meet your favorite fictional characters
    like Harry Potter, Sherlock Holmes, Anakin Skywalker or even Iron Man.
  prefs: []
  type: TYPE_NORMAL
- en: What we’re sure many readers are interested in though is programming assistants,
    because we all know Googling everything is actually one of the worst user experiences.
    Being able to write a few objectives in plain English and see a copilot write
    the code for you is exhilarating. I’ve personally used these tools to help me
    remember syntax, simplify and clean code, write tests, and learn a new programming
    language.
  prefs: []
  type: TYPE_NORMAL
- en: Video Gaming is another interesting field where we can expect LLMs to create
    a lot of innovation. Not only do they help the programmers create the game, but
    they are allowing designers to create more immersive experiences. For example,
    talking to NPC’s will have more depth and intriguing dialogue. Picture games like
    Animal Crossing or Stardew Valley having near infinite quests and conversations.
  prefs: []
  type: TYPE_NORMAL
- en: Consider other industries, like Education where there just doesn’t seem to be
    enough teachers to go around meaning our kids aren’t getting the one on one attention
    they need. An LLM assistant can help save the teacher time doing manual chores
    as well as serve as a private tutor for the kids that are struggling. Corporate
    is looking into LLMs for talk-to-your-data jobs, tasks helping employees understand
    quarterly reports and data tables, essentially giving everyone their own personal
    analyst. Sales and Marketing divisions are guaranteed to take advantage of this
    marvelous innovation, for better or worse. The state of Search Engine Optimization
    (SEO) will change a lot too since currently it is mostly a game of generating
    content to hopefully make websites more popular, which is now super easy.
  prefs: []
  type: TYPE_NORMAL
- en: That list is just a few of the common examples I’ve seen where companies are
    interested in using them. People are using them for personal reasons too. Writing
    music, poetry, and even books, translating languages, summarizing legal documents
    or emails, and even using them for free therapy—which yes, is an awful idea since
    they are still dreadful at this. Just a personal preference, but we wouldn’t try
    to save a buck when our sanity is on the line. Of course, this leads us to the
    fact that people are already using them for darker purposes like cheating, scams,
    and fake news to skew elections. At this point, the list has become rather large
    and varied, but we’ve only begun to scratch the surface of the possible. Really,
    since LLMs help us with communication often, it’s better to think, “What can’t
    they do?” than “What can they do?”.
  prefs: []
  type: TYPE_NORMAL
- en: Or better yet, “What shouldn’t they do?” Well, as a technology there are certain
    restrictions and constraints, for example, LLMs are kind of slow. Of course, slow
    is a relative term, but responsive times are often measured in seconds not milliseconds.
    We’ll dive deeper into this in Chapter 3, but as an example, we probably won’t
    see them being used in autocomplete tasks anytime soon which require blazingly
    fast inference in order to be useful. After all, autocomplete needs to be able
    to predict the word or phrase faster than someone types. In a similar fashion,
    LLMs are large complex systems, we don’t need them for such a simple problem anyway.
    Hitting an autocomplete problem with an LLM isn’t just hitting the nail with a
    sledgehammer, it’s hitting it with a full on wrecking ball. And just like it’s
    more expensive to rent a wrecking ball than buy a hammer, an LLM will cost you
    more to operate. There are a lot of similar tasks where we should consider the
    complexity of the problem we are trying to solve.
  prefs: []
  type: TYPE_NORMAL
- en: There are also many complex problems that are often poorly solved with LLMs
    such as predicting the future. No, we don’t mean with mystic arts, but forecasting
    problems, acts like predicting the weather or when high tide will hit on the ocean
    shore. These are actually problems we’ve solved, but we don’t necessarily have
    good ways to communicate how these have been solved. They are expressed through
    combinations of math solutions like Fourier transforms and harmonic analysis or
    through black box ML models. There are many problems that fit into this category,
    like outlier prediction, calculus, or finding the end of the roll of tape.
  prefs: []
  type: TYPE_NORMAL
- en: You also probably want to avoid using them for highly risky projects. LLMs aren’t
    infallible and make mistakes often. To increase creativity we often allow for
    a bit of randomness in LLMs which means you can ask an LLM the same question and
    get different answers. That’s risky. You can remove this randomness by doing what’s
    called turning down the temperature, but that might make it useless depending
    on your needs. For example, you might decide to use an LLM to categorize investment
    options as good or bad, but do you want it to then make actual investment decisions
    based on its output? Not without oversight, unless your goal is to create a meme
    video.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately an LLM is just a model, it can’t be held accountable for losing your
    money, and really it didn’t lose your money you did by choosing to use it. Similar
    risky problems could include filling out tax forms or getting medical advice.
    While an LLM could do these things, it won’t protect you from heavy penalties
    in an IRS audit like hiring a certified CPA would. If you take bad medical advice
    from an LLM, there’s no doctor you could sue for malpractice. However, in all
    of these examples, the LLM could potentially largely help the practitioner better
    perform their job roles both reducing errors and improving speed.
  prefs: []
  type: TYPE_NORMAL
- en: When to use an LLM
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Use them for:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question and answering services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatBots and AI assistants
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffusion (txt2img, txt23d, txt2vid, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Talk-to-your-data applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything that involves communication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Avoid using them for:'
  prefs: []
  type: TYPE_NORMAL
- en: Latency-sensitive workloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems we don’t solve with words but with math or algorithm - forecasting,
    outlier prediction, calculus, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Critical evaluations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-risk projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language is not just a medium people use to communicate. It is the tool that
    made humans apex predators and gives every individual self-definition to their
    community. Every aspect of human existence, from arguing with your parents to
    graduating from college to reading this book is pervaded by our language. Language
    models are learning to harness one of the fundamental aspects of being human and
    have the ability, when used responsibly, to help us with each and every one of
    those tasks. They have the potential to unlock dimensions of understanding both
    of ourselves and others if we responsibly teach them how.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have captured the world’s attention since their potential allows imaginations
    to run wild. LLMs promise so much, but… where are all these solutions? Where are
    the video games that give us immersive experiences? Why don’t our kids have personal
    AI tutors yet? Why am I not Iron Man with my own personal assistant yet? These
    are the deep and profound questions that motivated us to write this book. Particularly
    that last one, it keeps me up at night. So while LLMs can do amazing things, not
    enough people know how to actually turn them into a product and that’s what we
    aim to share in this book.
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/01__image001.png)'
  prefs: []
  type: TYPE_IMG
- en: This isn’t just a Machine Learning Operations book. There are a lot of gotchas
    and pitfalls involved with making an LLM work in production because LLMs just
    don’t work like traditional software solutions. To turn an LLM into a product
    that can interact coherently with your users will require an entire team and diverse
    set of skills. Depending on your use case you may need to train or finetune and
    then deploy your own model, or you may just need to access one from a vendor through
    an API.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of which LLM you use, if you want to take full advantage of the technology
    and build the best user experience, you will need to understand how they work.
    Not just on the math/tech side either, but on the soft side for how to make it
    a good experience for your users. In this book we’ll be covering everything you
    need to make LLMs work in production. We’ll talk about the best tools and infrastructure,
    how to maximize their utility with prompt engineering and other best practices
    like controlling costs. LLMs could be one step towards a greater equality, so
    if you are thinking, “I don’t feel like the person this book is for,” please reconsider.
    This book is for the whole team and anyone who will be interacting with LLMs in
    the future.
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to hit on a practical level everything that you’ll need for collecting
    and creating a dataset, training or finetuning an LLM on consumer or industrial
    hardware, and deploying that model in various ways for customers to interact with.
    While we aren’t going to cover too much theory, we will be covering the process
    from end to end with real-world examples. At the end of this book you will know
    how to deploy LLMs with some viable experience to back it up.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Navigating between the Build and Buy decision with Large Language Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you bought this book, you are likely already convinced of the overwhelming
    potential LLMs can have in your life and in your organization. Buying this book
    then is the first step to turning your dreams into a reality, because none of
    it is possible until we know how to put these models into production. After all,
    if you talk to any entrepreneur or investor out there they will tell you good
    ideas are a dime a dozen, what matters is execution and actually manifesting those
    ideas. What we need to do is get these models into production, where they are
    readily available to do actual work for you.
  prefs: []
  type: TYPE_NORMAL
- en: There’s no getting around it and no need to sugar coat it either, deploying
    LLMs into production is hard. Often anything worth pursuing is. In this book we
    aim to teach you everything you need to know to do it as well as give you some
    practical hands-on experience. But because it is so hard, it is mighty tempting
    to take a shortcut. Large corporations like OpenAI and Google have some great
    offerings of models to choose from, why not just buy them? Let’s start by considering
    what they offer and if this may be a good choice, and then we’ll take a look at
    the other side of the coin where these offerings tend to fall flat.
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.1 Buying: the beaten path'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many great reasons to simply just buy access to an LLM. First and
    foremost is the speed and flexibility accessing an API provides. Working with
    an API is an incredibly easy and cheap way to build a prototype and get your hands
    dirty quickly. In fact, so easy you can see in listing 1.1 that it only takes
    a few lines of code to start connecting to OpenAI’s API and start using LLMs.
    Sure, there’s a lot that’s possible, but it would be a bad idea to heavily invest
    in LLMs only to find out they happen to fail in your specific domain. Working
    with an API allows you to fail fast. Building a prototype application to prove
    the concept and launching it with an API is a great place to get started.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.1 A simple app calling OpenAI’s API
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Oftentimes, buying access to a model can give you a competitive edge. In many
    cases it could very well be that the best model on the market is built by a company
    specializing in the domain who are using specialized datasets they have spent
    a fortune to curate. While you could try to compete and build your own, it may
    better serve your purposes to simply buy access to their model instead. Ultimately,
    whoever has the better domain specific data to finetune on is likely going to
    win, and that might not be you if this is a side project for your company. Curating
    data can be expensive after all. It can save you a lot of work to go ahead and
    buy it.
  prefs: []
  type: TYPE_NORMAL
- en: Which leads to the next point, buying is a quick way to access expertise and
    support. For example, OpenAI has spent a lot of time making their models safe
    with plenty of filtering and controls to prevent the misuse of their LLMs. They’ve
    already encountered and covered a lot of the edge cases, so you don’t have to.
    Buying access to their model also gives you access to the system they’ve built
    around it.
  prefs: []
  type: TYPE_NORMAL
- en: Not to mention, the LLM itself is only half the problem in deploying them to
    production. There’s still an entire application you need to build on top of it.
    Sometimes buying OpenAI’s model has thrived over its competitors in not a small
    part due to their UX and some tricks like making the tokens look like they’re
    being typed. We’ll take you through how you can start solving for the UX in your
    use case, along with some ways you can prototype to give you a major head start
    in this area.
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.2 Building: the path less traveled'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using an API is easy, and in most cases, likely the best choice. However, there
    are many reasons why you should aim to own this technology and learn how to deploy
    it yourself instead. While this path might be harder, we’ll teach you how to do
    it. Let''s dive into several of those reasons starting with the most obvious:
    Control.'
  prefs: []
  type: TYPE_NORMAL
- en: Control
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the first companies to truly adopt LLMs as a core technology is a small
    video game company called Latitude. Latitude specializes in Dungeon and Dragons
    like role playing games utilizing LLM chatbots, and they have faced challenges
    when working with them. This shouldn’t come off as criticizing this company for
    their missteps, as they contributed to our collective learning experience and
    were pioneers forging a new path. Nonetheless, their story is a captivating and
    intriguing one, like a train wreck that we personally couldn't help but keep watching.
  prefs: []
  type: TYPE_NORMAL
- en: Latitude's first release was a game called AI Dungeon. At inception, it utilized
    OpenAI’s GPT2 to create an interactive and dynamic storytelling experience. It
    quickly garnered a large gathering of players, who of course started to use it
    inappropriately. When OpenAI gave Latitude access to GPT3 it promised an upgrade
    to the gaming experience, instead, what it got was a nightmare.[[2]](#_ftn2)
  prefs: []
  type: TYPE_NORMAL
- en: You see, with GPT3 they added Reinforcement Learning from Human Feedback (RLHF)
    which greatly helps improve functionality, but this also meant OpenAI contractors
    were now looking at the prompts. That’s the human feedback part. And these workers
    weren’t too thrilled to read the filth the game was creating. OpenAI's reps were
    quick to give Latitude an ultimatum. Either they needed to start censoring the
    players or they’d remove their access to the model—which would have essentially
    killed the game and the company. With no other option they quickly added some
    filters but the filtering system was too much a band-aid, a buggy and glitchy
    mess. Players were upset at how bad the system was and unnerved to realize Latitude’s
    developers were reading their stories, completely oblivious to the fact that OpenAI
    was already doing such. It was a PR nightmare. And it wasn’t over.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI decided the game studio wasn’t doing enough, stonewalled, they were
    forced to increase their safeguards, and so they started banning players. Here’s
    the twist, the reason so many of these stories turned to smut, was because the
    model had a preference for erotica. It would often unexpectedly transform harmless
    storylines into inappropriately risqué situations causing the player to be ejected
    and barred from the game. OpenAI was acting the paragon of purity, but it was
    their model that was the problem. Which led to one of the most ironic and unjust
    problems in gaming history: players were getting banned for what the game did.'
  prefs: []
  type: TYPE_NORMAL
- en: So there they were, a young game studio just trying to make a fun game stuck
    between upset customers and a tech giant that pushed all the blame and responsibility
    onto them. If the company had more control over the technology they could have
    gone after a real solution, like fixing the model. Instead of having to throw
    makeup on a pig.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, control may come off as your ability to finetune your mode
    and OpenAI now offers finetuning capabilities, but there are many fine-grained
    decisions that are still lost by using a service instead of rolling your own solution.
    For example, what training methodologies are used, what regions the model is deployed
    too, or what infrastructure it runs on. Control is also important for any customer
    or internal-facing tool. You don’t want to have a code generator accidentally
    output code that’s copyrighted or that creates a legal situation for your company.
    You also don’t want your customer-facing LLM to output factually incorrect information
    about your company or its processes.
  prefs: []
  type: TYPE_NORMAL
- en: Control is your ability to direct and manage the operations, processes, and
    resources in a way that aligns with your goals, objectives, and values. If a model
    ends up becoming central to your product offering and the vendor unexpectedly
    raises their prices there’s little you can do but pay it. If the vendor decides
    their model should give more liberal or conservative answers that no longer align
    with your values, you are just as stuck.
  prefs: []
  type: TYPE_NORMAL
- en: The more central a technology is to your business plan, the more important it
    is to control it. This is why McDonald's owns the real estate for its franchises
    and why Google, Microsoft, and Amazon all own their own cloud networks. Or even
    why so many entrepreneurs build online stores through Shopify versus just using
    other platforms like Etsy or Amazon Marketplace. Ultimately control is the first
    thing that’s lost when you buy someone else’s product. Keeping it will give you
    more options to solve future problems and will also give you a competitive edge.
  prefs: []
  type: TYPE_NORMAL
- en: Competitive edge
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the most valuable aspects of deploying your own models is the competitive
    edge it gives you over your competition. Customization - train the model to be
    the best at one thing. For example, after the release of Bidirectional Encoder
    Representations from Transformers (BERT) in 2017, which is a transformer model
    architecture you could use to train your own model, there was a surge of researchers
    and businesses testing this newfound technology on their own data to worldwide
    success. At the time of writing, if you search the Hugging Face Hub for “BERT,”
    there are more than 13.7k models returned, all that people trained individually
    for their own purposes to be the best model for their task.
  prefs: []
  type: TYPE_NORMAL
- en: One of my personal experiences in this area was training SlovenBERTcina. After
    aggregating the largest (at-the-time) monolingual Slovak language dataset by scraping
    the Slovak National Corpus with permission, along with a whole bunch of other
    resources like the OSCAR project and the Europarl corpus. It never set any computational
    records, and has never appeared in any model reviews or generated partnerships
    for the company I worked for. It did, however, outperform every other model on
    the market on the tasks it trained on.
  prefs: []
  type: TYPE_NORMAL
- en: Chances are, neither you nor your company need AGI to generate relevant insights
    from your data, and in fact if you invented an actual self-aware AGI and planned
    to only ever use it to crunch some numbers, analyze data and generate visuals
    for PowerPoint slides once a week, that would definitely be reason enough for
    the AGI to eradicate humans. More than likely, you need exactly what I did when
    I made SlovenBERTcina, a large language model that performs the two to three tasks
    you need better than any other model on the market and doesn’t also share your
    data with Microsoft or other potential competitors. While some data is required
    to keep secret for security or legal reasons, a lot of data should be guarded
    simply because they are trade secrets.
  prefs: []
  type: TYPE_NORMAL
- en: There are hundreds of open source LLMs both for general intelligence, and for
    foundational expertise on a specific task. We’ll hit some of our favorites in
    Chapter 4\. Taking one of these open source alternatives and training it on your
    data to create a model that is the best in the world at that task will ensure
    you have a competitive edge in your market. It will also allow you to deploy the
    model your way and integrate it into your system to make the most impact.
  prefs: []
  type: TYPE_NORMAL
- en: Integrate anywhere
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s say you want to deploy an LLM as part of a choose your own adventure style
    game that uses a device’s GPS location to determine story plots. You know your
    users are often going to go on adventures into the mountains, out at sea, and
    generally to locations where they are likely to experience poor service and lack
    of internet access. Hitting an API just isn’t going to work. Now, don’t get me
    wrong, deploying LLMs onto edge devices like in this scenario is still an exploratory
    subject, but it is possible, and we will be showing you how in chapter 9\. Relying
    upon an API service is just not going to work for immersive experiences.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, using third party LLM and hitting an API adds integration and latency
    issues, requiring you to send data over the wire and wait for a response. APIs
    are great, but they are always slow and not always reliable. When latency is important
    to a project it’s much better to serve the service in-house. The previous section
    on Competitive Edge discussed two projects with edge computing as a priority,
    however many more exist. LLAMA.cpp and ALPACA.cpp are two of the first of such
    projects, and this space is innovating quicker than any others. Quantization into
    4-bit, Low-Rank Adaptation, and Parameter Efficient Finetuning are all methodologies
    recently created just to meet these needs, and we’ll be going over each of these
    starting in Chapter 3.
  prefs: []
  type: TYPE_NORMAL
- en: When my team first started integrating with ChatGPT’s API, it was both an awe-inspiring
    and humbling experience. Awe-inspiring because it allowed us to quickly build
    some valuable tools. Humbling because as one engineer joked to me, “When you hit
    the end point you will get 503 errors, sometimes you get a text response as if
    the model was generating text, but I think that’s a bug.” Serving an LLM in a
    production environment, trying to meet the needs of so many clients, is no easy
    feat. However, deploying a model that’s integrated into your system allows you
    more control of the process affording higher availability and maintainability
    than you can currently find on the market.
  prefs: []
  type: TYPE_NORMAL
- en: Costs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Considering costs is always important because it plays a pivotal role in making
    informed decisions and ensuring the financial health of a project or an organization.
    It helps you manage budgets efficiently and make sure that resources are allocated
    appropriately. Keeping costs under control allows you to maintain the viability
    and sustainability of your endeavors in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, considering costs is crucial for risk management. When you understand
    the different cost aspects, you can identify potential risks and exert better
    control over them. This way, you can avoid unnecessary expenditures and ensure
    that your projects are more resilient to unexpected changes in the market or industry.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, cost considerations are important for maintaining transparency and
    accountability. By monitoring and disclosing costs, organizations demonstrate
    their commitment to ethical and efficient operations to stakeholders, clients,
    and employees. This transparency can improve an organization's reputation and
    help build trust.
  prefs: []
  type: TYPE_NORMAL
- en: All of these apply as you consider building versus buying LLMs. It may seem
    immediately less costly to buy, as the most costly service widely used on the
    market currently is only $20 USD per month. Compared to an EC2 instance on AWS,
    just running that same model for inference (not even training) could run you up
    a bill for about $250k USD per year. This is where building has done its quickest
    innovation, however. If all you need is an LLM for a proof of concept, any of
    the projects mentioned in the Competitive Edge section will allow you to create
    a demo for only the cost of electricity to run on the computer you are demoing
    on, and spell out training easily enough to allow for significantly reduced costs
    to train a model on your own data, as low as $100 (yes, that’s the real number)
    for a model with 20 billion parameters. Another benefit is knowing that if you
    build your own, your cost will never go up, like it very much will when paying
    for a service.
  prefs: []
  type: TYPE_NORMAL
- en: Security and privacy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider the following case. You are a military staff member in charge of maintenance
    for the nuclear warheads in your arsenal. All the documentation is kept in a hefty
    manual. There’s so much information required to outline all the safety requirements
    and maintenance protocols cadets are known to forget important information despite
    their best efforts. They often cut the wires before first removing the fuse[[3]](#_ftn3).
    You decide to fine-tune an LLM model to be a personal assistant, giving directions
    and helping condense all that information giving soldiers exactly what they need
    when they need it. It’s probably not a good idea to upload those manuals to another
    company–understatement of the century–you're going to want to train something
    locally that’s kept secure and private.
  prefs: []
  type: TYPE_NORMAL
- en: This scenario may sound farfetched, but when speaking to an expert working in
    analytics for a police department they echoed this exact concern. Talking with
    them, they expressed how cool ChatGPT is even having their whole team take a prompt
    engineering class to better take advantage of it, but lamented that there was
    no way for his team to use it for their most valuable work–the sort of work that
    literally saves lives–without exposing sensitive data and conversations. Anyone
    in similar shoes should be eager to learn how to deploy a model safely and securely.
  prefs: []
  type: TYPE_NORMAL
- en: You don’t have to be in the army or police force to handle sensitive data. Every
    company has important intellectual property and trade secrets that are best to
    keep a secret. Having worked in the semiconductor, healthcare, and finance industries
    we can tell you first hand, paranoia and corporate espionage are part of the culture
    in these industries. Because of this Samsung and other industry players at first
    locked down ChatGPT preventing employees from using it, later opening it up. Of
    course, it didn’t take long before several Samsung employees leaked confidential
    source code[[4]](#_ftn4). Because OpenAI uses RLHF, that code is retained and
    used to further train the model later on. Meaning with the right prompt injection,
    anyone could potentially pull the code out of the model.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not just code that can easily be lost. Business plans, meeting notes, confidential
    emails and even potential patent ideas are at risk. We unfortunately know of a
    few companies who have started sending confidential data to ChatGPT, using that
    model to clean and extract PII. If this strikes you as potential negligent misuse,
    you’d be right. This methodology directly exposes customer data, not just to Microsoft/OpenAI,
    but to any and all 3rd-party services that they use (including AWS Mechanical
    Turk, Fiverr, and Freelance workers) to perform the Human Feedback part of RLHF.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As you can see, there are lots of reasons why a company might want to own and
    build their own LLMs including having greater control, cutting costs, and meeting
    security and regulation requirements. Despite this we understand that buying is
    easy, and building is much more difficult so for many projects it makes sense
    to just buy, but before you do in figure 1.1 we share a flowchart of questions
    you should ask yourself first. Even though it’s the more difficult path, building
    can be much more rewarding.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.1 Questions you should ask yourself before making that build vs buy
    decision.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](images/01__image002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'One last point we think these build versus buy conversations never seem to
    hone in on enough is, “Porque no los dos?” Buying gets you all the things building
    is bad at: time-to-market, relatively low cost, and ease-of use. Building gets
    you all the things buying struggles with: privacy, control, and flexibility. Research
    and prototyping phases could very much benefit from buying a subscription to GPT4
    or Databricks for building something quick to help raise funding or get stakeholder
    buy-in. Production however, often isn’t an environment that lends itself to third-party
    solutions well.'
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, whether or not you plan to build or buy we wrote this book for you.
    Obviously if you plan to build it, there’s going to be a lot more you need to
    know about, so a majority of this book will be geared to these folks. In fact,
    we don’t need to belabor the point anymore, we’re going to teach you how to build
    in this book, but don’t let that stop you from doing the right thing for your
    company.
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.3 A word of warning: embrace the future now'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: New technologies are like fire, they can provide warmth on cold nights and help
    cook our food, but they can also burn our homes and hurt us. In business, there’s
    no shortage of stories of companies failing because they failed to adapt to new
    technologies. We can learn a lot from their failures.
  prefs: []
  type: TYPE_NORMAL
- en: Borders Books first opened its doors in 1971\. After developing a comprehensive
    inventory management system that included advanced analytic capabilities it skyrocketed
    to become the second-largest Book retailer in the world, only behind Barnes &
    Noble. Using this new technology it disrupted the industry, allowing it to easily
    keep track of tens of thousands of books, opening large stores where patrons could
    peruse many more books than they could at smaller stores. The analytic capabilities
    helped it track which books were gaining popularity and gain better insights into
    their customers allowing it to make better business decisions. It dominated the
    industry for over two decades.
  prefs: []
  type: TYPE_NORMAL
- en: Borders however, failed to learn from its own history, going bankrupt in 2011,
    failing to adapt and being disrupted by technology this time; e-commerce. In 2001,
    instead of building their own platform and online store, they decided to outsource
    their online sales to Amazon.[[5]](#_ftn5) A decision many critics would say was
    akin to giving your competitors the key to your business. While not exactly handing
    over their secret sauce, it was a decision that gave up their competitive edge.
  prefs: []
  type: TYPE_NORMAL
- en: For the next seven years they turned a blind eye to the growing online sector
    instead focusing on expanding their physical store presence, buying out competitors
    and securing a coveted Starbucks deal. When Amazon released the Kindle in 2007,
    the book retail landscape completely changed. Barnes & Noble having run their
    own online store quickly pivoted and released the Nook to compete, Borders however,
    did nothing, or in fact, could do nothing.
  prefs: []
  type: TYPE_NORMAL
- en: By embracing e-commerce through a third party, they failed to develop the in-house
    expertise required to create a successful online sales strategy, leading to a
    substantial loss in market share. They eventually launched their own e-reader,
    Kobo, in late 2010, but it was too late to catch up. Their inability to fully
    understand and implement e-commerce technology effectively led to massive financial
    losses, store closures, and ultimately, the company filed for bankruptcy in 2011.
  prefs: []
  type: TYPE_NORMAL
- en: Borders Books is a cautionary tale, but there are hundreds more of similar companies
    who failed to adopt new technology to their own detriment. With a new technology
    as impactful as LLMs each company has to decide on which side of the fence they
    want to be on. Do they delegate implementation and deployment to large FAANG like
    corporations relegating to just hitting an API, or do they take charge preferring
    to master the technology and deploy it themselves?
  prefs: []
  type: TYPE_NORMAL
- en: The biggest lesson we hope to impart from this story is that technologies build
    on top of one another. Ecommerce was built on top of the internet. Failing to
    build their own online store meant Borders failed to build the in-house technical
    expertise they needed to stay in the game when the landscape shifted. We see the
    same things with LLMs today because the companies that are best prepared to utilize
    them have already gathered expertise in machine learning and data science and
    have some idea of what they are doing.
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have a crystal ball that tells us the future, but many believe that
    LLMs are a revolutionary new technology like the internet or electricity before
    it. Learning how to deploy these models, or failing to do so, may very well be
    the defining moment for many companies. Not because doing so will make or break
    their company now, but in the future, when something even more valuable comes
    along that’s built on top of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Foraying into this new world of deploying LLMs may be challenging but will help
    your company build the technical expertise to stay on top of the game. No one
    really knows where this technology will lead, but learning about this technology
    will likely be necessary to avoid mistakes like Borders Books’.
  prefs: []
  type: TYPE_NORMAL
- en: There are many great reasons to buy your way to success, but there is at least
    one prevalent thought that is just absolutely wrong. It’s the myth that only large
    corporations can work in this field because it takes millions of dollars and thousands
    of GPUs to train these models. Creating this impenetrable moat of cash and resources
    the little guy can’t hope to cross. We’ll be talking about this more in the next
    section, but any company of any size can get started and there’s no better time
    than now to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Debunking myths
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have all heard from large corporations and the current leaders in LLMs how
    incredibly difficult it is to train an LLM from scratch and how intense it is
    to try to finetune them. Whether from OpenAI, BigScience, or Google they discuss
    large investments and the need for strong data and engineering talent. But how
    much of this is true and how much of it is just a corporate attempt to create
    a technical moat?
  prefs: []
  type: TYPE_NORMAL
- en: Most of these barriers start with the premise that you will need to train an
    LLM from scratch if you hope to solve your problems. Simply put, you don’t! Open
    source models covering many dimensions of language models are constantly being
    released, so you more-than-likely don’t need to start from scratch. While what
    they say is true that training LLMs from scratch is supremely difficult, we are
    still constantly learning about how to do it and are able to more and more automate
    the repeatable portions. In addition, since this is an active field of research
    frameworks and libraries are being released or updated daily and will help you
    start from wherever you currently are. Frameworks like oobabooga’s Gradio will
    help you run LLMs and base models like Falcon 40B will be your starting point.
    All of it is covered. To add to this, memos have circulated at large companies
    addressing the lack of a competitive edge that any organization currently holds
    over the open source community at large.
  prefs: []
  type: TYPE_NORMAL
- en: A friend once confided in me that, “I really want to get more involved in all
    this machine learning and data science stuff. It seems to be getting cooler every
    time I blink an eye. However, it feels like the only way to get involved is to
    go through a lengthy career change and go work for a FAANG. No, thank you. I’ve
    done my time at large companies, and they aren’t for me. But I hate feeling like
    I’m trapped on the outside.” This is the myth that inspired this book. We’re here
    to equip you with tools and examples to help you to stop feeling trapped on the
    outside. We’ll help you go through the language problems that we’re trying to
    solve with LLMs, along with machine learning operation strategies to account for
    the sheer size of the models.
  prefs: []
  type: TYPE_NORMAL
- en: Oddly enough, as many believe they are trapped on the outside, many others believe
    they can become experts in a weekend. Just get a GPT API key and that’s it, you’re
    done. This has led to a lot of fervor and hype with a cool new demo popping up
    on social media every day. But, most of these demos never become actual products
    and not because people don’t want them.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this, let’s discuss IBM’s Watson the world’s most advanced language
    model before GPT. Watson is a question and answering machine that went on to crush
    Jeopardy in 2011 against some of the best human contestants to ever appear on
    the show, Brad Rutter and Ken Jennings. Rutter the highest earning contestant
    ever to play the game show and Jennings a player so good he went on to win a whopping
    74 times in a row. Despite facing these legends, it wasn’t even close. Watson
    won in a landslide. Jennings in response to the loss responded with the famous
    quote, "I, for one, welcome our new computer overlords."[[6]](#_ftn6)
  prefs: []
  type: TYPE_NORMAL
- en: Watson was the first impressive foray into language modeling and many companies
    were clamoring to take advantage of its capabilities. Starting in 2013, Watson
    started being released for commercial use. One of the biggest applications involved
    many attempts trying to integrate it into healthcare to solve various problems.
    However, none of these solutions ever really worked the way they needed to and
    the business never became profitable. By 2022 Watson Health was sold off.
  prefs: []
  type: TYPE_NORMAL
- en: What we find when solving language related problems is that building a prototype
    is easy, building a functioning product on the other hand is very, *very* difficult.
    There are just too many nuances to language. Many people wonder what made ChatGPT
    so explosive? Gaining over a million clients in just five days. Most of the answers
    I’ve heard would never satisfy an expert because ChatGPT wasn’t much more impressive
    than GPT3 or other LLMs which had been around for several years already. I heard
    Sam Altman of OpenAI himself say in an interview they didn’t think ChatGPT would
    get this much attention, they thought that would come with GPT4’s release.[[7]](#_ftn7)
    So why was it explosive? The magic in our opinion, is that it was the first product
    to truly productionize LLMs. To turn it from a demo into an actual product. It
    was something anyone could interact with and ask it tough questions, only to be
    amazed by how well it responded. A demo only has to work once, but the product
    has to work every time and even when millions of users are showing it to their
    friends saying, “Check this out!” That magic is exactly what you can hope to learn
    from reading this book.
  prefs: []
  type: TYPE_NORMAL
- en: We’re excited about writing this book. We are excited about the possibilities
    of bringing this magic to you so you can bring it to the world. LLMs are at the
    intersection between so many fields such as linguistics, mathematics, computer
    science and more. While the more you know will help you, to be an expert isn’t
    required. Expertise in any of the individual parts only raises the skill ceiling,
    not the floor to get in. Consider an expert in physics or music theory, they won’t
    automatically have the skills for music production, but they will be more prepared
    to quickly learn. LLMs are a communication tool and communicating is a skill just
    about everyone needs.
  prefs: []
  type: TYPE_NORMAL
- en: Like all other skills, your proximity and willingness to get involved are the
    two main blockers to knowledge, not a degree or ability to notate—these only shorten
    your journey towards being heard and understood. If you don’t have any experience
    in this area, it might be good to start by just developing an intuition around
    what an LLM is and needs by going and contributing to a project like OpenAssistant.
    If you’re a human, that’s exactly what they need. By volunteering, you can start
    understanding exactly what these models train on and why. If you fall anywhere
    from no knowledge up to being a professional machine learning engineer, we’ll
    be imparting the knowledge necessary to shorten your conversations along with
    your time to understanding considerably. If you’re not interested in learning
    the theoretical underpinnings of the subject, we’ve got plenty of hands-on examples
    and projects to get your hands dirty.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve all heard a story by now of LLM hallucinations, but LLMs don’t need to
    be erratic. Companies like Lakera are working daily to improve security, while
    others like LangChain are making it easier to provide models with pragmatic context
    which makes them more consistent and less likely to deviate. Techniques such as
    RLHF and Chain of Thought further allow our models to align themselves with negotiations
    we’ve already accepted as people and models should understand from the get-go,
    such as basic addition or the current date, both of which are conceptually arbitrary.
    We’ll help you increase your model stability from a linguistic perspective, so
    they’ll figure out not just what are the most likely outputs, but the most useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Something to consider as you venture further down this path is not just the
    security of what goes into your model/code, but what comes out. LLMs can sometimes
    produce outdated, factually incorrect, or even copyrighted or licensed material,
    depending on what its training data contained. LLMs are unaware of any agreements
    people make about what is supposed to be a trade secret and what can be shared
    openly. That is, unless you tell it about those agreements during training or
    through careful prompting mechanisms during inference. Indeed, the challenges
    around prompt injection giving inaccurate information primarily arise due to two
    factors: firstly, users requesting information beyond the model''s understanding;
    and secondly, the model developers not fully predicting how users will interact
    with the models or the nature of their inquiries. If you had a resource that could
    help you get a head start on that second problem, it would be pretty close to
    invaluable, wouldn’t it?'
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we don’t want to artificially or untruthfully inflate your sense of
    hope with LLMs. They are resource intensive to train and run. They are hard to
    understand, and they are harder to get working how you want. They are new and
    not well-understood. The good news is that these problems are being actively worked
    on, and we’ve put in a lot of work finding implementations that are concurrent
    with writing and actively lessen the burden on you to know everything about the
    entire deep learning architecture. From quantization to Kubernetes, we’ll help
    you figure out everything you need to know to do this now with what you have.
    Maybe we’ll inadvertently convince you that it’s too much, and you should just
    purchase from a vendor. Either way, we’ll help you every step of the way to help
    you get the results you need from this magical technology.
  prefs: []
  type: TYPE_NORMAL
- en: 1.4 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are exciting because they work with humans instead of against them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Society has been built on language, so effective language models have limitless
    applications such as chatbots, programming assistants, video games, and AI assistants.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are excellent at many tasks and can even pass high-ranking medical and
    law exams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are wrecking balls not hammers, and should be avoided for simple problems,
    problems that require low latency, and problems with high risks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reasons to buy include:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly get up and running to conduct research and prototype use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy access to highly optimized production models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to vendors technical support and system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reasons to build include:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting a competitive edge for your business use case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping costs low and transparent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring reliability of the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping your data safe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling model output on sensitive or private topics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no technical moat that is preventing you from competing with larger
    companies since open source frameworks and models provide the building blocks
    to pave your own path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[[1]](#_ftnref1) Med-PaLM 2 has scored an 86.5% on the MedQA exam.'
  prefs: []
  type: TYPE_NORMAL
- en: '[[2]](#_ftnref2) WIRED, “It began as an AI-fueled dungeon game. Then it got
    much darker,” Ars Technica, May 08, 2021\. [https://arstechnica.com/gaming/2021/05/it-began-as-an-ai-fueled-dungeon-game-then-it-got-much-darker/](it-began-as-an-ai-fueled-dungeon-game-then-it-got-much-darker.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[[3]](#_ftnref3) M*A*S*H reference for those wondering: [https://youtu.be/UcaWQZlPXgQ](youtu.be.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[[4]](#_ftnref4) 이코노미스트, “[단독] 우려가 현실로…삼성전자, 챗GPT 빗장 풀자마자 ‘오남용’ 속출,” 이코노미스트,
    Mar. 30, 2023\. [https://economist.co.kr/article/view/ecn202303300057?s=31](view.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[[5]](#_ftnref5) A. Lowrey, “Borders bankruptcy: Done in by its own stupidity,
    not the Internet.,” Slate Magazine, Jul. 20, 2011\. [https://slate.com/business/2011/07/borders-bankruptcy-done-in-by-its-own-stupidity-not-the-internet.html](07.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[[6]](#_ftnref6) J. Best, “IBM Watson: The inside story of how the Jeopardy-winning
    supercomputer was born, and what it wants to do next,” TechRepublic, Sep. 09,
    2013\. [https://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/](ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[[7]](#_ftnref7) “A conversation with OpenAI CEO Sam Altman | Hosted by Elevate,”
    May 18, 2023 [https://youtu.be/uRIWgbvouEw](youtu.be.html).'
  prefs: []
  type: TYPE_NORMAL
