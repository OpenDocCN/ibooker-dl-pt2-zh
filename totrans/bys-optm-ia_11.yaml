- en: 8 Satisfying extra constraints with constrained optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: The problem of black box optimization with constraints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking constraints into account when making decisions in BayesOpt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing constraint-aware BayesOpt policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In previous chapters, we tackled black box optimization problems in which we
    aimed solely to maximize the objective function, without any other considerations.
    This is called an *unconstrained* optimization problem as we are free to explore
    the search space to look for the global optimum of the objective function. Many
    real-life situations do not follow this unconstrained formulation, however, and
    there might be a cost associated with the objective function’s global optimum
    that makes the optimum infeasible to achieve in practice.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when tuning the architecture of a neural network, you might find
    that increasing the number of layers in the network usually yields a higher accuracy,
    and a network with millions and billions of layers will perform the best. However,
    unless we have access to expensive, powerful computing resources, running such
    large neural networks isn’t practical. That is, there’s a cost associated with
    running a large neural network, which would otherwise correspond to the global
    optimum of the objective function in this hyperparameter tuning task. We, therefore,
    need to take this computational cost into account while tuning this neural network
    and only look for architectures that are actually feasible to implement in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Another black-box optimization problem in which we need to consider additional
    constraints is scientific discovery, such as in chemistry and materials science.
    For instance, scientists aim to design chemicals and materials that optimize a
    desirable characteristic, such as drugs that are effective against a disease,
    glass that is resilient against pressure, or metals that are malleable and, thus,
    easy to manipulate. Unfortunately, the drugs that are the most effective against
    a disease might have many side effects that make them dangerous to use, or the
    most resilient type of glass might be too expensive to produce on a large scale.
  prefs: []
  type: TYPE_NORMAL
- en: These are examples of *constrained* optimization problems, where we need to
    optimize an objective function while satisfying other constraints. Seeking to
    optimize the objective function alone might lead us to solutions that violate
    important constraints, rendering the solutions we find useless in practice. Instead,
    we need to identify other regions in the search space that both yield high objective
    values and satisfy these important constraints.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we learn about the constrained optimization problem and see
    examples where having extra constraints may completely change the solution of
    an optimization problem. This need to account for these constraints gives rise
    to constraint-aware optimization policies in BayesOpt. We are introduced to a
    variant of the Expected Improvement (EI) policy that is constraint-aware and learn
    how to implement it in BoTorch. By the end of the chapter, you will understand
    the problem of constrained optimization, learn how it is solved using BayesOpt,
    and see that the constraint-aware policy we use performs much better than constraint-agnostic
    ones. What we learn in this chapter will help us tackle more practical BayesOpt
    problems in real life and, thus, make more effective decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Accounting for constraints in a constrained optimization problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned in the introduction, many constrained optimization problems exist
    in the real world: making drugs with high efficacy and minimal side effects, finding
    materials that maximize desirable characteristics and are cheap to produce, or
    hyperparameter tuning while keeping the computational cost low.'
  prefs: []
  type: TYPE_NORMAL
- en: Note We focus on *inequality constraints*, where we require a result *y* to
    be inside a predetermined numerical range *a* ≤ *y* ≤ *b*.
  prefs: []
  type: TYPE_NORMAL
- en: We first take a closer look at the constrained optimization problem in the next
    section and see why it’s mathematically different from the unconstrained problem
    we see in previous chapters. We then redefine the BayesOpt framework we have been
    working with so far to account for extra constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.1 Constraints can change the solution of an optimization problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How do constraints complicate the optimization of a black box function? In many
    cases, regions within the search space that give high objective values might violate
    the constraints that come with the optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: Note In an optimization problem, we aim to find regions that give high objective
    values since we want to maximize the value of the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: If it is the case that regions with high objective values violate the given
    constraints, we need to rule out these regions that violate the constraints and
    only conduct our search within other regions that satisfy the constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Definition A data point that violates the predefined constraints in a constrained
    optimization problem is called an *infeasible* point, as it’s infeasible to use
    the point as the solution to the optimization problem. On the other hand, a data
    point that satisfies the constraints is called a *feasible* point. Our goal is
    to find the feasible point that maximizes the value of the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: Constraints can affect the quality of the optimal solution of the unconstrained
    optimization problem or change the optimal solution altogether. Consider the example
    in figure 8.1, where our objective function (the solid line) is the Forrester
    function we have used in previous chapters. In addition to this objective function,
    we have a cost function, shown as the dashed line. Assume that in this constrained
    optimization problem, the constraint is that the cost needs to be a maximum of
    zero—that is, the cost *c* ≤ 0\. This constraint means only the feasible points
    in the shaded regions in the right panel of figure 8.1 can be used as the optimization
    result.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 An example of a one-dimensional constrained optimization problem.
    The solid line is the objective function we aim to maximize, and the dashed line
    is the cost function that constrains the optimization problem. Only the shaded
    regions (right panel) that yield negative costs are feasible. Here, the constraint
    of nonpositive cost causes the highest objective value to decrease from more than
    8 to 4.
  prefs: []
  type: TYPE_NORMAL
- en: Note We first used the Forrester function as an example objective function in
    BayesOpt in section 2.4.1.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, the region where *x* > 4, which contains the true global optimum
    of the objective value (denoted as the diamond marker in the right panel), is
    cut off. That is, the global optimum that yields an objective value of more than
    8 is not feasible, and the constrained optimal solution (denoted as the star)
    only achieves an objective value of roughly 4\. An example of this “cutoff” scenario
    is when an effective drug has too severe of a side effect, so the drug company
    decides to use a less effective variant of the same chemical to make the product
    safe.
  prefs: []
  type: TYPE_NORMAL
- en: Another example of the same objective function and a slightly different cost
    function is shown in figure 8.2, where having this extra cost constraint changes
    the optimal solution of our optimization problem. Without the constraint, the
    global optimum of the objective function is located at *x* = 4.6\. This point,
    however, is an infeasible one that gives a positive cost and, thus, violates our
    constraint. The optimal solution of the constrained problem is at *x* = 1.6\.
    This phenomenon can happen, for example, when the entire family of some highly
    effective drug is dangerous to patients and cannot be produced, so we need to
    look for other solutions that are chemically different from the dangerous drug.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 An example of a one-dimensional constrained optimization problem.
    Here, the optimal solution changes to a different local optimum, as the nonpositive
    cost constraint rules out the region where *x* > 3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, inequality constraints may impose complex requirements on an optimization
    problem and change its optimal solution. That is, constraints may rule out the
    global optimum of a function as an infeasible point—a common scenario in the real
    world:'
  prefs: []
  type: TYPE_NORMAL
- en: The prohibitively large neural networks tend to achieve good predictive performance
    but are infeasible to implement in practice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most effective drugs are often too aggressive and dangerous to produce.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best materials are too expensive to use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Instead of using the unconstrained optimal point that violates our constraints,
    we need to modify our optimization strategy to account for the constraints and
    find the optimal feasible solution. That is, we need to pursue two goals: optimizing
    the objective function and satisfying the given constraints. Solely optimizing
    the objective function without accounting for the constraints will lead to infeasible
    solutions that are not usable in practice. Instead, we need to find points that
    both yield high objective values and satisfy the constraints.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-02-unnumb.png)'
  prefs: []
  type: TYPE_IMG
- en: 8.1.2 The constraint-aware BayesOpt framework
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How should we approach this constrained optimization problem from the BayesOpt
    angle? In this section, we learn how to modify our BayesOpt framework to account
    for the constraints that are given in a constrained optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: Remember in BayesOpt that we use a Gaussian process (GP) to train on the data
    points we have observed from the objective function and make predictions on unseen
    data. In constrained optimization, we have, in addition, one or many functions
    that define the constraints we need to satisfy. For example, in section 8.1.1,
    the cost function shown as the dashed line in figures 8.1 and 8.2 defines the
    constraints that the solution needs to have a nonpositive cost.
  prefs: []
  type: TYPE_NORMAL
- en: Note You can refer to sections 1.2.3 and 4.1.1 for a refresher on the BayesOpt
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: We assume that, just like the objective function, we don’t know what the true
    cost function looks like. In other words, the cost function is a black box. We
    only get to observe the cost values at the data points we query the objective
    function with, and from there, we determine whether those data points satisfy
    the constraints or not.
  prefs: []
  type: TYPE_NORMAL
- en: Note If we did know what the functions that define our constraints look like,
    we could simply identify the feasible regions and restrict our search space to
    be within those feasible regions. In our constrained optimization problem, we
    assume our constraints are also black boxes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we only have black box access to the functions that define our constraints,
    we can also use a GP to model each of these functions. That is, in addition to
    the GP that models our objective function, we use more GPs, one for each function
    that defines a constraint, to inform our decisions about where to query the objective
    function next. We follow the same procedure to train each of these GPs—it’s just
    a matter of using the appropriate training set for each GP:'
  prefs: []
  type: TYPE_NORMAL
- en: The GP that models the objective function trains on the observed objective values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A GP that models a constraint-defining function trains on the observed cost
    values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our constrained BayesOpt framework, which is a modified version of figure 1.6,
    is visualized in figure 8.3:'
  prefs: []
  type: TYPE_NORMAL
- en: At step 1, we train a GP on data from the objective function and another GP
    on data from each function that defines a constraint.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At step 3, we use the point identified by a BayesOpt policy to query both the
    objective function and the constraint-defining functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Steps 1 and 3 of figure 8.3 are straightforward to implement: we only need
    to maintain multiple GPs at the same time, keep track of the corresponding datasets,
    and keep those datasets updated. The more interesting question comes in step 2:
    decision-making. That is, how should we design a BayesOpt policy that can guide
    us toward feasible regions that yield high objective values? This is the topic
    of our discussion in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Constraint-aware decision-making in BayesOpt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An effective constrained BayesOpt policy needs to pursue both optimization and
    satisfying the constraints. One straightforward way to design such a policy is
    to incorporate the constraints into the way an unconstrained BayesOpt policy makes
    its decisions. That is, we wish to modify a policy we already know to take into
    account constraints in a constrained optimization problem and derive a constraint-aware
    decision-making procedure.
  prefs: []
  type: TYPE_NORMAL
- en: The policy we choose for this modification is EI, which we learned about in
    section 4.3\. (We discuss other BayesOpt policies later in this section.) Remember
    that the EI policy scores each unseen data point with the expected value of how
    much improvement from the current incumbent we observe if we query the objective
    function at this unseen point.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-03.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 The constrained BayesOpt loop. A separate GP models either the objective
    function or a function that defines a constraint. A BayesOpt policy recommends
    the next point for us to query both the objective function and the constraint-defining
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Definition The term *incumbent* refers to the point having the highest objective
    value within our training set, which is what we need to “beat” to make progress
    with optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'The acquisition score EI uses, which, again, computes the average value of
    the improvement of each potential query, ignores the inequality constraints in
    a constrained optimization problem, so we can’t use EI “as is” when optimizing
    a constrained objective function. Fortunately, there’s an easy way to account
    for these constraints: we can scale the EI acquisition score of each unseen point
    by how likely the data point is to satisfy the constraints—that is, the probability
    that the data point is a feasible point:'
  prefs: []
  type: TYPE_NORMAL
- en: If the data point is likely to satisfy the constraints, then its EI score will
    be multiplied by a large number (a high probability of feasibility), thus keeping
    the EI score high.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the data point is unlikely to satisfy the constraints, its EI score will
    be multiplied by a small number (a low probability of feasibility), thus de-prioritizing
    that data point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip The acquisition score of the constrained variant of EI is the product of
    the regular EI score and the probability that a data point satisfies the constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for the acquisition score of this constraint-aware variant of EI
    is shown in figure 8.4\. This acquisition score is the product of two terms: the
    EI score encourages optimization of the objective function, and the probability
    of feasibility encourages staying within the feasible regions. This balance between
    optimizing the objective function and satisfying the constraints is exactly what
    we want to achieve, as noted in section 8.1.1.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-04.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 Formula for the acquisition score of constrained EI, which is the
    product of the regular EI score and the probability of feasibility. This policy
    aims to optimize the objective value and satisfy the constraints at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: We already know how to compute the EI score, but how can we calculate the second
    term—the probability that a given data point is a feasible point? As noted in
    figure 8.4, we do this with the GPs modeling the constraints. Specifically, each
    GP provides a probabilistic belief about the shape of a function defining a constraint.
    From this probabilistic belief, we can calculate the probability that an unseen
    data point will satisfy the corresponding inequality constraint.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, let’s say when solving the constrained optimization problem defined
    in figure 8.2 that we have observed the objective function and the cost function
    at *x* = 0, *x* = 3, and *x* = 4\. From this training set, we train two GPs, one
    for the objective function and the other for the cost function, and obtain the
    predictions visualized in figure 8.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-05.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 Predictions about the objective function and the cost function made
    by corresponding GPs. Each GP allows us to reason about the shape of the corresponding
    function in a probabilistic manner.
  prefs: []
  type: TYPE_NORMAL
- en: Now, say we’d like to compute the constrained EI score for *x* = 1\. We already
    have a way to compute the regular EI score for any data point, so all we need
    to do now is calculate the probability that *x* = 1 is a feasible data point.
    To do this, we look at the normal distribution representing our prediction about
    the cost value of *x* = 1, as illustrated in figure 8.6.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-06.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 Probability of *x* = 1 being a feasible point, highlighted in a darker
    shade. The left panel shows the entire GP, while the right panel only shows the
    normal distribution corresponding to the prediction at *x* = 1 (the error bars
    are the same across the two panels). Here, feasibility follows a truncated normal
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The left panel of figure 8.6 contains the same GP as in the bottom panel of
    figure 8.5 that is cut off at the constraint threshold 0, additionally showing
    the CI of the normal distribution prediction at *x* = 1\. Slicing the GP vertically
    at this point *x* = 1, we obtain the right panel of figure 8.6, where the CIs
    in the two panels are the same. In other words, going from the left to the right
    panel of figure 8.6, we have zoomed in on the vertical scale, and instead of showing
    the cost function, we only keep the cost constraint (the dotted line) and the
    GP prediction at *x* = 1, which is a normal distribution. We see that only the
    highlighted portion of the normal distribution in the right panel represents the
    probability that *x* = 1 obeys the cost constraint, which is what we care about.
  prefs: []
  type: TYPE_NORMAL
- en: 'If figure 8.6 reminds you of figures 4.9 and 4.10, covering the PoI policy,
    that’s because our thought process is the same in the two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: With PoI, we compute the probability that a given data point yields an objective
    value *higher* than the incumbent. We, therefore, use the incumbent value as a
    *lower* bound, specifying that we only care about scenarios in which the objective
    value is *higher* than the incumbent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the probability of feasibility, we compute the probability that a given
    data point yields a cost value *lower* than the cost threshold at 0\. We use 0
    as an *upper* bound to specify that we target scenarios in which the cost value
    is *lower* than the threshold (to obey our cost constraint).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling different inequality constraints
  prefs: []
  type: TYPE_NORMAL
- en: The constraint in our current example requires the cost to be less than 0\.
    If we had a constraint requiring a function value to be higher than some threshold,
    then the probability of feasibility would be the probability that a given point
    yields a function value higher than some threshold, and the shaded region in figure
    8.6 would be to the right of the cutoff.
  prefs: []
  type: TYPE_NORMAL
- en: If there was a constraint requiring the value to be inside a range (*a* ≤ *y*
    ≤ *b*), then the probability of feasibility would be the probability that the
    data point gives a value between the lower and upper bounds of the range.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we want to compute the probability that the cost value at *x* =
    1 is lower than 0, which is the area of the shaded region under the curve in the
    right panel of figure 8.6\. As we have seen in section 4.2.2 of chapter 4, the
    normal distribution allows us to compute this area under the curve using the cumulative
    density function (CDF). In figure 8.6, the probability that *x* = 1 is feasible
    is roughly 84%—this is the second term in figure 8.4 that we use to compute the
    constrained EI acquisition score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Further, we can compute this probability-of-feasibility quantity at any point
    inside our search space. For example, figure 8.7 shows the truncated normal distributions
    for *x* = –1 (center panel) and *x* = 2 (right panel). As we can see, the probability
    that a given point is feasible depends on the predictive normal distribution at
    that point:'
  prefs: []
  type: TYPE_NORMAL
- en: At *x* = –1, almost the entire predictive normal distribution lies below the
    cost threshold at 0, so the probability of feasibility here is high, at almost
    98%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At *x* = 2, only a small portion of the normal distribution falls below the
    cost threshold, causing the probability of feasibility to be much lower, roughly
    6%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-07.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 Probability of feasibility at *x* = –1 and *x* = 2, highlighted in
    a darker shade. The left panel shows the entire GP, the center panel shows the
    prediction at *x* = –1, and the right panel shows the prediction at *x* = 2\.
    The highlighted portions show the probability of feasibility, which depends on
    the normal distribution at a given point.
  prefs: []
  type: TYPE_NORMAL
- en: With the ability to compute the probability of feasibility for any given point
    in hand, we can now compute the constrained EI acquisition score described in
    figure 8.4\. Again, this score balances between a potentially high objective value,
    quantified by the regular EI score, and satisfying the inequality constraint(s),
    quantified by the probability of feasibility.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 shows this score in the bottom right panel, along with the regular
    EI score and the current GPs. We see that constrained EI is aware of the cost
    constraint we need to satisfy and assigns a roughly zero score to the region to
    the right of the space (where *x* > 2). This is because the cost GP (top right
    panel) thinks this is an infeasible region that should be avoided. Ultimately,
    the regular EI policy recommends the objective function with the infeasible point
    *x* = 4 as the next point to query. Constrained EI, on the other hand, recommends
    *x* = –0.8, which, indeed, satisfies our cost constraint.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-08.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 The acquisition score of EI (bottom left) and that of constrained
    EI (bottom right), along with our current belief about the objective function
    (top left) and about the cost function (top right). By being aware of the cost
    constraint, constrained EI can avoid the infeasible region and recommend an entirely
    different point to query from regular EI.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have found a good heuristic of deriving a constraint-aware BayesOpt policy
    from a regular one: multiplying the acquisition score of the policy with the probability
    of feasibility to factor in the inequality constraints. Interestingly, adding
    the probability-of-feasibility factor to EI isn’t simply a heuristic—the formula
    in figure 8.4 can be obtained from a heuristic-free, more mathematically rigorous
    procedure. The interested reader can refer to a research paper that defines the
    constrained EI policy for more details ([http://proceedings.mlr.press/v32/gardner14.pdf](http://proceedings.mlr.press/v32/gardner14.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: While we can use the same heuristic on other BayesOpt policies we have learned,
    such as UCB, TS, and Entropy Search, the mathematically rigorous procedure won’t
    apply anymore. Further, at the time of writing, BoTorch only supports constrained
    EI, which is also widely used to solve constrained optimization problems in practice.
    We, therefore, only focus on constrained EI and its optimization results for the
    rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '8.3 Exercise 1: Manual computation of constrained EI'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We saw in figure 8.4 that the acquisition score of the constrained EI policy
    is the product of the EI score and the probability of feasibility. Although the
    `ConstrainedExpectedImprovement` class from BoTorch provides an implementation
    of the constrained EI score, we can, in fact, perform the computation manually.
    In this exercise, we explore this manual computation and verify our result against
    that of the `ConstrainedExpectedImprovement` class. The solution to this exercise
    is in the CH08/02 - Exercise 1.ipynb notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the constrained BayesOpt problem used in CH08/01 - Constrained optimization.ipynb,
    including the objective function, the cost function, the GP implementation, and
    the helper function that trains a GP on some training data `fit_gp_model()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a PyTorch tensor that is a dense grid between -5 and 5 by using, for
    example, the `torch.linspace()` method. This tensor will act as our test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a toy training data set by randomly sampling 3 data points from our search
    space (between –5 and 5), and evaluate the objective and cost functions at these
    points.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train a GP on the data from the objective function and another GP on the data
    from the cost function using the helper function `fit_gp_model()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the GP trained on the data from the cost function to compute the probability
    of feasibility for each point in the test set. You can use the `torch.distributions`
    `.Normal` class to initialize a normal distribution object and call the `cdf()`
    method of this object on 0 (implemented as `torch.zeros(1)`) to compute the probability
    that each data point yields a cost lower than 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Initialize a regular EI policy with the `model` argument as the GP trained
    on the data from the objective function and the `best_f` argument as the current
    feasible incumbent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the EI score for each point in the test set.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Refer to section 4.3 for more details on implementing the EI policy.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a constrained EI policy, and compute the constrained EI score for
    each point in the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the product of the EI scores and the probabilities of feasibility, and
    verify that this manual computation leads to the same results as those from BoTorch’s
    implementation. You can use `torch.isclose(a,` `b,` `atol=1e-3)`, which performs
    element-wise comparisons between two tensors `a` and `b`, specifying `atol=1e-3`
    to account for numerical instability, to verify that all corresponding scores
    match up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the EI scores and the constrained EI scores in a graph, and visually verify
    that the former is always greater than or equal to the latter. Prove that this
    is the case using figure 8.4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 8.4 Implementing constrained EI with BoTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While we can manually multiply two quantities, the EI score and the probability
    of feasibility, to make a new acquisition score, BoTorch already takes care of
    the low-level bookkeeping. This means we can import the constrained EI policy
    from BoTorch and use it like any other BayesOpt policy, without much overhead.
    We learn how to do so in this section, and the code we use is included in the
    CH08/01 - Constrained optimization.ipynb notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need the objective function and the cost function that defines the
    constraint in figure 8.2\. In the following code, the objective function is implemented
    as `objective()`, and the cost function is `cost()`. Our search space is between
    –5 and 5, and we make the variable `bounds` that contains these numbers, which
    will be passed to BayesOpt policies later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The objective function to be maximized
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The cost function
  prefs: []
  type: TYPE_NORMAL
- en: ❸ The bounds on the search space
  prefs: []
  type: TYPE_NORMAL
- en: We also need a class implementation of our GP model and a helper function `fit_
    gp_model()` that trains the GP given a training data set. As constrained optimization
    doesn’t require any changes to the GP and how we train it, we can reuse the class
    implementation and the helper function we used in previous chapters. For a more
    in-depth discussion of this implementation, refer to section 4.1.1.
  prefs: []
  type: TYPE_NORMAL
- en: 'To benchmark the optimization performance of the policies we use, we specify
    that each BayesOpt run has 10 queries, and we have 10 runs in total:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note We run each BayesOpt policy multiple times to have a holistic view of the
    performance of the policy. Refer to exercise 2 of chapter 4 for the discussion
    on repeated experiments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need to modify our BayesOpt loop to account for the changes visualized
    in figure 8.3\. At step 1 of figure 8.3—that is, at the beginning of each step
    in the BayesOpt loop—we need to retrain multiple GPs: one for the objective function
    and the other(s) for the constraint(s).'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we already have the helper function `fit_gp_model()` that trains a GP, this
    step comes down to passing appropriate datasets to this helper function. In our
    current example, we only have one cost function defining the constraint, so we
    have, in total, two GPs, which can be retrained with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Train a GP on the objective function’s data.
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Train a GP on the cost function’s data.
  prefs: []
  type: TYPE_NORMAL
- en: Here, the variable `train_x` contains the locations at which we have evaluated
    the objective and cost functions; `train_utility` is the corresponding objective
    values, and `train_cost` is the cost values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2 of figure 8.3 refers to running a BayesOpt policy, which we learn to
    do shortly. For step 3 of figure 8.3, we evaluate the objective and cost functions
    at the data point recommended by the chosen BayesOpt policy, stored in the variable
    `next_x`. We do this by evaluating both the objective and cost functions at `next_x`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Evaluates the objective and cost functions at the recommended point
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Updates the various datasets
  prefs: []
  type: TYPE_NORMAL
- en: One more bookkeeping step we need to take is keeping track of our optimization
    progress. Unlike in an unconstrained optimization problem, where we simply record
    the incumbent value (highest objective value seen thus far) at every step, here
    we need to filter out the infeasible observations before taking the maximum. We
    do this by first creating a tensor with `num_repeats` rows (one for each repeated
    run) and `num_queries` columns (one for each time step). This tensor contains
    only one value by default, denoting our utility if no feasible points are found
    throughout BayesOpt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspecting figure 8.2, we see that our objective function is greater than –2
    everywhere within our search space (between –5_ and 5), so we use –2 as this default
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Checks whether a feasible point has been found
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, at each step of the BayesOpt loop, we only record the feasible incumbent
    by taking the maximum of the filtered observations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Checks whether a feasible point has been found
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code completes our constrained BayesOpt loop. All that’s left
    for us to do is declare the BayesOpt policy we want to use to solve the constrained
    optimization problem. We use the constrained EI policy we discussed in section
    8.2 by using the BoTorch class `ConstrainedExpectedImprovement`. This class takes
    in a number of important arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`model`—A list of GP models for the objective function (`utility_model` in
    our case) and the functions that define the constraints (`cost_model`, in our
    case). We create this list using the `model_list_gp_regression.ModelListGP` class
    from BoTorch’s `models` module: `ModelListGP(utility_model,` `cost_model)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`objective_index`—The index of the GP modeling the objective function in the
    model list `model`. Since `utility_model` is the first GP we pass to `ModelListGP`,
    this index is 0 in our case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`constraints`—A dictionary mapping the index of each function defining a constraint
    to a two-element list storing the lower and upper bounds for the constraint. If
    a constraint doesn’t have a lower bound or an upper bound, we use `None` in lieu
    of an actual numerical value. Our example requires the cost corresponding to `cost_model`,
    which has an index of 1, to be a maximum of 0, so we set `constraints={1:` `[None,`
    `0]}`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`best_f`—The current feasible incumbent, which is `train_utility[train_cost`
    <= `0].max()`, if we have found at least one feasible point or the default value,
    –2, otherwise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Overall, we initialize the constrained EI policy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The list of GP models
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The current feasible incumbent
  prefs: []
  type: TYPE_NORMAL
- en: ❸ The objective function’s index in the model list
  prefs: []
  type: TYPE_NORMAL
- en: ❹ A dictionary mapping each constraint’s index to the lower and upper bounds
  prefs: []
  type: TYPE_NORMAL
- en: With the implementation of constrained EI in hand, let’s now run this policy
    on our one-dimensional constrained optimization problem and observe its performance.
    As a baseline, we can also run the regular version of EI that is constraint agnostic.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 shows the average feasible incumbent values found by these two policies
    and error bars as a function of time. We see that compared to the regular EI,
    the constrained variant finds a better feasible solution on average and almost
    always converges to the best possible solution. Figure 8.9 highlights the benefit
    of our constraint-aware optimization policy compared to a constraint-agnostic
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-09.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 Optimization progress on a one-dimensional constrained optimization
    problem of constrained EI. Compared to the regular EI, the constrained variant
    finds a better feasible solution on average.
  prefs: []
  type: TYPE_NORMAL
- en: 'The EI policy, which is blind to the constraint placed on the optimization
    problem, tends to veer off toward the infeasible optimum. Inspecting the incumbent
    values found by this policy, we notice that in many runs, the policy fails to
    progress from its initial value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this chapter, we have learned about the problem of black box constrained
    optimization and how it is different from the classic black box optimization problem
    discussed in previous chapters. We learned that an effective optimization policy
    needs to pursue both optimizing the objective function and satisfying the constraints.
    We then designed one such policy, a variant of EI, by adding a factor equal to
    the probability of feasibility to the acquisition score. This new acquisition
    score biases our search strategy toward feasible regions, thus better guiding
    us toward the feasible optimum.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we discuss a new BayesOpt setting, multifidelity optimization,
    with which there are different costs to querying the objective function. This
    setting requires us to balance finding a high objective value and preserving our
    querying budget.
  prefs: []
  type: TYPE_NORMAL
- en: '8.5 Exercise 2: Constrained optimization of airplane design'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we tackle a constrained optimization problem using the airplane-utility
    objective function in exercise 2 of chapter 7\. This process allows us to run
    constrained BayesOpt on a higher-dimensional problem in which it’s not obvious
    where the feasibility optimal solution is. The solution to this exercise is included
    in the CH08/03 - Exercise 2.ipynb notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt problem used in the CH07/04 - Exercise 2.ipynb notebook,
    including the airplane-utility objective function named `flight_utility()`, the
    bounds of our search space (the four-dimensional unit hypercube), the GP implementation,
    and the helper function that trains a GP on some training data `fit_gp_model()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement the following cost function, which simulates the cost of making the
    airplane design specified by a four-dimensional input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Figure 8.10 visualizes this cost function for various pairs of parameters we
    can tune, showing a complex nonlinear trend across these two-dimensional spaces.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/08-10.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.10 The cost function of the simulated airplane design optimization
    problem in various two-dimensional subspaces, corresponding to pairs of tunable
    parameters, shown as axis labels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Our goal is to maximize the objective function `flight_utility()`, while following
    the constraint that the cost, as computed by `flight_cost()`, is less than or
    equal to 0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To this end, we set the number of queries a BayesOpt policy can make in each
    experiment as 50 and designate that each policy needs to run 10 repeated experiments.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The default value quantifying optimization progress if no feasible solution
    is found should be set to –2.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the constrained EI policy as well as the regular EI policy on this problem,
    and then visualize and compare their average progress (along with error bars).
    The plot should look similar to figure 8.9.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Constrained optimization is an optimization problem in which, in addition to
    optimizing the objective function, we need to satisfy other constraints to have
    practical solutions to the optimization problem. Constrained optimization is common
    in materials and drug discovery as well as hyperparameter tuning, where the objective
    function’s optimum is too difficult or dangerous to be used in practice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A data point that satisfies the constraints in a constrained optimization problem
    is called a feasible point, while a data point that violates the constraints is
    called infeasible. We aim to find the point that maximizes the objective function
    among the feasible points.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constraints can vastly change the solution to an optimization problem, cutting
    off or even excluding a region with high objective values. We, therefore, need
    to actively account for the constraints when optimizing the objective function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the framework of constrained BayesOpt, we train a GP on each of the functions
    that define the constraints. These GPs allow us to reason about whether a data
    point will satisfy the constraints in a probabilistic manner. Specifically, the
    probability that a given data point is feasible is easy to compute thanks to the
    fact that the predictive distributions from a GP are normal distributions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can modify the EI policy to account for the constraints by adding the probability
    of feasibility to its acquisition score. The constrained EI policy can balance
    optimizing the objective function and satisfying the constraints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BoTorch provides a class implementation of the constrained EI policy. When implementing
    constrained EI, we need to pass in the GPs modeling the objective and constraint
    functions as well as declare the constraint lower and upper bounds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
