["```py\ndu -cha --block-size=1MB\n```", "```py\n8.0K    ./README_DC_Taxicab_trip.txt\n176K    ./taxi_2015_01.txt\n 60M    ./taxi_2015_02.txt\n151M    ./taxi_2015_03.txt\n190M    ./taxi_2015_04.txt\n302M    ./taxi_2015_05.txt\n317M    ./taxi_2015_06.txt\n\n...\n\n11986    total\n```", "```py\nexport AWS_ACCESS_KEY_ID=█████████████████████\nexport AWS_SECRET_ACCESS_KEY=█████████████████\n```", "```py\naws sts get-caller-identity\n```", "```py\n{\n    \"UserId\": \"█████████████████████\",\n    \"Account\": \"████████████\",\n    \"Arn\": \"arn:aws:iam::████████████:user/█████████\"\n}\n```", "```py\nexport AWS_DEFAULT_REGION=us-east-2\necho $AWS_DEFAULT_REGION\n```", "```py\nexport BUCKET_ID=$(echo $RANDOM | md5sum \n➥ | cut -c -32)                           ❶\n\necho $BUCKET_ID\n```", "```py\naws sts get-caller-identity\n```", "```py\naws s3api create-bucket --bucket dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION \\\n--create-bucket-configuration LocationConstraint=$AWS_DEFAULT_REGION\n```", "```py\n{\n\"Location\": \"http:/dc-taxi-████████████████████████████████-█████████.s3\n➥ .amazonaws.com/\"\n}\n```", "```py\necho s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION.\n```", "```py\naws s3api list-buckets\n```", "```py\naws s3 sync . s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/\n```", "```py\naws s3 ls --recursive --summarize \\\n--human-readable s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/\n```", "```py\naws iam create-role \\\n  --path \"/service-role/\" \\\n  --role-name AWSGlueServiceRole-dc-taxi            ❶\n  --assume-role-policy-document '{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"glue.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}'\n\naws iam attach-role-policy \\                      ❷\n  --role-name AWSGlueServiceRole-dc-taxi \\\n  --policy-arn arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\n\naws iam put-role-policy \\\n  --role-name AWSGlueServiceRole-dc-taxi \\        ❸\n  --policy-name GlueBucketPolicy \\\n  --policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::dc-taxi-'$BUCKET_ID'-'$AWS_DEFAULT_REGION'/*\"\n            ]\n        }\n    ]\n}'\n```", "```py\naws glue create-database --database-input '{    ❶\n  \"Name\": \"dc_taxi_db\"\n}'\n\naws glue get-database --name 'dc_taxi_db'       ❷\n```", "```py\naws glue create-crawler \\\n  --name dc-taxi-csv-crawler \\                         ❶\n  --database-name dc_taxi_db \\                         ❷\n  --table-prefix dc_taxi_ \\                            ❸\n  --role $( aws iam get-role \\\n          --role-name AWSGlueServiceRole-dc-taxi \\     ❹\n          --query 'Role.Arn' \\\n          --output text ) \\\n   --targets '{\n  \"S3Targets\": [                                       ❺\n    {\n      \"Path\": \"s3://dc-taxi-'$BUCKET_ID'-'$AWS_DEFAULT_REGION'/csv/\",\n      \"Exclusions\": [\"README*\"]                        ❻\n    }]\n}'\n\naws glue start-crawler --name dc-taxi-csv-crawler      ❼\n```", "```py\naws glue get-crawler --name dc-taxi-csv-crawler --query 'Crawler.State' \\\n--output text\n```", "```py\naws glue get-crawler --name dc-taxi-csv-crawler --query 'Crawler.LastCrawl'\n```", "```py\naws glue get-table --database-name dc_taxi_db --name dc_taxi_csv.\n```", "```py\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job                                             ❶\n\nargs = getResolvedOptions(sys.argv, ['JOB_NAME',\n                                     'BUCKET_SRC_PATH',\n                                     'BUCKET_DST_PATH',\n                                     'DST_VIEW_NAME'])\n\nBUCKET_SRC_PATH = args['BUCKET_SRC_PATH']\nBUCKET_DST_PATH = args['BUCKET_DST_PATH']\nDST_VIEW_NAME = args['DST_VIEW_NAME']\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\nlogger = glueContext.get_logger()\nspark = glueContext.spark_session\n\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)                                        ❷\n\ndf = ( spark.read.format(\"csv\")\n        .option(\"header\", True)\n        .option(\"inferSchema\", True)\n        .option(\"delimiter\", \"|\")\n        .load(\"{}\".format(BUCKET_SRC_PATH)) )                           ❸\n\ndf.createOrReplaceTempView(\"{}\".format(DST_VIEW_NAME))\n\nquery_df = spark.sql(\"\"\"\n\n SELECT\n    origindatetime_tr,\n\n    CAST(fareamount AS DOUBLE) AS fareamount_double,\n    CAST(fareamount AS STRING) AS fareamount_string,\n\n    origin_block_latitude,\n    CAST(origin_block_latitude AS STRING) AS origin_block_latitude_string,\n\n    origin_block_longitude,\n    CAST(origin_block_longitude AS STRING) AS origin_block_longitude_string,\n    destination_block_latitude,\n    CAST(destination_block_latitude AS STRING)\n      AS destination_block_latitude_string,\n\n    destination_block_longitude,\n    CAST(destination_block_longitude AS STRING)\n      AS destination_block_longitude_string,\n\n    CAST(mileage AS DOUBLE) AS mileage_double,\n    CAST(mileage AS STRING) AS mileage_string\n\n FROM dc_taxi_csv\n\n\"\"\".replace('\\n', ''))                                                  ❹\n\nquery_df.write.parquet(\"{}\".format(BUCKET_DST_PATH), mode=\"overwrite\")  ❺\n\njob.commit()\n```", "```py\naws s3 cp dctaxi_csv_to_parquet.py \\\ns3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/glue/    ❶\n\naws s3 ls \\                                          ❷\ns3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/glue/dctaxi_csv_to_parquet.py\n```", "```py\nupload: ./dctaxi_csv_to_parquet.py to \n➥ s3://dc-taxi-████████████████████████████████-█████████/glue/\n➥ dctaxi_csv_to_parquet.py\n2020-04-20 14:58:22       1736 dctaxi_csv_to_parquet.py\n```", "```py\naws glue create-job \\\n  --name dc-taxi-csv-to-parquet-job \\\n  --role `aws iam get-role \\\n  --role-name AWSGlueServiceRole-dc-taxi \\\n  --query 'Role.Arn' \\\n  --output text` \\\n  --default-arguments \\\n   '{\"--TempDir\":\"s3://dc-taxi-'$BUCKET_ID'-'$AWS_DEFAULT_REGION'/glue/\"}' \\\n  --command '{\n    \"ScriptLocation\": \"s3://dc-taxi-'$BUCKET_ID'-'$AWS_DEFAULT_REGION'\n➥       /glue/dctaxi_csv_to_parquet.py\",\n    \"Name\": \"glueetl\",\n    \"PythonVersion\": \"3\"\n}'\n\naws glue start-job-run \\\n  --job-name dc-taxi-csv-to-parquet-job \\\n  --arguments='--BUCKET_SRC_PATH=\"'$(\n      echo s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/\n    )'\",\n  --BUCKET_DST_PATH=\"'$(\n      echo s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/parquet/\n    )'\",\n  --DST_VIEW_NAME=\"dc_taxi_csv\"'\n```", "```py\naws glue get-job-runs --job-name dc-taxi-csv-to-parquet-job \\\n--query 'JobRuns[0].JobRunState'\n```", "```py\naws s3 ls --recursive --summarize --human-readable \\\ns3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/parquet/\n\n...\nTotal Objects: 99\n   Total Size: 940.7 MiB\n```", "```py\naws glue create-crawler \\                      ❶\n--name dc-taxi-parquet-crawler \\\n--database-name dc_taxi_db \\\n--table-prefix dc_taxi_ \\\n--role `aws iam get-role --role-name AWSGlueServiceRole-dc-taxi \n➥   --query 'Role.Arn' --output text` --targets '{\n  \"S3Targets\": [                               ❷\n    {\n      \"Path\": \"s3://dc-taxi-'$BUCKET_ID'-'$AWS_DEFAULT_REGION'/parquet/\"\n    }]\n}'\n\naws glue start-crawler \\                       ❸\n--name dc-taxi-parquet-crawler\n\naws glue get-crawler --name dc-taxi-parquet-crawler --query 'Crawler.State'\\\n --output text                                 ❹\n```", "```py\naws glue get-table --database-name dc_taxi_db --name dc_taxi_parquet\n```"]