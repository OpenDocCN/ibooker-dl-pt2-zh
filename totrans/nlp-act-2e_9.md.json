["```py\n>>> import math\n>>> import torch\n>>> from torch import nn\n...\n>>> class PositionalEncoding(nn.Module):\n...   def __init__(self, d_model=512, dropout=0.1, max_len=5000):\n...      super().__init__()\n...      self.dropout = nn.Dropout(p=dropout)  # #1\n...      self.d_model = d_model  # #2\n...      self.max_len = max_len  # #3\n...      pe = torch.zeros(max_len, d_model)  # #4\n...      position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n...      div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n...                           (-math.log(10000.0) / d_model))\n...      pe[:, 0::2] = torch.sin(position * div_term)  # #5\n...      pe[:, 1::2] = torch.cos(position * div_term)\n...      pe = pe.unsqueeze(0).transpose(0, 1)\n...      self.register_buffer('pe', pe)\n...\n...   def forward(self, x):\n...      x = x + self.pe[:x.size(0), :]\n...      return self.dropout(x)\n```", "```py\n>>> from datasets import load_dataset  # #1\n>>> opus = load_dataset('opus_books', 'de-en')\n>>> opus\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 51467\n    })\n})\n```", "```py\n>>> sents = opus['train'].train_test_split(test_size=.1)\n>>> sents\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 48893\n    })\n    test: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 2574\n    })\n})\n```", "```py\n>>> next(iter(sents['test']))  # #1\n{'id': '9206',\n 'translation': {'de': 'Es war wenigstens zu viel in der Luft.',\n  'en': 'There was certainly too much of it in the air.'}}\n```", "```py\n>>> DEVICE = torch.device(\n...     'cuda' if torch.cuda.is_available()\n...     else 'cpu')\n```", "```py\n>>> SRC = 'en'  # #1\n>>> TGT = 'de'  # #2\n>>> SOS, EOS = '<s>', '</s>'\n>>> PAD, UNK, MASK = '<pad>', '<unk>', '<mask>'\n>>> SPECIAL_TOKS = [SOS, PAD, EOS, UNK, MASK]\n>>> VOCAB_SIZE = 10_000\n...\n>>> from tokenizers import ByteLevelBPETokenizer  # #3\n>>> tokenize_src = ByteLevelBPETokenizer()\n>>> tokenize_src.train_from_iterator(\n...     [x[SRC] for x in sents['train']['translation']],\n...     vocab_size=10000, min_frequency=2,\n...     special_tokens=SPECIAL_TOKS)\n>>> PAD_IDX = tokenize_src.token_to_id(PAD)\n...\n>>> tokenize_tgt = ByteLevelBPETokenizer()\n>>> tokenize_tgt.train_from_iterator(\n...     [x[TGT] for x in sents['train']['translation']],\n...     vocab_size=10000, min_frequency=2,\n...     special_tokens=SPECIAL_TOKS)\n>>> assert PAD_IDX == tokenize_tgt.token_to_id(PAD)\n```", "```py\ndef preprocess(examples):\n    src = [x[source_lang] for x in examples[\"translation\"]]\n    src_toks = [tokenize_src(x) for x in src]\n    # tgt = [x[target_lang] for x in examples[\"translation\"]]\n    # tgt_toks = [tokenize_tgt(x) for x in tgt]\n    return src_toks\n```", "```py\n>>> from torch import Tensor\n>>> from typing import Optional, Any\n\n>>> class CustomDecoderLayer(nn.TransformerDecoderLayer):\n...     def forward(self, tgt: Tensor, memory: Tensor,\n...             tgt_mask: Optional[Tensor] = None,\n...             memory_mask: Optional[Tensor] = None,\n...             tgt_key_padding_mask: Optional[Tensor] = None\n...             ) -> Tensor:\n...         \"\"\"Like decode but returns multi-head attention weights.\"\"\"\n...         tgt2 = self.self_attn(\n...             tgt, tgt, tgt, attn_mask=tgt_mask,\n...             key_padding_mask=tgt_key_padding_mask)[0]\n...         tgt = tgt + self.dropout1(tgt2)\n...         tgt = self.norm1(tgt)\n...         tgt2, attention_weights = self.multihead_attn(\n...             tgt, memory, memory,  # #1\n...             attn_mask=memory_mask,\n...             key_padding_mask=mem_key_padding_mask,\n...             need_weights=True)\n...         tgt = tgt + self.dropout2(tgt2)\n...         tgt = self.norm2(tgt)\n...         tgt2 = self.linear2(\n...             self.dropout(self.activation(self.linear1(tgt))))\n...         tgt = tgt + self.dropout3(tgt2)\n...         tgt = self.norm3(tgt)\n...         return tgt, attention_weights  # #2\n```", "```py\n>>> class CustomDecoder(nn.TransformerDecoder):\n...     def __init__(self, decoder_layer, num_layers, norm=None):\n...         super().__init__(\n...             decoder_layer, num_layers, norm)\n...\n...     def forward(self,\n...             tgt: Tensor, memory: Tensor,\n...             tgt_mask: Optional[Tensor] = None,\n...             memory_mask: Optional[Tensor] = None,\n...             tgt_key_padding_mask: Optional[Tensor] = None\n...             ) -> Tensor:\n...         \"\"\"Like TransformerDecoder but cache multi-head attention\"\"\"\n...         self.attention_weights = []  # #1\n...         output = tgt\n...         for mod in self.layers:\n...             output, attention = mod(\n...                 output, memory, tgt_mask=tgt_mask,\n...                 memory_mask=memory_mask,\n...                 tgt_key_padding_mask=tgt_key_padding_mask)\n...             self.attention_weights.append(attention) # #2\n...\n...         if self.norm is not None:\n...             output = self.norm(output)\n...\n...         return output\n```", "```py\n>>> from einops import rearrange  # #1\n...\n>>> class TranslationTransformer(nn.Transformer):  # #2\n...     def __init__(self,\n...             device=DEVICE,\n...             src_vocab_size: int = VOCAB_SIZE,\n...             src_pad_idx: int = PAD_IDX,\n...             tgt_vocab_size: int = VOCAB_SIZE,\n...             tgt_pad_idx: int = PAD_IDX,\n...             max_sequence_length: int = 100,\n...             d_model: int = 512,\n...             nhead: int = 8,\n...             num_encoder_layers: int = 6,\n...             num_decoder_layers: int = 6,\n...             dim_feedforward: int = 2048,\n...             dropout: float = 0.1,\n...             activation: str = \"relu\"\n...         ):\n...\n...         decoder_layer = CustomDecoderLayer(\n...             d_model, nhead, dim_feedforward,  # #3\n...             dropout, activation)\n...         decoder_norm = nn.LayerNorm(d_model)\n...         decoder = CustomDecoder(\n...             decoder_layer, num_decoder_layers,\n...             decoder_norm)  # #4\n...\n...         super().__init__(\n...             d_model=d_model, nhead=nhead,\n...             num_encoder_layers=num_encoder_layers,\n...             num_decoder_layers=num_decoder_layers,\n...             dim_feedforward=dim_feedforward,\n...             dropout=dropout, custom_decoder=decoder)\n...\n...         self.src_pad_idx = src_pad_idx\n...         self.tgt_pad_idx = tgt_pad_idx\n...         self.device = device\n...\n...         self.src_emb = nn.Embedding(\n...             src_vocab_size, d_model)  # #5\n...         self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n...\n...         self.pos_enc = PositionalEncoding(\n...             d_model, dropout, max_sequence_length)  # #6\n...         self.linear = nn.Linear(\n...             d_model, tgt_vocab_size)  # #7\n```", "```py\nS: source sequence length\nT: target sequence length\nN: batch size\nE: embedding dimension number (the feature number)\n\nsrc: (S, N, E)\n\ntgt: (T, N, E)\nsrc_mask: (S, S)\ntgt_mask: (T, T)\nmemory_mask: (T, S)\nsrc_key_padding_mask: (N, S)\ntgt_key_padding_mask: (N, T)\nmemory_key_padding_mask: (N, S)\n\noutput: (T, N, E)\n```", "```py\n>>>     def _make_key_padding_mask(self, t, pad_idx):\n...         mask = (t == pad_idx).to(self.device)\n...         return mask\n...\n...     def prepare_src(self, src, src_pad_idx):\n...         src_key_padding_mask = self._make_key_padding_mask(\n...             src, src_pad_idx)\n...         src = rearrange(src, 'N S -> S N')\n...         src = self.pos_enc(self.src_emb(src)\n...             * math.sqrt(self.d_model))\n...         return src, src_key_padding_mask\n```", "```py\n>>>     def prepare_tgt(self, tgt, tgt_pad_idx):\n...         tgt_key_padding_mask = self._make_key_padding_mask(\n...             tgt, tgt_pad_idx)\n...         tgt = rearrange(tgt, 'N T -> T N')\n...         tgt_mask = self.generate_square_subsequent_mask(\n...             tgt.shape[0]).to(self.device)\n...         tgt = self.pos_enc(self.tgt_emb(tgt)\n...             * math.sqrt(self.d_model))\n...         return tgt, tgt_key_padding_mask, tgt_mask\n```", "```py\n>>>     def forward(self, src, tgt):\n...         src, src_key_padding_mask = self.prepare_src(\n...             src, self.src_pad_idx)\n...         tgt, tgt_key_padding_mask, tgt_mask = self.prepare_tgt(\n...             tgt, self.tgt_pad_idx)\n...         memory_key_padding_mask = src_key_padding_mask.clone()\n...         output = super().forward(\n...             src, tgt, tgt_mask=tgt_mask,\n...             src_key_padding_mask=src_key_padding_mask,\n...             tgt_key_padding_mask=tgt_key_padding_mask,\n...             memory_key_padding_mask=memory_key_padding_mask)\n...         output = rearrange(output, 'T N E -> N T E')\n...         return self.linear(output)\n```", "```py\n>>>     def init_weights(self):\n...         def _init_weights(m):\n...             if hasattr(m, 'weight') and m.weight.dim() > 1:\n...                 nn.init.xavier_uniform_(m.weight.data)\n...         self.apply(_init_weights);  # #1\n```", "```py\n>>> class TranslationTransformer(nn.Transformer):\n...     def __init__(self,\n...             device=DEVICE,\n...             src_vocab_size: int = 10000,\n...             src_pad_idx: int = PAD_IDX,\n...             tgt_vocab_size: int  = 10000,\n...             tgt_pad_idx: int = PAD_IDX,\n...             max_sequence_length: int = 100,\n...             d_model: int = 512,\n...             nhead: int = 8,\n...             num_encoder_layers: int = 6,\n...             num_decoder_layers: int = 6,\n...             dim_feedforward: int = 2048,\n...             dropout: float = 0.1,\n...             activation: str = \"relu\"\n...             ):\n...         decoder_layer = CustomDecoderLayer(\n...             d_model, nhead, dim_feedforward,\n...             dropout, activation)\n...         decoder_norm = nn.LayerNorm(d_model)\n...         decoder = CustomDecoder(\n...             decoder_layer, num_decoder_layers, decoder_norm)\n...\n...         super().__init__(\n...             d_model=d_model, nhead=nhead,\n...             num_encoder_layers=num_encoder_layers,\n...             num_decoder_layers=num_decoder_layers,\n...             dim_feedforward=dim_feedforward,\n...             dropout=dropout, custom_decoder=decoder)\n...\n...         self.src_pad_idx = src_pad_idx\n...         self.tgt_pad_idx = tgt_pad_idx\n...         self.device = device\n...         self.src_emb = nn.Embedding(src_vocab_size, d_model)\n...         self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n...         self.pos_enc = PositionalEncoding(\n...             d_model, dropout, max_sequence_length)\n...         self.linear = nn.Linear(d_model, tgt_vocab_size)\n...\n...     def init_weights(self):\n...         def _init_weights(m):\n...             if hasattr(m, 'weight') and m.weight.dim() > 1:\n...                 nn.init.xavier_uniform_(m.weight.data)\n...         self.apply(_init_weights);\n...\n...     def _make_key_padding_mask(self, t, pad_idx=PAD_IDX):\n...         mask = (t == pad_idx).to(self.device)\n...         return mask\n...\n...     def prepare_src(self, src, src_pad_idx):\n...         src_key_padding_mask = self._make_key_padding_mask(\n...             src, src_pad_idx)\n...         src = rearrange(src, 'N S -> S N')\n...         src = self.pos_enc(self.src_emb(src)\n...             * math.sqrt(self.d_model))\n...         return src, src_key_padding_mask\n...\n...     def prepare_tgt(self, tgt, tgt_pad_idx):\n...         tgt_key_padding_mask = self._make_key_padding_mask(\n...             tgt, tgt_pad_idx)\n...         tgt = rearrange(tgt, 'N T -> T N')\n...         tgt_mask = self.generate_square_subsequent_mask(\n...             tgt.shape[0]).to(self.device)      # #1\n...         tgt = self.pos_enc(self.tgt_emb(tgt)\n...             * math.sqrt(self.d_model))\n...         return tgt, tgt_key_padding_mask, tgt_mask\n...\n...     def forward(self, src, tgt):\n...         src, src_key_padding_mask = self.prepare_src(\n...             src, self.src_pad_idx)\n...         tgt, tgt_key_padding_mask, tgt_mask = self.prepare_tgt(\n...             tgt, self.tgt_pad_idx)\n...         memory_key_padding_mask = src_key_padding_mask.clone()\n...         output = super().forward(\n...             src, tgt, tgt_mask=tgt_mask,\n...             src_key_padding_mask=src_key_padding_mask,\n...             tgt_key_padding_mask=tgt_key_padding_mask,\n...             memory_key_padding_mask = memory_key_padding_mask,\n...             )\n...         output = rearrange(output, 'T N E -> N T E')\n...         return self.linear(output)\n```", "```py\n>>> model = TranslationTransformer(\n...     device=DEVICE,\n...     src_vocab_size=tokenize_src.get_vocab_size(),\n...     src_pad_idx=tokenize_src.token_to_id('<pad>'),\n...     tgt_vocab_size=tokenize_tgt.get_vocab_size(),\n...     tgt_pad_idx=tokenize_tgt.token_to_id('<pad>')\n...     ).to(DEVICE)\n>>> model.init_weights()\n>>> model  # #1\n```", "```py\nTranslationTransformer(\n  (encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(\n            in_features=512, out_features=512, bias=True)\n        )\n        (linear1): Linear(\n          in_features=512, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(\n          in_features=2048, out_features=512, bias=True)\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n...\n```", "```py\n>>> src = torch.randint(1, 100, (10, 5)).to(DEVICE)  # #1\n>>> tgt = torch.randint(1, 100, (10, 7)).to(DEVICE)\n...\n>>> with torch.no_grad():\n...     output = model(src, tgt)  # #2\n...\n>>> print(output.shape)\ntorch.Size([10, 7, 5893])\n```", "```py\nRuntimeError: the batch number of src and tgt must be equal\n```", "```py\n>>> LEARNING_RATE = 0.0001\n>>> optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n>>> criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)  # #1\n```", "```py\n>>> def train(model, iterator, optimizer, criterion, clip):\n...\n...     model.train()  # #1\n...     epoch_loss = 0\n...\n...     for i, batch in enumerate(iterator):\n...         src = batch.src\n...         trg = batch.trg\n...         optimizer.zero_grad()\n...         output = model(src, trg[:,:-1])  # #2\n...         output_dim = output.shape[-1]\n...         output = output.contiguous().view(-1, output_dim)\n...         trg = trg[:,1:].contiguous().view(-1)\n...         loss = criterion(output, trg)\n...         loss.backward()\n...         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n...         optimizer.step()\n...         epoch_loss += loss.item()\n...\n...     return epoch_loss / len(iterator)\n```", "```py\n>>> def evaluate(model, iterator, criterion):\n...     model.eval()  # #1\n...     epoch_loss = 0\n...\n...     with torch.no_grad():  # #2\n...         for i, batch in enumerate(iterator):\n...             src = batch.src\n...             trg = batch.trg\n...             output = model(src, trg[:,:-1])\n...             output_dim = output.shape[-1]\n...             output = output.contiguous().view(-1, output_dim)\n...             trg = trg[:,1:].contiguous().view(-1)\n...             loss = criterion(output, trg)\n...             epoch_loss += loss.item()\n...     return epoch_loss / len(iterator)\n```", "```py\n>>> def epoch_time(start_time, end_time):\n...     elapsed_time = end_time - start_time\n...     elapsed_mins = int(elapsed_time / 60)\n...     elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n...     return elapsed_mins, elapsed_secs\n```", "```py\n>>> import time\n>>> N_EPOCHS = 15\n>>> CLIP = 1\n>>> BEST_MODEL_FILE = 'best_model.pytorch'\n>>> best_valid_loss = float('inf')\n>>> for epoch in range(N_EPOCHS):\n...     start_time = time.time()\n...     train_loss = train(\n...         model, train_iterator, optimizer, criterion, CLIP)\n...     valid_loss = evaluate(model, valid_iterator, criterion)\n...     end_time = time.time()\n...     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n...\n...     if valid_loss < best_valid_loss:\n...         best_valid_loss = valid_loss\n...         torch.save(model.state_dict(), BEST_MODEL_FILE)\n...     print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n...     train_ppl = f'{math.exp(train_loss):7.3f}'\n...     print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {train_ppl}')\n...     valid_ppl = f'{math.exp(valid_loss):7.3f}'\n...     print(f'\\t Val. Loss: {valid_loss:.3f} | Val. PPL: {valid_ppl}')\n```", "```py\nEpoch: 01 | Time: 0m 55s\n        Train Loss: 4.835 | Train PPL: 125.848\n         Val. Loss: 3.769 |  Val. PPL:  43.332\nEpoch: 02 | Time: 0m 56s\n        Train Loss: 3.617 | Train PPL:  37.242\n         Val. Loss: 3.214 |  Val. PPL:  24.874\nEpoch: 03 | Time: 0m 56s\n        Train Loss: 3.197 | Train PPL:  24.448\n         Val. Loss: 2.872 |  Val. PPL:  17.679\n\n...\nEpoch: 13 | Time: 0m 57s\n        Train Loss: 1.242 | Train PPL:   3.463\n         Val. Loss: 1.570 |  Val. PPL:   4.805\nEpoch: 14 | Time: 0m 57s\n        Train Loss: 1.164 | Train PPL:   3.204\n         Val. Loss: 1.560 |  Val. PPL:   4.759\nEpoch: 15 | Time: 0m 57s\n        Train Loss: 1.094 | Train PPL:   2.985\n         Val. Loss: 1.545 |  Val. PPL:   4.689\n```", "```py\n>>> model.load_state_dict(torch.load(BEST_MODEL_FILE))\n>>> test_loss = evaluate(model, test_iterator, criterion)\n>>> print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n| Test Loss: 1.590 | Test PPL:   4.902 |\n```", "```py\n>>> def translate_sentence(sentence, src_field, trg_field,\n...         model, device=DEVICE, max_len=50):\n...     model.eval()\n...     if isinstance(sentence, str):\n...         nlp = spacy.load('de')\n...         tokens = [token.text.lower() for token in nlp(sentence)]\n...     else:\n...         tokens = [token.lower() for token in sentence]\n...     tokens = ([src_field.init_token] + tokens\n...         + [src_field.eos_token])  # #1\n...     src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n...     src = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n...     src, src_key_padding_mask = model.prepare_src(src, SRC_PAD_IDX)\n...     with torch.no_grad():\n...         enc_src = model.encoder(src,\n...             src_key_padding_mask=src_key_padding_mask)\n...     trg_indexes = [\n...         trg_field.vocab.stoi[trg_field.init_token]]  # #2\n...\n...     for i in range(max_len):\n...         tgt = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n...         tgt, tgt_key_padding_mask, tgt_mask = model.prepare_tgt(\n...             tgt, TRG_PAD_IDX)\n...         with torch.no_grad():\n...             output = model.decoder(\n...                 tgt, enc_src, tgt_mask=tgt_mask,\n...                 tgt_key_padding_mask=tgt_key_padding_mask)\n...             output = rearrange(output, 'T N E -> N T E')\n...             output = model.linear(output)\n...\n...         pred_token = output.argmax(2)[:,-1].item()  # #3\n...         trg_indexes.append(pred_token)\n...\n...         if pred_token == trg_field.vocab.stoi[\n...                 trg_field.eos_token]:  # #4\n...             break\n...\n...     trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n...     translation = trg_tokens[1:]\n...\n...     return translation, model.decoder.attention_weights\n```", "```py\n>>> example_idx = 10\n>>> src = vars(test_data.examples[example_idx])['src']\n>>> trg = vars(test_data.examples[example_idx])['trg']\n>>> src\n['eine', 'mutter', 'und', 'ihr', 'kleiner', 'sohn', 'genießen',\n 'einen', 'schönen', 'tag', 'im', 'freien', '.']\n>>> trg\n['a', 'mother', 'and', 'her', 'young', 'song', 'enjoying',\n 'a', 'beautiful', 'day', 'outside', '.']\n```", "```py\n>>> translation, attention = translate_sentence(src, SRC, TRG, model, device)\n>>> print(f'translation = {translation}')\ntranslation = ['a', 'mother', 'and', 'her', 'little', 'son', 'enjoying',\n 'a', 'beautiful', 'day', 'outside', '.', '<eos>']\n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> import matplotlib.ticker as ticker\n...\n>>> def display_attention(sentence, translation, attention_weights):\n...     n_attention = len(attention_weights)\n...\n...     n_cols = 2\n...     n_rows = n_attention // n_cols + n_attention % n_cols\n...\n...     fig = plt.figure(figsize=(15,25))\n...\n...     for i in range(n_attention):\n...\n...         attention = attention_weights[i].squeeze(0)\n...         attention = attention.cpu().detach().numpy()\n...         cax = ax.matshow(attention, cmap='gist_yarg')\n...\n...         ax = fig.add_subplot(n_rows, n_cols, i+1)\n...         ax.tick_params(labelsize=12)\n...         ax.set_xticklabels([''] + ['<sos>'] +\n...             [t.lower() for t in sentence]+['<eos>'],\n...             rotation=45)\n...         ax.set_yticklabels(['']+translation)\n...         ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n...         ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n...\n...     plt.show()\n...     plt.close()\n```", "```py\n>>> display_attention(src, translation, attention_weights)\n```", "```py\n>>> example_idx = 25\n...\n>>> src = vars(valid_data.examples[example_idx])['src']\n>>> trg = vars(valid_data.examples[example_idx])['trg']\n...\n>>> print(f'src = {src}')\n>>> print(f'trg = {trg}')\nsrc = ['zwei', 'hunde', 'spielen', 'im', 'hohen', 'gras', 'mit',\n 'einem', 'orangen', 'spielzeug', '.']\ntrg = ['two', 'dogs', 'play', 'with', 'an', 'orange', 'toy', 'in',\n 'tall', 'grass', '.']\n```", "```py\n>>> translation, attention = translate_sentence(src, SRC, TRG, model, device)\n>>> print(f'translation = {translation}')\ntranslation = ['two', 'dogs', 'are', 'playing', 'with', 'an', 'orange',\n 'toy', 'in', 'the', 'tall', 'grass', '.', '<eos>']\n```", "```py\n>>> display_attention(src, translation, attention)\n```", "```py\n>>> from torchtext.data.metrics import bleu_score\n...\n>>> def calculate_bleu(data, src_field, trg_field, model, device,\n max_len = 50):\n...     trgs = []\n...     pred_trgs = []\n...     for datum in data:\n...         src = vars(datum)['src']\n...         trg = vars(datum)['trg']\n...         pred_trg, _ = translate_sentence(\n...             src, src_field, trg_field, model, device, max_len)\n...         # strip <eos> token\n...         pred_trg = pred_trg[:-1]\n...         pred_trgs.append(pred_trg)\n...         trgs.append([trg])\n...\n...     return bleu_score(pred_trgs, trgs)\n```", "```py\n>>> bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n>>> print(f'BLEU score = {bleu_score*100:.2f}')\nBLEU score = 37.68\n```", "```py\n>>> from transformers import BertModel\n>>> model = BertModel.from_pre-trained('bert-base-uncased')\n>>> print(model)\n```", "```py\nBertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12,\n elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n\n      ... # #1\n\n      (11): BertLayer(\n        (attention): BertAttention(...)\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n  ) ) ) )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh() ) )\n```", "```py\n>>> import pandas as pd\n>>> df = pd.read_csv('data/train.csv')  # #1\n>>> df.head()\n                   comment_text toxic severe obscene threat insult hate\nExplanation\\nWhy the edits made     0      0       0      0      0    0\nD'aww! He matches this backgrou 0 0 0 0 0 0\nHey man, I'm really not trying 0 0 0 0 0 0\n\"\\nMore\\nI can't make any real 0 0 0 0 0 0\nYou, sir, are my hero. Any chan     0      0       0      0      0    0\n>>> df.shape\n(159571, 8)\n```", "```py\n>>> from sklearn.model_selection import train_test_split\n>>> random_state=42\n>>> labels = ['toxic', 'severe', 'obscene', 'threat', 'insult', 'hate']\n>>> X = df[['comment_text']]\n>>> y = df[labels]\n>>> X_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.2,\n...     random_state=random_state)  # #1\n```", "```py\n>>> def get_dataset(X, y):\n...     data = [[X.iloc[i][0], y.iloc[i].values.tolist()]\n for i in range(X.shape[0])]\n...     return pd.DataFrame(data, columns=['text', 'labels'])\n...\n>>> train_df = get_dataset(X_train, y_train)\n>>> eval_df = get_dataset(X_test, y_test)\n>>> train_df.shape, eval_df.shape\n((127656, 2), (31915, 2))\n\n>>> train_df.head()  # #1\n                                                text              labels\n0  Grandma Terri Should Burn in Trash \\nGrandma T...  [1, 0, 0, 0, 0, 0]\n1  , 9 May 2009 (UTC)\\nIt would be easiest if you...  [0, 0, 0, 0, 0, 0]\n2  \"\\n\\nThe Objectivity of this Discussion is dou... [0, 0, 0, 0, 0, 0]\n3              Shelly Shock\\nShelly Shock is. . .( )  [0, 0, 0, 0, 0, 0]\n4  I do not care. Refer to Ong Teng Cheong talk p...  [0, 0, 0, 0, 0, 0]\n```", "```py\n>>> import logging\n>>> logging.basicConfig(level=logging.INFO)  # #1\n\n>>> model_type = 'bert'  # #2\n>>> model_name = 'bert-base-cased'\n>>> output_dir = f'{model_type}-example1-outputs'\n\n>>> model_args = {\n...     'output_dir': output_dir, # where to save results\n...     'overwrite_output_dir': True, # allow re-run without having to manually clear output_dir\n...     'manual_seed': random_state, # #3\n...     'no_cache': True,\n... }\n```", "```py\n>>> from sklearn.metrics import roc_auc_score\n>>> from simpletransformers.classification\n import MultiLabelClassificationModel\n>>> model = MultiLabelClassificationModel(\n...     model_type, model_name, num_labels=len(labels),\n...     args=model_args)\nYou should probably TRAIN this model on a downstream task\n to be able to use it\nfor predictions and inference\n>>> model.train_model(train_df=train_df)  # #1\n```", "```py\n>>> result, model_outputs, wrong_predictions = model.eval_model(eval_df,\n...     acc=roc_auc_score)  # #1\n>>> result\n{'LRAP': 0.9955934600588362,\n 'acc': 0.9812396881786198,\n 'eval_loss': 0.04415484298031397}\n```", "```py\n>>> from preprocessing.preprocessing import TextPreprocessor\n>>> tp = TextPreprocessor()\nloaded ./inc/preprocessing/json/contractions.json\nloaded ./inc/preprocessing/json/misc_replacements.json\nloaded ./inc/preprocessing/json/misspellings.json\n>>> df = df.rename(columns={'comment_text':'original_text'})\n>>> df['comment_text'] = df['original_text'].apply(\n...     lambda x: tp.preprocess(x))  # #1\n>>> pd.set_option('display.max_colwidth', 45)\n>>> df[['original_text', 'comment_text']].head()\n                    original_text                       comment_text\n0  Explanation\\nWhy the edits ...  Explanation Why the edits made...\n1  D'aww! He matches this back... D'aww! He matches this backgro...\n2  Hey man, I'm really not try... Hey man, i am really not tryin...\n3  \"\\nMore\\nI can't make any r... \" More I cannot make any real ...\n4  You, sir, are my hero. Any ...  You, sir, are my hero. Any cha...\n```", "```py\n>>> model_type = 'bert'\n>>> model_name = 'bert-base-cased'\n>>> output_dir = f'{model_type}-example2-outputs'  # #1\n>>> best_model_dir = f'{output_dir}/best_model'\n>>> model_args = {\n...     'output_dir': output_dir,\n...     'overwrite_output_dir': True,\n...     'manual_seed': random_state,\n...     'no_cache': True,\n...     'best_model_dir': best_model_dir,\n...     'max_seq_length': 300,\n...     'train_batch_size': 24,\n...     'eval_batch_size': 24,\n...     'gradient_accumulation_steps': 1,\n...     'learning_rate': 5e-5,\n...     'evaluate_during_training': True,\n...     'evaluate_during_training_steps': 1000,\n...     'save_eval_checkpoints': False,\n...     \"save_model_every_epoch\": False,\n...     'save_steps': -1,  # saving model unnecessarily takes time during training\n...     'reprocess_input_data': True,\n...     'num_train_epochs': 5,  # #2\n...     'use_early_stopping': True,\n...     'early_stopping_patience': 4,  # #3\n...     'early_stopping_delta': 0,\n... }\n```", "```py\n>>> model = MultiLabelClassificationModel(\n...     model_type, model_name, num_labels=len(labels),\n...     args=model_args)\n>>> model.train_model(\n...     train_df=train_df, eval_df=eval_df, acc=roc_auc_score,\n...     show_running_loss=False, verbose=False)\n```", "```py\n>>> best_model = MultiLabelClassificationModel(\n...     model_type, best_model_dir,\n...     num_labels=len(labels), args=model_args)\n>>> result, model_outputs, wrong_predictions = best_model.eval_model(\n...     eval_df, acc=roc_auc_score)\n>>> result\n{'LRAP': 0.996060542761153,\n 'acc': 0.9893854727083252,\n 'eval_loss': 0.040633044850540305}\n```"]