["```py\nimport os\nimport requests\nimport tarfile\n\n# Retrieve the data\nif *not* os.path.exists(os.path.join('data','VOCtrainval_11-May-2012.tar')): ❶\n    url = \"http:/ /host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-\n➥ May-2012.tar\"\n    # Get the file from web\n    r = requests.get(url)                                                  ❷\n\n    if *not* os.path.exists('data'):\n        os.mkdir('data')\n\n    # Write to a file\n    with open(os.path.join('data','VOCtrainval_11-May-2012.tar'), 'wb') as f:\n        f.write(r.content)                                                 ❸\nelse:\n    print(\"The tar file already exists.\")\n\nif *not* os.path.exists(os.path.join('data', 'VOCtrainval_11-May-2012')):    ❹\n    with tarfile.open(os.path.join('data','VOCtrainval_11-May-2012.tar'), 'r') as tar:\n        tar.extractall('data')\nelse:\n    print(\"The extracted data already exists\")\n```", "```py\nfrom PIL import Image\n\norig_image_path = os.path.join('data', 'VOCtrainval_11-May-2012', \n➥ 'VOCdevkit', 'VOC2012', 'JPEGImages', '2007_000661.jpg')\n\norig_image = Image.open(orig_image_path)\n```", "```py\nprint(\"The format of the data {}\".format(orig_image.format))\n>>> The format of the data JPEG\n\nprint(\"This image is of size: {}\".format(orig_image.shape))\n>>> This image is of size: (375, 500, 3)\n```", "```py\ndef rgb_image_from_palette(image):\n\n    \"\"\" This function restores the RGB values form a palletted PNG image \"\"\"\n    palette = image.get_palette()                                         ❶\n\n    palette = np.array(pallette).reshape(-1,3)                            ❷\n    if isinstance(image, PngImageFile):\n        h, w = image.height, image.width                                  ❸\n        # Squash height and width dimensions (makes slicing easier)\n        image = np.array(image).reshape(-1)                               ❹\n    elif isinstance(image, np.ndarray):                                   ❺\n        h, w = image.shape[0], image.shape[1]\n        image = image.reshape(-1)\n\n    rgb_image = np.zeros(shape=(image.shape[0],3))                        ❻\n    rgb_image[(image != 0),:] = pallette[image[(image != 0)], :]          ❻\n    rgb_image = rgb_image.reshape(h, w, 3)                                ❼\n\n    return rgb_image\n```", "```py\ndef get_subset_filenames(orig_dir, seg_dir, subset_dir, subset):\n    \"\"\" Get the filenames for a given subset (train/valid/test)\"\"\"\n\n    if subset.startswith('train'):\n        ser = pd.read_csv(                                            ❶\n            os.path.join(subset_dir, \"train.txt\"), \n            index_col=None, header=None, squeeze=True\n        ).tolist()\n        elif subset.startswith('val') or subset.startswith('test'):\n\n        random.seed(random_seed)                                      ❷\n\n        ser = pd.read_csv(                                            ❸\n            os.path.join(subset_dir, \"val.txt\"), \n            index_col=None, header=None, squeeze=True\n        ).tolist()\n\n        random.shuffle(ser)                                           ❹\n\n        if subset.startswith('val'):\n            ser = ser[:len(ser)//2]                                   ❺\n        else:\n            ser = ser[len(ser)//2:]                                   ❻\n    else:\n        raise NotImplementedError(\"Subset={} is not recognized\".format(subset))\n\n    orig_filenames = [os.path.join(orig_dir,f+'.jpg') for f in ser]   ❼\n    seg_filenames = [os.path.join(seg_dir, f+'.png') for f in ser]    ❽\n\n    for o, s in zip(orig_filenames, seg_filenames):\n        yield o, s                                                    ❾\n```", "```py\nfilename_ds = tf.data.Dataset.from_generator(\n        subset_filename_gen_func, output_types=(tf.string, tf.string)\n    )\n```", "```py\nt = [ [1,2,3,4],\n      [2,3,4,5],\n      [6,7,8,9] ]\n```", "```py\ntf.image.decode_jpeg(tf.io.read_file(image_filename))\n```", "```py\nfrom PIL import Image\n\ndef load_image_func(image):\n    \"\"\" Load the image given a filename \"\"\"\n\n    img =  np.array(Image.open(image))        \n    return img\n```", "```py\ntf.numpy_function(load_image_func, inp=[y], Tout=[tf.uint8])\n```", "```py\ndef load_image_func(image):\n    \"\"\" Load the image given a filename \"\"\"\n\n    img =  np.array(Image.open(image))        \n    return img\n\n# Load the images from the filenames returned by the above step\n    image_ds = filename_ds.map(lambda x,y: (\n        tf.image.decode_jpeg(tf.io.read_file(x)), \n        tf.numpy_function(load_image_func, [y], [tf.uint8])\n    ))\n```", "```py\n  dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4])\n```", "```py\n  dataset = dataset.map(lambda x: x**2)\n```", "```py\n  dataset = tf.data.Dataset.from_tensor_slices([[1,3], [2,4], [3,5], [4,6]])\n  dataset = dataset.map(lambda x, y: (x**2, y+x))\nwhich will return,\n[[1, 4], [4, 6], [9, 8], [16, 10]]\n```", "```py\nimage_ds = image_ds.map(lambda x, y: (tf.cast(x, 'float32')/255.0, y))\n```", "```py\nimage_ds = image_ds.batch(10)\n```", "```py\nInvalidArgumentError: Cannot batch tensors with different shapes in \n➥ component 0\\. First element had shape [375,500,3] and element 1 had \n➥ shape [333,500,3]. [Op:IteratorGetNext]\n```", "```py\ndef randomly_crop_or_resize(x,y):\n    \"\"\" Randomly crops or resizes the images \"\"\"\n\n    def rand_crop(x, y):                                                  ❶\n        \"\"\" Randomly crop images after enlarging them \"\"\"\n        x = tf.image.resize(x, resize_to_before_crop, method='bilinear')  ❷\n        y = tf.cast(                                                      ❸\n                tf.image.resize(\n                    tf.transpose(y,[1,2,0]),                              ❹\n                    resize_to_before_crop, method='nearest'\n                ),\n                'float32'\n            )          \n\n        offset_h = tf.random.uniform(\n            [], 0, x.shape[0]-input_size[0], dtype='int32'\n        )                                                                 ❺\n        offset_w = tf.random.uniform(\n            [], 0, x.shape[1]-input_size[1], dtype='int32'\n        )                                                                 ❻\n        x = tf.image.crop_to_bounding_box(\n            image=x, \n            offset_height=offset_h, offset_width=offset_w,\n            target_height=input_size[0], target_width=input_size[1]       ❼\n        )\n        y = tf.image.crop_to_bounding_box(\n            image=y, \n            offset_height=offset_h, offset_width=offset_w,\n            target_height=input_size[0], target_width=input_size[1]       ❼\n        )\n\n        return x, y\n\n    def resize(x, y):\n        \"\"\" Resize images to a desired size \"\"\"\n        x = tf.image.resize(x, input_size, method='bilinear')             ❽\n        y = tf.cast(\n                tf.image.resize(\n                    tf.transpose(y,[1,2,0]),                                        \n                    input_size, method='nearest'                          ❽\n                ),\n                'float32'\n            )          \n\n        return x, y\n\n    rand = tf.random.uniform([], 0.0,1.0)                                 ❾\n\n    if augmentation and \\                                                 ❿\n        (input_size[0] < resize_to_before_crop[0] or \\\n         input_size[1] < resize_to_before_crop[1]):\n        x, y = tf.cond(\n                rand < 0.5,                                               ⓫\n                lambda: rand_crop(x, y),\n                 lambda: resize(x, y)\n                )\n        else:\n            x, y = resize(x, y)                                           ⓬\n\n        return x, y\n```", "```py\nx = tf.image.crop_to_bounding_box(\n    image=x, \n    offset_height=offset_h, offset_width=offset_w,\n    target_height=input_size[0], target_width=input_size[1]                 \n)\ny = tf.image.crop_to_bounding_box(\n    image=y, \n    offset_height=offset_h, offset_width=offset_w,\n    target_height=input_size[0], target_width=input_size[1]               \n)\n```", "```py\n    image_ds = image_ds.map(lambda x,y: randomly_crop_or_resize(x,y))\n```", "```py\n(None, None, None)\n```", "```py\nt.set_shape([<shape of the tensor>])\n```", "```py\ndef fix_shape(x, y, size):\n    \"\"\" Set the shape of the input/target tensors \"\"\"\n\n    x.set_shape((size[0], size[1], 3))\n    y.set_shape((size[0], size[1], 1))\n\n    return x, y\n\nimage_ds = image_ds.map(lambda x,y: fix_shape(x,y, target_size=input_size))\n```", "```py\ndef randomly_flip_horizontal(x, y):\n    \"\"\" Randomly flip images horizontally. \"\"\"\n\n    rand = tf.random.uniform([], 0.0,1.0)                                           ❶\n\n    def flip(x, y):\n        return tf.image.flip_left_right(x), tf.image.flip_left_right(y)             ❷\n\n    x, y = tf.cond(rand < 0.5, lambda: flip(x, y), lambda: (x, y))                  ❸\n\n    return x, y\n\nif augmentation:    \n    image_ds = image_ds.map(lambda x, y: randomly_flip_horizontal(x,y))             ❹\n\n    image_ds = image_ds.map(lambda x, y: (tf.image.random_hue(x, 0.1), y))          ❺\n\n    image_ds = image_ds.map(lambda x, y: (tf.image.random_brightness(x, 0.1), y))   ❻\n\n    image_ds = image_ds.map(lambda x, y: (tf.image.random_contrast(x, 0.8, 1.2), y))❼\n```", "```py\nif output_size:\n    image_ds = image_ds.map(\n                   lambda x, y: (\n                       x, \n                       tf.image.resize(y, output_size, method='nearest')\n                   )\n    )\n```", "```py\nif shuffle:\n    image_ds = image_ds.shuffle(buffer_size=batch_size*5)\n```", "```py\nimage_ds = image_ds.batch(batch_size).repeat(epochs)\n```", "```py\nimage_ds = image_ds.map(lambda x, y: (x, tf.squeeze(y)))\n```", "```py\ndef get_subset_tf_dataset(\n    subset_filename_gen_func, batch_size, epochs, \n    input_size=(256, 256), output_size=None, resize_to_before_crop=None, \n    augmentation=False, shuffle=False\n):\n\n    if augmentation and not resize_to_before_crop:\n        raise RuntimeError(                                                          ❶\n            \"You must define resize_to_before_crop when augmentation is enabled.\"\n        )\n\n    filename_ds = tf.data.Dataset.from_generator(\n        subset_filename_gen_func, output_types=(tf.string, tf.string)                ❷\n    )\n\n image_ds = filename_ds.map(lambda x,y: (\n tf.image.decode_jpeg(tf.io.read_file(x)),                                   ❸\n tf.numpy_function(load_image_func, [y], [tf.uint8])\n )).cache()\n\n    image_ds = image_ds.map(lambda x, y: (tf.cast(x, 'float32')/255.0, y))           ❹\n\n    def randomly_crop_or_resize(x,y):                                                ❺\n        \"\"\" Randomly crops or resizes the images \"\"\"\n        ...\n\n        def rand_crop(x, y):\n            \"\"\" Randomly crop images after enlarging them \"\"\"\n            ...\n\n        def resize(x, y):\n            \"\"\" Resize images to a desired size \"\"\"\n            ...\n\n    image_ds = image_ds.map(lambda x,y: randomly_crop_or_resize(x,y))                ❻\n    image_ds = image_ds.map(lambda x,y: fix_shape(x,y, target_size=input_size))      ❼\n\n    if augmentation:    \n        image_ds = image_ds.map(lambda x, y: randomly_flip_horizontal(x,y))          ❽\n        image_ds = image_ds.map(lambda x, y: (tf.image.random_hue(x, 0.1), y))       ❽\n        image_ds = image_ds.map(lambda x, y: (tf.image.random_brightness(x, 0.1), y))❽\n        image_ds = image_ds.map(\n            lambda x, y: (tf.image.random_contrast(x, 0.8, 1.2), y)                  ❽\n        )\n\n    if output_size:\n        image_ds = image_ds.map(\n            lambda x, y: (x, tf.image.resize(y, output_size,  method='nearest'))     ❾\n        )\n\n    if shuffle:\n        image_ds = image_ds.shuffle(buffer_size=batch_size*5)                        ❿\n    image_ds = image_ds.batch(batch_size).repeat(epochs)                             ⓫\n\n    image_ds = image_ds.prefetch(tf.data.experimental.AUTOTUNE)                      ⓬\n\n    image_ds = image_ds.map(lambda x, y: (x, tf.squeeze(y)))                         ⓭\n\n    return image_ds                                                                  ⓮\n```", "```py\nimage_ds = filename_ds.map(lambda x,y: (\n tf.image.decode_jpeg(tf.io.read_file(x)), \n tf.numpy_function(load_image_func, [y], [tf.uint8])\n)).cache()\n```", "```py\nimage_ds = image_ds.prefetch(tf.data.experimental.AUTOTUNE)\n```", "```py\norig_dir = os.path.join(\n    'data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'JPEGImages'                 ❶\n)\nseg_dir = os.path.join(\n    'data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'SegmentationClass'          ❷\n)\nsubset_dir = os.path.join(\n    'data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'ImageSets',                 ❸\n    'Segmentation'\n)\n\npartial_subset_fn = partial(\n    get_subset_filenames, orig_dir=orig_dir, seg_dir=seg_dir, subset_dir=subset_dir         ❹\n)\ntrain_subset_fn = partial(partial_subset_fn, subset='train')                                ❺\nval_subset_fn = partial(partial_subset_fn, subset='val')                                    ❺\ntest_subset_fn = partial(partial_subset_fn, subset='test')                                  ❺\n\ninput_size = (384, 384)                                                                     ❻\n\ntr_image_ds = get_subset_tf_dataset(                                                        ❼\n    train_subset_fn, batch_size, epochs, \n    input_size=input_size, resize_to_before_crop=(444,444),\n    augmentation=True, shuffle=True\n)\nval_image_ds = get_subset_tf_dataset(                                                       ❽\n    val_subset_fn, batch_size, epochs, \n    input_size=input_size, \n    shuffle=False\n)\ntest_image_ds = get_subset_tf_dataset(                                                      ❾\n    test_subset_fn, batch_size, 1, \n    input_size=input_size, \n    shuffle=False\n)\n```", "```py\n# Pretrained model and the input\ninp = layers.Input(shape=target_size+(3,))\nresnet50 = tf.keras.applications.ResNet50(\n    include_top=False, input_tensor=inp,pooling=None\n)\n\nfor layer *in* resnet50.layers:\n    if layer.name == \"conv5_block1_1_conv\":\n        break\n    out = layer.output\n\nresnet50_upto_conv4 = models.Model(resnet50.input, out)\n```", "```py\ndef block_level3(\n    inp, filters, kernel_size, rate, block_id, convlayer_id, activation=True           ❶\n):\n    \"\"\" A single convolution layer with atrous convolution and batch normalization \n    inp: 4-D tensor having shape [batch_size, height, width, channels]\n    filters: number of output filters\n    kernel_size: The size of the convolution kernel\n    rate: dilation rate for atrous convolution\n    block_id, convlayer_id - IDs to distinguish different convolution blocks and layers\n    activation: If true ReLU is applied, if False no activation is applied\n    \"\"\"\n\n    conv5_block_conv_out = layers.Conv2D(\n        filters, kernel_size, dilation_rate=rate, padding='same',                      ❷\n        name='conv5_block{}_{}_conv'.format(block_id, convlayer_id)\n    )(inp)\n\n    conv5_block_bn_out = layers.BatchNormalization(\n        name='conv5_block{}_{}_bn'.format(block_id, convlayer_id)                      ❸\n    )(conv5_block_conv_out)\n\n    if activation:\n        conv5_block_relu_out = layers.Activation(\n            'relu', name='conv5_block{}_{}_relu'.format(block_id, convlayer_id)        ❹\n        )(conv5_block_bn_out)\n\n        return conv5_block_relu_out\n    else:\n        return conv5_block_bn_out                                                      ❺\n```", "```py\ndef block_level2(inp, rate, block_id):\n    \"\"\" A level 2 resnet block that consists of three level 3 blocks \"\"\"\n\n    block_1_out = block_level3(inp, 512, (1,1), rate, block_id, 1)\n    block_2_out = block_level3(block_1_out, 512, (3,3), rate, block_id, 2)\n    block_3_out = block_level3(\n        block_2_out, 2048, (1,1), rate, block_id, 3, activation=False\n    )\n\n    return block_3_out\n```", "```py\ndef resnet_block(inp, rate):\n    \"\"\" Redefining a resnet block with atrous convolution \"\"\"\n\n    block0_out = block_level3(\n        inp, 2048, (1,1), 1, block_id=1, convlayer_id=0, activation=False ❶\n    )\n    block1_out = block_level2(inp, 2, block_id=1)                         ❷\n    block1_add = layers.Add(\n        name='conv5_block{}_add'.format(1))([block0_out, block1_out]      ❸\n    )\n    block1_relu = layers.Activation(\n        'relu', name='conv5_block{}_relu'.format(1)                       ❹\n    )(block1_add)\n    block2_out = block_level2 (block1_relu, 2, block_id=2) # no relu      ❺\n    block2_add = layers.Add(\n        name='conv5_block{}_add'.format(2)                                ❻\n    )([block1_add, block2_out])\n    block2_relu = layers.Activation(\n        'relu', name='conv5_block{}_relu'.format(2)                       ❼\n    )(block2_add)\n\n    block3_out = block_level2 (block2_relu, 2, block_id=3)                ❽\n    block3_add = layers.Add(\n        name='conv5_block{}_add'.format(3)                                ❽\n    )([block2_add, block3_out])\n    block3_relu = layers.Activation(\n        'relu', name='conv5_block{}_relu'.format(3)                       ❽\n    )(block3_add)\n\n     return block3_relu\n```", "```py\nresnet_block4_out = resnet_block(resnet50_upto_conv4.output, 2)\n```", "```py\ndef atrous_spatial_pyramid_pooling(inp):\n    \"\"\" Defining the ASPP (Atrous spatial pyramid pooling) module \"\"\"\n\n    # Part A: 1x1 and atrous convolutions\n    outa_1_conv = block_level3(\n        inp, 256, (1,1), 1, '_aspp_a', 1, activation='relu'\n    )                                                                                 ❶\n    outa_2_conv = block_level3(\n        inp, 256, (3,3), 6, '_aspp_a', 2, activation='relu'\n    )                                                                                 ❷\n    outa_3_conv = block_level3(\n        inp, 256, (3,3), 12, '_aspp_a', 3, activation='relu'\n    )                                                                                 ❸\n    outa_4_conv = block_level3(\n        inp, 256, (3,3), 18, '_aspp_a', 4, activation='relu'\n    )                                                                                 ❹\n\n    # Part B: global pooling\n    outb_1_avg = layers.Lambda(\n        lambda x: K.mean(x, axis=[1,2], keepdims=True)\n    )(inp)                                                                            ❺\n    outb_1_conv = block_level3(\n        outb_1_avg, 256, (1,1), 1, '_aspp_b', 1, activation='relu'                    ❻\n    )\n    outb_1_up = layers.UpSampling2D((24,24), interpolation='bilinear')(outb_1_avg)    ❼\n    out_aspp = layers.Concatenate()(\n        [outa_1_conv, outa_2_conv, outa_3_conv, outa_4_conv, outb_1_up]               ❽\n    )   \n\n    return out_aspp\n\nout_aspp = atrous_spatial_pyramid_pooling(resnet_block4_out)                          ❾\n```", "```py\noutb_1_avg = layers.Lambda(lambda x: K.mean(x, axis=[1,2], keepdims=True))(inp)\n```", "```py\noutb_1_up = layers.UpSampling2D((24,24), interpolation='bilinear')(outb_1_avg)\n```", "```py\ninp = layers.Input(shape=target_size+(3,))                               ❶\n\nresnet50= tf.keras.applications.ResNet50(\n    include_top=False, input_tensor=inp,pooling=None                     ❷\n)\n\nfor layer *in* resnet50.layers:\n    if layer.name == \"conv5_block1_1_conv\":\n        break\n    out = layer.output                                                   ❸\n\nresnet50_upto_conv4 = models.Model(resnet50.input, out)                  ❹\n\nresnet_block4_out = resnet_block(resnet50_upto_conv4.output, 2)          ❺\n\nout_aspp = atrous_spatial_pyramid_pooling(resnet_block4_out)             ❻\n\nout = layers.Conv2D(21, (1,1), padding='same')(out_aspp)                 ❼\nfinal_out = layers.UpSampling2D((16,16), interpolation='bilinear')(out)  ❼\n\ndeeplabv3 = models.Model(resnet50_upto_conv4.input, final_out)           ❽\n```", "```py\nw_dict = {}\nfor l *in* [\"conv5_block1_0_conv\", \"conv5_block1_0_bn\", \n          \"conv5_block1_1_conv\", \"conv5_block1_1_bn\", \n          \"conv5_block1_2_conv\", \"conv5_block1_2_bn\", \n          \"conv5_block1_3_conv\", \"conv5_block1_3_bn\"]:\n    w_dict[l] = resnet50.get_layer(l).get_weights()\n```", "```py\ndef get_label_weights(y_true, y_pred):\n\n    weights = tf.reduce_sum(tf.one_hot(y_true, num_classes), axis=[1,2])  ❶\n\n    tot = tf.reduce_sum(weights, axis=-1, keepdims=True)                  ❷\n\n    weights = (tot - weights) / tot  # [b, classes]                       ❸\n\n    y_true = tf.reshape(y_true, [-1, y_pred.shape[1]*y_pred.shape[2]])    ❹\n\n    y_weights = tf.gather(params=weights, indices=y_true, batch_dims=1)   ❺\n    y_weights = tf.reshape(y_weights, [-1])                               ❻\n\n    return y_weights\n```", "```py\ny_weights = tf.gather(params=weights, indices=y_true, batch_dims=1)\n```", "```py\ndef ce_weighted_from_logits(num_classes):\n\n    def loss_fn(y_true, y_pred):\n        \"\"\" Defining cross entropy weighted loss \"\"\"\n\n        valid_mask = tf.cast(\n            tf.reshape((y_true <= num_classes - 1), [-1,1]), 'int32'\n        )                                                                ❶\n\n        y_true = tf.cast(y_true, 'int32')                                ❷\n        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])       ❷\n\n        y_weights = get_label_weights(y_true, y_pred)                    ❸\n        y_pred_unwrap = tf.reshape(y_pred, [-1, num_classes])            ❹\n        y_true_unwrap = tf.reshape(y_true, [-1])                         ❹\n\n        return tf.reduce_mean(\n            y_weights * tf.nn.sparse_softmax_cross_entropy_with_logits(  ❺\n                y_true_unwrap * tf.squeeze(valid_mask), \n                y_pred_unwrap * tf.cast(valid_mask, 'float32')) \n        )\n\n    return loss_fn                                                       ❻\n```", "```py\ndef dice_loss_from_logits(num_classes):\n    \"\"\" Defining the dice loss 1 - [(2* i + 1)/(u + i)]\"\"\"    \n\n    def loss_fn(y_true, y_pred):\n\n        smooth = 1.\n\n        # Convert y_true to int and set shape\n        y_true = tf.cast(y_true, 'int32')                                      ❶\n        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])             ❶\n\n        # Get pixel weights\n        y_weights = tf.reshape(get_label_weights(y_true, y_pred), [-1, 1])     ❷\n\n        # Apply softmax to logits      \n        y_pred = tf.nn.softmax(y_pred)                                         ❸\n\n        y_true_unwrap = tf.reshape(y_true, [-1])                               ❹\n        y_true_unwrap = tf.cast(\n            tf.one_hot(tf.cast(y_true_unwrap, 'int32'), num_classes), \n➥ 'float32'\n        )                                                                      ❹\n        y_pred_unwrap = tf.reshape(y_pred, [-1, num_classes])                  ❹\n\n        intersection = tf.reduce_sum(y_true_unwrap * y_pred_unwrap * y_weights)❺\n\n        union = tf.reduce_sum((y_true_unwrap + y_pred_unwrap) * y_weights)     ❻\n\n        score = (2\\. * intersection + smooth) / ( union + smooth)               ❼\n\n        loss = 1 - score                                                       ❽\n\n        return loss\n\n    return loss_fn\n```", "```py\ndef ce_dice_loss_from_logits(num_classes):\n\n    def loss_fn(y_true, y_pred):\n        # Sum of cross entropy and dice losses\n        loss = ce_weighted_from_logits(num_classes)(\n            tf.cast(y_true, 'int32'), y_pred\n        ) + dice_loss_from_logits(num_classes)(\n            y_true, y_pred\n        )    \n\n        return loss\n\n    return loss_fn \n```", "```py\nclass MyMetric(tf.keras.metrics.Metric):\n\n  def __init__(self, name='binary_true_positives', **kwargs):\n    super(MyMetric, self).__init__(name=name, **kwargs)\n\n    # Create state related variables\n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n\n    # update state in this function\n\n  def result(self):\n\n    # We return the result computed from the state\n\n  def reset_states():\n    # Do what’s required to reset the maintained states\n    # This function is called between epochs     \n```", "```py\nclass PixelAccuracyMetric(tf.keras.metrics.Accuracy):\n\n  def __init__(self, num_classes, name='pixel_accuracy', **kwargs):\n    super(PixelAccuracyMetric, self).__init__(name=name, **kwargs)    \n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n\n    y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])      ❶\n    y_true = tf.reshape(y_true, [-1])                               ❷\n\n    y_pred = tf.reshape(tf.argmax(y_pred, axis=-1),[-1])            ❸\n\n    valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])      ❹\n\n    y_true = tf.boolean_mask(y_true, valid_mask)                    ❺\n    y_pred = tf.boolean_mask(y_pred, valid_mask)                    ❺\n\n    super(PixelAccuracyMetric, self).update_state(y_true, y_pred)   ❻\n```", "```py\nclass MeanAccuracyMetric(tf.keras.metrics.Mean):\n\n  def __init__(self, num_classes, name='mean_accuracy', **kwargs):\n    super(MeanAccuracyMetric, self).__init__(name=name, **kwargs)    \n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n\n    smooth = 1            \n\n    y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])             ❶\n\n    y_true = tf.reshape(y_true, [-1])                                      ❶\n    y_pred = tf.reshape(tf.argmax(y_pred, axis=-1),[-1])                   ❶\n\n    valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])             ❶\n\n    y_true = tf.boolean_mask(y_true, valid_mask)                           ❶\n    y_pred = tf.boolean_mask(y_pred, valid_mask)                           ❶\n\n    conf_matrix = tf.cast(                                                            \n        tf.math.confusion_matrix(y_true, y_pred, num_classes=num_classes), \n➥ 'float32'                                                               ❷\n    )\n    true_pos = tf.linalg.diag_part(conf_matrix)                            ❸\n\n    mean_accuracy = tf.reduce_mean(\n        (true_pos + smooth)/(tf.reduce_sum(conf_matrix, axis=1) + smooth)  ❹\n    )\n\n    super(MeanAccuracyMetric, self).update_state(mean_accuracy)            ❺\n```", "```py\nclass MeanIoUMetric(tf.keras.metrics.MeanIoU):\n\n  def __init__(self, num_classes, name='mean_iou', **kwargs):\n    super(MeanIoUMetric, self).__init__(num_classes=num_classes, name=name, **kwargs)    \n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n\n    y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n    y_true = tf.reshape(y_true, [-1])\n\n    y_pred = tf.reshape(tf.argmax(y_pred, axis=-1),[-1])\n\n    valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])\n\n    # Get pixels corresponding to valid mask\n    y_true = tf.boolean_mask(y_true, valid_mask)\n    y_pred = tf.boolean_mask(y_pred, valid_mask)\n\n    super(MeanIoUMetric, self).update_state(y_true, y_pred)    ❶\n```", "```py\ndeeplabv3.compile(\n    loss=ce_dice_loss_from_logits(num_classes), \n    optimizer=optimizer, \n    metrics=[\n        MeanIoUMetric(num_classes), \n        MeanAccuracyMetric(num_classes), \n        PixelAccuracyMetric(num_classes)\n    ])\n```", "```py\n# Setting weights for newly added layers\nfor k, w *in* w_dict.items():    \n    deeplabv3.get_layer(k).set_weights(w)\n```", "```py\nif *not* os.path.exists('eval'):\n    os.mkdir('eval')\n\ncsv_logger = tf.keras.callbacks.CSVLogger(\n    os.path.join('eval','1_pretrained_deeplabv3.log')                      ❶\n\nmonitor_metric = 'val_loss'\nmode = 'min' if 'loss' *in* monitor_metric else 'max'                        ❷\nprint(\"Using metric={} and mode={} for EarlyStopping\".format(monitor_metric, mode))\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=monitor_metric, factor=0.1, patience=3, mode=mode, min_lr=1e-8 ❸\n)\nes_callback = tf.keras.callbacks.EarlyStopping(\n    monitor=monitor_metric, patience=6, mode=mode                          ❹\n)\n\n# Train the model\ndeeplabv3.fit(                                                             ❺\n    x=tr_image_ds, steps_per_epoch=n_train,\n    validation_data=val_image_ds, validation_steps=n_valid, \n    epochs=epochs, callbacks=[lr_callback, csv_logger, es_callback])\n```", "```py\ndeeplabv3.evaluate(test_image_ds, steps=n_valid)\n```", "```py\npalettized_image = np.zeros(shape=rgb_image.shape[:-1])\nfor i in range(rgb_image.shape[0]):\n    for j in range(rgb_image.shape[1]):\n        for k in range(palette.shape[0]):\n            if (palette[k] == rgb_image[i,j]).all():\n                palettized_image[i,j] = k\n                break\n```", "```py\ndataset_a = tf.data.Dataset.from_tensor_slices(a)\ndataset_b = tf.data.Dataset.from_tensor_slices(b)\n\nimage_ds = tf.data.Dataset.zip((dataset_a, dataset_b))\n\nimage_ds = image_ds.map(\n            lambda x, y: (x, tf.image.resize(y, (64,64),  method='nearest'))\n        )\n\nimage_ds = image_ds.map(\n            lambda x, y: ((x-128.0)/255.0, tf.image.resize(y, (64,64),  method='nearest'))\n        )\n\nimage_ds = image_ds.batch(32).repeat(5).prefetch(tf.data.experimental.AUTOTUNE)\n```", "```py\nimport tensorflow.keras.layers as layers\n\ndef aug_aspp(out_1, out_2):\n\n    atrous_out_1 = layers.Conv2D(128, (3,3), dilation_rate=16, \n➥ padding='same', activation='relu')(out_1)\n\n    atrous_out_2_1 = layers.Conv2D(128, (3,3), dilation_rate=8, \n➥ padding='same', activation='relu')(out_1)\n    atrous_out_2_2 = layers.Conv2D(128, (3,3), dilation_rate=8, \n➥ padding='same', activation='relu')(out_2)\n    atrous_out_2 = layers.Concatenate()([atrous_out_2_1, atrous_out_2_2])\n\n    tmp1 = layers.Conv2D(64, (1,1), padding='same', activation='relu')(atrous_out_1)\n    tmp2 = layers.Conv2D(64, (1,1), padding='same', activation='relu')(atrous_out_2)\n    conv_out = layers.Concatenate()([tmp1,tmp2])\n\n    out = layers.UpSampling2D((2,2), interpolation='bilinear')(conv_out)\n    out = layers.Activation('sigmoid')(out)\n\n    return out\n```", "```py\nout = (y_pred - (y_pred * y_true)) + (y_true - (y_pred * y_true))\n```", "```py\ndef get_top_n_bad_examples(model, batch_images, batch_targets, n):\n\n    batch_pred = model.predict(batch_images)\n\n    batch_loss = tf.reduce_sum(batch_pred*batch_targets, axis=[1,2,3])\n\n    _, hard_inds = tf.math.top_k(batch_loss, n)\n\n    return hard_inds\n```"]