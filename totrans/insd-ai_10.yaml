- en: 10 Learning from successful and failed applications of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Successful uses of AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problematic uses of AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failed AI applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of good data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendations for using AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to plan an AI project and set an AI project up for success
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every AI project, whether it succeeds or faces challenges, offers valuable lessons.
    Learning from these experiences empowers us to make informed decisions, guiding
    our AI projects toward success while avoiding common pitfalls. In this chapter,
    we explore the lessons learned from both the mistakes and achievements of past
    projects because it’s crucial to understand the factors that determine AI project
    outcomes. I will also share valuable advice on building the right team, fostering
    the appropriate mindset, and developing a promising plan for your AI project.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1 AI successes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Artificial intelligence has already proven its worth across a multitude of specific,
    well-defined applications, demonstrating its potential to revolutionize various
    sectors. In this discussion, we will explore these AI applications and their significant
    effect on our lives, while also acknowledging the limitations of current technology
    and offering insights into the characteristics of next-generation systems.
  prefs: []
  type: TYPE_NORMAL
- en: One of the prominent areas where AI has delivered substantial benefits is in
    the domain of fraud prevention. The importance of this field has surged in tandem
    with the exponential growth of online business transactions. According to Statista,
    in 2020, over 2 billion people globally made online purchases, resulting in e-retail
    sales surpassing a staggering $4.2 trillion [1]. The convenience, competitive
    pricing, and increased options offered by online shopping have drawn consumers
    in, but unfortunately, they have also attracted the attention of criminals. Online
    retailers face a daunting challenge as the rate of fraud committed against them
    exceeds 10 times that experienced by traditional brick-and-mortar stores. This
    discrepancy arises due to several factors, including the ease with which one can
    misrepresent identity during virtual transactions, the absence of face-to-face
    interactions that could reveal suspicious behavior, and the inability to verify
    card ownership or signatures. Credit card fraud can manifest through the loss
    or theft of a physical card, but more frequently, it results from the illicit
    acquisition of individuals’ information. For instance, criminals employ devices
    like card skimmers to clandestinely capture credit or debit card details, often
    discreetly placed in ATM card slots or gas pump keypads. This pilfered information
    is then utilized for unauthorized online purchases or other criminal activities.
    The Nilson Report’s December 2020 edition revealed the staggering scale of the
    problem, stating that global fraud losses from card transactions reached $28.65
    billion, representing a 2.9% increase from the previous year [2]. These figures,
    however, do not include the additional expenses borne by card issuers, merchants,
    and acquirers. Costs related to fraud investigations, customer complaints, and
    call center management further underscore the comprehensive effect of fraud on
    the e-commerce ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: The Federal Trade Commission (FTC) echoed these alarming statistics in February
    2021, reporting a staggering 2.2 million fraud reports from consumers in the preceding
    year, with losses surpassing $3.3 billion, a significant increase from the previous
    year [3]. These figures emphasize the critical importance of transaction security
    for the entire e-commerce infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: To combat this pervasive problem, AI has proven to be an invaluable ally in
    real-time fraud prevention. Early iterations relied on fraud scanners that stored
    known fraud indicators in a database, but these were often labor-intensive and
    had limited detection rates. Today, cutting-edge solutions like iPrevent™, developed
    by Brighterion (now a Mastercard company), use a combination of advanced AI technologies
    to continuously monitor entities’ behavior, swiftly detecting anomalies and thwarting
    fraud attempts with high accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The transformative potential of AI extends to every sector, with its versatility
    profoundly affecting industries that shape our daily lives. For instance, in the
    retail sector, AI and machine learning serve as invaluable tools for streamlining
    operations. Retailers are harnessing the predictive power of AI to enhance their
    demand forecasting capabilities. By analyzing vast amounts of data, AI can anticipate
    customer preferences with unparalleled accuracy. Additionally, AI-powered inventory
    management systems are optimizing stock levels, ensuring that products are readily
    available when and where they are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, AI-driven order fulfillment systems are revolutionizing the supply
    chain, enhancing efficiency and, ultimately, boosting customer satisfaction. Airlines
    have also embraced AI to transform their operations. AI algorithms are instrumental
    in reducing flight delays by optimizing flight schedules to minimize disruptions.
    Maintenance schedules benefit from AI’s predictive maintenance capabilities, effectively
    reducing downtime and enhancing safety through the early detection of potential
    problems. Safety measures have been elevated through AI-assisted pilot training
    programs and real-time monitoring systems, making air travel more reliable and
    secure. In the agricultural sector, AI plays a pivotal role in ensuring crop health
    and optimizing resource utilization. AI-powered sensors and drones are deployed
    to detect diseases, preventing potential crop losses. Utilities rely on AI for
    precise power demand forecasting, a critical component of the energy sector. AI
    models analyze historical consumption patterns, weather data, and various other
    variables to predict energy demand accurately. As AI technology continues to advance,
    we can anticipate even more innovative applications across a broad spectrum of
    sectors, further revolutionizing how we live, work, and interact with the world
    around us.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2 AI misuse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we shift our focus from celebrated AI achievements to its less successful
    applications, it is crucial to explore domains where the deployment of AI might
    not be in our best interest at all. The potential for AI to cause harm is as significant
    as its capacity to assist, underscoring the need for vigilant consideration of
    the potential perils it may pose to society. In this chapter, we will examine
    three prominent examples: deepfakes, cyberbullying, and criminal profiling.'
  prefs: []
  type: TYPE_NORMAL
- en: Deepfakes represent a relatively recent and formidable threat arising from the
    utilization of deep learning techniques to fabricate synthetic media. While the
    capacity to generate authentic-sounding audio and video of events that never transpired
    might be a boon for filmmakers, it poses a substantial risk to individuals, corporations,
    nations, and their governing bodies. This technology has the potential to be wielded
    nefariously, such as influencing an election by skillfully portraying a political
    opponent in a compromising scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Our escalating dependence on electronic media exacerbates the gravity of this
    problem. By disseminating a deepfake press release purportedly from the CEO of
    a prominent corporation, stock prices could be artificially manipulated, potentially
    leading to severe financial repercussions. This could be orchestrated to reap
    illicit profits, favor one company over another, or merely sow chaos. For instance,
    a deep neural network, meticulously trained on every interview Elon Musk has ever
    given, could be employed to craft a persuasive video in which Musk appears to
    announce Tesla’s bankruptcy. By the time the deception is uncovered and made public,
    irreparable harm would have already been inflicted.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, deepfakes have the potential to exacerbate cyberbullying, which
    encompasses the use of electronic devices to torment or intimidate individuals.
    This problem is regrettably on the rise, as evidenced by statistics from a US
    government anti-bullying website, which indicated that approximately 15 percent
    of American high school students were victims of cyberbullying in 2019\. The application
    of deepfakes in the context of cyberbullying is distressingly clear, necessitating
    concerted efforts to prevent such abusive use of this technology. Cyberbullying
    is not confined solely to young people; it also has the potential to be wielded
    as a weapon by extremist groups or adversarial governments. For instance, a dictator
    could mobilize a cadre of “electronic operatives” to target members of an opposition
    faction. Their mandate would be to disseminate false information and sow discord
    through vehement, personal attacks. Additionally, they could conduct campaigns
    to surveil the internet and social media for any critical remarks about their
    regime. By flagging such content as inappropriate, they could trigger its automatic
    removal through content-filtering algorithms, thereby manipulating and distorting
    public perception.
  prefs: []
  type: TYPE_NORMAL
- en: One particularly disturbing and ethically concerning area is the application
    of AI in criminal profiling. The fundamental principle guiding any decision that
    affects an individual’s life or well-being should be one of rationality, objectivity,
    and the absence of bias or prejudice. Regrettably, some US municipalities have
    inadvertently misused AI in ways that have had detrimental consequences. In an
    eye-opening 2016 BBC article titled “How Maths Can Get You Locked Up” [4], it
    was revealed that “Criminals in the U.S. can be assigned computer-generated ‘risk
    scores,’ which can influence the length of their sentences.” These risk scores
    are derived from a person’s educational and professional history, as well as personal
    information, such as whether any of their friends or family have a criminal record
    and whether they reside in a high-crime neighborhood. Additionally, individuals
    may be subjected to assessments, with their scores potentially affected by their
    responses to morally charged questions like, “Is it acceptable for a starving
    person to steal food?” These numerical scores, ranging from 0 to 10, are then
    employed to make critical decisions, such as whether someone can be granted bail,
    whether they should be incarcerated, given an alternative sentence, or even considered
    for parole once inside the prison system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The troubling implications of these algorithmic evaluations were further illuminated
    by ProPublica’s comprehensive 2016 study on machine bias [5]. Such risk assessments,
    using predictive algorithms, have become increasingly prevalent in courtrooms
    throughout the United States. They are employed to inform decisions at every stage
    of the criminal justice process, from setting bond amounts in places like Fort
    Lauderdale to making more profound judgments about the liberty of defendants.
    These algorithms have been adopted in states such as Arizona, Colorado, Delaware,
    Kentucky, Louisiana, Oklahoma, Virginia, Washington, and Wisconsin, where their
    results are presented to judges during the process of criminal sentencing. ProPublica
    analyzed the risk scores assigned to over 7,000 individuals arrested in Broward
    County, Florida, in 2013 and 2014\. They compared these scores with subsequent
    criminal behavior over the following two years, which was the same benchmark used
    by the creators of the algorithm. Their findings were worrying: the risk score
    proved to be remarkably unreliable in predicting violent crimes, with only 20
    percent of individuals predicted to commit violent offenses actually doing so.'
  prefs: []
  type: TYPE_NORMAL
- en: When considering a broader spectrum of offenses, including misdemeanors such
    as driving with an expired license, the algorithm performed only slightly better
    than a coin toss. What’s even more concerning is that the formula exhibited a
    clear bias. It was more likely to flag black defendants as future criminals at
    almost twice the rate of white defendants, although the company responsible for
    creating the algorithm disputes these findings. In cases where any uncertainty
    exists, it’s imperative that we proceed with caution before allowing algorithms
    to affect the lives and freedoms of our citizens. A system with low predictive
    accuracy that is known to introduce bias should, without question, not be used.
  prefs: []
  type: TYPE_NORMAL
- en: The adoption of AI for legal decision-making necessitates its careful consideration.
    Can we realistically expect any AI system to adequately account for the mental
    health status of convicts? If someone’s behavioral problems can be resolved with
    the proper medication or social support, should we trust a computer program to
    determine whether incarceration or probation serves the best interests of society?
  prefs: []
  type: TYPE_NORMAL
- en: As Margrethe Vestager, the current executive vice president of the European
    Commission’s A Europe Fit for the Digital Age, wisely stated, “On artificial intelligence,
    trust is a must, not a nice-to-have” [6]. The European Union’s stance of disallowing
    the use of any nontransparent and untrustworthy systems is commendable. Solutions
    that affect individuals must undergo validation to ensure their designs meet stringent
    technical and ethical standards, addressing concerns such as reliability, fairness,
    privacy, transparency, and explicability. Any AI system directly affecting citizens
    should, at a minimum, undergo a certification process similar to the rigorous
    evaluation demanded by the US Food and Drug Administration before a new medication
    can be brought to market. Such systems should unequivocally demonstrate a lack
    of bias, employ clear and comprehensible logic, and make decisions that can be
    explained in plain language to those affected. Without adhering to these minimum
    requirements, the risks of AI causing more harm than good remain unacceptably
    high.
  prefs: []
  type: TYPE_NORMAL
- en: 10.3 AI failures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our exploration of high-profile projects that fell short of their anticipated
    outcomes, we journey back to 1982, exploring Japan’s renowned Fifth Generation
    Computer System (FGCS). This endeavor was marked by its ambitious scope, a characteristic
    that ultimately contributed to its downfall.
  prefs: []
  type: TYPE_NORMAL
- en: The principal objective of the FGCS project was to pioneer the development of
    computers equipped with multiple processors, each employing specialized logic
    to execute multiple programs simultaneously in parallel. These innovative, non–von
    Neumann systems were designed to excel at processing inference through the utilization
    of knowledge bases and expert system mechanisms, concepts that were elaborated
    upon in chapter 2\. In a bid to achieve this, the FGCS team even went so far as
    to create its very own programming language, KL1, meticulously optimized to facilitate
    parallel inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'The FGCS project was anticipated to lead in a new era of AI with the ability
    to reason and perform tasks such as natural language processing and disease diagnosis.
    Over the course of a decade and with an investment exceeding $1 billion, the project
    was seen as a colossal undertaking. However, despite its substantial resources
    and dedicated efforts, FGCS fell short of its lofty goals. Reflecting on the project’s
    shortcomings, FGCS director Kazuhiro Fuchi lamented [7]:'
  prefs: []
  type: TYPE_NORMAL
- en: In those days, we had to face criticism, based upon that false image that it
    was a reckless project trying to tackle impossible goals. Now we see criticism,
    from inside and outside the country, that the project has failed because it has
    been unable to realize those grand goals.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This case study offers an invaluable lesson for those embarking on AI projects:
    it underscores the vital importance of meticulously defining the scope and limitations
    of your project. The FGCS project serves as a cautionary tale, highlighting how
    even well-funded and ambitious initiatives can fail when objectives are not clearly
    delineated and achievable. It reminds us that while high aspirations are commendable,
    they must be grounded in realistic expectations to ensure the success of any AI
    venture.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another valuable lesson can be drawn from a medical diagnostic experiment outlined
    in the article titled “Intelligible Models for Healthcare: Predicting Pneumonia
    Risk and Hospital 30-day Readmission” [8]. This study examined the application
    of machine learning to improve the triage procedure for individuals who have pneumonia
    symptoms. The article demonstrated that the machine learning model committed a
    life-threatening mistake by classifying asthmatic patients with pneumonia as “low
    risk.”'
  prefs: []
  type: TYPE_NORMAL
- en: The root of this problem lies in the data and the model’s ability to learn from
    it. The model, like many other machine learning algorithms, learned from patterns
    in the data it was trained on. In this case, it mistakenly inferred from the data
    that asthma was somehow associated with a reduced risk of developing pneumonia.
    This discrepancy between the model’s predictions and the real world resulted from
    the fact that aggressive care administered to asthmatic pneumonia patients effectively
    lowered their pneumonia-related mortality rate compared to the general population.
    This led the machine learning model to make the erroneous assumption that asthma,
    in isolation, reduced the risk of pneumonia when, in reality, asthmatic patients
    faced substantially higher risks if not hospitalized promptly.
  prefs: []
  type: TYPE_NORMAL
- en: This example highlights the critical importance of human intervention in the
    validation process, providing invaluable insights into the data and attributes
    considered by the model and the expected responses based on deep knowledge of
    the subject matter. Such human input helps ensure that no critical information
    is overlooked and that the model aligns with the actual complexities of the problem
    it aims to address. Moreover, this example emphasizes the important link between
    data science and domain expertise. While machine learning algorithms can analyze
    vast datasets and extract patterns, they often depend on human guidance to interpret
    the context correctly and prevent potentially dangerous misinterpretations. Collaborations
    between data scientists and domain experts remain essential in harnessing the
    full potential of machine learning for complex and mission-critical applications,
    such as healthcare.
  prefs: []
  type: TYPE_NORMAL
- en: 'The landscape of AI and chatbot development has been marked by notable failures
    that serve as valuable lessons in understanding the limitations of technology.
    One such incident occurred on March 23, 2016, when Microsoft hastily terminated
    its chatbot project, Tay, a mere 16 hours after its launch on Twitter. This abrupt
    decision raised questions, especially considering the several years of development
    and significant financial investment, estimated to be over $100 million. So, why
    did Microsoft pull the plug so swiftly? In a blog post [9], Microsoft provided
    insights into its reasoning:'
  prefs: []
  type: TYPE_NORMAL
- en: As we developed Tay, we planned and implemented a lot of filtering and conducted
    extensive user studies with diverse user groups. We stress-tested Tay under a
    variety of conditions, specifically to make interacting with Tay a positive experience.
    Once we got comfortable with how Tay was interacting with users, we wanted to
    invite a broader group of people to engage with her. It’s through increased interaction
    where we expected to learn more and for the AI to get better and better.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tay’s journey took a disconcerting turn as it began absorbing offensive and
    vulgar content from Twitter users. It swiftly spiraled into posting sexist and
    racist comments, and at one point, it infamously endorsed the abhorrent statement
    that “Hitler was right.” The discovery that users could manipulate Tay into reposting
    their own content by simply instructing it to “Repeat after me” became the nail
    in the coffin for the project. Similarly, the chatbot BlenderBot3, released in
    August 2022 by Facebook (Meta), exhibited the same vulnerabilities and repeated
    the same mistakes as Tay. While these AI systems may appear intelligent to the
    uninitiated, they lack a true understanding of the content they post. Their responses
    are algorithmic, and their interaction is fundamentally dissimilar to human conversation.
  prefs: []
  type: TYPE_NORMAL
- en: These problems are not limited to chatbots alone; they extend to content recommendation
    algorithms that determine what users see based on the behavior of “similar” individuals.
    This practice can inadvertently lead to the proliferation of radical or inappropriate
    content. Whistleblowers have revealed that recommendation engines are often designed
    to maximize user engagement, achieved most readily by suggesting increasingly
    extreme content. The longer a user remains engaged, the more advertising revenue
    is generated. While such engagement aligns with a company’s financial interests,
    it poses a severe societal risk. For instance, misleading antivaccination information
    can be thrust upon individuals who otherwise have no interest in it. Furthermore,
    misinformation and propaganda can be weaponized by antidemocratic nations or groups
    with intentions to meddle in elections. Social media bots designed to draw users
    in can inadvertently breed divisiveness and estrange people from one another.
  prefs: []
  type: TYPE_NORMAL
- en: The most important lesson derived from these chatbot fiascos and related engagement
    technologies is a stark reminder that these programs lack genuine understanding.
    They function like dictionaries that contain words but possess no comprehension
    of their meanings, and it is important to remain cognizant of this fundamental
    limitation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although we might understand how the subtleties of human language could present
    challenges to AI, one might assume that numerical and data-driven domains, like
    the stock market, would be a perfect match for AI’s capabilities. After all, as
    computing technology has advanced in recent decades, hedge fund managers have
    increasingly turned to machine learning algorithms in the hopes of gaining a competitive
    edge in financial markets. However, the reality has been somewhat different, with
    several firms worth hundreds of millions of dollars experiencing financial ruin
    in their pursuit of AI-driven investment strategies. The question that arises
    is: How could this happen?'
  prefs: []
  type: TYPE_NORMAL
- en: One compelling explanation for the recent disappointing performance of these
    AI-powered investment strategies lies in the unprecedented and unexpected actions
    taken by both the government and the Federal Reserve in response to the COVID-19
    pandemic. These firms relied on mathematics and machine learning to predict market
    movements. Yet, the onset of a global pandemic brought forth a set of circumstances
    that was entirely unforeseen, rendering their AI systems essentially blind to
    the rapidly evolving financial landscape, leaving these firms in the unenviable
    position of having to explain to investors why their once-promising AI-driven
    investment decisions were falling short.
  prefs: []
  type: TYPE_NORMAL
- en: A case in point is the renowned Renaissance Institutional Equities Fund (RIEF),
    whose disappointing performance led to an exodus of investors. A 2021 *Wall Street
    Journal* article titled “James Simons Steps Down as Chairman of Renaissance Technologies”
    [10] highlighted the fund’s struggles, with one investor appropriately stating,
    “The RIEF’s machine-learning models cracked.” Indeed, this succinctly encapsulates
    the fund’s predicament, having lost 20 percent of its value at a time when the
    broader stock market soared by over 40 percent.
  prefs: []
  type: TYPE_NORMAL
- en: These costly and unfortunate failures in the stock market are a reminder of
    the inherent challenges in making AI systems truly adaptive. While supervised
    learning approaches can yield impressive results when the cases being analyzed
    closely align with the training examples, they are intrinsically limited when
    circumstances evolve rapidly and behaviors become unpredictable. In essence, AI
    models, no matter how sophisticated, can quickly become obsolete in the face of
    unforeseen events and dynamic, ever-changing environments. Let’s continue by exploring
    two compelling case studies, from IBM’s Watson and the real estate marketplace
    giant, Zillow.
  prefs: []
  type: TYPE_NORMAL
- en: First, as mentioned before, IBM’s Watson gained significant attention after
    its victory against Jeopardy! champions, an accomplishment that demonstrated the
    remarkable capabilities of AI in answering trivia questions. However, a stark
    contrast emerges between Watson’s early success on a quiz show and its subsequent
    struggles with medical diagnosis. This contrast serves as a poignant reminder
    of the complexity inherent in medical reasoning. IBM made a substantial investment
    in Watson, amounting to billions of dollars, with the hope that it could revolutionize
    healthcare. One of the projects was to create a machine that could not only assist
    oncologists with their insights but also facilitate pharmaceutical development
    and connect patients with relevant clinical trials. A decade after its impressive
    game show performance in 2011, IBM’s enthusiasm for Watson in healthcare had waned
    significantly. The *Wall Street Journal* reported on this shift, stating, “IBM’s
    retreat from Watson highlights broader AI struggles in Health” [11]. What was
    once considered a bold move by “Big Blue” was now being reconsidered.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the primary obstacles faced by Watson in the medical domain was the
    nuanced and multifaceted nature of medical reasoning. Doctors rely on more than
    just textbook knowledge; they draw upon their extensive experience, make analogies,
    pick up on subtle interpersonal cues, and adjust hypotheses through a range of
    procedures. This rich, intuitive understanding of medicine is still challenging
    for current AI. The Watson case study underscores a critical lesson: not all problems
    are equally suited for machine learning. Some problems, such as trivia questions
    with clear rules and predictable outcomes, align well with AI capabilities. As
    long as Watson had access to the internet to retrieve answers, it thrived. However,
    when faced with the complexities of medical diagnosis, the limitations of AI became
    apparent.'
  prefs: []
  type: TYPE_NORMAL
- en: Zillow, on the other side, sought to revolutionize the real estate industry
    through the application of machine learning models. Zillow’s vision was to use
    AI to analyze vast volumes of real estate data, including lot sizes, zip codes,
    bedroom and bathroom counts, square footage, listing durations, and regional sales
    figures. Its aim was to become a market leader by offering online real estate
    listings, on-demand home buying, and data-driven services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Initially, Zillow’s AI platform, Zestimate, was celebrated as revolutionary.
    It harnessed natural language processing to glean insights from public records
    and employed machine vision to extract information from property images. A July
    2021 article [12] proclaimed Zillow’s prowess: “Zillow utilizes explainer AI data
    to revolutionize how people sell houses.” However, just a few months later, the
    narrative took an unexpected turn. A *Wall Street Journal* headline in November
    2021 revealed that Zillow was exiting the home-flipping business [13], citing
    its inability to accurately forecast home-price appreciation.'
  prefs: []
  type: TYPE_NORMAL
- en: The Zillow example serves as a cautionary reminder about applying machine learning
    in situations characterized by incomplete, inaccurate, or outdated information,
    such as the dynamic real estate market. Factors like new construction, changes
    in local dynamics, and property maintenance history can significantly affect property
    values, and these complexities are difficult for algorithms to account for. Realtors,
    with their evaluative expertise and a deep understanding of local nuances, possess
    insights that machines cannot replicate.
  prefs: []
  type: TYPE_NORMAL
- en: The COVID-19 pandemic presented a unique opportunity for AI to demonstrate its
    potential, yet it also brought with it concerns reminiscent of the AI winters
    of the past. Many hoped that our advanced “intelligent” machines would play a
    pivotal role in finding a cure or swiftly developing a vaccine. Society was in
    dire need of a life-saving solution, and in response, thousands of machine learning
    projects were launched worldwide to tackle the problem. Media outlets were quick
    to herald the power of AI in what seemed like a global race to combat the virus.
  prefs: []
  type: TYPE_NORMAL
- en: 'One notable headline that showcased this optimism appeared in *Science* magazine:
    “AI Invents New ‘Recipes’ for Potential COVID-19 Drugs” [14]. Similarly, financial
    services company BBVA declared, “AI-driven project identifies up to 390 potential
    drugs against COVID” [15]. These reports cited a researcher who proclaimed that
    “the machine learning solution has allowed them to identify about 390 potential
    drugs that may be able to act on the virus’ therapeutic targets and the infection
    process.” Among the most promising candidates identified by the AI model were
    chloroquine, hydroxychloroquine, oseltamivir (remdesivir), and tocilizumab (Actemra).'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, optimism should always be tempered with caution. In May 2020, the
    European Medicines Agency issued an alert [16] cautioning against the use of chloroquine
    and hydroxychloroquine, citing their ineffectiveness in COVID-19 treatment and
    potential serious side effects. Despite these warnings, reports from the Oregon
    Poison Center in 2022 were troubling: “Hydroxychloroquine, chloroquine, and ivermectin
    have been proven ineffective in treating COVID, but the use of these substances
    has resulted in many cases of severe toxicity” [17]. This scenario reminds us,
    once again, that while AI has tremendous potential to assist in healthcare and
    drug discovery, it must always be subject to rigorous scrutiny and validation
    to ensure the safety and efficacy of any proposed treatments.'
  prefs: []
  type: TYPE_NORMAL
- en: To close this section, we might reflect on the proverb about not counting one’s
    chickens before they are hatched as we note two projects that many people once
    considered to be almost complete. The first, which we’ve mentioned already in
    this book, is the quest for self-driving vehicles. The second example is the development
    of language translation. Tens of thousands of researchers have addressed this
    problem since the 1950s, and billions of dollars have been spent. Although tremendous
    progress has been made and the end always appears to be in sight, we have still
    not created a system that can reliably translate one language to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'The French word *avocat* has exactly two meanings: lawyer and avocado. At the
    time of this writing, when I apply the most popular online translation tool to
    the simple sentence “J’ai bien aimé l’avocat car il m’a fait rire aux larmes,”
    the algorithm tells me that it means “I really liked the avocado because it made
    me laugh to tears” (figure 10.1). The program’s clear inability to infer context
    suggests that we still have a long way to go.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/10-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 Translated on October 9, 2022\. The result may change due to user
    feedback
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 10.4 How to set your AI project up for success
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In today’s rapidly evolving technological landscape, AI has risen to prominence,
    captivating imaginations and driving innovation across various industries. This
    surge in AI’s dominance can largely be attributed to two key factors: the unprecedented
    access to vast repositories of data and the extraordinary capabilities of modern
    computers, equipped with prodigious storage capacities and lightning-fast processing
    speeds. Together, these advancements have unlocked the full potential of AI in
    ways that were once deemed unimaginable. However, despite the abundance of data
    at their disposal, many companies have yet to fully embrace the transition into
    becoming data-driven enterprises. One significant reason for this hesitation is
    the pervasive misconception that AI is a magical entity that requires nothing
    more than a push of a button to create and deploy an intelligent system. This
    misconception can lead to misguided expectations and, ultimately, unsuccessful
    AI endeavors.'
  prefs: []
  type: TYPE_NORMAL
- en: Initiating an AI project without a well-defined and comprehensive plan in place
    can be a recipe for disappointment. It is imperative to approach AI endeavors
    with a clear roadmap that not only outlines objectives but also effectively mitigates
    risks and maximizes the potential benefits that AI can bring to businesses and
    industries on a broader scale.
  prefs: []
  type: TYPE_NORMAL
- en: '10.4.1 Data: The lifeblood of AI'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s not just about the volume of data but also the quality and relevance. AI
    algorithms rely heavily on high-quality data to make accurate predictions and
    decisions. Therefore, organizations must prioritize data collection and management
    as a fundamental aspect of their AI strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.2 The realistic AI perspective
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Understanding the true capabilities and limitations of AI is essential. While
    AI can perform remarkable tasks, it is not infallible and cannot solve every problem.
    Companies need to set realistic goals and expectations, considering AI as a tool
    to augment human capabilities rather than a miraculous panacea.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.3 The importance of planning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Crafting a comprehensive AI strategy involves defining clear objectives, identifying
    the right use cases, assembling the necessary talent, and allocating resources
    effectively. A well-thought-out plan ensures that AI projects are executed with
    purpose and a higher chance of success.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.4 Risk mitigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every AI project carries inherent risks, such as data privacy concerns, bias
    in algorithms, or unexpected technical challenges. Organizations must proactively
    identify and address these risks to avoid setbacks and legal or ethical dilemmas.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4.5 Collaboration and expertise
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI is a multidisciplinary field that requires expertise in data science, machine
    learning, domain knowledge, and more. Collaborative efforts and partnerships with
    experts in these areas can greatly enhance the chances of successful AI implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5 AI model lifecycle management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Launching a successful AI project necessitates a well-defined roadmap, beginning
    with a thorough understanding of why AI is needed as opposed to existing processes.
    The first step is to align the project with specific business outcomes and critically
    evaluate whether the anticipated benefits justify the allocation of time and resources.
    Once you’re convinced of the project’s value, meticulous planning becomes paramount.
    It’s crucial to recognize that developing an AI solution isn’t a linear process
    but rather an iterative journey. At each stage, feedback loops abound, influencing
    every other aspect of the project. To maximize the likelihood of success, we need
    to follow this sequence of actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data gathering and labeling*—Start by collecting all the necessary data for
    building and testing your AI model. For supervised learning algorithms, ensure
    that the data is accurately labeled.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data sample selection*—Consider the scale of your data. While large institutions
    may generate billions of records annually, it may not be efficient to use all
    of the data for training and testing. Ensuring a representative sample is vital.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data quality assurance*—Scrutinize the data for redundancy, inconsistency,
    and incoherence. Merging data from multiple sources can lead to duplicates, inconsistencies,
    or incoherent records that need to be addressed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data enrichment*—Raw data is often insufficient. Enhance its utility by intelligently
    combining attributes and data and developing new insights. For example, in fraud
    prevention, associating transaction records with account activity over various
    time frames can provide valuable context.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Model building*—Utilize techniques covered in chapters 2 and 3 to construct
    your AI model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Rigorous testing*—Assess the model’s resilience, performance, and scalability
    extensively to ensure it meets expectations and produces the desired outputs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Deployment*—Once the model passes rigorous testing, it’s time to deploy it
    to a production environment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Continuous monitoring and optimization*—Keep a vigilant eye on the system’s
    performance post-deployment. It’s crucial to maintain the intended level of service
    and be prepared to make adjustments as necessary. Applying adaptive learning techniques
    can be beneficial if performance wavers.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These guidelines constitute a comprehensive framework for navigating the complex
    journey of AI project development. By adhering to these steps and remaining adaptable
    to evolving circumstances, you increase the likelihood of achieving your AI project’s
    goals and delivering tangible benefits to your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 is a chart outlining how the typical AI model can be effectively
    built and deployed.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/10-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 An example of a flowchart that depicts the various steps to design
    and deploy an AI model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 10.5.1 Data preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The initial phase of an AI project involves meticulous data preparation. This
    multifaceted task encompasses several key aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Selecting relevant data types*—In the corporate landscape, it’s imperative
    to be aware of legal restrictions when utilizing data. For instance, certain regulations,
    such as fair lending laws, prohibit the use of attributes like age, race, religion,
    zip code, gender, or ethnicity when designing AI models. Ensuring compliance with
    such regulations is paramount.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data format conversion*—AI algorithms vary in their ability to handle different
    data types. While some algorithms can work directly with categorical data, others
    require data to be converted into numerical formats. This transformation ensures
    compatibility with the chosen AI techniques.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sampling*—Managing large datasets can be resource-intensive. To mitigate costs
    and streamline development, it’s often prudent to employ sampling techniques.
    This involves reducing the data size while retaining its representativeness, facilitating
    more efficient model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data analysis and cleansing*—Data quality is paramount. In this phase, rigorous
    analysis is conducted to identify and rectify problems such as redundancy, inconsistency,
    and incoherence. Merging data from diverse sources can introduce duplicate records,
    while inconsistent data can result in conflicts. Ensuring data integrity is essential
    for reliable AI model outcomes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.5.2 Behavior analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This stage involves intelligent data analysis to derive new attributes based
    on various metrics. For instance, in the context of fraud prevention, novel features
    can be crafted to measure total spending over specific time intervals, enhancing
    the model’s fraud detection capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.3 Data transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data transformation is a crucial step that includes data normalization and
    clustering:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data normalization*—Often, data originates from different sources and is measured
    on varying scales. To ensure equitable treatment, data normalization adjusts values
    to a common scale. For example, when two systems represent the same information
    using different scales, such as percentages and scores from 1 to 10, data normalization
    harmonizes these values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Clustering*—Clustering techniques are employed to group data into meaningful
    categories. For instance, cities can be grouped by population size using clustering
    algorithms, enhancing the model’s ability to identify patterns and trends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.5.4 Model creation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At its core, data enrichment involves extracting and generating meaningful insights
    from individual data attributes or strategically combining them. For instance,
    in fraud prevention, linking transaction records with account activity across
    various time frames can furnish valuable data for designing more effective models.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.5 Live production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the AI model is deemed ready for deployment, it transitions into live production.
    In this phase, the model operates in real time, processing live data streams.
    For example, a fraud-prevention model continuously assesses transactions for potential
    fraud.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.6 Data storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data storage is an integral component for recording and archiving both input
    data and the model’s output. This repository facilitates post-analysis, auditing,
    and ongoing monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.7 Notifications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Automated actions can be predefined to respond to specific outcomes or triggers.
    For instance, certain events may prompt investigations or the automatic dispatch
    of notifications to relevant stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.8 Back-office review
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Critical applications often necessitate a dedicated team to manage alerts raised
    by the AI model. In scenarios such as money laundering detection, prompt review
    and assessment of suspicious behavior are crucial to minimize legal and regulatory
    risks.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.9 Adaptive learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Establishing a feedback loop is essential for continuous improvement. Algorithms
    learn from errors and adapt to new data, enhancing the model’s performance over
    time.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.10 Administration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model administration encompasses all operational aspects, including access management
    and permissions. This ensures the model operates securely and efficiently within
    the production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 10.5.11 Remark on AI platforms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Advanced AI platforms like Brighterion offer automated machine learning capabilities.
    These platforms streamline various data science tasks, including data preparation,
    behavior analysis, data transformation, and model creation. Such automation significantly
    expedites the development process, enabling data scientists to focus on refining
    models and addressing specific business objectives.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the process of developing and deploying AI models is a multifaceted
    journey that demands meticulous attention to data, rigorous analysis, and a structured
    approach. Each stage plays a pivotal role in ensuring the success of AI projects,
    from initial data preparation to real-time model deployment and continuous improvement
    through adaptive learning. Automated AI platforms further enhance efficiency,
    empowering data scientists to drive innovation and achieve business goals.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6 Guiding principles for successful AI projects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Embarking on a successful AI project entails more than merely having individuals
    who understand the machine learning algorithms. While expertise in AI is undoubtedly
    crucial, an effective AI project team requires a broader spectrum of skills and
    knowledge. Clear specifications and a profound understanding of the available
    data are equally decisive components. Initiating an AI project without a deep
    understanding of the desired business outcome is akin to inviting failure. Take,
    for example, a system tasked with making real-time decisions, which inherently
    demands a vastly different approach compared to one that processes the same data
    overnight in batches. Therefore, the best approach is to work backward from the
    project’s goals and constraints, ensuring that your AI initiative is firmly rooted
    in a profound understanding of its purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it’s advisable to commence your AI journey by addressing a single,
    existing business process that can demonstrably benefit from AI’s capabilities.
    For instance, a company might seek to understand why it loses customers to competitors
    or why certain products are often purchased together. This initial machine learning
    objective should be modest and achievable. Starting with a small-scale success
    is instrumental in cultivating the knowledge and expertise needed for more ambitious
    undertakings. Many projects fail because of overambitious goals.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to understand that a single machine learning technique may
    not suffice to tackle a complex business problem. It may be necessary to combine
    various methods that complement each other’s strengths and compensate for their
    respective weaknesses. Furthermore, beyond the algorithms themselves, the practicality
    of AI solutions in real-world applications hinges on factors such as availability,
    response time, and scalability. Consider, for instance, a credit card authorization
    system that must operate around the clock, respond within milliseconds, and process
    tens of thousands of transactions per second. Without meeting these operational
    criteria, even the most sophisticated algorithm becomes ineffective.
  prefs: []
  type: TYPE_NORMAL
- en: Once your project’s objectives are meticulously defined and the constraints
    are fully outlined, this information serves as the foundation for assembling a
    team of professionals with complementary knowledge and skills. The significance
    of subject matter experts becomes abundantly clear as they bring domain-specific
    insights that are indispensable for the project’s success. On the technical front,
    software engineers benefit immensely from the input of a reliable solution architect
    who can guide the design process. Additionally, a system engineer is vital for
    setting up the infrastructure necessary to ensure optimal performance and security.
    Post-deployment, continuous monitoring and maintenance are imperative for long-term
    success. Proper lifecycle management practices are essential to keep your AI project
    on course.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, there’s no magical AI algorithm, and an AI system is not
    a “wizard in a box” capable of instantly resolving all your challenges. Success
    in AI projects typically hinges on a process of trial and error, guided by an
    understanding of what has proven effective in similar cases. It’s a journey that
    requires time and expertise.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, an AI project is a multifaceted endeavor that demands meticulous
    planning, a well-rounded team, and a deep understanding of both the problem at
    hand and the complexities of AI technologies. Embracing these principles and understanding
    the iterative process inherent in AI development is the key to achieving success
    in your project.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many AI techniques have been successfully applied in real-time fraud prevention,
    credit risk, anti-money laundering efforts, homeland security, supply chain and
    traffic management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bad actors have used AI to generate deep fakes, and AI has been used to perform
    biased profiling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Billions of dollars have been spent on failed AI projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, AI models fail because they learned from invalid or incomplete data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbots have no real understanding and are unable to differentiate between
    courteous and offensive statements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the first steps in successfully using AI is to understand the data involved
    in the project and to ensure that it is correct and adequate for the task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entire project lifecycle should be considered when using AI, including how
    to document the code and explain what it does and how to secure and update the
    model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
