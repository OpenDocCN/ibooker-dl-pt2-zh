- en: 14 Conclusions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14 结论
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章内容*'
- en: Important takeaways from this book
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书的重要内容
- en: The limitations of deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习的局限性
- en: Possible future directions for deep learning, machine learning, and AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能的深度学习、机器学习和人工智能的未来方向
- en: Resources for further learning and applying your skills in practice
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进一步学习和将您的技能应用于实践的资源
- en: You’ve almost reached the end of this book. This last chapter will summarize
    and review core concepts while also expanding your horizons beyond what you’ve
    learned so far. Becoming an effective AI practitioner is a journey, and finishing
    this book is merely your first step on it. I want to make sure you realize this
    and are properly equipped to take the next steps of this journey on your own.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您几乎已经读完了本书。 这最后一章将总结和回顾核心概念，同时将您的视野扩展到远远超出您到目前为止所学到的内容。 成为一名有效的人工智能从业者是一段旅程，而完成本书只是您迈出的第一步。
    我希望您意识到这一点，并且能够得到适当的装备，以便独自迈出这段旅程的下一步。
- en: We’ll start with a bird’s-eye view of what you should take away from this book.
    This should refresh your memory regarding some of the concepts you’ve learned.
    Next, I’ll present an overview of some key limitations of deep learning. To use
    a tool appropriately, you should not only understand what it *can* do but also
    be aware of what it *can’t* do. Finally, I’ll offer some speculative thoughts
    about the future evolution of deep learning, machine learning, and AI. This should
    be especially interesting to you if you’d like to get into fundamental research.
    The chapter ends with a short list of resources and strategies for further learning
    about machine learning and staying up to date with new advances.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个鸟瞰本书中您应该带走的内容开始。 这应该可以帮助您恢复对一些您所学概念的记忆。 接下来，我将概述一些深度学习的主要局限性。 要适当地使用一项工具，您不仅应该了解它
    *能* 做什么，还应该意识到它 *不能* 做什么。 最后，我将提出一些关于深度学习、机器学习和人工智能未来发展的推测性思考。 如果您想从事基础研究，这对您应该特别有趣。
    本章以一份关于进一步学习机器学习和保持与新进展同步的资源和策略的简短清单结束。
- en: 14.1 Key concepts in review
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 重要概念回顾
- en: This section briefly synthesizes key takeaways from this book. If you ever need
    a quick refresher to help you recall what you’ve learned, you can read these few
    pages.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要总结了本书的关键内容。 如果您需要一个快速的提醒来帮助您回忆您所学到的内容，您可以阅读这几页。
- en: 14.1.1 Various approaches to AI
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.1 人工智能的各种方法
- en: 'First of all, deep learning isn’t synonymous with AI, or even with machine
    learning:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，深度学习不等同于AI，甚至不等同于机器学习：
- en: '*Artificial intelligence* (AI) is an ancient, broad field that can generally
    be understood as “all attempts to automate human cognitive processes.” This can
    range from the very basic, such as an Excel spreadsheet, to the very advanced,
    like a humanoid robot that can walk and talk.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工智能*（AI）是一个古老而广泛的领域，通常可以理解为“自动化人类认知过程的所有尝试。” 这可以从非常基础的东西开始，比如一个Excel电子表格，到非常先进的东西，比如一个能够行走和说话的
    humanoid 机器人。'
- en: '*Machine learning* is a specific subfield of AI that aims at automatically
    developing programs (called *models*) purely from exposure to training data. This
    process of turning data into a program is called *learning*. Although machine
    learning has been around for a long time, it started to take off only in the 1990s,
    before becoming the dominant form of AI in the 2000s.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习* 是人工智能的一个特定子领域，旨在通过纯粹暴露于训练数据来自动开发程序（称为 *模型*）。 将数据转化为程序的过程称为 *学习*。 尽管机器学习已经存在很长时间，但直到1990年代才开始起飞，然后在2000年代成为主导形式的人工智能。'
- en: '*Deep learning* is one of many branches of machine learning, where the models
    are long chains of geometric transformations, applied one after the other. These
    operations are structured into modules called *layers*: deep learning models are
    typically stacks of layers—or, more generally, graphs of layers. These layers
    are parameterized by *weights*, which are the parameters learned during training.
    The *knowledge* of a model is stored in its weights, and the process of learning
    consists of finding “good values” for these weights—values that minimize a *loss
    function*. Because the chain of geometric transformations considered is differentiable,
    updating the weights to minimize the loss function is done efficiently via *gradient
    descent*.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习*是机器学习的众多分支之一，其中模型是长链的几何变换，依次应用。这些操作被结构化为称为*层*的模块：深度学习模型通常是层的堆叠——或者更普遍地，层的图形。这些层由*权重*参数化，在训练期间学习。模型的*p学习是存储在其权重中的知识，并且学习过程包括找到这些权重的“好值”——最小化*损失函数*的值。由于考虑的几何变换链是可微的，通过*梯度下降*有效地更新权重以最小化损失函数。'
- en: Even though deep learning is just one among many approaches to machine learning,
    it isn’t on an equal footing with the others. Deep learning is a breakout success.
    Here’s why.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 即使深度学习只是机器学习中的一种方法，它也与其他方法不平等。深度学习是突破性的成功。以下是原因。
- en: 14.1.2 What makes deep learning special within the field of machine learning
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.2 深度学习在机器学习领域中所特殊之处
- en: 'In the span of only a few years, deep learning has achieved tremendous breakthroughs
    across a wide range of tasks that have been historically perceived as extremely
    difficult for computers, especially in the area of machine perception: extracting
    useful information from images, videos, sound, and more. Given sufficient training
    data (in particular, training data appropriately labeled by humans), deep learning
    makes it possible to extract from perceptual data almost anything a human could.
    Hence, it’s sometimes said that deep learning has “solved perception”— although
    that’s true only for a fairly narrow definition of perception.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅在几年的时间内，深度学习已经在历史上被认为是计算机极为困难的一系列任务中取得了巨大的突破，尤其是在机器感知的领域：从图像、视频、声音等感知数据中提取有用信息。在充足的训练数据（特别是由人类正确标注的训练数据）的情况下，深度学习可以从感知数据中提取出几乎任何一个人可能做出的内容。因此，有时被称为深度学习“解决了感知问题”——尽管这仅针对感知的一个相当狭窄的定义而言。
- en: 'Due to its unprecedented technical successes, deep learning has singlehandedly
    brought about the third and by far the largest *AI summer*: a period of intense
    interest, investment, and hype in the field of AI. As this book is being written,
    we’re in the middle of it. Whether this period will end in the near future, and
    what happens after it ends, are topics of debate. One thing is certain: in stark
    contrast with previous AI summers, deep learning has provided enormous business
    value to both large and small technology companies, enabling human-level speech
    recognition, smart assistants, human-level image classification, vastly improved
    machine translation, and more. The hype may (and likely will) recede, but the
    sustained economic and technological impact of deep learning will remain. In that
    sense, deep learning could be analogous to the internet: it may be overly hyped
    for a few years, but in the longer term, it will still be a major revolution that
    will transform our economy and our lives.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其前所未有的技术成功，深度学习独自引发了第三个、迄今为止最大的“人工智能夏令营”：一段对人工智能领域充满了浓厚兴趣、投资和炒作的时期。在本书撰写时，我们正处于其中。这一时期是否会在不久的将来结束，以及结束后会发生什么，都是有争议的话题。有一件事情是肯定的：与以往的人工智能夏令营形成鲜明反差的是，深度学习对大型和小型科技公司都带来了巨大的商业价值，实现了人类级别的语音识别、智能助手、人类级别的图像分类、大幅改进的机器翻译等。炒作可能（并很可能会）消退，但深度学习的可持续经济和技术影响将会保持存在。在这个意义上，深度学习可能类似于互联网：它可能在短时间内被过度炒作，但从更长期看，它仍将是一场重大的革命，将改变我们的经济和生活。
- en: I’m particularly optimistic about deep learning, because even if we were to
    make no further technological progress in the next decade, deploying existing
    algorithms to every applicable problem would be a game changer for most industries.
    Deep learning is nothing short of a revolution, and progress is currently happening
    at an incredibly fast rate, due to an exponential investment in resources and
    headcount. From where I stand, the future looks bright, although short-term expectations
    are somewhat overoptimistic; deploying deep learning to the full extent of its
    potential will likely take multiple decades.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我对深度学习特别乐观，因为即使在未来十年内我们不再取得技术上的进步，将现有算法应用到每个适用的问题上都将改变大多数行业的游戏规则。深度学习无异于一场革命，而目前的进展正以令人难以置信的速度发生，这要归功于对资源和人力的指数级投资。站在我现在的位置看，未来看起来很光明，尽管短期内的期望有些过于乐观；要充分发挥深度学习的潜力可能需要数十年时间。
- en: 14.1.3 How to think about deep learning
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.3 如何思考深度学习
- en: The most surprising thing about deep learning is how simple it is. Ten years
    ago, no one expected that we would achieve such amazing results on machine-perception
    problems by using simple parametric models trained with gradient descent. Now
    it turns out that all you need is sufficiently large parametric models trained
    with gradient descent on sufficiently many examples. As Feynman once said about
    the universe, “It’s not complicated, it’s just a lot of it.^([1](#Rendnote1))
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 关于深度学习最令人惊讶的是它有多简单。十年前，没有人预料到我们会通过使用简单的参数模型，使用梯度下降训练的方式，在机器感知问题上取得如此惊人的结果。现在，事实证明你所需要的一切只是足够大的参数模型，以及在足够多的示例上使用梯度下降进行训练。正如费曼曾经说过关于宇宙的，“它并不复杂，只是很多而已。”^([1](#Rendnote1))
- en: In deep learning, everything is a vector—that is to say, everything is a *point*
    in a *geometric space*. Model inputs (text, images, and so on) and targets are
    first *vectorized*— turned into an initial input vector space and target vector
    space. Each layer in a deep learning model operates one simple geometric transformation
    on the data that goes through it. Together, the chain of layers in the model forms
    one complex geometric transformation, broken down into a series of simple ones.
    This complex transformation attempts to map the input space to the target space,
    one point at a time. This transformation is parameterized by the weights of the
    layers, which are iteratively updated based on how well the model is currently
    performing. A key characteristic of this geometric transformation is that it must
    be *differentiable*, which is required for us to be able to learn its parameters
    via gradient descent. Intuitively, this means the geometric morphing from inputs
    to outputs must be smooth and continuous—a significant constraint.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，一切都是向量——也就是说，一切都是*几何空间*中的*点*。模型输入（文本、图像等）和目标首先被*向量化*——转换为初始输入向量空间和目标向量空间。深度学习模型中的每一层对通过它的数据进行一次简单的几何变换。模型中层的链条一起形成一个复杂的几何变换，分解为一系列简单的变换。这个复杂的变换试图将输入空间一点一点地映射到目标空间。这个变换由层的权重参数化，这些权重根据模型当前的性能进行迭代更新。这个几何变换的一个关键特性是它必须是*可微分*的，这是我们能够通过梯度下降来学习其参数的必要条件。直觉上，这意味着从输入到输出的几何变形必须是平滑和连续的——这是一个重要的约束。
- en: 'The entire process of applying this complex geometric transformation to the
    input data can be visualized in 3D by imagining a person trying to uncrumple a
    paper ball: the crumpled paper ball is the manifold of the input data that the
    model starts with. Each movement operated by the person on the paper ball is similar
    to a simple geometric transformation operated by one layer. The full uncrumpling
    gesture sequence is the complex transformation of the entire model. Deep learning
    models are mathematical machines for uncrumpling complicated manifolds of high-dimensional
    data.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个复杂的几何变换应用到输入数据的整个过程可以在3D中可视化，就好像一个人试图展开一个纸球：皱巴巴的纸球就是模型初始的输入数据的流形。人对纸球施加的每一个移动都类似于一个简单的几何变换，由一个层操作。完整的展开手势序列是整个模型的复杂变换。深度学习模型是用于展开高维数据复杂流形的数学机器。
- en: 'That’s the magic of deep learning: turning meaning into vectors, then into
    geometric spaces, and then incrementally learning complex geometric transformations
    that map one space to another. All you need are spaces of sufficiently high dimensionality
    to capture the full scope of the relationships found in the original data.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是深度学习的魔力：将意义转化为向量，然后转化为几何空间，然后逐渐学习将一个空间映射到另一个空间的复杂几何变换。你所需要的只是足够高维度的空间来捕捉原始数据中发现的关系的全部范围。
- en: 'The whole process hinges on a single core idea: *that meaning is derived from
    the pairwise relationship between things* (between words in a language, between
    pixels in an image, and so on) and that *these relationships can be captured by
    a distance function*. But note that whether the brain also implements meaning
    via geometric spaces is an entirely separate question. Vector spaces are efficient
    to work with from a computational standpoint, but different data structures for
    intelligence can easily be envisioned—in particular, graphs. Neural networks initially
    emerged from the idea of using graphs as a way to encode meaning, which is why
    they’re named *neural networks*; the surrounding field of research used to be
    called *connectionism*. Nowadays the name “neural network” exists purely for historical
    reasons—it’s an extremely misleading name because they’re neither neural nor networks.
    In particular, neural networks have hardly anything to do with the brain. A more
    appropriate name would have been *layered representations learning* or *hierarchical
    representations learning*, or maybe even *deep differentiable models* or *chained
    geometric transforms*, to emphasize the fact that continuous geometric space manipulation
    is at their core.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程的关键思想在于：*意义来源于事物之间的成对关系*（在语言中的单词之间，在图像中的像素之间等），*这些关系可以用距离函数来捕捉*。但请注意，大脑是否也通过几何空间实现了意义是一个完全独立的问题。从计算的角度来看，向量空间是有效的，但是可以很容易地构想出不同的智能数据结构——特别是图形。神经网络最初是从使用图形作为编码意义的一种方式的想法中产生的，这就是为什么它们被命名为*神经网络*；周围的研究领域曾经被称为*连接主义*。现在“神经网络”的名字纯粹是出于历史原因——这是一个极其误导性的名字，因为它们既不是神经也不是网络。特别是神经网络与大脑几乎毫无关系。一个更合适的名称可能应该是*层次表示学习*或*深度可微模型*或*链式几何变换*，以强调连续几何空间操作是它们的核心。
- en: 14.1.4 Key enabling technologies
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.4 关键技术
- en: 'The technological revolution that’s currently unfolding didn’t start with any
    single breakthrough invention. Rather, like any other revolution, it’s the product
    of a vast accumulation of enabling factors—gradual at first, and then sudden.
    In the case of deep learning, we can point out the following key factors:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当前正在展开的技术革命并不是始于任何单一的突破性发明。相反，就像任何其他革命一样，它是巨大的 enabling 因素的积累的产物——一开始是渐进的，然后是突然的。在深度学习的情况下，我们可以指出以下关键因素：
- en: '*Incremental algorithmic innovations*—These first began appearing slowly over
    the span of two decades (starting with backpropagation), and then were developed
    increasingly faster as more research effort was poured into deep learning after
    2012.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*渐进的算法创新*——这些创新最初在两个十年内缓慢出现（从反向传播开始），然后随着在2012年之后更多的研究工作投入到深度学习中而日益加快发展。'
- en: '*The availability of large amounts of perceptual data*—This was a requirement
    in order to realize that sufficiently large models trained on sufficiently large
    data are all we need. This is, in turn, a byproduct of the rise of the consumer
    internet and Moore’s law applied to storage media.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*大量感知数据的可用性*——这是一个前提，以便意识到在足够大的数据上训练的足够大的模型是我们所需要的。这又是消费互联网的崛起和摩尔定律应用于存储介质的副产品。'
- en: '*The availability of fast, highly parallel computation hardware at a low price*—Especially
    the GPUs produced by NVIDIA—first gaming GPUs and then chips designed from the
    ground up for deep learning. Early on, NVIDIA CEO Jensen Huang took note of the
    deep learning boom and decided to bet the company’s future on it, which paid off
    in a big way.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*价格低廉的快速、高度并行计算硬件的可用性*——尤其是由NVIDIA生产的GPU——首先是游戏GPU，然后是从头开始设计用于深度学习的芯片。早在初期，NVIDIA首席执行官黄仁勋注意到了深度学习的兴起，并决定把公司的未来押注在这一点上，这种决定带来了巨大的回报。'
- en: '*A complex stack of software layers that makes this computational power available
    to humans*—The CUDA language, frameworks like TensorFlow that do automatic differentiation,
    and Keras, which makes deep learning accessible to most people.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一堆软件层，使这种计算能力可用于人类*——CUDA语言、像TensorFlow这样执行自动微分的框架，以及使深度学习对大多数人可接触的Keras。'
- en: 'In the future, deep learning will not be used only by specialists—researchers,
    graduate students, and engineers with an academic profile—it will be a tool in
    the toolbox of every developer, much like web technology today. Everyone needs
    to build intelligent apps: just as every business today needs a website, every
    product will need to intelligently make sense of user-generated data. Bringing
    about this future will require us to build tools that make deep learning radically
    easy to use and accessible to anyone with basic coding abilities. Keras has been
    the first major step in that direction.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，深度学习将不仅仅被专家——研究人员、研究生和具有学术背景的工程师所使用——它将成为每个开发者工具箱中的一个工具，就像今天的网络技术一样。每个人都需要构建智能应用程序：正如今天每个企业都需要一个网站一样，每个产品都需要智能地理解用户生成的数据。实现这一未来将需要我们构建使深度学习变得极易使用并且对具备基本编程能力的任何人都可接触的工具。Keras已经是朝着这个方向迈出的第一步。
- en: 14.1.5 The universal machine learning workflow
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.5 通用机器学习工作流程
- en: 'Having access to an extremely powerful tool for creating models that map any
    input space to any target space is great, but the difficult part of the machine
    learning work-flow is often everything that comes before designing and training
    such models (and, for production models, what comes after, as well). Understanding
    the problem domain so as to be able to determine what to attempt to predict, given
    what data, and how to measure success, is a prerequisite for any successful application
    of machine learning, and it isn’t something that advanced tools like Keras and
    TensorFlow can help you with. As a reminder, here’s a quick summary of the typical
    machine learning workflow as described in chapter 6:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 能够访问一个非常强大的工具，可以将任何输入空间映射到任何目标空间，这很棒，但是机器学习工作流程中困难的部分通常是在设计和训练这样的模型之前发生的一切（对于生产模型来说，在之后发生的部分也是如此）。理解问题领域，以便能够确定尝试预测什么，给定什么数据，以及如何衡量成功，是任何成功应用机器学习的先决条件，并且这不是像Keras和TensorFlow这样的高级工具可以帮助你解决的问题。作为提醒，以下是第6章中描述的典型机器学习工作流程的简要总结：
- en: '**1** Define the problem. What data is available, and what are you trying to
    predict? Will you need to collect more data or hire people to manually label a
    dataset?'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**1** 定义问题。可用的数据是什么，你想要预测什么？你是否需要收集更多数据或者雇佣人手来手动标记数据集？'
- en: '**2** Identify a way to reliably measure success on your goal. For simple tasks,
    this may be prediction accuracy, but in many cases, it will require sophisticated,
    domain-specific metrics.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**2** 确定一种可靠地衡量目标成功的方法。对于简单的任务，这可能是预测准确性，但在许多情况下，它将需要复杂的、特定于领域的指标。'
- en: '**3** Prepare the validation process that you’ll use to evaluate your models.
    In particular, you should define a training set, a validation set, and a test
    set. The validation and test set labels shouldn’t leak into the training data:
    for instance, with temporal prediction, the validation and test data should be
    posterior to the training data.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**3** 准备您将用于评估模型的验证过程。特别是，您应该定义一个训练集、一个验证集和一个测试集。验证集和测试集的标签不应泄漏到训练数据中：例如，在时间预测中，验证和测试数据应该位于训练数据之后。'
- en: '**4** Vectorize the data by turning it into vectors and preprocessing it in
    a way that makes it more easily approachable by a neural network (normalization
    and so on).'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**4** 通过将数据转换为向量并对其进行预处理，使其更容易被神经网络接近（归一化等）。'
- en: '**5** Develop a first model that beats a trivial common-sense baseline, thus
    demonstrating that machine learning can work on your problem. This may not always
    be the case!'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**5** 开发一个能击败琐碎的常识基线的第一个模型，从而证明机器学习可以解决你的问题。这并不总是成立！'
- en: '**6** Gradually refine your model architecture by tuning hyperparameters and
    adding regularization. Make changes based on performance on the validation data
    only, not the test data or the training data. Remember that you should get your
    model to overfit (thus identifying a model capacity level that’s greater than
    you need) and only then begin to add regularization or downsize your model. Beware
    of validation-set overfitting when tuning hyperparameters—your hyper-parameters
    may end up being overspecialized to the validation set. Avoiding this is the purpose
    of having a separate test set.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**6** 通过调整超参数和添加正则化逐渐完善模型架构。基于验证数据的表现进行更改，而不是测试数据或训练数据。记住，你应该使你的模型过度拟合（因此识别出一个比你需要的模型容量水平更高的水平），然后才开始添加正则化或减小模型尺寸。在调整超参数时要小心验证集的过拟合
    - 你的超参数可能最终被过于专门化于验证集。避免这种情况是拥有一个单独的测试集的目的。'
- en: '**7** Deploy your final model in production—as a web API, as part of a JavaScript
    or C++ application, on an embedded device, and so on. Keep monitoring its performance
    on real-world data, and use your findings to refine the next iteration of the
    model!'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**7** 将最终模型部署到生产环境 - 作为web API、JavaScript或C++应用的一部分、嵌入式设备等等。继续监控其在真实世界数据上的性能，并利用您的发现来完善模型的下一个迭代版本！'
- en: 14.1.6 Key network architectures
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.6 关键的网络架构
- en: 'The four families of network architectures that you should be familiar with
    are *densely connected networks, convolutional networks, recurrent networks*,
    and *Transformers*. Each type of model is meant for a specific input modality.
    A network architecture encodes *assumptions* about the structure of the data:
    a *hypothesis space* within which the search for a good model will proceed. Whether
    a given architecture will work on a given problem depends entirely on the match
    between the structure of the data and the assumptions of the network architecture.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该熟悉的四个网络架构家族分别是*密集连接网络、卷积网络、循环网络*和*Transformer*。每种模型类型针对特定的输入模态。网络架构对数据结构有*假设*：一个良好模型搜索将进行的*假设空间*。给定架构是否适用于给定问题完全取决于数据结构与网络架构假设之间的匹配。
- en: 'These different network types can easily be combined to achieve larger multi-modal
    models, much as you combine LEGO bricks. In a way, deep learning layers are LEGO
    bricks for information processing. Here’s a quick overview of the mapping between
    input modalities and appropriate network architectures:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些不同类型的网络可以轻松地组合在一起，以实现更大的多模型，就像组合乐高积木一样。从某种意义上说，深度学习层是信息处理的乐高积木。以下是输入模态和适当的网络架构之间的快速映射概述：
- en: '*Vector data*—Densely connected models.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*矢量数据* - 密集连接模型。'
- en: '*Image data*—2D convnets.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图像数据* - 2D 卷积神经网络。'
- en: '*Sequence data*—RNNs for time series, or Transformers for discrete sequences
    (such as sequences of words). 1D convnets can also be used for translation-invariant,
    continuous sequence data, such as birdsong waveforms.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*序列数据* - 用于时间序列的RNN，或用于离散序列（例如单词序列）的Transformer。也可以使用 1D 卷积神经网络来处理翻译不变的连续序列数据，例如鸟鸣波形。'
- en: '*Video data*—Either 3D convnets (if you need to capture motion effects), or
    a combination of a frame-level 2D convnet for feature extraction followed by a
    sequence-processing model.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视频数据* - 3D 卷积神经网络（如果需要捕捉运动效果），或者是一个用于特征提取的帧级 2D 卷积神经网络，后跟一个序列处理模型的组合。'
- en: '*Volumetric data*—3D convnets.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*体积数据* - 3D 卷积神经网络。'
- en: Now let’s quickly review the specificities of each network architecture.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们快速复习每种网络架构的特点。
- en: DENSELY CONNECTED NETWORKS
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 密集连接网络
- en: 'A densely connected network is a stack of Dense layers meant to process vector
    data (where each sample is a vector of numerical or categorical attributes). Such
    networks assume no specific structure in the input features: they’re called *densely
    connected* because the units of a Dense layer are connected to every other unit.
    The layer attempts to map relationships between any two input features; this is
    unlike a 2D convolution layer, for instance, which looks only at *local* relationships.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 密集连接网络是一堆用于处理矢量数据的密集层（其中每个样本都是数字或分类属性的矢量）。这些网络假设输入特征没有特定的结构：它们被称为*密集连接*，因为密集层的单元与每个其他单元相连。该层试图映射任何两个输入特征之间的关系；这与例如只关注*局部*关系的
    2D 卷积层不同。
- en: Densely connected networks are most commonly used for categorical data (e.g.,
    where the input features are lists of attributes), such as the Boston housing
    price data-set used in chapter 4\. They’re also used as the final classification
    or regression stage of most networks. For instance, the convnets covered in chapter
    8 typically end with one or two Dense layers, and so do the recurrent networks
    in chapter 10.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 密集连接网络通常用于分类数据（例如，输入特征是属性列表的情况），比如第4章中使用的波士顿房价数据集。它们也被用作大多数网络的最终分类或回归阶段。例如，第8章介绍的卷积网络通常以一个或两个密集层结束，第10章介绍的循环网络也是如此。
- en: 'Remember, to perform *binary classification*, end your stack of layers with
    a Dense layer with a single unit and a sigmoid activation, and use binary_crossentropy
    as the loss. Your targets should be either 0 or 1:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，要进行*二元分类*，请在层堆叠的最后使用一个具有单个单元和Sigmoid激活的密集层，并使用binary_crossentropy作为损失函数。你的目标应该是0或1：
- en: inputs <- layer_input(shape = c(num_inputs_features))
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(num_inputs_features))
- en: outputs <- inputs %>%
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(1, activation = "sigmoid")
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(1, activation = "sigmoid")
- en: model <- keras_model(inputs, outputs)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
- en: 'To perform *single-label categorical classification* (where each sample has
    exactly one class, no more), end your stack of layers with a Dense layer with
    a number of units equal to the number of classes, and a softmax activation. If
    your targets are one-hot encoded, use categorical_crossentropy as the loss; if
    they’re integers, use sparse_categorical_ crossentropy:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行*单标签分类*（每个样本只有一个类，不多不少），请在层堆叠的最后使用一个具有与类数相等的单元数和softmax激活的密集层。如果你的目标是one-hot编码的，使用categorical_crossentropy作为损失；如果它们是整数，使用sparse_categorical_crossentropy：
- en: inputs <- layer_input(shape = c(num_inputs_features))
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(num_inputs_features))
- en: outputs <- inputs %>%
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(num_classes, activation = "softmax")
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(num_classes, activation = "softmax")
- en: model <- keras_model(inputs, outputs)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy")
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy")
- en: 'To perform *multilabel categorical classification* (where each sample can have
    several classes), end your stack of layers with a Dense layer with a number of
    units equal to the number of classes, and a sigmoid activation, and use binary_crossentropy
    as the loss. Your targets should be multi-hot encoded:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行*多标签分类*（每个样本可以有多个类），请在层堆叠的最后使用一个具有与类数相等的单元数和Sigmoid激活的密集层，并使用binary_crossentropy作为损失函数。你的目标应该是多热编码的：
- en: inputs <- layer_input(shape = c(num_inputs_features))
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(num_inputs_features))
- en: outputs <- inputs %>%
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(num_classes, activation = "sigmoid")
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(num_classes, activation = "sigmoid")
- en: model <- keras_model(inputs, outputs)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
- en: 'To perform *regression* toward a vector of continuous values, end your stack
    of layers with a Dense layer with a number of units equal to the number of values
    you’re trying to predict (often a single one, such as the price of a house), and
    no activation. Various losses can be used for regression—most commonly mean_squared_error
    (MSE):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行*回归*以预测一组连续值的向量，可以在层堆叠的最后使用一个具有与你要预测的值数量相等的单元数（通常是一个，比如房屋价格）的密集层，没有激活。回归可以使用各种损失函数，最常见的是均方误差（MSE）：
- en: inputs <- layer_input(shape = c(num_inputs_features))
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(num_inputs_features))
- en: outputs <- inputs %>%
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(num_values)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(num_values)
- en: model <- keras_model(inputs, outputs)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "mse")
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "mse")
- en: CONVNETS
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积网络
- en: 'Convolution layers look at spatially local patterns by applying the same geometric
    transformation to different spatial locations (*patches*) in an input tensor.
    This results in representations that are *translation invariant*, making convolution
    layers highly data efficient and modular. This idea is applicable to spaces of
    any dimensionality: 1D (continuous sequences), 2D (images), 3D (volumes), and
    so on. You can use the Conv1D layer to process sequences, the Conv2D layer to
    process images, and the Conv3D layers to process volumes. As a leaner, more efficient
    alternative to convolution layers, you can also use *depthwise separable convolution*
    layers, such as SeparableConv2D.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层通过将同一几何变换应用于输入张量中的不同空间位置（*patch*）来查看空间局部模式。这导致产生的表示是*平移不变的*，使卷积层具有高数据效率和模块化性。这个想法适用于任何维度的空间：1D（连续序列），2D（图像），3D（体积）等。您可以使用Conv1D层处理序列，Conv2D层处理图像，Conv3D层处理体积。作为卷积层的更轻、更高效的替代方案，您还可以使用*深度可分离卷积*层，比如SeparableConv2D。
- en: '*Convnets*, or *convolutional networks*, consist of stacks of convolution and
    max-pooling layers. The pooling layers let you spatially downsample the data,
    which is required to keep feature maps to a reasonable size as the number of features
    grows, and to allow subsequent convolution layers to “see” a greater spatial extent
    of the inputs. Convnets are often ended with either a Flatten operation or a global-pooling
    layer, turning spatial feature maps into vectors, followed by Dense layers to
    achieve classification or regression.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*卷积神经网络*，或者*卷积网络*，由一系列的卷积层和最大池化层组成。池化层允许对数据进行空间下采样，这对于保持特征图的合理大小是必要的，因为特征数量增加，以及允许后续的卷积层“看到”输入的更大空间范围。卷积网络通常以Flatten操作或全局池化层结束，将空间特征图转换为向量，然后通过Dense层实现分类或回归。'
- en: 'Here’s a typical image classification network (categorical classification,
    in this case), leveraging SeparableConv2D layers:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的图像分类网络（在这种情况下是分类分类），利用可分离卷积层：
- en: inputs <- layer_input(shape = c(height, width, channels))
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(height, width, channels))
- en: outputs <- inputs %>%
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_separable_conv_2d(32, 3, activation = "relu") %>%
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: layer_separable_conv_2d(32, 3, activation = "relu") %>%
- en: layer_separable_conv_2d(64, 3, activation = "relu") %>%
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: layer_separable_conv_2d(64, 3, activation = "relu") %>%
- en: layer_max_pooling_2d(2) %>%
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: layer_max_pooling_2d(2) %>%
- en: layer_separable_conv_2d(64, 3, activation = "relu") %>%
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: layer_separable_conv_2d(64, 3, activation = "relu") %>%
- en: layer_separable_conv_2d(128, 3, activation = "relu") %>%
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: layer_separable_conv_2d(128, 3, activation = "relu") %>%
- en: layer_max_pooling_2d(2) %>%
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: layer_max_pooling_2d(2) %>%
- en: layer_separable_conv_2d(64, 3, activation = "relu") %>%
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: layer_separable_conv_2d(64, 3, activation = "relu") %>%
- en: layer_separable_conv_2d(128, 3, activation = "relu") %>%
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: layer_separable_conv_2d(128, 3, activation = "relu") %>%
- en: layer_global_average_pooling_2d() %>%
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: layer_global_average_pooling_2d() %>%
- en: layer_dense(32, activation = "relu") %>%
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(32, activation = "relu") %>%
- en: layer_dense(num_classes, activation = "softmax")
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(num_classes, activation = "softmax")
- en: model <- keras_model(inputs, outputs)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy")
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy")
- en: When building a very deep convnet, it’s common to add *batch normalization*
    layers as well as *residual connections*—two architecture patterns that help gradient
    information flow smoothly through the network.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建非常深的卷积网络时，通常会添加*批量归一化*层以及*残差连接*——这两种架构模式有助于梯度信息在网络中平滑流动。
- en: RNNS
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RNNS
- en: '*Recurrent neural networks* (RNNs) work by processing sequences of inputs one
    time step at a time, and maintaining a state throughout (a state is typically
    a vector or set of vectors). They should be used preferentially over 1D convnets
    in the case of sequences where patterns of interest aren’t invariant by temporal
    translation (e.g., time-series data where the recent past is more important than
    the distant past).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*循环神经网络*（RNNs）通过逐个时间步骤处理输入序列，并在整个过程中保持状态（状态通常是一个向量或一组向量）。在序列的情况下，感兴趣的模式不是通过时间平移不变的（例如，在时间序列数据中，最近的过去比遥远的过去更重要），应优先使用RNNs，而不是1D卷积网络。'
- en: 'Three RNN layers are available in Keras: SimpleRNN, GRU, and LSTM. For most
    practical purposes, you should use either GRU or LSTM. LSTM is the more powerful
    of the two but is also more expensive; you can think of GRU as a simpler, cheaper
    alternative to it.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Keras提供了三种RNN层：SimpleRNN、GRU和LSTM。在大多数实际情况下，您应该使用GRU或LSTM。LSTM是其中更强大的一个，但也更昂贵；你可以将GRU视为其更简单、更便宜的替代品。
- en: To stack multiple RNN layers on top of each other, each layer prior to the last
    layer in the stack should return the full sequence of its outputs (each input
    time step will correspond to an output time step). If you aren’t stacking any
    further RNN layers, it’s common to return only the last output, which contains
    information about the entire sequence.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要在彼此之上堆叠多个 RNN 层，堆栈中倒数第二个层之前的每一层应该返回其输出的完整序列（每个输入时间步对应一个输出时间步）。如果您不再堆叠任何其他 RNN
    层，只返回包含有关整个序列信息的最后输出是很常见的。
- en: 'Following is a single RNN layer for binary classification of vector sequences:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个用于二元分类向量序列的单个 RNN 层：
- en: inputs <- layer_input(shape = c(num_timesteps, num_features))
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(num_timesteps, num_features))
- en: outputs <- inputs %>%
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_lstm(32) %>%
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: layer_lstm(32) %>%
- en: layer_dense(num_classes, activation = "sigmoid")
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(num_classes, activation = "sigmoid")
- en: model <- keras_model(inputs, outputs)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
- en: 'And this is a stacked RNN for binary classification of vector sequences:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于二元分类向量序列的堆叠 RNN：
- en: inputs <- layer_input(shape = c(num_timesteps, num_features))
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(num_timesteps, num_features))
- en: outputs <- inputs %>%
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_lstm(32, return_sequences = TRUE) %>%
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: layer_lstm(32, return_sequences = TRUE) %>%
- en: layer_lstm(32, return_sequences = TRUE) %>%
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: layer_lstm(32, return_sequences = TRUE) %>%
- en: layer_lstm(32) %>% layer_dense(num_classes, activation = "sigmoid")
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: layer_lstm(32) %>% layer_dense(num_classes, activation = "sigmoid")
- en: model <- keras_model(inputs, outputs)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
- en: TRANSFORMERS
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TRANSFORMERS
- en: A Transformer looks at a set of vectors (such as word vectors), and leverages
    *neural attention* to transform each vector into a representation that is aware
    of the *context* provided by the other vectors in the set. When the set in question
    is an ordered sequence, you can also leverage *positional encoding* to create
    Transformers that can take into account both global context and word order, capable
    of processing long text paragraphs much more effectively than RNNs or 1D convnets.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Transformer 看待一组向量（如单词向量），并利用 *神经注意力* 将每个向量转换为一个考虑到集合中其他向量提供的 *上下文* 的表示。当涉及的集合是有序序列时，您还可以利用
    *位置编码* 创建可以考虑全局上下文和单词顺序的 Transformer，能够比 RNNs 或 1D convnets 更有效地处理长文段。
- en: 'Transformers can be used for any set-processing or sequence-processing task,
    including text classification, but they excel especially at *sequence-to-sequence
    learning*, such as translating paragraphs in a source language into a target language.
    A sequence-to-sequence Transformer is made up of two parts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers 可用于任何集合处理或序列处理任务，包括文本分类，但它们在 *序列到序列学习* 方面表现出色，比如将源语言中的段落翻译成目标语言。序列到序列
    Transformer 由两部分组成：
- en: A TransformerEncoder that turns an input vector sequence into a context-aware,
    order-aware output vector sequence
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 TransformerEncoder 将输入向量序列转换为一个具有上下文感知和顺序感知的输出向量序列
- en: A TransformerDecoder that takes the output of the TransformerEncoder, as well
    as a target sequence, and predicts what should come next in the target sequenc
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 TransformerDecoder，它接受 TransformerEncoder 的输出以及目标序列，并预测目标序列中接下来应该出现的内容
- en: If you’re only processing a single sequence (or set) of vectors, you’d be only
    using the TransformerEncoder.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只处理单个序列（或集合）的向量，则只会使用 TransformerEncoder。
- en: 'Following is a sequence-to-sequence Transformer for mapping a source sequence
    to a target sequence (this setup could be used for machine translation or question
    answering, for instance):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个序列到序列的 Transformer，用于将源序列映射到目标序列（这种设置可以用于机器翻译或问答等任务）：
- en: encoder_inputs <- layer_input(shape = c(sequence_length),➊
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: encoder_inputs <- layer_input(shape = c(sequence_length),➊
- en: dtype = "int64")
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: dtype = "int64")
- en: encoder_outputs <- encoder_inputs %>%
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: encoder_outputs <- encoder_inputs %>%
- en: layer_positional_embedding(sequence_length, vocab_size, embed_dim) %>%
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: layer_positional_embedding(sequence_length, vocab_size, embed_dim) %>%
- en: layer_transformer_encoder(embed_dim, dense_dim, num_heads)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: layer_transformer_encoder(embed_dim, dense_dim, num_heads)
- en: decoder <- layer_transformer_decoder(NULL, embed_dim, dense_dim, num_heads)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: decoder <- layer_transformer_decoder(NULL, embed_dim, dense_dim, num_heads)
- en: decoder_inputs <- layer_input(shape = c(NA),➋
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: decoder_inputs <- layer_input(shape = c(NA),➋
- en: dtype = "int64")
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: dtype = "int64")
- en: decoder_outputs <- decoder_inputs %>%➌
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: decoder_outputs <- decoder_inputs %>%➌
- en: layer_positional_embedding(sequence_length, vocab_size, embed_dim) %>%
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: layer_positional_embedding(sequence_length, vocab_size, embed_dim) %>%
- en: decoder(., encoder_outputs) %>%
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: decoder(., encoder_outputs) %>%
- en: layer_dense(vocab_size, activation = "softmax")
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(vocab_size, activation = "softmax")
- en: transformer <- keras_model(list(encoder_inputs, decoder_inputs),
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: transformer <- keras_model(list(encoder_inputs, decoder_inputs),
- en: decoder_outputs)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: decoder_outputs)
- en: transformer %>%
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: transformer %>%
- en: compile(optimizer = "rmsprop", loss = "categorical_crossentropy")
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: compile(optimizer = "rmsprop", loss = "categorical_crossentropy")
- en: ➊ **Source sequence**
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ➊ **源序列**
- en: ➋ **Target sequence so far**
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ➋ **目标序列迄今为止**
- en: ➌ **Target sequence one step in the future**
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ➌ **目标序列一步在未来**
- en: 'And this is a lone TransformerEncoder for binary classification of integer
    sequences:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于整数序列的二元分类的孤立的 TransformerEncoder：
- en: inputs <- layer_input(shape = c(sequence_length), dtype = "int64")
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: inputs <- layer_input(shape = c(sequence_length), dtype = "int64")
- en: outputs <- inputs %>%
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: outputs <- inputs %>%
- en: layer_positional_embedding(sequence_length, vocab_size, embed_dim) %>%
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: layer_positional_embedding(sequence_length, vocab_size, embed_dim) %>%
- en: layer_transformer_encoder(embed_dim, dense_dim, num_heads) %>%
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: layer_transformer_encoder(embed_dim, dense_dim, num_heads) %>%
- en: layer_global_max_pooling_1d() %>%
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: layer_global_max_pooling_1d() %>%
- en: layer_dense(1, activation = "sigmoid")
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: layer_dense(1, activation = "sigmoid")
- en: model <- keras_model(inputs, outputs)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: model <- keras_model(inputs, outputs)
- en: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy")
- en: Full implementations of the TransformerEncoder, the TransformerDecoder, and
    the PositionalEmbedding layers are provided in chapter 11.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 11 章中提供了 TransformerEncoder、TransformerDecoder 和 PositionalEmbedding 层的完整实现。
- en: 14.1.7 The space of possibilities
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.7 可能性的空间
- en: 'What will you build with these techniques? Remember, building deep learning
    models is like playing with LEGO bricks: layers can be plugged together to map
    essentially anything to anything, given that you have appropriate training data
    available and that the mapping is achievable via a continuous geometric transformation
    of reasonable complexity. The space of possibilities is infinite. This section
    offers a few examples to inspire you to think beyond the basic classification
    and regression tasks that have traditionally been the bread and butter of machine
    learning.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你会用这些技术构建什么？记住，构建深度学习模型就像玩乐高积木一样：层可以连接在一起，将基本上任何东西映射到任何东西，只要你有适当的训练数据可用，并且映射通过合理复杂度的连续几何变换是可行的。可能性的空间是无限的。本节提供了一些示例，以激发您超越传统机器学习中的基本分类和回归任务的思考。
- en: 'I’ve sorted my suggested applications by input and output modalities in the
    following list. Note that quite a few of them stretch the limits of what is possible,
    although a model could be trained on all of these tasks—in some cases, such a
    model probably wouldn’t generalize far from its training data. Sections 14.2 through
    14.4 will address how these limitations could be lifted in the future:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经按照以下列表中的输入和输出模态对我的建议应用进行了排序。请注意，其中有相当多的任务都超出了可能性的限制，尽管一个模型可能会在所有这些任务上进行训练——在某些情况下，这样的模型可能不会远离其训练数据。第
    14.2 至 14.4 节将讨论如何在未来消除这些限制：
- en: 'Mapping vector data to vector data:'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将向量数据映射到向量数据：
- en: '*Predictive health care*—Mapping patient medical records to predictions of
    patient outcomes'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测性医疗保健*—将患者的医疗记录映射到对患者结果的预测'
- en: '*Behavioral targeting*—Mapping a set of website attributes with data on how
    long a user will spend on the website'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*行为定向*—将一组网站属性与用户在网站上停留时间的数据相映射'
- en: '*Product quality control*—Mapping a set of attributes relative to an instance
    of a manufactured product with the probability that the product will fail by next
    year'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*产品质量控制*—将一组相对于制造产品实例的属性映射到产品明年可能失败的概率'
- en: 'Mapping image data to vector data:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像数据映射到向量数据：
- en: '*Medical assistant*—Mapping slides of medical images to a prediction about
    the presence of a tumor'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*医疗助手*—将医学图像幻灯片映射到关于肿瘤存在的预测'
- en: '*Self-driving vehicle*—Mapping car dashcam video frames to steering wheel angle
    commands and gas and braking commands'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动驾驶车辆*—将汽车行车记录仪视频帧映射到方向盘角度命令以及油门和刹车命令'
- en: '*Board game AI*—Mapping Go or chess boards to the next player move'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*棋盘游戏 AI*—将围棋或国际象棋棋盘映射到下一步的玩家移动'
- en: '*Diet helper*—Mapping pictures of a dish to its calorie count'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*饮食助手*—将一道菜的图片映射到其卡路里计数'
- en: '*Age prediction*—Mapping selfies to the age of the person'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*年龄预测*—将自拍照映射到人的年龄'
- en: 'Mapping time-series data to vector data:'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将时间序列数据映射到向量数据：
- en: '*Weather prediction*—Mapping time series of weather data in a grid of locations
    to the temperature in a specific place one week later'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*天气预测*—将时间序列的天气数据映射到一个星期后特定地点的温度'
- en: '*Brain-computer interfaces*—Mapping time series of magnetoencephalogram (MEG)
    data to computer commands'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*脑机接口*—将脑磁图（MEG）数据的时间序列映射到计算机命令'
- en: '*Behavioral targeting*—Mapping time series of user interactions on a website
    to the probability that a user will buy something'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*行为定向*—将用户在网站上的时间序列交互映射到用户购买某物的概率'
- en: 'Mapping text to text:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本映射到文本：
- en: '*Machine translation*—Mapping a paragraph in one language to a translated version
    in a different language'
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器翻译*—将一种语言中的段落映射到另一种语言的翻译版本'
- en: '*Smart reply*—Mapping emails to possible one-line replies'
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*智能回复*—将电子邮件映射到可能的一行回复'
- en: '*Question answering*—Mapping general-knowledge questions to answers'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问答*—将普通知识问题映射到答案'
- en: '*Summarization*—Mapping a long article to a short summary of the article'
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*摘要*—将一篇长文章映射到文章的简短摘要'
- en: 'Mapping images to text:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像映射到文本：
- en: '*Text transcription*—Mapping images that contain a text element to the corresponding
    text string'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文本转录*—将包含文本元素的图像映射到相应的文本字符串'
- en: '*Captioning*—Mapping images to short captions describing the contents of the
    images'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*字幕*—将图像映射到描述图像内容的简短字幕'
- en: 'Mapping text to images:'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本映射到图像：
- en: '*Conditioned image generation*—Mapping a short text description to images matching
    the description'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*条件图像生成*—将简短的文本描述映射到与描述匹配的图像'
- en: '*Logo generation/selection*—Mapping the name and description of a company to
    a logo suggestion'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标志生成/选择*—将公司的名称和描述映射到标志建议'
- en: 'Mapping images to images:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像映射到图像：
- en: '*Super-resolution*—Mapping downsized images to higher-resolution versions of
    the same images'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超分辨率*—将缩小的图像映射到相同图像的更高分辨率版本'
- en: '*Visual depth sensing*—Mapping images of indoor environments to maps of depth
    predictions'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视觉深度感知*—将室内环境的图像映射到深度预测的地图'
- en: 'Mapping images and text to text:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像和文本映射到文本：
- en: '*Visual QA*—Mapping images and natural language questions about the contents
    of images to natural language answers'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视觉问答*—将图像和关于图像内容的自然语言问题映射到自然语言答案'
- en: Mapping video and text to text
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将视频和文本映射到文本
- en: '*Video QA*—Mapping short videos and natural language questions about the contents
    of videos to natural language answers'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视频问答*—将短视频和关于视频内容的自然语言问题映射到自然语言答案'
- en: '*Almost* anything is possible, but not quite *anything*. You’ll see in the
    next section what we *can’t* do with deep learning.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*几乎*什么都可能，但并非*一切*。在下一节中，您将看到我们用深度学习*无法*做到的事情。'
- en: 14.2 The limitations of deep learning
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 深度学习的局限性
- en: The space of applications that can be implemented with deep learning is infinite.
    And yet, many applications remain completely out of reach for current deep learning
    techniques—even given vast amounts of human-annotated data. Say, for instance,
    that you could assemble a dataset of hundreds of thousands—even millions—of English-language
    descriptions of the features of a software product, written by a product manager,
    as well as the corresponding source code developed by a team of engineers to meet
    these requirements. Even with this data, you could not train a deep learning model
    to read a product description and generate the appropriate codebase. That’s just
    one example among many. In general, anything that requires reasoning—like programming
    or applying the scientific method—long-term planning—and algorithmic data manipulation
    is out of reach for deep learning models, no matter how much data you throw at
    them. Even learning a simple sorting algorithm with a deep neural network is tremendously
    difficult.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用深度学习实现的应用空间是无限的。然而，许多应用程序仍然完全超出了当前深度学习技术的范围——即使提供了大量的人工注释数据。比如，假设您可以组合成一个包含数十万甚至数百万个英语软件产品特性描述的数据集，这些描述是由产品经理撰写的，以及由工程师团队开发的相应源代码，以满足这些要求。即使有了这些数据，您也无法训练一个深度学习模型来阅读产品描述并生成相应的代码库。这只是众多例子中的一个。通常情况下，任何需要推理的事情——比如编程或应用科学方法——长期规划——和算法数据处理都超出了深度学习模型的范围，无论您向它们提供多少数据。甚至用深度神经网络学习一个简单的排序算法也是极其困难的。
- en: 'This is because a deep learning model is just *a chain of simple, continuous
    geometric transformations* mapping one vector space into another. All it can do
    is map one data manifold X into another manifold Y, assuming the existence of
    a learnable continuous transform from X to Y. A deep learning model can be interpreted
    as a kind of program, but, inversely, *most programs can’t be expressed as deep
    learning models*. For most tasks, either there exists no corresponding neural
    network of reasonable size that solves the task, or, even if one exists, it may
    not be *learnable*: the corresponding geometric transform may be far too complex,
    or there may not be appropriate data available to learn it.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为深度学习模型只是*一系列简单的、连续的几何变换*，将一个向量空间映射到另一个。它所能做的就是将一个数据流形X映射到另一个流形Y，假设存在从X到Y的可学习连续变换。深度学习模型可以解释为一种程序，但是，*大多数程序无法表示为深度学习模型*。对于大多数任务，要么不存在解决该任务的合理大小的相应神经网络，要么，即使存在一个，它也可能是*不可学习*的：相应的几何变换可能太复杂，或者可能没有适当的数据可用于学习它。
- en: Scaling up current deep learning techniques by stacking more layers and using
    more training data can only superficially palliate some of these issues. It won’t
    solve the more fundamental problems that deep learning models are limited in what
    they can represent and that most of the programs you may wish to learn can’t be
    expressed as a continuous geometric morphing of a data manifold.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 通过堆叠更多层次和使用更多训练数据来扩展当前的深度学习技术只能表面上缓解其中一些问题。这不会解决深度学习模型所能表示的内容受限以及你可能希望学习的大多数程序无法表示为数据流形的连续几何变换的更根本性问题。
- en: 14.2.1 The risk of anthropomorphizing machine learning models
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.1 将机器学习模型拟人化的风险
- en: 'One real risk with contemporary AI is misinterpreting what deep learning models
    do and overestimating their abilities. A fundamental feature of humans is our
    *theory of mind*: our tendency to project intentions, beliefs, and knowledge on
    the things around us. Drawing a smiley face on a rock suddenly makes it “happy”
    in our minds. Applied to deep learning, this means that, for instance, when we’re
    able to somewhat successfully train a model to generate captions to describe pictures,
    we’re led to believe that the model “understands” the contents of the pictures
    and the captions it generates. Then we’re surprised when any slight departure
    from the sort of images present in the training data causes the model to generate
    completely absurd captions (see [figure 14.1](#fig14-1)).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当代人工智能的一个真正风险是误解深度学习模型的作用并高估它们的能力。人类的一个基本特征是我们的*心智理论*：我们倾向于将意图、信念和知识投射到我们周围的事物上。在岩石上画一个笑脸突然让我们心里认为它“快乐”。应用于深度学习时，这意味着，例如，当我们能够在某种程度上成功地训练一个模型来生成描述图片的标题时，我们会认为模型“理解”了图片的内容和它所生成的标题。然后，当训练数据中的图像与稍微偏离时，我们会对模型生成完全荒谬的标题感到惊讶（见[图14.1](#fig14-1)）。
- en: '![Image](../images/f0486-01.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0486-01.jpg)'
- en: '**Figure 14.1 Failure of an image-captioning system based on deep learning**'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.1 基于深度学习的图像标题生成系统的失败**'
- en: In particular, this is highlighted by *adversarial examples*, which are samples
    fed to a deep learning network that are designed to trick the model into misclassifying
    them. You’re already aware that, for instance, it’s possible to do gradient ascent
    in input space to generate inputs that maximize the activation of some convnet
    filter—this is the basis of the filter-visualization technique introduced in chapter
    9, as well as the DeepDream algorithm from chapter 12\. Similarly, through gradient
    ascent, you can slightly modify an image to maximize the class prediction for
    a given class. By taking a picture of a panda and adding to it a gibbon gradient,
    we can get a neural network to classify the panda as a gibbon (see [figure 14.2](#fig14-2)).
    This evidences both the brittleness of these models and the deep difference between
    their input-to-output mapping and our human perception.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，这一点被*对抗样本*所突出显示，对抗样本是向深度学习网络提供的样本，旨在使模型误分类。你已经意识到，例如，可能在输入空间中进行梯度上升以生成最大化某些卷积网络滤波器激活的输入——这是第9章介绍的滤波器可视化技术的基础，以及第12章中的DeepDream算法。同样，通过梯度上升，你可以微调图像以最大化给定类别的类别预测。通过在熊猫的图片上添加一个猿猴的梯度，我们可以让神经网络将熊猫分类为猿猴（见[图14.2](#fig14-2)）。这既证明了这些模型的脆弱性，也显示了它们的输入到输出映射与我们的人类感知之间的深刻差异。
- en: In short, deep learning models don’t have any understanding of their input—at
    least not in a human sense. Our own understanding of images, sounds, and language
    is grounded in our sensorimotor experience as humans. Machine learning models
    have no access to such experiences and thus can’t understand their inputs in a
    human-relatable way. By annotating large numbers of training examples to feed
    into our models, we get them to learn a geometric transform that maps data to
    human concepts on a specific set of examples, but this mapping is a simplistic
    sketch of the original model in our minds—the one developed from our experience
    as embodied agents. It’s like a dim image in a mirror (see [figure 14.3](#fig14-1)).
    The models you create will take any shortcut available to fit their training data.
    For instance, image models tend to rely more on local textures than on a global
    understanding of the input images—a model trained on a dataset that features both
    leopards and sofas is likely to classify a leopard-pattern sofa as an actual leopard.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，深度学习模型在人类意义上并不了解它们的输入。我们对图像、声音和语言的理解基于我们作为人类的感觉运动体验。机器学习模型无法获得这样的经验，因此无法以人类可理解的方式理解它们的输入。通过为大量训练示例进行注释并输入我们的模型，我们使它们学习到将数据映射到特定示例集上的人类概念的几何变换，但这种映射只是我们头脑中原始模型的简化草图
    —— 这个模型是从我们作为感知机构的经验中发展而来的。就像镜中的模糊图像（参见[图14.3](#fig14-1)）。你创建的模型将采取任何可用的捷径来适应其训练数据。例如，图像模型往往更多地依赖于局部纹理，而不是对输入图像的整体理解
    —— 对具有豹纹和沙发两种特征的数据集进行训练的模型很可能将豹纹沙发误分类为实际豹子。
- en: '![Image](../images/f0487-01.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0487-01.jpg)'
- en: '**Figure 14.2 An adversarial example: Imperceptible changes in an image can
    upend a model’s classification of an image.**'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.2 对抗样本：图像中微不可见的变化可能颠覆模型对图像的分类。**'
- en: '![Image](../images/f0487-02.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0487-02.jpg)'
- en: '**Figure 14.3 Current machine learning models: Like a dim image in a mirror**'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.3 当前机器学习模型：就像镜子中的模糊图像**'
- en: 'As a machine learning practitioner, always be mindful of this, and never fall
    into the trap of believing that neural networks understand the tasks they perform—they
    don’t, at least not in a way that would make sense to us. They were trained on
    a different, far narrower task than the one we wanted to teach them: that of mapping
    training inputs to training targets, point by point. Show them anything that deviates
    from their training data, and they will break in absurd ways.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习实践者，始终要意识到这一点，并且不要陷入这样的误解：神经网络理解自己所执行的任务——它们不理解，至少对我们来说没有意义。它们接受的训练是不同的，远比我们想要教给它们的任务狭窄：它们只是逐点地将训练输入映射到训练目标而已。当它们看到任何偏离其训练数据的东西时，它们就会以一种荒谬的方式崩溃。
- en: 14.2.2 Automatons vs. intelligent agents
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.2 自动机与智能代理
- en: Fundamental differences exist between the straightforward geometric morphing
    from input to output that deep learning models do and the way humans think and
    learn. It isn’t just the fact that humans learn by themselves from embodied experience
    instead of being presented with explicit training examples. The human brain is
    an entirely different beast compared to a differentiable parametric function.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型从输入到输出的直接几何变换与人类思维和学习方式存在根本差异。不仅仅是因为人类通过自身的经验学习，而不是被呈现给明确的训练示例。人脑与可微分参数化函数完全不同。
- en: 'Let’s zoom out a little bit and ask, “what’s the purpose of intelligence?”
    Why did it arise in the first place? We can only speculate, but we can make fairly
    informed speculations. We can start by looking at brains—the organ that produces
    intelligence. Brains are an evolutionary adaption—a mechanism developed incrementally
    over hundreds of millions of years, via random trial and error, guided by natural
    selection— that dramatically expanded the ability of organisms to adapt to their
    environment. Brains originally appeared more than half a billion years ago as
    a way to *store and execute behavioral programs*. “Behavioral programs” are just
    sets of instructions that make an organism reactive to its environment: “if this
    happens, then do that.” They link the organism’s sensory inputs to its motor controls.
    In the beginning, brains would have served to hardcode behavioral programs (as
    neural connectivity patterns), which would allow an organism to react appropriately
    to its sensory input. This is the way insect brains still work—flies, ants, *C.
    elegans* (see [figure 14.4](#fig14-1)), and so on. Because the original “source
    code” of these programs was DNA, which would be decoded as neural connectivity
    patterns, evolution was suddenly able to *search over behavior space* in a largely
    unbounded way—a major evolutionary shift.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微放大一点，并问：“智能的目的是什么？”它为什么首次出现？我们只能进行推测，但我们可以做出相当有根据的推测。我们可以从大脑开始看起——这个产生智能的器官。大脑是一种进化适应——一个通过数亿年的随机试错，受自然选择引导的机制，大大扩展了生物适应环境的能力。大脑最初出现在五亿多年前，作为一种*存储和执行行为程序*的方式。
    “行为程序”只是使生物对其环境产生反应的一组指令：“如果发生这种情况，那么做那个。”它们将生物的感觉输入与其运动控制联系起来。起初，大脑将用于硬编码行为程序（作为神经连接模式），这将使生物对其感觉输入做出适当反应。这是昆虫大脑仍然工作的方式——蝇，蚂蚁，*秀丽隐杆线虫*（见[图14.4](#fig14-1)），等等。因为这些程序的原始“源代码”是DNA，它将被解码为神经连接模式，进化突然能够在很大程度上无限制地*搜索行为空间*——这是一个重大的进化转变。
- en: Evolution was the programmer, and brains were computers carefully executing
    the code evolution gave them. Because neural connectivity is a very general computing
    substrate, the sensorimotor space of all brain-enabled species could suddenly
    start undergoing a dramatic expansion. Eyes, ears, mandibles, four legs, 24 legs—as
    long as you have a brain, evolution will kindly figure out for you behavioral
    programs that make good use of these. Brains can handle any modality—or combination
    of modalities—you throw at them.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 进化是程序员，而大脑是小心执行进化赋予它们的代码的计算机。由于神经连接是一种非常通用的计算基质，所有启用大脑的物种的感觉运动空间都突然开始经历戏剧性的扩展。眼睛，耳朵，下颚，四条腿，24条腿——只要你有一个大脑，进化就会为你找到行为程序，使这些行为程序得到很好的利用。大脑可以处理你投入其中的任何模式——或模式的任何组合。
- en: 'Now, mind you, these early brains weren’t exactly intelligent per se. They
    were very much *automatons*: they would merely execute behavioral programs hardcoded
    in the organism’s DNA. They could only be described as intelligent in the same
    sense that a thermostat is “intelligent.” Or a list-sorting program. Or… a trained
    deep neural network (of the artificial kind). This is an important distinction,
    so let’s look at it carefully: what’s the difference between automatons and actual
    intelligent agents?'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些早期的大脑本质上并不是真正的智能。它们非常地是*自动机*：它们只会执行生物体DNA中硬编码的行为程序。它们只能被描述为智能，就像恒温器是“智能”一样。或者是列表排序程序。又或者……是经过训练的深度神经网络（人工类型）。这是一个重要的区别，让我们仔细看看它：自动机和实际智能代理之间有什么区别？
- en: '![Image](../images/f0489-01.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/f0489-01.jpg)'
- en: '**Figure 14.4 The brain network of the *C. elegans* worm: A behavioral automaton
    “programmed” by natural evolution. Figure created by Emma Towlson (from Yan et
    al., “Network Control Principles Predict Neuron Function in the *Caenorhabditis
    elegans* Connectome,” *Nature*, Oct. 2017).**'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.4 *秀丽隐杆线虫*的大脑网络：由自然演化“编程”而成的行为自动机。由Emma Towlson创建的图像（来源：Yan等人，“网络控制原则预测*秀丽隐杆线虫*连接组中的神经元功能”，*自然*，2017年10月）。**'
- en: 14.2.3 Local generalization vs. extreme generalization
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.3 本地泛化 vs. 极端泛化
- en: Seventeenth-century French philosopher and scientist René Descartes wrote in
    1637 an illuminating comment that perfectly captures this distinction, long before
    the rise of AI, and in fact, before the first mechanical computer (which his colleague
    Pascal would create five years later). Descartes tells us, in reference to automatons,
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 十七世纪法国哲学家和科学家勒内·笛卡尔于1637年写了一篇启发性的评论，完美地捕捉到了这种区别，远在人工智能崛起之前，事实上，远在第一台机械计算机出现之前（他的同事帕斯卡将在五年后创造出来）。笛卡尔告诉我们，关于自动机，
- en: '*Even though such machines might do some things as well as we do them, or perhaps
    even better, they would inevitably fail in others, which would reveal they were
    acting not through understanding, but only from the disposition of their organs.*'
  id: totrans-221
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*即使这样的机器可能在某些方面做得和我们一样好，甚至可能更好，但它们必然会在其他方面失败，这将显示它们不是通过理解而是仅仅通过其器官的排列来行动。*'
- en: ''
  id: totrans-222
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: René Descartes, *Discourse on the Method* (1637)
  id: totrans-223
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 勒内·笛卡尔，《方法论》（1637年）
- en: There it is. Intelligence is characterized by *understanding*, and understanding
    is evidenced by *generalization*—the ability to handle whatever novel situation
    may arise. How do you tell the difference between a student that has memorized
    the past three years of exam questions but has no understanding of the subject,
    and a student who actually understands the material? You give them a brand-new
    problem. An automaton is static, crafted to accomplish specific things in a specific
    context—”if this, then that”—while an intelligent agent can adapt on the fly to
    novel, unexpected situations. When an automaton is exposed to something that doesn’t
    match what it is “programmed” to do (whether we’re talking about human-written
    programs, evolution-generated programs, or the implicit programming process of
    fitting a model on a training dataset), it will fail. Meanwhile, intelligent agents,
    like humans, will use their understanding to find a way forward.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 智能就在这里。智能的特征在于*理解*，而理解则表现为*泛化*——处理可能出现的任何新情况的能力。你如何区分一个记住了过去三年考试题但对学科没有理解的学生，和一个真正理解了材料的学生？你给他们一个全新的问题。自动机是静态的，设计来在特定环境中完成特定的事情——“如果这样，那么那样”——而智能代理可以根据新的、意想不到的情况即时适应。当自动机暴露在与其“编程”不匹配的情况下时（无论我们是在谈论人类编写的程序，还是演化生成的程序，还是在训练数据集上拟合模型的隐式编程过程），它将失败。与此同时，像人类这样的智能代理将利用他们的理解找到前进的方法。
- en: 'Humans are capable of far more than mapping immediate stimuli to immediate
    responses, as a deep net, or an insect, would. We maintain complex, abstract models
    of our current situation, of ourselves, and of other people, and we can use these
    models to anticipate different possible futures and perform long-term planning.
    You can merge together known concepts to represent something you’ve never experienced
    before— like imagining what you’d do if you won the lottery, or picturing how
    your friend would react if you discreetly replaced her keys with exact copies
    made of elastic rubber. This ability to handle novelty and what-ifs, to expand
    our mental model space far beyond what we can experience directly—to leverage
    *abstraction* and *reasoning*—is the defining characteristic of human cognition.
    I call it *extreme generalization*: an ability to adapt to novel, never-before-experienced
    situations using little data or even no new data at all. This capability is key
    to the intelligence displayed by humans and advanced animals.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 人类能够做的远不止将即时刺激映射到即时反应，就像深度神经网络或昆虫那样。我们保持着对当前情况、自己以及他人的复杂抽象模型，我们可以利用这些模型来预测不同的可能未来并进行长期规划。你可以合并已知的概念来代表你以前从未经历过的事物——比如想象如果你中了彩票会怎么做，或者想象如果你偷偷地用弹性橡胶制成的精确复制品替换了朋友的钥匙，她会有什么反应。这种处理新奇事物和假设情况的能力，将我们的思维模型空间扩展到远远超出我们可以直接经历的范围——利用*抽象*和*推理*——是人类认知的定义特征。我称之为*极端泛化*：利用少量数据甚至没有新数据就能适应新的、以前从未经历过的情况的能力。这种能力是人类和高级动物展示出的智能的关键。
- en: 'This stands in sharp contrast with what automaton-like systems do. A very rigid
    automaton wouldn’t feature any generalization at all—it would be incapable of
    handling anything that it wasn’t precisely told about in advance. A hash table
    or a basic question-answering program implemented as hardcoded if-then-else statements
    would fall into this category. Deep nets do slightly better: they can successfully
    process inputs that deviate a bit from what they’re familiar with, which is precisely
    what makes them useful. Our cats vs. dogs model from chapter 8 could classify
    cat or dog pictures it had not seen before, as long as they were close enough
    to what it was trained on. However, deep nets are limited to what I call *local
    generalization* (see [figure 14.5](#fig14-5)): the mapping from inputs to outputs
    performed by a deep net quickly stops making sense as inputs start deviating from
    what the net saw at training time. Deep nets can only generalize to *known unknowns*—to
    factors of variation that were anticipated during model development and that are
    extensively featured in the training data, such as different camera angles or
    lighting conditions for pet pictures. That’s because deep nets generalize via
    interpolation on a manifold (remember chapter 5): any factor of variation in their
    input space needs to be captured by the manifold they learn. That’s why basic
    data augmentation is so helpful in improving deep net generalization. Unlike humans,
    these models have no ability to improvise in the face of situations for which
    little or no data is available (like winning the lottery or being handed rubber
    keys) that only share abstract commonalities with past situations.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这与自动机器人系统的做法形成了鲜明对比。一个非常刚性的自动机器人将不会有任何泛化能力——它将无法处理任何不是事先准确告知的情况。一个作为硬编码的if-then-else语句实现的哈希表或基本问答程序将属于这一类别。深度网络做得稍微好一些：它们可以成功地处理与其熟悉的输入略有偏差的输入，这正是使它们有用的地方。我们在第8章的猫狗模型可以对其之前未见过的猫或狗图片进行分类，只要它们与其训练的内容足够接近。然而，深度网络局限于我称之为*本地泛化*（见[图14.5](#fig14-5)）：深度网络执行的从输入到输出的映射在输入开始偏离网络在训练时所见的内容时很快就变得没有意义。深度网络只能对*已知未知*进行泛化——对模型开发期间预期到的并且在训练数据中广泛出现的变化因素，例如宠物图片的不同摄像机角度或光照条件。这是因为深度网络通过流形插值进行泛化（请记住第5章）：它们学习的流形需要捕获其输入空间的任何变化因素。这就是为什么基本数据增强对改善深度网络泛化很有帮助。与人类不同，这些模型在面对很少或没有可用数据的情况下没有任何即兴表演的能力（比如中彩票或被交给橡胶钥匙）只与过去情况有抽象共同点的情况。
- en: '![Image](../images/f0490-01.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0490-01.jpg)'
- en: '**Figure 14.5 Local generalization vs. extreme generalization**'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.5 本地泛化 vs. 极端泛化**'
- en: 'Consider, for instance, the problem of learning the appropriate launch parameters
    to get a rocket to land on the moon. If you used a deep net for this task and
    trained it using supervised learning or reinforcement learning, you’d have to
    feed it tens of thousands or even millions of launch trials: you’d need to expose
    it to a *dense sampling* of the input space, for it to learn a reliable mapping
    from input space to output space. In contrast, as humans, we can use our power
    of abstraction to come up with physical models—rocket science—and derive an exact
    solution that will land the rocket on the moon in one or a few trials. Similarly,
    if you developed a deep net controlling a human body, and you wanted it to learn
    to safely navigate a city without getting hit by cars, the net would have to die
    many thousands of times in various situations until it could infer that cars are
    dangerous and develop appropriate avoidance behaviors. Dropped into a new city,
    the net would have to relearn most of what it knows. On the other hand, humans
    are able to learn safe behaviors without having to die even once—again, thanks
    to our power of abstract modeling of novel situations.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑学习适当的发射参数以使火箭着陆月球的问题。如果你为此任务使用深度网络，并使用监督学习或强化学习对其进行训练，你将不得不向其提供成千上万甚至数百万次的发射试验：你需要让它暴露于*密集的采样*输入空间，以便学习从输入空间到输出空间的可靠映射。相比之下，作为人类，我们可以利用我们的抽象能力提出物理模型——火箭科学——并得出一个确切的解决方案，可以在一次或几次试验中将火箭着陆在月球上。同样，如果你开发了一个控制人体的深度网络，并且你希望它能够学会在城市中安全导航而不被汽车撞击，那么这个网络将不得不在各种情况下死亡成千上万次，直到它能够推断出汽车是危险的，并发展出适当的避让行为。放到一个新城市，这个网络将不得不重新学习大部分它所知道的东西。另一方面，人类能够学会安全行为，而不需要死亡一次——这再次归功于我们对新情况的抽象建模能力。
- en: 14.2.4 The purpose of intelligence
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.4 智能的目的
- en: This distinction between highly adaptable intelligent agents and rigid automatons
    leads us back to brain evolution. Why did brains—originally a mere medium for
    natural evolution to develop behavioral automatons—eventually turn intelligent?
    Like every significant evolutionary milestone, it happened because natural selection
    constraints encouraged it to happen.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 高度适应性智能代理和僵化自动机之间的区别使我们回到了大脑进化的范畴。为什么大脑——最初只是自然进化发展行为自动机的媒介——最终演化成了具有智能的器官？与每个重大的进化里程碑一样，它之所以发生，是因为自然选择的限制性促使它发生。
- en: 'Brains are responsible for behavior generation. If the set of situations an
    organism had to face was mostly static and known in advance, behavior generation
    would be an easy problem: evolution would just figure out the correct behaviors
    via random trial and error and hardcode them into the organism’s DNA. This first
    stage of brain evolution— brains as automatons—would already be optimal. However,
    crucially, as organism complexity—and alongside it, environmental complexity—kept
    increasing, the situations that animals had to deal with became much more dynamic
    and more unpredictable. A day in your life, if you look closely, is unlike any
    day you’ve ever experienced, and unlike any day ever experienced by any of your
    evolutionary ancestors. You need to be able to face unknown and surprising situations
    constantly. There is no way for evolution to find and hardcode as DNA the sequence
    of behaviors you’ve been executing to successfully navigate your day since you
    woke up a few hours ago. It has to be generated on the fly, every day.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 大脑负责行为生成。如果生物所面临的情境大部分是静态的并且可以事先知晓的，行为生成将是一个简单的问题：进化会通过随机试错找出正确的行为，并将其硬编码到生物的DNA中。这个大脑进化的第一阶段——大脑作为自动机——已经是最优的。然而，随着生物复杂性的增加（以及与之相伴的环境复杂性增加），动物所面临的情境变得更加动态和不可预测。你生活中的一天，仔细观察的话，与你过去经历的任何一天都不同，也与任何一个你的进化祖先经历的一天都不同。你必须能够不断面对未知和令人惊讶的情况。进化无法找到并硬编码成你今天早上醒来后成功应对你的一天所执行的行为序列的DNA。它必须每天都根据实际情况生成行为。
- en: The brain, as a good behavior-generation engine, simply adapted to fit this
    need. It optimized for adaptability and generality, rather than merely optimizing
    for fitness to a fixed set of situations. This shift likely occurred multiple
    times throughout evolutionary history, resulting in highly intelligent animals
    in very distant evolutionary branches—apes, octopuses, ravens, and more. Intelligence
    is an answer to challenges presented by complex, dynamic ecosystems.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个优秀的行为生成引擎，大脑简单地适应了这一需求。它优化的是适应性和普遍性，而不仅仅是对一组固定情境的适应。这种转变可能在进化历史中多次发生，导致在非常遥远的进化分支上出现了高智能动物，比如猿类、章鱼、渡鸦等。智能是对复杂、动态生态系统所提出挑战的一种应对。
- en: 'That’s the nature of intelligence: it is the ability to efficiently leverage
    the information at your disposal to produce successful behavior in the face of
    an uncertain, ever-changing future. What Descartes calls “understanding” is the
    key to this remarkable capability: the power to mine your past experience to develop
    modular, reusable abstractions that can be quickly repurposed to handle novel
    situations and achieve extreme generalization.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是智能的本质：它是利用手边的信息来高效地产生成功行为，应对不确定、不断变化的未来的能力。笛卡尔所谓的“理解”就是这种非凡能力的关键：开采过去经验的力量，开发可重用的模块化抽象，能够快速地重新调整来处理新情况和实现极端概括。
- en: 14.2.5 Climbing the spectrum of generalization
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.5 拓宽概括的谱系
- en: As a crude caricature, you could summarize the evolutionary history of biological
    intelligence as a slow climb up the *spectrum of generalization*. It started with
    automaton-like brains that could perform only local generalization. Over time,
    evolution started producing organisms capable of increasingly broader generalization
    that could thrive in evermore complex and variable environments. Eventually, in
    the past few millions of years— an instant in evolutionary terms—certain hominid
    species started trending toward an implementation of biological intelligence capable
    of extreme generalization, precipitating the start of the Anthropocene and forever
    changing the history of life on earth.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个粗糙的夸张，你可以将生物智能的进化历史总结为对*泛化程度*的缓慢攀升。它始于只能执行局部泛化的类似自动机的大脑。随着时间的推移，进化开始产生越来越广泛泛化的生物体，它们能够在越来越复杂和多变的环境中茁壮成长。最终，在过去几百万年中——在进化的时间尺度上算是瞬间—某些类人猿物种开始趋向于实现极端泛化的生物智能，引发了人类世的开始，并永远改变了地球生命的历史。
- en: The progress of AI over the past 70 years bears striking similarities to this
    evolution. Early AI systems were pure automatons, like the ELIZA chat program
    from the 1960s, or SHRDLU,^([2](#Rendnote2)) a 1970 AI capable of manipulating
    simple objects from natural language commands. In the 1990s and 2000s, we saw
    the rise of machine learning systems capable of local generalization, which could
    deal with some level of uncertainty and novelty. In the 2010s, deep learning further
    expanded the local-generalization power of these systems by enabling engineers
    to leverage much larger datasets and much more expressive models.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 过去70年来人工智能的进步与这种进化有惊人的相似之处。早期的人工智能系统是纯自动机，例如上世纪60年代的ELIZA聊天程序，或者是一个1970年的AI，能够通过自然语言命令操纵简单的物体。在90年代和2000年代，我们看到了能够进行局部泛化的机器学习系统的兴起，它们能够处理一定程度的不确定性和新奇性。在2010年代，深度学习进一步扩展了这些系统的局部泛化能力，使工程师能够利用更大的数据集和更具表现力的模型。
- en: Today, we may be on the cusp of the next evolutionary step. There is increasing
    interest in systems that could achieve *broad generalization*, which I define
    as the ability to deal with *unknown unknowns* within a single broad domain of
    tasks (including situations the system was not trained to handle and that its
    creators could not have anticipated), for instance, a self-driving car capable
    of safely dealing with any situation you throw at it, or a domestic robot that
    could pass the “Woz test of intelligence”—entering a random kitchen and making
    a cup of coffee.^([3](#Rendnote3)) By combining deep learning and painstakingly
    handcrafted abstract models of the world, we’re already making visible progress
    toward these goals.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，我们可能正处于下一个进化步骤的前夕。人们对能够实现*广泛泛化*的系统越来越感兴趣，我将其定义为处理*未知未知*的能力，即在单一广泛任务领域内处理（包括系统未经训练处理和其创造者无法预料的情况），例如，一个能够安全处理你提出的任何情况的自动驾驶汽车，或者能够通过“智能测试”的家用机器人——进入一个随机的厨房并煮一杯咖啡。通过结合深度学习和精心制作的世界抽象模型，我们已经在朝着这些目标取得了可见的进展。
- en: 'However, for the time being, AI remains limited to *cognitive automation*:
    the “intelligence” label in “artificial intelligence” is a category error. It
    would be more accurate to call our field “artificial cognition,” with “cognitive
    automation” and “artificial intelligence” being two nearly independent subfields
    within it. In this subdivision, “artificial intelligence” would be a greenfield
    where almost everything remains to be discovered.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前，人工智能仍然局限于*认知自动化*：在“人工智能”中的“智能”标签是一个范畴错误。更准确地说，将我们的领域称为“人工认知”，而“认知自动化”和“人工智能”则是其两个几乎独立的子领域。在这个划分中，“人工智能”将是一个几乎一切都有待发现的新领域。
- en: 'Now, I don’t mean to diminish the achievements of deep learning. Cognitive
    automation is incredibly useful, and the way deep learning models are capable
    of automating tasks from exposure to data alone represents an especially powerful
    form of cognitive automation, far more practical and versatile than explicit programming.
    Doing this well is a game-changer for essentially every industry. But it’s still
    a long way from human (or animal) intelligence. Our models, so far, can perform
    only local generalization: they map space X to space Y via a smooth geometric
    transform learned from a dense sampling of X-to-Y data points, and any disruption
    within spaces X or Y invalidates this mapping. They can generalize only to new
    situations that stay similar to past data, whereas human cognition is capable
    of extreme generalization, quickly adapting to radically novel situations and
    planning for long-term future situations.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我并不是要贬低深度学习的成就。认知自动化非常有用，深度学习模型能够仅通过暴露于数据而自动化任务的方式代表了一种特别强大的认知自动化形式，比明确编程要实用和多功能得多。做好这一点对于几乎每个行业都是一个改变游戏规则的举措。但它仍然远远落后于人类（或动物）智能。到目前为止，我们的模型只能执行局部泛化：它们通过对X到Y数据点的密集采样学习到的平滑几何变换，将空间X映射到空间Y，而在空间X或Y内的任何破坏都会使得这种映射无效。它们只能泛化到与过去数据相似的新情况，而人类认知能够进行极端泛化，迅速适应根本新颖的情况并规划长期未来的情况。
- en: 14.3 Setting the course toward greater generality in AI
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 迈向AI更大普适性的路线设定
- en: To lift some of the limitations we have discussed and create AI that can compete
    with human brains, we need to move away from straightforward input-to-output mappings
    and on to *reasoning* and *abstraction*. In the following couple of sections,
    we’ll take a look at what the road ahead may look like.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了消除我们讨论过的一些限制并创建能够与人类大脑竞争的AI，我们需要摆脱简单的输入到输出映射，转向*推理*和*抽象*。在接下来的几节中，我们将看一下前进之路可能是什么样子的。
- en: '14.3.1 On the importance of setting the right objective: The shortcut rule'
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.1 关于设定正确目标的重要性：捷径法则
- en: Biological intelligence was the answer to a question asked by nature. Likewise,
    if we want to develop true artificial intelligence, first, we need to be asking
    the right questions.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 生物智能是自然提出的一个问题的答案。同样，如果我们想要开发真正的人工智能，首先，我们需要问正确的问题。
- en: 'An effect you see constantly in systems design is the *shortcut rule*: if you
    focus on optimizing one success metric, you will achieve your goal, but at the
    expense of everything in the system that wasn’t covered by your success metric.
    You end up taking every available shortcut toward the goal. Your creations are
    shaped by the incentives you give yourself.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统设计中经常出现的一个效应是*捷径法则*：如果你专注于优化一个成功度量标准，你会实现你的目标，但会牺牲系统中未涵盖你的成功度量标准的一切。你最终会采取通往目标的所有可用捷径。你的创造受到你给自己的激励的影响。
- en: 'You see this often in machine learning competitions. In 2009, Netflix ran a
    challenge that promised a $1 million prize to the team that achieved the highest
    score on a movie-recommendation task. It ended up never using the system created
    by the winning team, because it was way too complex and compute intensive. The
    winners had optimized for prediction accuracy alone—what they were incentivized
    to achieve—at the expense of every other desirable characteristic of the system:
    inference cost, maintainability, and explainability. The shortcut rule holds true
    in most Kaggle competitions as well: the models produced by Kaggle winners can
    rarely, if ever, be used in production.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常在机器学习竞赛中看到这种情况。2009年，Netflix举办了一个挑战赛，承诺给予在电影推荐任务中取得最高分的团队100万美元的奖金。最终他们没有采用获胜团队创建的系统，因为它过于复杂且计算密集。获胜者只优化了预测准确性，也就是他们被激励要达到的目标，而牺牲了系统的其他所有理想特性：推断成本、可维护性和可解释性。Kaggle竞赛中的大多数情况也适用于这一捷径法则：Kaggle获胜者生成的模型很少能够在生产中使用。
- en: 'The shortcut rule has been everywhere in AI over the past few decades. In the
    1970s, psychologist and computer science pioneer Allen Newell, concerned that
    his field wasn’t making any meaningful progress toward a proper theory of cognition,
    proposed a new grand goal for AI: chess-playing. The rationale was that playing
    chess, in humans, seemed to involve—perhaps even require—capabilities such as
    perception, reasoning and analysis, memory, study from books, and so on. Surely,
    if we could build a chess-playing machine, it would have to feature these attributes
    as well. Right?'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，快速的规则一直在人工智能中被广泛应用。在20世纪70年代，心理学家和计算机科学先驱艾伦·纽厄尔对他所在的领域在认知理论方面没有取得任何有意义的进展感到担忧，他提出了一个新的人工智能的宏伟目标：下棋。理论依据是在人类中，下棋似乎涉及——甚至可能需要——一些能力，比如感知、推理和分析、记忆、从书籍中学习等等。当然，如果我们能够构建一个下棋的机器，它也必须具备这些特征，对吗？
- en: 'Over two decades later, the dream came true: in 1997, IBM’s Deep Blue beat
    Gary Kasparov, the best chess player in the world. Researchers had then to contend
    with the fact that creating a chess-champion AI had taught them little about human
    intelligence. The Alpha-Beta algorithm at the heart of Deep Blue wasn’t a model
    of the human brain and couldn’t generalize to tasks other than similar board games.
    It turned out it was easier to build an AI that could only play chess than to
    build an artificial mind—so that’s the shortcut researchers took.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 二十多年后，梦想成真了：1997年，IBM的深蓝超越了全球最佳棋手加里·卡斯帕罗夫。然而，研究人员随后不得不面对这样一个事实，即创造一个国际象棋冠军级人工智能并没有对他们对人类智能的理解有所帮助。深蓝的核心是阿尔法贝塔算法，并不是人脑的一个模型，而且不能推广到除了类似棋盘游戏之外的其他任务。事实证明，建立一个只能下国际象棋而不能构建一个人工智能大脑将比较容易，所以研究人员选择了这个捷径。
- en: So far, the driving success metric of the field of AI has been to solve specific
    tasks, from chess to Go, from MNIST classification to ImageNet, from Atari arcade
    games to *StarCraft* and *Dota 2*. Consequently, the history of the field has
    been defined by a series of “successes” where we figured out how to solve these
    tasks *without featuring any intelligence*.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，人工智能领域的驱动成功指标一直是解决特定的任务，从国际象棋到围棋，从MNIST分类到ImageNet，从Atari街机游戏到《星际争霸》和《Dota
    2》。因此，这个领域的历史被一系列“成功”所定义，我们在解决这些任务时发现没有任何智能特征。
- en: If that sounds like a surprising statement, keep in mind that human-like intelligence
    isn’t characterized by skill at any particular task—rather, it is the ability
    to adapt to novelty, to efficiently acquire new skills and master never-seen-before
    tasks. By fixing the task, you make it possible to provide an arbitrarily precise
    description of what needs to be done, either via hardcoding human-provided knowledge
    or by supplying humongous amounts of data. You make it possible for engineers
    to “buy” more skill for their AI by just adding data or adding hardcoded knowledge,
    without increasing the generalization power of the AI (see [figure 14.6](#fig14-6)).
    If you have near-infinite training data, even a very crude algorithm like nearest-neighbor
    search can play video games with superhuman skill. Likewise if you have a near-infinite
    amount of human-written if-then-else statements. That is, until you make a small
    change to the rules of the game—the kind a human could adapt to instantly—which
    will require the nonintelli-gent system to be retrained or rebuilt from scratch.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来有些令人惊讶，记住类人型智能不是以特定任务的技能为特征，而是能够适应新颖性，高效地掌握新技能和掌握之前从未见过的任务的能力。通过固定任务，你可以提供一个任意精确的任务描述，无论通过硬编码人类提供的知识，还是通过提供巨大量的数据。你可以让工程师通过添加数据或添加硬编码的知识来“购买”他们的AI更多的技能，而不需要增加AI的泛化能力（参见[图14.6](#fig14-6)）。如果你有几乎无限的训练数据，甚至一个非常简单的算法如最近邻搜索也能以超人的技能玩视频游戏。同样，如果你拥有几乎无限量的人工编写的if-then-else语句。然而，当你对游戏规则进行一次小的改变——这是一个人类可以立即适应的改变——非智能系统将需要重新训练或从头开始构建。
- en: '![Image](../images/f0494-01.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0494-01.jpg)'
- en: '**Figure 14.6 A low-generalization system can achieve arbitrary skill at a
    fixed task given unlimited task-specific information.**'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.6：一个低泛化系统可以在给定无限的任务特定信息的情况下取得任意技能水平的固定任务。**'
- en: In short, by fixing the task, you remove the need to handle uncertainty and
    novelty, and because the nature of intelligence is the ability to handle uncertainty
    and novelty, you’re effectively removing the need for intelligence. And because
    it’s always easier to find a non-intelligent solution to a specific task than
    to solve the general problem of intelligence, that’s the shortcut you will take
    100% of the time. Humans can use their general intelligence to acquire skills
    at any new task, but in reverse, there is no path from a collection of task-specific
    skills to general intelligence.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，通过固定任务，你消除了处理不确定性和新奇性的需求，而因为智能的本质是处理不确定性和新奇性的能力，你实际上是在消除智能的需求。而且因为在特定任务上找到非智能解决方案总是比解决智能的一般问题更容易，所以你会100%地采取这种捷径。人类可以利用其一般智能来获得任何新任务的技能，但反过来，从一系列特定任务技能到一般智能是没有路径的。
- en: 14.3.2 A new target
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.2 新目标
- en: To make artificial intelligence actually intelligent, and give it the ability
    to deal with the incredible variability and ever-changing nature of the real world,
    we first need to move away from seeking to achieve *task-specific skill* and,
    instead, start targeting generalization power itself. We need new metrics of progress
    that will help us develop increasingly intelligent systems, metrics that will
    point in the right direction and that will give us an actionable feedback signal.
    As long as we set our goal to be “create a model that solves task X,” the shortcut
    rule will apply, and we’ll end up with a model that does X, period.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 要使人工智能真正具有智能，并赋予其处理不可预测的变化和永远变化的现实世界的能力，我们首先需要摆脱追求*特定任务技能*的想法，而是开始针对通用化能力本身。我们需要新的进展指标，这些指标将帮助我们开发越来越智能的系统，指标将指向正确的方向，并给我们提供可操作的反馈信号。只要我们的目标设定为“创建一个解决任务
    X 的模型”，那么捷径规则就会适用，我们最终会得到一个只能做 X 任务的模型。
- en: 'In my view, intelligence can be precisely quantified as an *efficiency ratio*:
    the conversion ratio between the *amount of relevant information* you have available
    about the world (which could be either *past experience* or innate *prior knowledge*)
    and your *future operating area*, the set of novel situations where you will be
    able to produce appropriate behavior (you can view this as your *skill set*).
    A more intelligent agent will be able to handle a broader set of future tasks
    and situations using a smaller amount of past experience. To measure such a ratio,
    you just need to fix the information available to your system—its experience and
    its prior knowledge—and measure its performance on a set of reference situations
    or tasks that are known to be sufficiently different from what the system has
    had access to. Trying to maximize this ratio should lead you toward intelligence.
    Crucially, to avoid cheating, you’re going to need to make sure you test the system
    only on tasks it wasn’t programmed or trained to handle—in fact, you need tasks
    that the *creators of the system could not have anticipated*.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，智能可以精确地量化为*效率比*：你可用于世界的*相关信息量*（可以是*过去经验*或先天*先验知识*）与你的*未来操作领域*之间的转化比率，即你能够产生适当行为的新颖情况集合（你可以将其视为你的*技能集*）。更智能的代理将能够使用更少的过去经验来处理更广泛的未来任务和情况。要测量这样的比率，你只需要固定系统可用的信息——其经验和先验知识——并在一组已知与系统接触到的情况或任务足够不同的参考情况或任务上测量其性能。试图最大化这一比率应该会引导你走向智能。关键是，为了避免作弊，你需要确保只在系统不是被编程或训练来处理的任务上测试系统——事实上，你需要一些*系统的创建者无法预料到的任务*。
- en: In 2018 and 2019, I developed a benchmark dataset called the *Abstraction and
    Reasoning Corpus* (ARC)^([4](#Rendnote4)) that seeks to capture this definition
    of intelligence. ARC is meant to be approachable by both machines and humans,
    and it looks very similar to human IQ tests, such as Raven’s progressive matrices.
    At test time, you’ll see a series of “tasks.” Each task is explained via three
    or four “examples” that take the form of an input grid and a corresponding output
    grid (see [figure 14.7](#fig14-7)). You’ll then be given a brand-new input grid,
    and you’ll have three tries to produce the correct output grid before moving on
    to the next task.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2018 年和 2019 年，我开发了一个称为*抽象与推理语料库*（ARC）^([4](#Rendnote4))的基准数据集，旨在捕捉这种智能的定义。ARC
    旨在既能被机器理解，又能被人类理解，它看起来非常类似于人类智商测试，比如雷文氏递进矩阵。在测试时，您会看到一系列“任务”。每个任务都通过三或四个“示例”来解释，这些示例采用输入网格和相应的输出网格的形式（见[图14.7](#fig14-7)）。然后，您将被给出一个全新的输入网格，您将有三次机会在移动到下一个任务之前产生正确的输出网格。
- en: 'Compared to IQ tests, two things are unique about ARC. First, ARC seeks to
    measure generalization power, by only testing you on tasks you’ve never seen before.
    That means that ARC is *a game you can’t practice for*, at least in theory: the
    tasks you will be tested on will have their own unique logic that you will have
    to understand on the fly. You can’t just memorize specific strategies from past
    tasks.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 与智商测试相比，ARC 有两个独特之处。首先，ARC 试图衡量泛化能力，只测试您从未见过的任务。这意味着 ARC *是一个您无法练习的游戏*，至少在理论上：您将被测试的任务将具有自己独特的逻辑，您必须即兴理解。您不能仅仅从过去任务中记忆特定策略。
- en: '![Image](../images/f0496-01.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0496-01.jpg)'
- en: '**Figure 14.7 An ARC task: The nature of the task is demonstrated by a couple
    of input-output pair examples. Provided with a new input, you must construct the
    corresponding output.**'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.7 一个 ARC 任务：任务的性质由几个输入输出对示例来演示。给定一个新输入，您必须构建相应的输出。**'
- en: In addition, ARC tries to control for the *prior knowledge* that you bring to
    the test. You never approach a new problem entirely from scratch—you bring to
    it preexisting skills and information. ARC makes the assumption that all test
    takers should start from the set of knowledge priors, called “Core Knowledge priors,”
    that represent the “knowledge systems” that humans are born with. Unlike an IQ
    test, ARC tasks will never involve acquired knowledge, like English sentences,
    for instance.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，ARC 试图控制您带入测试的*先验知识*。您永远不会完全从零开始解决一个新问题——您会带入预先存在的技能和信息。ARC 假设所有的测试者都应该从一组称为“核心知识先验”的知识先验开始，这些知识先验代表了人类与生俱来的“知识系统”。与智商测试不同，ARC
    任务永远不会涉及到已获得的知识，比如英语句子等。
- en: Unsurprisingly, deep-learning-based methods (including models trained on extremely
    large amounts of external data, like GPT-3) have proven entirely unable to solve
    ARC tasks, because these tasks are non-interpolative and thus are a poor fit for
    curve-fitting. Meanwhile, average humans have no issue solving these tasks on
    the first try, without any practice. When you see a situation like this, where
    humans as young as five are able to naturally perform something that seems to
    be completely out of reach for modern AI technology, that’s a clear signal that
    something interesting is going on—that we’re missing something.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，基于深度学习的方法（包括在大量外部数据上训练的模型，如 GPT-3）完全无法解决 ARC 任务，因为这些任务是非插值的，因此不适合曲线拟合。与此同时，普通人没有任何问题在第一次尝试时解决这些任务，而且无需练习。当你看到这样的情况，即使是五岁的人类也能自然地执行一些现代人工智能技术似乎完全无法达到的事情时，这清楚地表明有趣的事情正在发生——我们漏掉了什么。
- en: 'What would it take to solve ARC? Hopefully, this challenge will get you thinking.
    That’s the entire point of ARC: to give you a goal of a different kind that will
    nudge you in a new direction—hopefully a productive direction. Now let’s take
    a quick look at the key ingredients you’re going to need if you want to answer
    the call.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如何解决 ARC 需要什么？希望这个挑战会让您思考。这就是 ARC 的全部目的：给您一个不同种类的目标，希望能引导您朝一个新方向——希望是一个富有成效的方向。现在让我们快速看一下您想要回答这个呼唤时需要的关键要素。
- en: '14.4 Implementing intelligence: The missing ingredients'
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现智能：缺失的要素
- en: So far, you’ve learned that there’s a lot more to intelligence than the sort
    of latent manifold interpolation that deep learning does. But what, then, do we
    need to start building real intelligence? What are the core pieces that are currently
    eluding us?
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经了解到智能远不止是深度学习所做的潜在流形插值。但那么，我们需要开始构建真正的智能吗？目前正在逃避我们的核心部分是什么？
- en: 14.4.1 Intelligence as sensitivity to abstract analogies
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.4.1 智能作为对抽象类比的敏感性
- en: Intelligence is the ability to use your past experience (and innate prior knowledge)
    to face novel, unexpected future situations. If the future you had to face was
    *truly novel*— sharing no common ground with anything you’ve seen before—you’d
    be unable to react to it, no matter how intelligent you were.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 智能是利用你的过去经验（和先天知识）来应对新的、意想不到的未来情况的能力。如果你将要面对的未来 *真的是新奇的*——与你以前见过的任何东西都没有共同基础——那么无论你有多聪明，你都无法对其做出反应。
- en: Intelligence works because nothing is ever truly without precedent. When we
    encounter something new, we’re able to make sense of it by drawing analogies to
    our past experience, by articulating it in terms of the abstract concepts we’ve
    collected over time. A person from the 17th century seeing a jet plane for the
    first time might describe it as a large, loud metal bird that doesn’t flap its
    wings. A car? That’s a horseless carriage. If you’re trying to teach physics to
    a grade schooler, you can explain how electricity is like water in a pipe, or
    how space-time is like a rubber sheet getting distorted by heavy objects.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 智能起作用是因为没有什么是真正没有先例的。当我们遇到新事物时，我们能够通过将其与过去的经验进行类比来理解它，通过用我们随时间收集的抽象概念来表达它。17世纪的人第一次看到喷气飞机可能会描述它为一只大而吵闹的不拍动翅膀的金属鸟。汽车？那是一辆没有马的马车。如果你试图向小学生教授物理学，你可以解释电是如何像管道中的水，或者时空如何像橡皮片被重物扭曲。
- en: Besides such clear-cut, explicit analogies, we’re constantly making smaller,
    implicit analogies, every second, with every thought. Analogies are how we navigate
    life. Going to a new supermarket? You’ll find your way by relating it to similar
    stores you’ve been to. Talking to someone new? They’ll remind you of a few people
    you’ve met before. Even seemingly random patterns, like the shape of clouds, instantly
    evoke in us vivid images—an elephant, a ship, a fish.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这种明确的、明显的类比，我们每秒钟都在不断地进行更小的、隐含的类比。类比是我们生活的导航。去一个新的超市？你会通过将其与你去过的类似店铺联系起来找到路。与陌生人交谈？他们会让你想起你以前遇到过的几个人。甚至看似随机的模式，如云的形状，立即在我们心中唤起生动的形象——一只大象，一艘船，一条鱼。
- en: 'These analogies aren’t just in our minds, either: physical reality itself is
    full of isomorphisms. Electromagnetism is analogous to gravity. Animals are all
    structurally similar to each other, due to shared origins. Silica crystals are
    similar to ice crystals. And so on.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类比不仅仅存在于我们的头脑中：物理现实本身充满了同构。电磁力类似于重力。动物们在结构上彼此相似，因为有着共同的起源。硅晶体类似于冰晶体。等等。
- en: 'I call this the *kaleidoscope hypothesis*: our experience of the world seems
    to feature incredible complexity and never-ending novelty, but everything in this
    sea of complexity is similar to everything else. The number of *unique atoms of
    meaning* that you need to describe the universe you live in is relatively small,
    and everything around you is a recombination of these atoms, a few seeds, endless
    variation—much like what goes on inside a kaleidoscope, where a few glass beads
    are reflected by a system of mirrors to produce rich, seemingly ever-changing
    patterns (see [figure 14.8](#fig14-8)).'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我称之为 *万花筒假设*：我们对世界的经验似乎充满了难以置信的复杂性和永无止境的新奇，但这片复杂的海洋中的一切都与其他一切相似。描述你所生活的宇宙所需的
    *独特意义的原子* 数量相对较少，你周围的一切都是这些原子的重组，几颗种子，无尽的变化——就像在万花筒内发生的一样，少数玻璃珠被一套镜子反射，产生丰富、似乎不断变化的图案（参见
    [图14.8](#fig14-8)）。
- en: Generalization power—intelligence—is the ability to mine your experience to
    identify these atoms of meaning that can seemingly be reused across many different
    situations. Once extracted, they’re called *abstractions*. Whenever you encounter
    a new situation, you make sense of it via your accumulated collection of abstractions.
    How do you identify reusable atoms of meaning? Simply by noticing when two things
    are similar—by noticing analogies. If something is repeated twice, then both instances
    must have a single origin, like in a kaleidoscope. Abstraction is the engine of
    intelligence, and analogy-making is the engine that produces abstraction.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 智力的泛化能力——智能——是利用你的经验来识别这些意义原子，它们似乎可以在许多不同的情况下重复使用的能力。一旦提取出来，它们被称为*抽象*。每当你遇到一个新情况，你都会通过你积累的抽象集合来理解它。你如何识别可重用的意义原子？只需注意到两个事物何时相似——通过注意类比。如果某事重复两次，那么两个实例必定有一个单一的起源，就像在万花筒中一样。抽象是智力的引擎，制作类比是产生抽象的引擎。
- en: In short, intelligence is literally sensitivity to abstract analogies, and that’s
    in fact all there is to it. If you have a high sensitivity to analogies, you will
    extract powerful abstractions from little experience, and you will be able to
    use these abstractions to operate in a maximally large area of future experience
    space. You will be maximally efficient in converting past experience into the
    ability to handle future novelty.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，智能实际上就是对抽象类比的敏感性，事实上就是这样。如果你对类比的敏感性很高，你将从少量经验中提取出强大的抽象，并能够使用这些抽象来在未来的经验空间中最大限度地操作。你将能够将过去的经验最大程度地转化为处理未来新奇事物的能力。
- en: '![Image](../images/f0498-01.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0498-01.jpg)'
- en: '**Figure 14.8 A kaleidoscope produces rich (yet repetitive) patterns from just
    a few beads of colored glass.**'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 14.8 万花筒仅用几颗彩色玻璃珠产生丰富（但重复）的图案。**'
- en: 14.4.2 The two poles of abstraction
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.4.2 抽象的两极
- en: If intelligence is sensitivity to analogies, then developing artificial intelligence
    should start with spelling out a step-by-step algorithm for analogy-making. Analogy-making
    starts with *comparing things to one another*. Crucially, there are *two distinct
    ways* to compare things, from which arise two different kinds of abstraction,
    two modes of thinking, each better suited to a different kind of problem. Together,
    these two poles of abstraction form the basis for all of our thoughts.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果智能是对类比的敏感性，那么开发人工智能应该从阐明制作类比的逐步算法开始。制作类比始于*将事物相互比较*。关键是，有*两种不同的方式*比较事物，从中产生两种不同类型的抽象，两种思维模式，每一种都更适合不同类型的问题。这两极抽象共同构成了我们所有思想的基础。
- en: The first way to relate things to each other is *similarity comparison*, which
    gives rise to *value-centric analogies*. The second way is *exact structural match*,
    which gives rise to *program-centric analogies* (or structure-centric analogies).
    In both cases, you start from *instances* of a thing, and you merge together related
    instances to produce an *abstraction* that captures the common elements of the
    underlying instances. What varies is how you tell that two instances are related,
    and how you merge instances into abstractions. Let’s take a close look at each
    type.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 将事物联系起来的第一种方式是*相似性比较*，这产生了*以价值为中心的类比*。第二种方式是*确切的结构匹配*，这产生了*以程序为中心的类比*（或结构为中心的类比）。在这两种情况下，你从事物的*实例*开始，并将相关实例合并在一起，以产生一个捕捉底层实例共同元素的*抽象*。变化的是你如何确定两个实例之间的关系，以及如何将实例合并成抽象。让我们仔细看看每种类型。
- en: VALUE-CENTRIC ANALOGY
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 以价值为中心的类比
- en: 'Let’s say you come across a number of different beetles in your backyard, belonging
    to multiple species. You’ll notice similarities between them. Some will be more
    similar to one another, and some will be less similar: the notion of similarity
    is implicitly a smooth, continuous *distance function* that defines a latent manifold
    where your instances live. Once you’ve seen enough beetles, you can start clustering
    more similar instances together and merging them into a set of *prototypes* that
    captures the shared visual features of each cluster (see [figure 14.9](#fig14-9)).
    This prototype is abstract: it doesn’t look like any specific instance you’ve
    seen, though it encodes properties that are common across all of them. When you
    encounter a new beetle, you won’t need to compare it to every single beetle you’ve
    seen before to know what to do with it. You can simply compare it to your handful
    of prototypes, so as to find the closest prototype— the beetle’s *category*—and
    use it to make useful predictions: is the beetle likely to bite you? Will it eat
    your apples?'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在后院看到了许多不同种类的甲壳虫。你会注意到它们之间的相似之处。有些会彼此更相似，而有些则不太相似：相似性的概念在隐含地定义了一个平滑连续的*距离函数*，它定义了一个潜在的流形，你的实例就存在其中。一旦你看过足够多的甲壳虫，你就可以开始将更相似的实例聚集在一起，并将它们合并成一组*原型*，这些原型捕捉了每个聚类的共享视觉特征（参见[图14.9](#fig14-9)）。这个原型是抽象的：它看起来不像你见过的任何具体实例，尽管它编码了所有这些实例都共有的属性。当你遇到一个新的甲壳虫时，你不需要将它与之前见过的每一个甲壳虫进行比较，才知道该怎么做。你可以简单地将它与你手里的几个原型进行比较，以找到最接近的原型——甲壳虫的*类别*——并用它来进行有用的预测：这只甲壳虫可能会咬你吗？它会吃你的苹果吗？
- en: '![Image](../images/f0499-01.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/f0499-01.jpg)'
- en: '**Figure 14.9 Value-centric analogy relates instances via a continuous notion
    of similarity to obtain abstract prototypes.**'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.9 价值为中心的类比通过连续的相似性概念将实例关联起来，以获得抽象的原型。**'
- en: Does this sound familiar? It’s pretty much a description of what unsupervised
    machine learning (such as the *K*-means clustering algorithm) does. In general,
    all of modern machine learning, unsupervised or not, works by learning latent
    manifolds that describe a space of instances encoded via prototypes. (Remember
    the convnet features you visualized in chapter 9? They were visual prototypes.)
    Value-centric analogy is the kind of analogy-making that enables deep learning
    models to perform local generalization.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来耳熟能详吗？这基本上就是无监督机器学习（例如*K*均值聚类算法）所做的事情的描述。总的来说，现代机器学习，无论是有监督还是无监督的，都通过学习描述由原型编码的实例空间的潜在流形来工作。（还记得你在第9章中可视化的卷积网络特征吗？它们就是视觉原型。）价值为中心的类比是使深度学习模型能够执行局部概括的类比制作方式。
- en: It’s also what many of your own cognitive abilities run on. As a human, you
    perform value-centric analogies all the time. It’s the type of abstraction that
    underlies *pattern recognition, perception*, and *intuition*. If you can do a
    task without thinking about it, you’re relying heavily on value-centric analogies.
    If you’re watching a movie and you start subconsciously categorizing the different
    characters into “types,” that’s value-centric abstraction.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是你自己许多认知能力所依赖的。作为人类，你一直在进行价值为中心的类比。这是潜在的抽象的类型，它是*模式识别*、*感知*和*直觉*的基础。如果你可以在不经思考的情况下完成一项任务，那么你就是在大量依赖价值为中心的类比。如果你正在看电影，并且开始下意识地将不同的角色分类为“类型”，那就是价值为中心的抽象。
- en: PROGRAM-CENTRIC ANALOGY
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 程序为中心的类比
- en: 'Crucially, there’s more to cognition than the kind of immediate, approximative,
    intuitive categorization that value-centric analogy enables. There’s another type
    of abstraction-generation mechanism that’s slower, exact, deliberate: program-centric
    (or structure-centric) analogy.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 至关重要的是，认知不仅仅是价值为中心的类比所能实现的那种即时的、近似的、直觉的分类。还有另一种生成抽象的机制，即较慢、精确、审慎的程序为中心（或结构为中心）类比。
- en: 'In software engineering, you often write different functions or classes that
    seem to have a lot in common. When you notice these redundancies, you start asking,
    “could there be a more abstract function that performs the same job, that could
    be reused twice? Could there be an abstract base class that both of my classes
    could inherit from?” The definition of abstraction you’re using here corresponds
    to program-centric analogy. You’re not trying to compare your classes and functions
    by *how similar* they look the way you’d compare two human faces, via an implicit
    distance function. Rather, you’re interested in whether there are *parts* of them
    that have *exactly the same structure*. You’re looking for what is called a *subgraph
    isomorphism* (see [figure 14.10](#fig14-10)): programs can be represented as graphs
    of operators, and you’re trying to find subgraphs (program subsets) that are exactly
    shared across your different programs.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程中，你经常编写不同的函数或类，它们看起来很相似。当你注意到这些冗余时，你开始问自己，“是否存在一个更抽象的函数，可以执行相同的任务，可以重复使用两次？是否存在一个抽象基类，可以由我的两个类继承？”这里定义的抽象化与程序为中心的类比相对应。你并不是试图通过类和函数之间有多相似来比较它们，就像你通过一个隐含的距离函数来比较两个人的脸一样。相反，你感兴趣的是它们是否有*完全相同结构的部分*。你正在寻找所谓的*子图同构*（见[图14.10](#fig14-10)）：程序可以表示为操作符的图，你正在试图找到跨不同程序完全共享的子图（程序子集）。
- en: '![Image](../images/f0500-01.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0500-01.jpg)'
- en: '**Figure 14.10 Program-centric analogy identifies and isolates isomorphic substructures
    across different instances.**'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.10 程序为中心的类比识别和隔离不同实例之间的同构子结构。**'
- en: This kind of analogy-making via exact structural match within different discrete
    structures isn’t at all exclusive to specialized fields like computer science
    or mathematics— you’re constantly using it without noticing. It underlies *reasoning,
    planning*, and the general concept of *rigor* (as opposed to intuition). Any time
    you’re thinking about objects connected to each other by a discrete network of
    relationships (rather than a continuous similarity function), you’re leveraging
    program-centric analogies.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这种通过在不同的离散结构内进行精确结构匹配进行类比的方法，不是专业领域如计算机科学或数学所特有的——你经常在不知不觉中使用它。它是推理、规划和*严谨性*（与直觉相反）的一种基础。每当你思考由离散关系网络连接的对象时（而不是连续相似度函数），你正在利用程序为中心的类比。
- en: COGNITION AS A COMBINATION OF BOTH KINDS OF ABSTRACTION
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 认知是这两种抽象的结合
- en: Let’s compare these two poles of abstraction side by side (see [table 14.1](#tab14-1)).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们并排比较这两种抽象的两极（见[表14.1](#tab14-1)）。
- en: Table 14.1 The two poles of abstraction
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.1 抽象的两极
- en: '| Value-centric abstraction | Program-centric abstraction |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 以价值为中心的抽象 | 以程序为中心的抽象 |'
- en: '| Relates things by distance | Relates things by exact structural match |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 通过距离关系相互关联 | 通过精确结构匹配相互关联 |'
- en: '| Continuous, grounded in geometry | Discrete, grounded in topology |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 连续，以几何为基础 | 离散，以拓扑学为基础 |'
- en: '| Produces abstractions by “averaging” instances into “prototypes” | Produces
    abstractions by isolating isomorphic substructures across instances |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 通过将实例“平均”成“原型”来产生抽象 | 通过隔离异构子结构跨实例来产生抽象 |'
- en: '| Underlies perception and intuition | Underlies reasoning and planning |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 基础感知和直觉 | 基础推理和规划 |'
- en: '| Immediate, fuzzy, approximative | Slow, exact, rigorous |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 即时、模糊、近似 | 缓慢、精确、严谨 |'
- en: '| Requires a lot of experience to produce reliable results | Experience efficient;
    can operate on as few as two instances |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 需要大量经验才能产生可靠结果 | 经验高效；可以在仅有两个实例的情况下操作 |'
- en: 14.4.3 The two poles of abstraction
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.4.3 抽象化的两极
- en: Everything we do, everything we think, is a combination of these two types of
    abstraction. You’d be hard-pressed to find tasks that involve only one of the
    two. Even a seemingly “pure perception” task, like recognizing objects in a scene,
    involves a fair amount of implicit reasoning about the relationships between the
    objects you’re looking at. And even a seemingly “pure reasoning” task, like finding
    the proof of a mathematical theorem, involves a good amount of intuition. When
    a mathematician puts their pen to the paper, they’ve already got a fuzzy vision
    of the direction in which they’re going. The discrete reasoning steps they take
    to get to the destination are guided by high-level intuition.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所做的一切，我们所思考的一切，都是这两种抽象类型的结合。你很难找到仅涉及其中一种的任务。即使是看似“纯粹感知”的任务，比如在场景中识别物体，也涉及对你所看到的物体之间关系的某种程度上的隐含推理。而即使是看似“纯推理”的任务，比如找到一个数学定理的证明，也涉及一定程度的直觉。当数学家将他们的笔放在纸上时，他们已经对他们要走的方向有了模糊的想法。他们采取的离散推理步骤是由高级直觉引导的。
- en: These two poles are complementary, and it’s their interleaving that enables
    extreme generalization. No mind could be complete without both of them.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个极端是互补的，它们的交织使得极端的泛化成为可能。没有一个思维可以完全没有它们。
- en: 14.4.4 The missing half of the picture
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.4.4 这个问题的缺失之处
- en: 'By this point, you should start seeing what’s missing from modern deep learning:
    it’s very good at encoding value-centric abstraction, but it has basically no
    ability to generate program-centric abstraction. Human-like intelligence is a
    tight interleaving of both types, so we’re literally missing half of what we need—arguably
    the most important half.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点上，你应该开始看到现代深度学习中缺失的东西：它非常擅长编码以价值为中心的抽象，但基本上没有生成以程序为中心的抽象的能力。像人类一样的智能是这两种类型的紧密交织，所以我们实际上正在失去我们需要的一半-可以说是最重要的一半。
- en: 'Now, here’s a caveat. So far, I’ve presented each type of abstraction as entirely
    separate from the other—opposite, even. In practice, however, they’re more of
    a spectrum: to an extent, you could do reasoning by embedding discrete programs
    in continuous manifolds, just like you may fit a polynomial function through any
    set of discrete points, as long as you have enough coefficients. And inversely,
    you could use discrete programs to emulate continuous distance functions—after
    all, when you’re doing linear algebra on a computer, you’re working with continuous
    spaces, entirely via discrete programs that operate on ones and zeros.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这里有一个注意事项。到目前为止，我按照完全不同的方式呈现了每种抽象类型，甚至可以说是相反的方式。然而，在实践中，它们更像是一个连续体谱：在某种程度上，你可以通过嵌入离散程序到连续曲面中进行推理，就像你可以通过足够多的系数适应多项式函数来适应离散点集一样。反过来，你也可以使用离散程序来模拟连续距离函数-毕竟，当你在计算机上进行线性代数运算时，你完全是通过作用于一和零的离散程序来处理连续空间的。
- en: 'However, there are clearly types of problems that are better suited to one
    or the other. Try to train a deep learning model to sort a list of five numbers,
    for instance. With the right architecture, it’s not impossible, but it’s an exercise
    in frustration. You’ll need a massive amount of training data to make it happen,
    and even then, the model will still make occasional mistakes when presented with
    new numbers. And if you want to start sorting lists of 10 numbers instead, you’ll
    need to completely retrain the model on even more data. Meanwhile, writing a sorting
    algorithm in R takes just a few lines, and the resulting program, once validated
    on a couple more examples, will work every time on lists of any size. That’s pretty
    strong generalization: going from a couple of demonstration examples and test
    examples to a program that can successfully process literally any list of numbers.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，显然有些类型的问题更适合其中一个。例如，试着训练一个深度学习模型对一个由五个数字组成的列表进行排序。通过正确的架构，这并不是不可能，但这是一个令人沮丧的练习。你将需要大量的训练数据来做到这一点，即使如此，当模型面对新的数字时，它仍然会偶尔出错。如果你想开始对由10个数字组成的列表进行排序，你将需要在更多数据上完全重新训练模型。与此同时，在R中编写一个排序算法只需要几行代码，而且一经验证，在更多的示例上工作后，结果程序将可以成功地处理任何大小的列表。这是相当强大的泛化能力：从几个示例和测试示例到一个可以成功处理任何列表的程序。
- en: 'In reverse, perception problems are a terrible fit for discrete reasoning processes.
    Try to write a pure-R program to classify MNIST digits without using any machine
    learning technique: you’re in for a ride. You’ll find yourself painstakingly coding
    functions that can detect the number of closed loops in a digit, the coordinates
    of the center of mass of a digit, and so on. After thousands of lines of code,
    you might achieve… 90% test accuracy. In this case, fitting a parametric model
    is much simpler; it can better utilize the large amount of data that’s available,
    and it achieves much more robust results. If you have lots of data and you’re
    faced with a problem where the manifold hypothesis applies, go with deep learning.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，感知问题对于离散推理过程来说是非常糟糕的。尝试编写一个纯粹的 R 程序来分类 MNIST 数字，而不使用任何机器学习技术：你会遇到麻烦。你会发现自己辛苦地编写能够检测数字中闭合环数量、数字质心坐标等函数。经过数千行代码，你可能会获得……90%
    的测试准确率。在这种情况下，拟合参数模型要简单得多；它可以更好地利用可用的大量数据，并且得到更加稳健的结果。如果你有大量数据，并且面临着一个适用于流形假设的问题，请选择深度学习。
- en: For this reason, it’s unlikely that we’ll see the rise of an approach that would
    reduce reasoning problems to manifold interpolation, or that would reduce perception
    problems to discrete reasoning. The way forward in AI is to develop a unified
    framework that incorporates *both* types of abstract analogy-making. Let’s examine
    what that might look like.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这个原因，我们不太可能看到一种方法的崛起，将推理问题简化为流形插值，或将感知问题简化为离散推理。人工智能的前进方向是开发一个统一的框架，结合 *两种*
    类型的抽象类比生成。让我们看看这可能是什么样子。
- en: 14.5 The future of deep learning
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.5 深度学习的未来
- en: Given what we know of how deep nets work, their limitations, and what they’re
    currently missing, can we predict where things are headed in the medium term?
    Following are some purely personal thoughts. Note that I don’t have a crystal
    ball, so a lot of what I anticipate may fail to become reality. I’m sharing these
    predictions not because I expect them to be proven completely right in the future
    but because they’re interesting and actionable in the present.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们对深度网络的工作原理、它们的限制以及它们目前缺少的东西的了解，我们能否预测中期事物的发展方向呢？以下是一些纯粹个人的想法。请注意，我没有水晶球，所以我预期的许多事情可能无法变为现实。我分享这些预测，不是因为我希望它们在未来被证明完全正确，而是因为它们在现在是有趣的和可行的。
- en: 'At a high level, these are the main directions in which I see promise:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，这些是我认为有前景的主要方向：
- en: '*Models closer to general-purpose computer programs*, built on top of far richer
    primitives than the current differentiable layers. This is how we’ll get to reasoning
    and abstraction, the lack of which is the fundamental weakness of current models.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*更接近通用计算程序的模型*，构建在比当前的可微分层更丰富的基本单元之上。这是我们将达到推理和抽象的方式，而目前模型的基本弱点是缺乏这些。'
- en: '*A fusion between deep learning and discrete search over program spaces*, with
    the former providing perception and intuition capabilities, and the latter providing
    reasoning and planning capabilities.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习与程序空间上的离散搜索的融合*，前者提供感知和直觉能力，后者提供推理和规划能力。'
- en: '*Greater, systematic reuse of previously learned features and architectures*,
    such as meta-learning systems using reusable and modular program subroutines.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*更大规模、系统化地重复使用先前学习的特征和架构*，比如使用可重用和模块化的程序子例程的元学习系统。'
- en: Additionally, note that these considerations aren’t specific to the sort of
    supervised learning that has been the bread and butter of deep learning so far—rather,
    they’re applicable to any form of machine learning, including unsupervised, self-supervised,
    and reinforcement learning. It isn’t fundamentally important where your labels
    come from or what your training loop looks like; these different branches of machine
    learning are different facets of the same construct. Let’s dive in.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意，这些考虑并不特定于到目前为止一直是深度学习的主要内容的监督学习类型——相反，它们适用于任何形式的机器学习，包括无监督、自监督和强化学习。你的标签来自何处或你的训练循环是什么样的并不是根本重要的；这些不同分支的机器学习是相同构建的不同方面。让我们深入探讨。
- en: 14.5.1 Models as programs
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.1 模型作为程序
- en: 'As noted in the previous section, a necessary transformational development
    that we can expect in the field of machine learning is a move away from models
    that perform purely *pattern recognition* and can achieve only *local generalization*,
    toward models capable of abstraction and reasoning that can achieve *extreme generalization*.
    Current AI programs that are capable of basic forms of reasoning are all hardcoded
    by human programmers: for instance, software that relies on search algorithms,
    graph manipulation, and formal logic.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一节所指出的，我们可以期待的机器学习领域的一个必要的变革性发展是远离仅执行*模式识别*且只能实现*局部泛化*的模型，转向能够抽象和推理并能实现*极端泛化*的模型。当前能够进行基本形式推理的AI程序都是由人类程序员硬编码的：例如，依赖于搜索算法、图形操作和形式逻辑的软件。
- en: 'That may be about to change, thanks to *program synthesis*—a field that is
    very niche today, but I expect to take off in a big way over the next few decades.
    Program synthesis consists of automatically generating simple programs by using
    a search algorithm (possibly genetic search, as in *genetic programming*) to explore
    a large space of possible programs (see [figure 14.11](#fig14-11)). The search
    stops when a program is found that matches the required specifications, often
    provided as a set of input-output pairs. This is highly reminiscent of machine
    learning: given training data provided as input-output pairs, we find a program
    that matches inputs to outputs and can generalize to new inputs. The difference
    is that instead of learning parameter values in a hardcoded program (a neural
    network), we generate source code via a discrete search process (see [table 14.2](#tab14-2)).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能即将改变，多亏了*程序合成*——这是一个今天非常小众的领域，但我预计在未来几十年将大获成功。程序合成包括通过使用搜索算法（可能是遗传搜索，如*遗传编程*）自动生成简单程序来探索可能程序的大空间（见[图14.11](#fig14-11)）。当找到一个符合所需规格的程序时，搜索就会停止，通常以一组输入输出对提供。这非常类似于机器学习：给定作为输入输出对提供的训练数据，我们找到一个将输入与输出匹配并能推广到新输入的程序。不同之处在于，我们不是学习硬编码程序中的参数值（神经网络），而是通过离散搜索过程生成源代码（见[表14.2](#tab14-2)）。
- en: '![Image](../images/f0503-01.jpg)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0503-01.jpg)'
- en: '**Figure 14.11 A schematic view of program synthesis: Given a program specification
    and a set of building blocks, a search process assembles the building blocks into
    candidate programs, which are then tested against the specification. The search
    continues until a valid program is found.**'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.11 程序合成的示意图：给定一个程序规范和一组构建块，一个搜索过程将构建块组装成候选程序，然后将其与规范进行测试。搜索将继续，直到找到一个有效的程序。**'
- en: Table 14.2 Machine learning vs. program synthesis
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.2 机器学习与程序合成
- en: '| Machine learning | Program synthesis |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习 | 程序合成 |'
- en: '| Model: differentiable parametric function | Model: graph of operators from
    a programming language |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 模型：可微分参数函数 | 模型：来自编程语言的操作符图 |'
- en: '| Engine: gradient descent | Engine: discrete search (such as genetic search)
    |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 引擎：梯度下降 | 引擎：离散搜索（例如遗传搜索） |'
- en: '| Requires a lot of data to produce reliable results | Data efficient; can
    work with a couple of training examples |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 需要大量数据才能产生可靠结果 | 数据高效；可以使用几个训练样本 |'
- en: 14.5.2 Machine learning vs. program synthesis
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.2 机器学习与程序合成
- en: Program synthesis is how we’re going to add program-centric abstraction capabilities
    to our AI systems. It’s the missing piece of the puzzle. I mentioned earlier that
    deep learning techniques were entirely unusable on ARC, a reasoning-focused intelligence
    test. Meanwhile, very crude program-synthesis approaches are already producing
    very promising results on this benchmark.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 程序合成是我们将如何向我们的人工智能系统添加以程序为中心的抽象能力。这是缺失的拼图。我之前提到深度学习技术在以推理为重点的ARC上完全无法使用。与此同时，非常简陋的程序合成方法已经在这一基准上产生了非常有前途的结果。
- en: 14.5.3 Blending together deep learning and program synthesis
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.3 将深度学习与程序合成融合在一起
- en: 'Of course, deep learning isn’t going anywhere. Program synthesis isn’t its
    replacement; it is its complement. It’s the hemisphere that has been so far missing
    from our artificial brains. We’re going to be leveraging both, in combination.
    There are two major ways this will take place:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，深度学习并不会消失。程序合成不是它的替代品；它是它的补充。这是迄今为止缺失的我们人工大脑的半球。我们将结合使用这两者。这将以两种主要方式进行：
- en: '**1** Developing systems that integrate both deep learning modules and discrete
    algorithmic modules'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**1** 开发既包含深度学习模块又包含离散算法模块的系统'
- en: '**2** Using deep learning to make the program search process itself more efficient'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**2** 利用深度学习使程序搜索过程本身更加高效'
- en: Let’s review each of these possible avenues.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一审查这些可能的途径。
- en: INTEGRATING DEEP LEARNING MODULES AND ALGORITHMIC MODULES INTO HYBRID SYSTEMS
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将深度学习模块和算法模块集成到混合系统中
- en: 'Today, the most powerful AI systems are hybrid: they leverage both deep learning
    models and handcrafted symbol-manipulation programs. In DeepMind’s AlphaGo, for
    example, most of the intelligence on display is designed and hardcoded by human
    programmers (such as Monte Carlo Tree Search). Learning from data happens only
    in specialized submodules (value networks and policy networks). Or consider autonomous
    vehicles: a self-driving car is able to handle a large variety of situations because
    it maintains a model of the world around it—a literal 3D model—full of assumptions
    hardcoded by human engineers. This model is constantly updated via deep learning
    perception modules that interface it with the surroundings of the car.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，最强大的人工智能系统是混合型的：它们利用了深度学习模型和手工制作的符号操作程序。例如，在 DeepMind 的 AlphaGo 中，展示出的大部分智能是由人类程序员设计和硬编码的（例如蒙特卡洛树搜索）。从数据中学习只发生在专门的子模块中（价值网络和策略网络）。再比如自动驾驶汽车：自动驾驶汽车能够处理大量情况，因为它维护着周围世界的模型——一个字面上的三维模型——充满了人类工程师硬编码的假设。这个模型通过深度学习感知模块不断更新，将其与汽车周围的环境接口连接起来。
- en: For both of these systems—AlphaGo and self-driving vehicles—the combination
    of human-created discrete programs and learned continuous models is what unlocks
    a level of performance that would be impossible with either approach in isolation,
    such as an end-to-end deep net or a piece of software without ML elements. So
    far, the discrete algorithmic elements of such hybrid systems are painstakingly
    hardcoded by human engineers. But in the future, such systems may be fully learned,
    with no human involvement.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两种系统——AlphaGo 和自动驾驶汽车——人类创建的离散程序和学习的连续模型的结合是解锁一种性能水平的关键，这种性能水平在单独使用任一方法时都是不可能的，例如端到端深度神经网络或没有机器学习元素的软件片段。到目前为止，这种混合系统的离散算法元素是由人类工程师费力地硬编码的。但在未来，这些系统可能会完全学习，没有人类参与。
- en: 'What will this look like? Consider a well-known type of network: RNNs. It’s
    important to note that RNNs have slightly fewer limitations than feed-forward
    networks. That’s because RNNs are a bit more than mere geometric transformations:
    they’re geometric transformations *repeatedly applied inside a* for *loop*. The
    temporal for loop is itself hard-coded by human developers: it’s a built-in assumption
    of the network. Naturally, RNNs are still extremely limited in what they can represent,
    primarily because each step they perform is a differentiable geometric transformation,
    and they carry information from step to step via points in a continuous geometric
    space (state vectors). Now imagine a neural network that’s augmented in a similar
    way with programming primitives, but instead of a single hardcoded for loop with
    hardcoded continuous-space memory, the network includes a large set of programming
    primitives that the model is free to manipulate to expand its processing function,
    such as if branches, while statements, variable creation, disk storage for long-term
    memory, sorting operators, and advanced data structures (such as lists, graphs,
    and hash tables). The space of programs that such a network could represent would
    be far broader than what can be represented with current deep learning models,
    and some of these programs could achieve superior generalization power. Importantly,
    such programs will not be differentiable end-to-end, though specific modules will
    remain differentiable and thus will need to be generated via a combination of
    discrete program search and gradient descent.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这会是什么样子呢？考虑一种众所周知的网络类型：RNNs。重要的是要注意，RNNs比前馈网络具有稍少的限制。这是因为RNNs不仅仅是几何转换：它们是几何转换*在*for*循环内*重复应用的。时间上的for循环本身由人类开发人员硬编码：这是网络的内置假设。当然，RNNs在它们可以表示的东西上仍然极其有限，主要是因为它们执行的每一步都是可微的几何转换，并且它们通过连续几何空间中的点（状态向量）在步骤之间携带信息。现在想象一下，一个神经网络以类似的方式通过编程基元增强，但是这个网络包括了一大堆的编程基元，模型可以自由操纵以扩展其处理功能，例如if分支、while语句、变量创建、用于长期存储的磁盘存储、排序运算符和高级数据结构（如列表、图和哈希表）。这样一个网络可以表示的程序空间将远远超过目前深度学习模型可以表示的内容，其中一些程序可以达到更高的泛化能力。重要的是，这样的程序不会端对端地可微分，尽管特定的模块将保持可微分，因此需要通过离散程序搜索和梯度下降的组合来生成。
- en: We’ll move away from having, on one hand, hardcoded algorithmic intelligence
    (handcrafted software) and, on the other hand, learned geometric intelligence
    (deep learning). Instead, we’ll have a blend of formal algorithmic modules that
    provide reasoning and abstraction capabilities, and geometric modules that provide
    informal intuition and pattern-recognition capabilities (see [figure 14.12](#fig14-12)).
    The entire system will be learned with little or no human involvement. This should
    dramatically expand the scope of problems that can be solved with machine learning—the
    space of programs that we can generate automatically, given appropriate training
    data. Systems like AlphaGo—or even RNNs—can be seen as a prehistoric ancestor
    of such hybrid algorithmic-geometric models.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将摆脱一方面是硬编码的算法智能（手工制作的软件），另一方面是学习到的几何智能（深度学习）。相反，我们将拥有一种混合形式的正式算法模块，这些模块提供推理和抽象能力，并且提供非正式直觉和模式识别能力的几何模块（参见[图14.12](#fig14-12)）。整个系统将在很少或没有人类参与的情况下学习。这应该大大扩展了可以用机器学习解决的问题范围——在给定适当的训练数据的情况下，我们可以自动生成的程序空间。像AlphaGo这样的系统——甚至是RNNs——可以被看作是这种混合算法-几何模型的史前祖先。
- en: '![Image](../images/f0505-01.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0505-01.jpg)'
- en: '**Figure 14.12 A learned program relying on both geometric primitives (pattern
    recognition, intuition) and algorithmic primitives (reasoning, search, memory)**'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.12 依赖于几何基元（模式识别、直觉）和算法基元（推理、搜索、记忆）的学习程序**'
- en: USING DEEP LEARNING TO GUIDE PROGRAM SEARCH
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用深度学习指导程序搜索
- en: 'Today, program synthesis faces a major obstacle: it’s tremendously inefficient.
    To caricature, program synthesis works by trying every possible program in a search
    space until it finds one that matches the specification provided. As the complexity
    of the program specification increases, or as the vocabulary of primitives used
    to write programs expands, the program search process runs into what’s known as
    *combinatorial explosion*, where the set of possible programs to consider grows
    very fast—in fact, much faster than merely exponentially fast. As a result, today,
    program synthesis can be used to generate only very short programs. You’re not
    going to be generating a new OS for your computer anytime soon.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，程序合成面临着一个主要障碍：它的效率极低。夸张地说，程序合成通过尝试搜索空间中的每个可能的程序，直到找到一个与提供的规范匹配的程序来工作。随着程序规范的复杂性增加，或者随着用于编写程序的原语词汇的扩展，程序搜索过程会遇到所谓的*组合爆炸*，即要考虑的可能程序集增长得非常快——实际上远远快于指数增长。因此，今天，程序合成只能用于生成非常短的程序。你不会很快为你的计算机生成一个新的操作系统。
- en: 'To move forward, we’re going to need to make program synthesis efficient by
    bringing it closer to the way humans write software. When you open your editor
    to code up a script, you’re not thinking about every possible program you could
    potentially write. You have in mind only a handful of possible approaches: you
    can use your understanding of the problem and your past experience to drastically
    cut through the space of possible options to consider.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 要取得进展，我们需要通过使程序合成更接近人类编写软件的方式来使程序合成变得高效。当你打开编辑器编写脚本时，你并不会考虑你可能潜在地编写的每个可能的程序。你只考虑了几种可能的方法：你可以利用你对问题的理解和过去的经验来大幅缩减可能要考虑的选项空间。
- en: 'Deep learning can help program synthesis do the same: although each specific
    program we’d like to generate might be a fundamentally discrete object that performs
    non-interpolative data manipulation, evidence so far indicates that *the space
    of all useful programs* may look a lot like a continuous manifold. That means
    that a deep learning model that has been trained on millions of successful program-generation
    episodes might start to develop solid *intuition* about the *path through program
    space* that the search process should take to go from a specification to the corresponding
    program— just like a software engineer might have immediate intuition about the
    overall architecture of the script they’re about to write, about the intermediate
    functions and classes they should use as stepping-stones on the way to the goal.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习可以帮助程序合成实现同样的目标：尽管我们想生成的每个具体程序可能都是一种根本上离散的对象，执行非插值数据操作，但迄今的证据表明*所有有用程序的空间*可能看起来很像一个连续的流形。这意味着，一个经过数百万次成功程序生成情景训练的深度学习模型可能会开始对*程序空间中的路径*发展出坚实的*直觉*，以便搜索过程从规范到相应程序的过程中走出一条路线——就像软件工程师可能对他们即将编写的脚本的整体架构，以及在达到目标时应该使用的中间函数和类有直觉一样。
- en: Remember that human reasoning is heavily guided by value-centric abstraction,
    that is, by pattern recognition and intuition. Program synthesis should be, too.
    I expect the general approach of guiding program search via learned heuristics
    to see increasing research interest over the next 10 to 20 years.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，人类的推理受到价值中心的抽象的重大指导，即模式识别和直觉。程序合成也应该如此。我预计通过学习启发程序搜索的一般方法将在未来 10 到 20 年内受到越来越多的研究关注。
- en: 14.5.4 Lifelong learning and modular subroutine reuse
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.4 终身学习和模块化子程序重用
- en: If models become more complex and are built on top of richer algorithmic primitives,
    this increased complexity will require higher reuse between tasks, rather than
    training a new model from scratch every time we have a new task or a new dataset.
    Many datasets don’t contain enough information for us to develop a new, complex
    model from scratch, and it will be necessary to use information from previously
    encountered datasets (much as you don’t learn English from scratch every time
    you open a new book—that would be impossible). Training models from scratch on
    every new task is also inefficient due to the large overlap between the current
    tasks and previously encountered tasks.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型变得更加复杂，并建立在更丰富的算法原语之上，这种增加的复杂性将需要更高的任务重用，而不是每次有新任务或新数据集时都从头开始训练一个新模型。许多数据集不包含足够的信息，让我们能够从头开发一个新的复杂模型，并且使用先前遇到的数据集的信息是必要的（就像你不会每次打开一本新书都从头学习英语一样——那是不可能的）。在每个新任务上从头开始训练模型也是低效的，因为当前任务与先前遇到的任务之间存在很大的重叠。
- en: 'A remarkable observation has been made repeatedly in recent years: training
    the *same* model to do several loosely connected tasks at the same time results
    in a model that’s *better at each task*. For instance, training the same neural
    machine-translation model to perform both English-to-German translation and French-to-Italian
    translation will result in a model that’s better at each language pair. Similarly,
    training an image-classification model jointly with an image-segmentation model,
    sharing the same convolutional base, results in a model that’s better at both
    tasks. This is fairly intuitive: there’s always *some* information overlap between
    seemingly disconnected tasks, and a joint model has access to a greater amount
    of information about each individual task than a model trained on that specific
    task only.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来已经多次做出了一个引人注目的观察：将*相同*模型训练以同时执行几个松散相关的任务会导致在每个任务上都*更好*的模型。例如，将同一神经机器翻译模型训练为执行英语到德语翻译和法语到意大利语翻译将产生一个在每种语言对上都更好的模型。类似地，联合训练图像分类模型和图像分割模型，共享相同的卷积基，会产生在两个任务上都更好的模型。这是相当直观的：看似不相关任务之间总是存在*一些*信息重叠，联合模型能够获取关于每个单独任务的更多信息。
- en: 'Currently, when it comes to model reuse across tasks, we use pretrained weights
    for models that perform common functions, such as visual feature extraction. You
    saw this in action in chapter 9\. In the future, I expect a generalized version
    of this to be commonplace: we’ll use not only previously learned features (submodel
    weights) but also model architectures and training procedures. As models become
    more like programs, we’ll begin to reuse *program subroutines* like the functions
    and classes found in human programming languages.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及跨任务重复使用模型时，我们目前使用预训练权重来执行常见功能的模型，例如视觉特征提取。你在第 9 章中看到了这一过程。未来，我期望这一概括性版本将变得司空见惯：我们将不仅使用先前学习到的特征（子模型权重），还将使用模型架构和训练程序。随着模型越来越像程序，我们将开始重用像人类编程语言中的函数和类那样的*程序子例程*。
- en: 'Think of the process of software development today: once an engineer solves
    a specific problem (HTTP queries, for instance), they package it as an abstract,
    reusable library. Engineers who face a similar problem in the future will be able
    to search for existing packages, download one, and use it in their own project.
    In a similar way, in the future, meta-learning systems will be able to assemble
    new programs by sifting through a global library of high-level reusable blocks.
    When the system finds itself developing similar program subroutines for several
    different tasks, it can come up with an *abstract*, reusable version of the subroutine
    and store it in the global library (see [figure 14.13](#fig14-1)). These subroutines
    can be either geometric (deep learning modules with pretrained representations)
    or algorithmic (closer to the libraries that contemporary software engineers manipulate).'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下今天的软件开发过程：一旦工程师解决了一个特定问题（比如 HTTP 查询），他们将其打包成一个抽象的、可重用的库。未来面临类似问题的工程师将能够搜索现有的包，下载一个，并在自己的项目中使用它。同样地，未来，元学习系统将能够通过筛选全球高级可重用块的库来组装新的程序。当系统发现自己为几个不同任务开发类似的程序子例程时，它可以想出一个*抽象*的、可重用的子例程，并将其存储在全球库中（参见
    [图 14.13](#fig14-1)）。这些子例程可以是几何的（具有预训练表示的深度学习模块）或算法的（与当代软件工程师操作的库更接近）。
- en: '![Image](../images/f0507-01.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0507-01.jpg)'
- en: '**Figure 14.13 A meta-learner capable of quickly developing task-specific models
    using reusable primitives (both algorithmic and geometric), thus achieving extreme
    generalization**'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14.13一个元学习者能够快速开发使用可重复使用的基本部件（既有算法的又有几何的）的任务特定模型，从而实现极端泛化**'
- en: 14.5.5 The long-term vision
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.5 长期愿景
- en: 'In short, here’s my long-term vision for machine learning:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这是我对机器学习的长期愿景：
- en: Models will be more like programs and will have capabilities that go far beyond
    the continuous geometric transformations of the input data we currently work with.
    These programs will arguably be much closer to the abstract mental models that
    humans maintain about their surroundings and themselves, and they will be capable
    of stronger generalization due to their rich algorithmic nature.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型将更像程序，并且具有远远超出我们当前处理的连续几何变换的输入数据的能力。这些程序可能会更接近于人类对周围环境和自身的抽象心理模型，并且由于其丰富的算法性质，它们将能够进行更强的泛化。
- en: In particular, models will blend *algorithmic modules* providing formal reasoning,
    search, and abstraction capabilities with *geometric modules* providing informal
    intuition and pattern-recognition capabilities. This will achieve a blend of value-centric
    and program-centric abstraction. AlphaGo or self-driving cars (systems that require
    a lot of manual software engineering and human-made design decisions) provide
    an early example of what such a blend of symbolic and geometric AI could look
    like.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别是，模型将结合*算法模块*和*几何模块*，提供形式推理、搜索和抽象能力与提供非正式直觉和模式识别能力。这将实现价值中心和程序中心抽象的融合。AlphaGo或自动驾驶汽车（这些系统需要大量手动软件工程和人为设计决策）提供了这样一种符号和几何人工智能融合的早期示例。
- en: Such models will be *grown* automatically rather than hardcoded by human engineers,
    using modular parts stored in a global library of reusable subroutines—a library
    evolved by learning high-performing models on thousands of previous tasks and
    datasets. As frequent problem-solving patterns are identified by the meta-learning
    system, they will be turned into reusable subroutines—much like functions and
    classes in software engineering—and added to the global library.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这样的模型将自动*增长*而不是由人类工程师硬编码，使用全球可重复使用子程序库中存储的模块化部件——一个通过学习上千个先前任务和数据集的高性能模型进化而来的库。随着元学习系统识别出频繁的问题解决模式，它们将被转换为可重复使用的子程序——就像软件工程中的函数和类一样——并添加到全球库中。
- en: The process that searches over possible combinations of subroutines to grow
    new models will be a discrete search process (program synthesis), but it will
    be heavily guided by a form of *program-space intuition* provided by deep learning.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索潜在子程序组合以生成新模型的过程将是一个离散搜索过程（程序合成），但它将受到由深度学习提供的一种*程序空间直觉*的严格指导。
- en: 'This global subroutine library and associated model-growing system will be
    able to achieve some form of humanlike *extreme generalization*: given a new task
    or situation, the system will be able to assemble a new working model appropriate
    for the task using very little data, thanks to rich programlike primitives that
    generalize well and extensive experience with similar tasks. In the same way,
    humans can quickly learn to play a complex new video game if they have experience
    with many previous games, because the models derived from this previous experience
    are abstract and programlike, rather than a basic mapping between stimuli and
    action.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个全局子程序库和相关的模型增长系统将能够实现某种形式的人类*极端泛化*：在给定新任务或情境的情况下，该系统将能够使用极少的数据组装一个适合任务的新工作模型，这要归功于良好泛化的丰富程序化原语以及对类似任务的广泛经验。同样，如果人类有很多先前游戏的经验，他们可以快速学会玩一个复杂的新视频游戏，因为从这些先前经验中派生出来的模型是抽象的和程序化的，而不是刺激和动作之间的基本映射。
- en: 'As such, this perpetually learning model-growing system can be interpreted
    as an *artificial general intelligence* (AGI). But don’t expect any singularitarian
    robot apocalypse to ensue: that’s pure fantasy, coming from a long series of profound
    misunderstandings of both intelligence and technology. Such a critique, however,
    doesn’t belong in this book'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，这种不断学习的模型增长系统可以被解释为一种*人工通用智能*（AGI）。但不要期望会发生任何奇异论者的机器人启示录：那纯粹是幻想，源自对智能和技术的长期深刻误解。
- en: 14.6 Staying up-to-date in a fast-moving field
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.6 在快速发展的领域保持最新
- en: As final parting words, I want to give you some pointers about how to keep learning
    and updating your knowledge and skills after you’ve turned the last page of this
    book. The field of modern deep learning, as we know it today, is only a few years
    old, despite a long, slow prehistory stretching back decades. With an exponential
    increase in financial resources and research headcount since 2013, the field as
    a whole is now moving at a frenetic pace. What you’ve learned in this book won’t
    stay relevant forever, and it isn’t all you’ll need for the rest of your career.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我想给您一些关于如何在翻阅本书最后一页后继续学习和更新您的知识和技能的指引。现代深度学习领域，就我们今天所知，只有几年的历史，尽管其漫长而缓慢的前史可追溯几十年。自
    2013 年以来，随着资金资源和研究人员数量的指数增长，整个领域现在正以疯狂的速度发展。您在本书中学到的内容不会永远保持相关性，并且并非您未来职业生涯所需的全部。
- en: Fortunately, there are plenty of free online resources that you can use to stay
    up to date and expand your horizons. Here are a few.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有大量免费在线资源可供您使用，以保持最新并拓展视野。以下是一些。
- en: 14.6.1 Practice on real-world problems using Kaggle
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Kaggle 在真实世界问题上进行练习
- en: An effective way to acquire real-world experience is to try your hand at machine
    learning competitions on Kaggle ([https://kaggle.com](https://www.kaggle.com)).
    The only real way to learn is through practice and actual coding—that’s the philosophy
    of this book, and Kaggle competitions are the natural continuation of this. On
    Kaggle, you’ll find an array of constantly renewed data science competitions,
    many of which involve deep learning, prepared by companies interested in obtaining
    novel solutions to some of their most challenging machine learning problems. Fairly
    large monetary prizes are offered to top entrants.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 获得实际经验的有效方法是尝试在 Kaggle（[https://kaggle.com](https://www.kaggle.com)）上进行机器学习比赛。学习的唯一真实方法是通过实践和实际编码——这是本书的理念，而
    Kaggle 比赛是这一理念的自然延伸。在 Kaggle 上，您将找到一系列不断更新的数据科学竞赛，其中许多涉及深度学习，由一些公司准备，这些公司希望获得一些最具挑战性的机器学习问题的新解决方案。为排名靠前的参赛者提供相当可观的奖金。
- en: Most competitions are won using either the XGBoost library (for shallow machine
    learning) or Keras (for deep learning), so you’ll fit right in! By participating
    in a few competitions, maybe as part of a team, you’ll become more familiar with
    the practical side of some of the advanced best practices described in this book,
    especially hyper-parameter tuning, avoiding validation set overfitting, and model
    ensembling.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数比赛使用 XGBoost 库（用于浅层机器学习）或 Keras（用于深度学习）获胜，所以您将会完全适应！通过参加一些比赛，也许作为团队的一部分，您将更加熟悉本书中描述的一些高级最佳实践的实际方面，特别是超参数调整，避免验证集过拟合和模型集成。
- en: 14.6.2 Read about the latest developments on arXiv
  id: totrans-367
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 arXiv 上的最新发展
- en: 'Deep learning research, in contrast with some other scientific fields, takes
    place completely in the open. Papers are made publicly and freely accessible as
    soon as they’re finalized, and a lot of related software is open source. arXiv
    ([https://arxiv.org](https://www.arxiv.org))—pronounced “archive” (the X stands
    for the Greek *chi*)—is an open-access preprint server for physics, mathematics,
    and computer science research papers. It has become the de facto way to stay up-to-date
    on the bleeding edge of machine learning and deep learning. The large majority
    of deep learning researchers upload any paper they write to arXiv shortly after
    completion. This allows them to plant a flag and claim a specific finding without
    waiting for a conference acceptance (which takes months), which is necessary given
    the fast pace of research and the intense competition in the field. It also allows
    the field to move extremely fast: all new findings are immediately available for
    all to see and to build on.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他一些科学领域相比，深度学习研究完全是公开进行的。论文一经完成就会公开并免费提供访问，而许多相关软件都是开源的。arXiv（[https://arxiv.org](https://www.arxiv.org)）——发音为“archive”（X
    代表希腊字母 *chi*）——是一个开放获取的物理、数学和计算机科学研究论文的预印本服务器。它已成为了解机器学习和深度学习最前沿的事实标准。绝大多数深度学习研究人员在完成论文后不久就会将其上传到
    arXiv。这使他们能够立即宣布特定的发现，而不必等待会议接受（这需要数月时间），考虑到研究的快速节奏和领域中的激烈竞争，这是必要的。它还使得领域能够迅速发展：所有新发现都立即对所有人可见，并可以进行进一步的建立。
- en: 'An important downside is that the sheer quantity of new papers posted every
    day on arXiv makes it impossible to even skim them all, and the fact that they
    aren’t peer-reviewed makes it difficult to identify those that are both important
    and high quality. It’s challenging, and becoming increasingly more so, to find
    the signal in the noise. But some tools can help: in particular, you can use Google
    Scholar ([https://scholar.google.com](https://www.scholar.google.com)) to keep
    track of publications by your favorite authors.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的缺点是，每天在 arXiv 上发布的论文数量庞大，甚至无法全部浏览，而且它们没有经过同行评议，这使得难以确定哪些是重要且高质量的。要在噪音中找到信号是具有挑战性的，并且越来越困难。但是一些工具可以帮助您：特别是，您可以使用
    Google 学术 ([https://scholar.google.com](https://www.scholar.google.com)) 来追踪您喜欢的作者发表的论文。
- en: 14.6.3 Explore the Keras ecosystem
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.6.3 探索 Keras 生态系统
- en: 'With over one million users as of late 2021 and still growing, Keras has a
    large ecosystem of tutorials, guides, and related open source projects:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 截至 2021 年末，Keras 拥有超过一百万用户，并且仍在增长，拥有大量教程、指南和相关开源项目的生态系统：
- en: Your main reference for working with Keras in R is the online documentation
    at [https://keras.rstudio.com](https://www.keras.rstudio.com) and [https://tensorflow.rstudio.com](https://www.tensorflow.rstudio.com).
    In particular, you’ll find extensive developer guides at [http://tensorflow.rstudio.com/guides](http://www.tensorflow.rstudio.com/guides),
    dozens of high-quality Keras code examples at [http://tensorflow.rstudio.com/](http://www.tensorflow.rstudio.com/)
    examples, and many tutorials at [http://tensorflow.rstudio.com/tutorials](http://www.tensorflow.rstudio.com/tutorials).
    Make sure to check them out!
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您在 R 中使用 Keras 的主要参考资料是在线文档，网址为 [https://keras.rstudio.com](https://www.keras.rstudio.com)
    和 [https://tensorflow.rstudio.com](https://www.tensorflow.rstudio.com)。特别是，在 [http://tensorflow.rstudio.com/guides](http://www.tensorflow.rstudio.com/guides)
    可找到广泛的开发者指南，在 [http://tensorflow.rstudio.com/](http://www.tensorflow.rstudio.com/)
    examples 可找到数十个高质量的 Keras 代码示例，还有许多教程在 [http://tensorflow.rstudio.com/tutorials](http://www.tensorflow.rstudio.com/tutorials)。务必查阅！
- en: Don’t hesitate to also consult the Python documentation for Keras and Tensor-Flow,
    available at [https://www.tensorflow.org/api_docs/python/tf](https://www.tensorflow.org/api_docs/python/tf)
    and [https://keras.io/](https://www.keras.io/), even if you don’t know Python.
    Almost everything there you can read, understand, and apply to the R interface,
    all without any knowledge of Python. (If you do encounter some perplexing Python
    syntax, be sure to consult the appendix.)
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要犹豫，还可以参考 Keras 和 Tensor-Flow 的 Python 文档，网址分别为 [https://www.tensorflow.org/api_docs/python/tf](https://www.tensorflow.org/api_docs/python/tf)
    和 [https://keras.io/](https://www.keras.io/)，即使您不懂 Python 也可以。几乎所有内容您都能阅读、理解并应用于
    R 界面，而无需任何 Python 知识。（如果您遇到一些令人困惑的 Python 语法，请务必参考附录。）
- en: The R source code for Keras and Tensorflow can be found at [https://github.com/rstudio/keras](https://www.github.com/rstudio/keras)
    and [https://github.com/rstudio/tensorflow](https://www.github.com/rstudio/tensorflow).
    The Python and C++ sources are available at [https://github.com/keras-team/keras](https://www.github.com/keras-team/keras)
    and [https://github.com/tensorflow/tensorflow](https://www.github.com/tensorflow/tensorflow).
    All are open source.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 和 Tensorflow 的 R 源代码可在 [https://github.com/rstudio/keras](https://www.github.com/rstudio/keras)
    和 [https://github.com/rstudio/tensorflow](https://www.github.com/rstudio/tensorflow)
    找到。Python 和 C++ 源代码可在 [https://github.com/keras-team/keras](https://www.github.com/keras-team/keras)
    和 [https://github.com/tensorflow/tensorflow](https://www.github.com/tensorflow/tensorflow)
    获取。所有源代码均为开源。
- en: 'You can ask for help and join deep learning discussions in a few places:'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在一些地方寻求帮助并加入深度学习讨论：
- en: 'The Machine Learning section of Rstudio community: [https://community.rstudio.com/c/ml/15](https://www.community.rstudio.com/c/ml/15)'
  id: totrans-376
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rstudio 社区的机器学习部分：[https://community.rstudio.com/c/ml/15](https://www.community.rstudio.com/c/ml/15)
- en: 'Stack overflow: [https://stackoverflow.com](https://www.stackoverflow.com)
    (Be sure to tag your question with both R and Keras.)'
  id: totrans-377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stack overflow：[https://stackoverflow.com](https://www.stackoverflow.com)（确保标记您的问题同时带有
    R 和 Keras 标签。）
- en: 'The (Python) Keras mailing list: keras-users@googlegroups.com.'
  id: totrans-378
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: (Python) Keras 邮件列表：keras-users@googlegroups.com。
- en: 'You can follow me (François) on Twitter: @fchollet.'
  id: totrans-379
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在 Twitter 上关注我（弗朗索瓦）：@fchollet。
- en: 14.7 Final words
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.7 结语
- en: This is the end of *Deep Learning with R, Second Edition*. I hope you’ve learned
    a thing or two about machine learning, deep learning, Keras, and maybe even cognition
    in general. Learning is a lifelong journey, especially in the field of AI, where
    we have far more unknowns on our hands than certitudes. So please go on learning,
    questioning, and researching. Never stop! Because even given the progress made
    so far, most of the fundamental questions in AI remain unanswered. Many haven’t
    even been properly asked yet.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是*《R 深度学习，第二版》*的结尾。希望你对机器学习、深度学习、Keras，甚至通常的认知学到了一些东西。学习是一生的旅程，特别是在人工智能领域，我们手中的未知远远超过确定性。所以请继续学习、质疑和研究。永远不要停止！因为即使在取得了迄今为止的进步，人工智能中的大部分基本问题仍然没有答案。许多问题甚至还没有得到适当的提出。
- en: ^([1](#endnote1)) Richard Feynman, interview, “The World from Another Point
    of View,” Yorkshire Television, 1972.
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ^([1](#endnote1)) 理查德·费曼，采访，"另一种视角的世界"，约克郡电视台，1972年。
- en: ^([2](#endnote2)) Terry Winograd, “Procedures as a Representation for Data in
    a Computer Program for Understanding Natural Language” (1971).
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ^([2](#endnote2)) 特里·维诺格拉德，“Procedures as a Representation for Data in a Computer
    Program for Understanding Natural Language”（1971年）。
- en: '^([3](#endnote3)) Fast Company, “Wozniak: Could a Computer Make a Cup of Coffee?”
    (March 2010), [http://mng.bz/pJMP](http://mng.bz/pJMP).'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ^([3](#endnote3)) 《Fast Company》，"沃兹尼亚克：计算机能泡杯咖啡吗？"（2010年3月），[http://mng.bz/pJMP](http://mng.bz/pJMP)。
- en: ^([4](#endnote4)) François Chollet, “On the Measure of Intelligence” (2019),
    [https://arxiv.org/abs/1911.01547](https://arxiv.org/abs/1911.01547).
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ^([4](#endnote4)) 弗朗索瓦·肖莱，"关于智能的衡量"（2019年），[https://arxiv.org/abs/1911.01547](https://arxiv.org/abs/1911.01547)。
