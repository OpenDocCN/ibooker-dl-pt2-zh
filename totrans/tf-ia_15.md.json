["```py\noutput, next_state = tf.keras.layers.GRUCell(input, state)\n```", "```py\ndef __init__(self, cell_fn, units, **kwargs):\n    self._cell_fn = cell_fn\n    self.units = units\n    super(DecoderRNNAttentionWrapper, self).__init__(**kwargs)\n```", "```py\ndef build(self, input_shape):\n\n    self.W_a = self.add_weight(\n        name='W_a',\n        shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n        initializer='uniform',\n        trainable=True\n    )\n\n    self.U_a = self.add_weight(\n        name='U_a',\n        shape=tf.TensorShape((self._cell_fn.units, self._cell_fn.units)),\n        initializer='uniform',\n        trainable=True\n    )\n\n    self.V_a = self.add_weight(\n        name='V_a',\n        shape=tf.TensorShape((input_shape[0][2], 1)),\n        initializer='uniform',\n        trainable=True\n    )\n\n    super(DecoderRNNAttentionWrapper, self).build(input_shape)\n```", "```py\ndef call(self, inputs, initial_state, training=False):\n\n    def _step(inputs, states):\n        \"\"\" Step function for computing energy for a single decoder state\n        inputs: (batchsize * de_in_dim)\n        states: [(batchsize * de_latent_dim)]\n        \"\"\"\n\n        encoder_full_seq = states[-1]                                   ❶\n\n        W_a_dot_h = K.dot(encoder_outputs, self.W_a)                    ❷\n\n        U_a_dot_s = K.expand_dims(K.dot(states[0], self.U_a), 1)        ❸\n\n        Wh_plus_Us = K.tanh(W_a_dot_h + U_a_dot_s)                      ❹\n\n        e_i = K.squeeze(K.dot(Wh_plus_Us, self.V_a), axis=-1)           ❺\n        a_i = K.softmax(e_i)                                            ❺\n\n        c_i = K.sum(encoder_outputs * K.expand_dims(a_i, -1), axis=1)   ❻\n\n        s, states = self._cell_fn(K.concatenate([inputs, c_i], axis=-1), \n➥ states)                                                              ❼\n\n        return (s, a_i), states\n\n   \"\"\" Computing outputs \"\"\"\n\n   encoder_outputs, decoder_inputs = inputs                             ❽\n\n   _, attn_outputs, _ = K.rnn(\n        step_function=_step, inputs=decoder_inputs, \n➥ initial_states=[initial_state], constants=[encoder_outputs]          ❾\n   )\n\n   # attn_out => (batch_size, de_seq_len, de_hidden_size)\n   # attn_energy => (batch_size, de_seq_len, en_seq_len)\n   attn_out, attn_energy = attn_outputs                                 ❿\n\n   return attn_out, attn_energy\n```", "```py\n_, attn_outputs, _ = K.rnn(\n        step_function=_step, inputs=decoder_inputs, initial_states=[initial_state], constants=[encoder_outputs],\n   )\n```", "```py\ndef get_final_seq2seq_model_with_attention(n_vocab, encoder, vectorizer):\n    \"\"\" Define the final encoder-decoder model \"\"\"\n\n    e_inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='e_input_final')          \n    fwd_state, bwd_state, en_states = encoder(e_inp)                              ❶\n\n    d_inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='d_input')           ❷\n\n    d_vectorized_out = vectorizer(d_inp)                                          ❸\n\n    d_emb_layer = tf.keras.layers.Embedding(\n        n_vocab+2, 128, mask_zero=True, name='d_embedding'                        ❹\n    )    \n    d_emb_out = d_emb_layer(d_vectorized_out)                                     ❹\n\n    d_init_state = tf.keras.layers.Concatenate(axis=-1)([fwd_state, bwd_state])   ❺\n\n    gru_cell = tf.keras.layers.GRUCell(256)                                       ❻\n    attn_out, _  = DecoderRNNAttentionWrapper(\n        cell_fn=gru_cell, units=512, name=\"d_attention\"\n    )([en_states, d_emb_out], initial_state=d_init_state)                         ❼\n\n    d_dense_layer_1 = tf.keras.layers.Dense(512, activation='relu', name='d_dense_1')\n    d_dense1_out = d_dense_layer_1(attn_out)                                      ❽\n\n    d_final_layer = tf.keras.layers.Dense(\n        n_vocab+2, activation='softmax', name='d_dense_final'\n    )\n    d_final_out = d_final_layer(d_dense1_out)                                     ❽\n\n    seq2seq = tf.keras.models.Model(\n        inputs=[e_inp, d_inp], outputs=d_final_out,                               ❾\n        name='final_seq2seq_with_attention'\n    )\n\n    return seq2seq\n```", "```py\n    gru_cell = tf.keras.layers.GRUCell(256)\n    attn_out, _  = DecoderRNNAttentionWrapper(\n        cell_fn=gru_cell, units=512, name=\"d_attention\"\n    )(\n        [en_states, d_emb_out], initial_state=d_init_state\n    )\n```", "```py\ndef get_vectorizer(\n    corpus, n_vocab, max_length=None, return_vocabulary=True, name=None\n):\n\n    \"\"\" Return a text vectorization layer or a model \"\"\"\n\n    inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='encoder_input')❶\n\n    vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n        max_tokens=n_vocab+2,                                              ❷\n        output_mode='int',\n        output_sequence_length=max_length,        \n        name=name\n    )\n\n    vectorize_layer.adapt(corpus)                                          ❸\n\n    vectorized_out = vectorize_layer(inp)                                  ❹\n\n    if not return_vocabulary: \n        return tf.keras.models.Model(inputs=inp, outputs=vectorized_out)   ❺\n    else:\n        return tf.keras.models.Model(\n            inputs=inp, outputs=vectorized_out                             ❻\n        ), vectorize_layer.get_vocabulary() \n```", "```py\ndef get_encoder(n_vocab, vectorizer):\n    \"\"\" Define the encoder of the seq2seq model\"\"\"\n\n    inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='e_input')  ❶\n\n    vectorized_out = vectorizer(inp)                                   ❷\n\n    emb_layer = tf.keras.layers.Embedding(\n        n_vocab+2, 128, mask_zero=True, name='e_embedding'             ❸\n    )\n\n    emb_out = emb_layer(vectorized_out)                                ❹\n\n    gru_layer = tf.keras.layers.Bidirectional(\n        tf.keras.layers.GRU(128, name='e_gru'),                        ❺\n        name='e_bidirectional_gru'\n    )\n\n    gru_out = gru_layer(emb_out)                                       ❻\n    encoder = tf.keras.models.Model(\n        inputs=inp, outputs=gru_out, name='encoder'\n    )                                                                  ❼\n\n    return encoder\n```", "```py\n# Get the English vectorizer/vocabulary\nen_vectorizer, en_vocabulary = \n➥ get_vectorizer(np.array(train_df[\"EN\"].tolist()), en_vocab, max_length=en_seq_length, name='e_vectorizer')\n# Get the German vectorizer/vocabulary\nde_vectorizer, de_vocabulary = \n➥ get_vectorizer(np.array(train_df[\"DE\"].tolist()), de_vocab, \n➥ max_length=de_seq_length-1, name='d_vectorizer')\n\n# Define the final model with attention\nencoder = get_encoder_with_attention(en_vocab, en_vectorizer)\nfinal_model_with_attention = \n➥ get_final_seq2seq_model_with_attention(de_vocab, encoder, de_vectorizer)\n\n# Compile the model\nfinal_model_with_attention.compile(\n    loss='sparse_categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)\n```", "```py\nepochs = 5\nbatch_size = 128\n\ntrain_model(final_model_with_attention, de_vectorizer, train_df, valid_df, \n➥ test_df, epochs, batch_size)\n```", "```py\nEvaluating batch 39/39\nEpoch 1/5\n    (train) loss: 2.096887740951318 - accuracy: 0.6887444907274002 - \n➥ bleu: 0.00020170408678925458\n    (valid) loss: 1.5872839291890461 - accuracy: 0.7375801282051282 - \n➥ bleu: 0.002304922518160425\n...\n\nEvaluating batch 39/39\nEpoch 5/5\n    (train) loss: 0.7739567615282841 - accuracy: 0.8378756006176655 - \n➥ bleu: 0.20010080750506093\n    (valid) loss: 0.8180131682982812 - accuracy: 0.837830534348121 - \n➥ bleu: 0.20100039279462362\nEvaluating batch 39/39\n(test) loss: 0.8390972828253721 - accuracy: 0.8342147454237326 - bleu: \n➥ 0.19782372616582572\n```", "```py\n## Save the model\nos.makedirs('models', exist_ok=True)\ntf.keras.models.save_model(final_model_with_attention, \n➥ os.path.join('models', 'seq2seq_attention'))\n\n# Save the vocabulary\nimport json\nos.makedirs(\n    os.path.join('models', 'seq2seq_attention_vocab'), exist_ok=True\n)\nwith open(os.path.join('models', 'seq2seq_attention_vocab', \n➥ 'de_vocab.json'), 'w') as f:\n    json.dump(de_vocabulary, f)\n\nwith open(os.path.join('models', 'seq2seq_attention_vocab', \n➥ 'en_vocab.json'), 'w') as f:\n    json.dump(en_vocabulary, f)\n```", "```py\nz = AttentionX()([x, y])\n```", "```py\ne_inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='e_input_final')          \nfwd_state, bwd_state, en_states = encoder(e_inp)      \n\nd_inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='d_input')     \n\nd_vectorized_out = vectorizer(d_inp)                                \n\nd_emb_layer = tf.keras.layers.Embedding(\n    n_vocab+2, 128, mask_zero=True, name='d_embedding'         \n)    \nd_emb_out = d_emb_layer(d_vectorized_out)     \n\nd_init_state = tf.keras.layers.Concatenate(axis=-1)([fwd_state, bwd_state]) \n\ngru_out = tf.keras.layers.GRU(256, return_sequences=True)(\n    d_emb_out, initial_state=d_init_state\n)           \n\nd_dense_layer_1 = tf.keras.layers.Dense(512, activation='relu', name='d_dense_1')\nd_dense1_out = d_dense_layer_1(attn_out)         \n\nd_final_layer = tf.keras.layers.Dense(\n    n_vocab+2, activation='softmax', name='d_dense_final'\n)\nd_final_out = d_final_layer(d_dense1_out)   \n```", "```py\ndef attention_visualizer(save_path):\n    \"\"\" Define the attention visualizer model \"\"\"\n\n    model = tf.keras.models.load_model(save_path)                  ❶\n\n    e_inp = tf.keras.Input(\n        shape=(1,), dtype=tf.string, name='e_input_final'\n    )                                                              ❷\n    en_model = model.get_layer(\"encoder\")                          ❷\n    fwd_state, bwd_state, en_states = en_model(e_inp)              ❷\n\n    e_vec_out = en_model.get_layer(\"e_vectorizer\")(e_inp)          ❸\n\n    d_inp = tf.keras.Input(\n        shape=(1,), dtype=tf.string, name='d_infer_input'\n    )                                                              ❹\n\n    d_vec_layer = model.get_layer('d_vectorizer')                  ❺\n    d_vec_out = d_vec_layer(d_inp)                                 ❺\n\n    d_emb_out = model.get_layer('d_embedding')(d_vec_out)          ❻\n\n    d_attn_layer = model.get_layer(\"d_attention\")                  ❻\n\n    d_init_state = tf.keras.layers.Concatenate(axis=-1)(\n        [fwd_state, bwd_state]\n    )                                                              ❻\n\n    attn_out, attn_states = d_attn_layer(\n        [en_states, d_emb_out], initial_state=d_init_state\n    )                                                              ❻\n\n    d_dense1_out = model.get_layer(\"d_dense_1\")(attn_out)          ❻\n\n    d_final_out = model.get_layer(\"d_dense_final\")(d_dense1_out)   ❻\n\n    visualizer_model = tf.keras.models.Model(                      ❼\n        inputs=[e_inp, d_inp], \n        outputs=[d_final_out, attn_states, e_vec_out, d_vec_out]\n    )\n\n    return visualizer_model\n```", "```py\ndef get_vocabularies(save_dir):\n    \"\"\" Load the vocabularies \"\"\"\n\n    with open(os.path.join(save_dir, 'en_vocab.json'), 'r') as f:\n        en_vocabulary = json.load(f)\n\n    with open(os.path.join(save_dir, 'de_vocab.json'), 'r') as f:\n        de_vocabulary = json.load(f)\n\n    return en_vocabulary, de_vocabulary\n```", "```py\nprint(\"Loading vocabularies\")\nen_vocabulary, de_vocabulary = get_vocabularies(\n    os.path.join('models', 'seq2seq_attention_vocab')\n)\n\nprint(\"Loading weights and generating the inference model\")\nvisualizer_model = attention_visualizer(\n    os.path.join('models', 'seq2seq_attention')\n)\nprint(\"\\tDone\")\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef visualize_attention(visualizer_model, en_vocabulary, de_vocabulary, \n➥ sample_en_text, sample_de_text, fig_savepath):\n    \"\"\" Visualize the attention patterns \"\"\"\n\n    print(\"Input: {}\".format(sample_en_text))\n\n    d_pred, attention_weights, e_out, d_out = visualizer_model.predict(\n        [np.array([sample_en_text]), np.array([sample_de_text])]\n    )                                                              ❶\n\n    d_pred_out = np.argmax(d_pred[0], axis=-1)                     ❷\n\n    y_ticklabels = []                                              ❸\n    for e_id in e_out[0]:                                          ❸\n        if en_vocabulary[e_id] == \"\":                              ❸\n            break                                                  ❸\n        y_ticklabels.append(en_vocabulary[e_id])                   ❸\n\n    x_ticklabels = []                                              ❹\n    for d_id in d_pred_out:                                        ❹\n        if de_vocabulary[d_id] == 'eos':                           ❹\n            break                                                  ❹\n        x_ticklabels.append(de_vocabulary[d_id])                   ❹\n\n    fig, ax = plt.subplots(figsize=(14, 14))\n\n    attention_weights_filtered = attention_weights[\n        0, :len(y_ticklabels), :len(x_ticklabels)\n    ]                                                              ❺\n\n    im = ax.imshow(attention_weights_filtered)                     ❻\n\n    ax.set_xticks(np.arange(attention_weights_filtered.shape[1]))  ❼\n    ax.set_yticks(np.arange(attention_weights_filtered.shape[0]))  ❼\n    ax.set_xticklabels(x_ticklabels)                               ❼\n    ax.set_yticklabels(y_ticklabels)                               ❼\n\n    ax.tick_params(labelsize=20)                                   ❼\n    ax.tick_params(axis='x', labelrotation=90)                     ❼\n\n    plt.colorbar(im)                                               ❽\n    plt.subplots_adjust(left=0.2, bottom=0.2)\n\n    save_dir, _ = os.path.split(fig_savepath)                      ❾\n    if not os.path.exists(save_dir):                               ❾\n        os.makedirs(save_dir, exist_ok=True)                       ❾\n    plt.savefig(fig_savepath)                                      ❾\n```", "```py\n# Generate attention patterns for a few inputs\ni = 0\nj = 0\nwhile j<9:\n    sample_en_text = test_df[\"EN\"].iloc[i]\n    sample_de_text = test_df[\"DE\"].iloc[i:i+1].str.rsplit(n=1, \n➥ expand=True).iloc[:,0].tolist()\n    i += 1\n\n    if len(sample_en_text.split(\" \")) > 10:\n        j += 1\n    else:\n        continue\n\n    visualize_attention(\n        visualizer_model, en_vocabulary, de_vocabulary, sample_en_text, \n        sample_de_text, os.path.join('plots','attention_{}.png'.format(i))\n    )\n```", "```py\ne_inp = tf.keras.Input(\n    shape=(1,), dtype=tf.string, name='e_input_final'\n)          \nfwd_state, bwd_state, en_states = encoder(e_inp)      \n\nd_inp = tf.keras.Input(shape=(1,), dtype=tf.string, name='d_input')     \n\nd_vectorized_out = vectorizer(d_inp)                                \n\nd_emb_layer = tf.keras.layers.Embedding(\n    n_vocab+2, 128, mask_zero=True, name='d_embedding'         \n)    \nd_emb_out = d_emb_layer(d_vectorized_out)     \n\nd_init_state = tf.keras.layers.Concatenate(axis=-1)([fwd_state, bwd_state]) \n\ngru_out = tf.keras.layers.GRU(256, return_sequences=True)(\n    d_emb_out, initial_state=d_init_state\n)           \n\nattn_out = AttentionX()([en_states, gru_out])\n\nd_dense_layer_1 = tf.keras.layers.Dense(\n    512, activation='relu', name='d_dense_1'\n)\nd_dense1_out = d_dense_layer_1(attn_out)         \n\nd_final_layer = tf.keras.layers.Dense(\n    n_vocab+2, activation='softmax', name='d_dense_final'\n)\nd_final_out = d_final_layer(d_dense1_out)\n```", "```py\nim = ax.imshow(attention_matrix)  \n\nax.set_xticks(np.arange(attention_matrix.shape[1])) \nax.set_yticks(np.arange(attention_matrix.shape[0])) \n\nax.set_xticklabels(german_text_labels)  \nax.set_yticklabels(english_text_labels)\n```"]