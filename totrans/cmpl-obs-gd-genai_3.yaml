- en: '3 Creating with Generative AI: Text and Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Automating the process of filtering content for accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating new content based on complex details you can define
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating customized documentation matching specialized fields
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating programming code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Until now we’ve explored some of the underlying context and mechanics of generative
    AI: how it works and how you can fine tune it. Beginning with this chapter we’ll
    be working with some actual content generation.'
  prefs: []
  type: TYPE_NORMAL
- en: But how exactly is that going to work? Well I don’t see much point in me throwing
    you a long list of ChatGPT prompts. I’m sure you’ve already done plenty that.
    And in case you haven’t, typing "cool prompts for ChatGPT" into your favorite
    internet search engine will soon fix you up.
  prefs: []
  type: TYPE_NORMAL
- en: What I *am* going to give you is some more complex and sometimes unexpected
    approaches to dealing with bigger problems - including how to train your AI model
    to work within a closely defined conceptual universe and how to build real-world
    websites just by describing them. We’re going to use all the same toys everyone
    else is playing with, but we’re going to be tweaking things to more perfectly
    fit our specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: Callout
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'One caveat. As I’ll point out more than once in the coming chapters: I don’t
    expect you to use the tricks and configurations we’ll encounter *exactly* the
    way I’m presenting them. Rather, the goal is to provide some basic skills and
    to inspire your curiosity and creativity so you’ll see new solutions to *your*
    problems.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will focus on using generative AI to generate original text-based
    content of one kind or another. The next chapter will do the same, but for *non-text*
    content like images, audio, and videos.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Automating accuracy checking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you haven’t yet noticed, we’ll be focusing mostly on OpenAI tools like GPT
    in this book. That’s not to say there aren’t other powerful and effective resources
    out there for getting this stuff done. There are. But right now at least OpenAI
    has the most creativity and momentum in the industry, and it’s where most of the
    groundbreaking action is happening.
  prefs: []
  type: TYPE_NORMAL
- en: To be honest, I can already see subtle indications that this might be starting
    to change. I wouldn’t be surprised if, twelve months from now, Meta (Facebook)
    or even an independent platform was leading the way forward. But you use the tools
    you’ve got. And right now, most of those tools are, one way or another, connected
    to OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: So GPT it will be. The thing about the [GPT Playground](platform.openai.com.html)
    is that it’s supposed to make you think about *program code* rather than *chat
    sessions*. In other words, how can the Playground’s `View code` feature help you
    build an automated workflow?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s imagine that you’re trying to integrate GPT creation into a larger process.
    Perhaps your organization is encouraging its website users to post their own thoughts
    and comments on your public discussion forum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the product or service you provide is technically complex, you have an
    interest in maintaining a high level of dialog on the platform. On the other hand,
    you don’t have the time and resources to manually edit each and every user comment
    before it goes public. Instead, you decide you’d rather have GPT do the work for
    you. Here’s how that would look in the Playground:'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.1 The GPT Playground using the Edit mode
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 3 1](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-3-1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note how the `Mode` drop-down is set to the default value of `Chat`. This gives
    me a `SYSTEM` field in addition to the USER field. and an `Output` field to the
    Playground interface. Here, I entered some text containing an obvious error in
    to the Input field:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The most famous musicians from the 1960’s were the Beatles, Bob Dylan, and J.S.
    Bach
  prefs: []
  type: TYPE_NORMAL
- en: I then typed `Check for accuracy and and output a corrected version` as my instruction.
    When I submitted the prompt, the output came back with "Elvis Presley" as the
    third item in the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'And here it is as code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When I ran that code through the API, I got a slightly different response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This next image shows how, for our use-case example, I can also filter content
    based on keywords using the `Stop sequences` field. This can be helpful if I’d
    like to catch and prevent the use of inappropriate words in user posts altogether.
    I’m sure you could come up with your own list of even less appropriate words that
    could be added to this field.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.2 The GPT Playground using the Edit mode with Stop sequences
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 3 2](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-3-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Naturally, you’ll need to make your own decision whether it’s appropriate to
    give GPT the power to effectively censor your users. While I for one would be
    nervous giving AI that kind of authority, that example is really about illustrating
    possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Use the OpenAI Playground (or other resources) to build workflows that leverage
    LLM functionality to parse text in real-time and check for accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Creating new contextually-aware content
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section is going to be fun. Unless you’re not into fun, of course. Don’t
    let me get in your way. By all means, feel free to skip ahead.
  prefs: []
  type: TYPE_NORMAL
- en: But the rest of us are going to dive deep into the strange world of generating
    fiction on-demand. Which is not to say that I would ever advise you to try to
    earn money selling AI-generated fiction. It’s hard enough getting genuine human-sourced
    fiction noticed amongst the millions of titles competing for readers' attention
    on Amazon. Instead, the fiction angle is really only here as another way to get
    you thinking creatively. As it turns out, I don’t even read fiction.
  prefs: []
  type: TYPE_NORMAL
- en: 'So where could such creativity lead you? Well, consider how much time and effort
    you could save configuring an AI model to generate annual company reports. The
    AI would need to be familiar with your company’s operations (i.e., to be "contextually
    aware"). So it would need to:'
  prefs: []
  type: TYPE_NORMAL
- en: Ingest your company’s complex financial history
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ingest the details of its most recent fiscal year
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the reporting requirements of your industry and local regulators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With all that taken care of, you’ll be just a mouse click away from automated
    business documents.
  prefs: []
  type: TYPE_NORMAL
- en: But that would be a bit complicated to simulate. So instead I’ll use this "fan-fiction"
    example to illustrate the process.
  prefs: []
  type: TYPE_NORMAL
- en: My plan is to have GPT index a large collection of existing novels written by
    a single author that feature a largely fixed cast of core characters. Once the
    index exists, I’ll try to confirm that GPT is familiar with all the events of
    the complete set of novels, and then get it to write new content using the original
    style and characters. Hopefully the new works will also be internally consistent
    and free of "historical" contradictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, to get my plan going, I first asked ChatGPT this question:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Is there a series of famous English-language novels that are now all in the
    public domain that follow the same set of characters through multiple books?*'
  prefs: []
  type: TYPE_NORMAL
- en: True to form, ChatGPT came through, reminding me of the "Sherlock Holmes" series
    by Sir Arthur Conan Doyle, the "Tarzan" Series by Edgar Rice Burroughs, the "Anne
    of Green Gables" Series by Lucy Maud Montgomery, and the "Tom Swift" Series by
    Victor Appleton. Excellent. I’ll go with Sherlock.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll browse over to the [Project Gutenberg site](www.gutenberg.org.html) where
    70,000 public domain e-books live, just waiting for you to come by and enjoy them.
    Most of the books are older classics whose copyrights have expired according to
    at least US copyright laws. As you can see from the image, books are available
    in a wide range of formats.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.3 The many formats available on a Shakespeare collection page on the
    Project Gutenberg site
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 3 3](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-3-3.png)'
  prefs: []
  type: TYPE_IMG
- en: I’ll then download the plain text versions covering around 25 novels and short
    stories from the original Sherlock Holmes series. I’ll save those files to the
    `data/` directory beneath the location where my Python code will run.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Setting up your environment for Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this exercise, I’ll assume you’ve got the Python programming language installed
    along with the Python package manager, `pip`. For help with getting Python itself
    set up for your operating system, see [the official download page](downloads.html).
    And [this page](installation.html) should give you everything you need to know
    about `pip`.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t yet have a valid OpenAI API key, you can get one by signing up
    on [the OpenAI API reference page](docs.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'From here on in you’ll need to work within a Python environment. One way to
    make that happen is by typing `python` from a command line. Everything you type
    into such an environment will be handled by the Python interpreter. You could
    also create a plain text file and, when you’ve added all the code you’ll need,
    run it from the command line using something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: My personal favorite Python environment, though, is [JupyterLab](jupyter.org.html).
    Jupyter will give you a browser-based environment that comes with all kinds of
    optimizations for managing serious data workloads. Another environment that’s
    particularly popular for Python work is [Google’s Colab](colab.google.html).
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Creating your prompt (using Python)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'But either way, here’s how you’ll import all the necessary Python modules that’ll
    actually run our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: By the way, this will cost you some money in API charges. When I ran it myself,
    it probably set me back around $0.25.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you haven’t net installed a module on your system, running something like
    this will get you there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Next, you’ll create an environment variable to hold your OpenAI API key. Make
    sure you replace my `sk-xxxx` with your actual key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This will load the contents of any documents in the `data/` directory and read
    them to a the variable `documents`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The next three lines use the `parser.get_nodes_from_documents` method to convert
    the actual contents of our `data/` directory to a GPT-friendly index. Depending
    on how much data you’ve got, this step could take a while.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we’ll pass our prompt and run it against the index. I began with this
    question about contradictions between books for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Because this is a reasonably reliable way to confirm that the model has actually
    read and "understood" the content
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Because I’m actually curious to see if Doyle himself had trouble keeping all
    his details straight
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the response I got when I submitted that prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*No, there are no contradictions between events in any one story and events
    in any other. All of the stories in these documents are connected by the same
    characters and plot points, and the events in each story are consistent with the
    events in the other stories, including the new context provided. The fragment
    of paper found between the finger and thumb of the dead man is consistent with
    the events in the other stories, as it appears to be an appointment and the hour
    mentioned upon it is the very time at which the poor fellow met his fate.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s good enough for this experiment, but it definitely wouldn’t do for projects
    where accuracy is critical. After all, when I asked the regular ChatGPT the same
    question I was given no less than five factual discrepancies. Of those, however,
    Watson’s war wound being somehow in both his arm ("A Study in Scarlet") and leg
    ("The Sign of Four") was the only one that truly met my criteria. The bottom line:
    independently confirm any AI output on which you plan to rely for important operations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s my prompt asking for the opening paragraphs of a brand new Sherlock
    Holmes story:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what came back:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: I had heard the rumors of a daring heist, but I never expected it to be true.
    A passenger liner in the Cunard line had been stolen in its entirety, and the
    authorities were at a loss as to how it had been done. I had to find out the truth,
    and so I made my way to the docks, where I knew I would find the answers I sought.
  prefs: []
  type: TYPE_NORMAL
- en: As I waited, I passed down the steps, worn hollow in the centre by the ceaseless
    tread of drunken feet. By the light of a flickering oil-lamp above the door, I
    found the latch and made my way into a long, low room, thick and heavy with the
    brown opium smoke, and terraced with wooden berths, like the forecastle of an
    emigrant ship. Through the gloom, I could dimly make out the figures of men lying
    in strange, fantastic poses, bowed shoulders, bent knees, heads thrown back, and
    chins pointing upward. Out of the black shadows, there glimmered little red circles
    of light, now bright, now faint, as the burning poison waxed or waned in the bowls
    of the metal pipes.
  prefs: []
  type: TYPE_NORMAL
- en: Suddenly, I heard a commotion from the street outside. I rushed
  prefs: []
  type: TYPE_NORMAL
- en: 'Sounds dark. But it’s actually darker than you think: when I did a bit of poking
    around, I found that GPT had stolen that second paragraph more or less intact
    from one of the existing stories that was included in the documents: "The Man
    With the Twisted Lip".'
  prefs: []
  type: TYPE_NORMAL
- en: So I asked again, this time adding `but without using any verbatim quotations`.
    The new results were more original and, I guess, more or less credible.
  prefs: []
  type: TYPE_NORMAL
- en: Callout
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now is probably a good time to talk about copyright restrictions. As you saw,
    the original Sherlock Holmes stories are all in the public domain, so there’s
    no problem reusing their content, characters, or plot lines. Generating content
    based on protected works - much like works of fan fiction - will be more complicated.
    In many jurisdictions there may be allowances for content that can be classified
    as fair use, transformative work, or non-commercial work. Just make sure you do
    your research in advance.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned back in chapter 1, it’s also possible that any content you use
    to *feed* an AI model will be archived and even used used by the organization
    provider (like OpenAI). This could be a problem for owners of copyrighted creative
    or sensitive business data.
  prefs: []
  type: TYPE_NORMAL
- en: But the real point is that AI can "understand" and index the contents of enormous
    data archives and use those as a resource for building new content…​like annual
    financial reports.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Generating specialized documents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There’s a certain unmatchable advantage to having an instant recall-level knowledge
    of the entire internet, even if it’s only the pre-2022 version. Troubleshooting
    even deeply uncommon technical or household problems is now easy. There’s no detail
    too obscure or abstract, no process too involved, and no product assembly guide
    too obscure. Forever gone is the correlation between marital friction and putting
    Ikea furniture together.
  prefs: []
  type: TYPE_NORMAL
- en: That’s great if your name, dear reader, happens to be GPT. (And why shouldn’t
    it be? What’s to stop me creating a GPT agent that runs around the internet buying
    all the available copies of my book and then happily reading them over and over
    again?) The rest of us, however, will have to satisfy our technical needs through
    the medium of AI prompts.
  prefs: []
  type: TYPE_NORMAL
- en: But getting the most out of AI does require that we have at least some domain
    knowledge of our own. Contract law - a field that requires gallons of domain knowledge
    - is one area where GPT can shine. After all, GPT-4 has already passed the Uniform
    Bar Exam, scoring in the 90th percentile.
  prefs: []
  type: TYPE_NORMAL
- en: 'A great deal of what lawyers do when preparing new contracts involves manipulating
    templated blocks of text. They’ll generally have two goals:'
  prefs: []
  type: TYPE_NORMAL
- en: To accurately identify the assets and principals involved
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To protect their clients from potential loss of rights
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Well, manipulating templated blocks of text while closely complying with a
    clearly stated set of facts and anticipating well documented possible perils is
    a perfect use-case for a mature, well trained LLM. To demonstrate that, I prompted
    ChatGPT with this request:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Draft a contract for me that formalizes the relationship between David Clinton
    of 123 Any St., Smallville, Ohio, USA with Manning Publishers in which David Clinton
    will provide ongoing consulting services to Manning in exchange for a 75% share
    in all net revenues.*'
  prefs: []
  type: TYPE_NORMAL
- en: The response was remarkable (although I have no idea why it arbitrarily dropped
    my share of Manning’s profits from 75% to 15%). There’s no reason to reproduce
    the contract here, but you - along with any interested Manning executives - are
    free to view it [on my website](bootstrap-it.com.html). I’m no lawyer, but I’ve
    signed more than a few contracts through my career and this draft really seemed
    to cover all the key elements.
  prefs: []
  type: TYPE_NORMAL
- en: Callout
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Once again however I must emphasise that AI is still nothing more than a dumb
    computer that doesn’t really know what it’s doing. Never automatically rely on
    anything that comes from an LLM. And, as GPT itself warned me when delivering
    that contract, it would be wise to seek a professional opinion before executing
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s where domain knowledge (the specialized understanding and expertise one
    has for a particular subject) comes in. No matter how impressive your LLM’s results
    may be, without your own general understanding of a field, the risk of misunderstanding,
    misinterpreting, and misapplying the generated content is high. How else can you
    be sure your output isn’t missing important context or making outright errors?
  prefs: []
  type: TYPE_NORMAL
- en: And even if you are an experienced specialist within a particular domain, it’ll
    be hard to be sure the thousands of words your AI gives you don’t contain a few
    broken details or confusing language. For many applications, "mostly accurate"
    is just not good enough.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s where the kind of *specialized* AI projects I’m seeing more frequently
    can help. As an example, take [the website called Harvey.ai](www.harvey.ai.html).
    The people behind the site appear to be using their legal and technological expertise
    to offer law firms access to a specialized AI. But what they’re offering goes
    far beyond the silly contract I discussed a moment ago. Harvey is clearly leveraging
    the considerable expertise - meaning, domain knowledge - of its creators to make
    their service more accurate, predictable, and useful.
  prefs: []
  type: TYPE_NORMAL
- en: No matter how much law-related information general tools like GPT might have
    ingested, they’ll never be able to compete with a specialized AI. There’s room
    for domain experts to add significant value to the service.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can apply far beyond just law. Whatever it is that you do well can probably
    be used for a productive partnership with AI to provide customer-facing services.
    Here are some particularly useful categories of content where LLMs combined with
    human domain expertise can be effective:'
  prefs: []
  type: TYPE_NORMAL
- en: Insights, explanations, and tutorials on a wide range of **technology topics**
    such as programming languages, artificial intelligence, cybersecurity, blockchain,
    and emerging technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scientific content** produced as explainers, research summaries, and detailed
    articles on subjects like physics, chemistry, biology, astronomy, and environmental
    science.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Healthcare content** like patient education materials, information on diseases,
    medical procedures, and research developments along with insights into emerging
    healthcare technologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finance and Economics** content can include real-time market analysis, investment
    insights, economic forecasts, financial concepts explainers, and customisable
    guidance on personal finance, budgeting, and retirement planning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Marketing and Advertising** content can include generate marketing strategies,
    ad content, social media posts, product descriptions, and consumer behavior and
    trend analytics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Education** materials can include lesson plans, explanations of academic
    concepts, and assistance in various subjects such as mathematics, history, literature,
    and foreign languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI platforms can provide **travel guides**, recommendations for tourist destinations,
    tips for planning trips, and insights into local culture and customs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Use large volumes of existing data to train your LLM to generate content that’s
    both aware of existing constraints and capable of adopting a specific writing
    "voice" and style. And be aware that that training should incorporate domain-specific
    knowledge and constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Generating programming code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Domain knowledge is also helpful when you’re looking for assistance with your
    programming code. Asking GPT for help will be far more effective if you already
    have a fairly clear understanding of what the code you’re after is meant to accomplish.
    But it’s also important to have a general familiarity with common coding structures
    and design, like loops, variables, and conditional statements.
  prefs: []
  type: TYPE_NORMAL
- en: 'That means a prompt like:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Show me how to build a website.
  prefs: []
  type: TYPE_NORMAL
- en: '…​won’t be nearly as effective as:'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Engineering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Show me how to build a responsive, full-stack web page that incorporates HTML,
    CSS, JavaScript, Node.js, and SQLite.
  prefs: []
  type: TYPE_NORMAL
- en: You should also never assume that the code your AI gives you will actually work.
    When something does fail to run, be sure to note the precise error messages you
    see and go back and use those as you ask for more help.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Interactive coding with Copilot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An interactive chat coding session with a AI can feel an awful lot like pair
    programming. And that’s a good thing. In fact, the name they chose for what is
    probably the most popular GPT-based code support tools around now is [GitHub’s
    Copilot](en.html): which says it all.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I won’t go too deeply into the general topic because it’s been well documented
    online and, even better, because Nathan B. Crocker has focused on it for his [Manning
    book: AI-Powered Developer](books.html). But I will quickly take you through the
    process of getting up to speed with Copilot.'
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to know is that, after your 30-day free trial, Copilot charges
    a monthly fee.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to use Copilot: GitHub Copilot for Individuals is available
    for personal GitHub accounts, and GitHub Copilot for Business can be used by organizations.
    "Verified students, teachers, and maintainers of popular open source projects"
    can be eligible for free access.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you enable Copilot within your GitHub account and then set up your payment
    preferences, you’ll need to choose a code editor. At this point, Copilot is compatible
    with Visual Studio, Visual Studio Code, Neovim, and JetBrains IDEs. Whichever
    IDE you choose, you’ll need to find and install the GitHub Copilot extension.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve got everything enabled and installed and you’re logged into your
    GitHub account, you can start using Copilot. As you write code in your preferred
    programming language, Copilot will provide code suggestions in real-time based
    on the context and patterns it’s learned from its training data. You can accept
    the suggestions by pressing Tab, and Copilot will generate code snippets to speed
    up your development process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Copilot understands code structure and descriptive naming usage. Using an example
    from the Copilot documentation, you could begin with nothing more than a JavaScript
    (`.js`) file containing a single function header like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Copilot can take that and build a complete working function that might work
    right out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the GPT Playground to learn how to apply AI models, completion configurations,
    and environmental controls to your prompts. The Playground is also an excellent
    source of code for API-directed prompts and automation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train your AI model using existing data/content and incorporating domain-specific
    constraints to create optimally suitable new content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI tools have been widely adopted for help with programming code,
    but purpose-built tools like GitHub’s CoPilot can be particularly effective, given
    how they’ve been trained on the entire GitHub site. Use code-assistant tools to
    build on your existing programming ideas and code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.7 Try this for yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Why not use llama_index - the way you saw above with the stories of Sherlock
    Holmes - on as much of *your* writing as you can to train GPT to speak for you?
    Then prompt your model to respond to specific questions or scenarios using your
    style.
  prefs: []
  type: TYPE_NORMAL
