- en: Chapter 3\. Programming with GPT-3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。使用 GPT-3 进行编程
- en: Almost all of GPT-3’s NLP capabilities are created in the Python programming
    language. But to enable wider accessibility, the API comes with built-in support
    for all the major programming languages so users can build GPT-3-powered applications
    using the programming language of their choice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有 GPT-3 的 NLP 功能都是使用 Python 编程语言创建的。但为了实现更广泛的可访问性，API 内置支持所有主要的编程语言，因此用户可以使用他们选择的编程语言构建基于
    GPT-3 的应用程序。
- en: 'In this section we will illustrate how this works by replicating an example
    with three common programming languages: Python, Go, and Java.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过复制一个示例来说明这是如何工作的，该示例涉及三种常见的编程语言：Python、Go 和 Java。
- en: 'Just a heads-up: In each language-specific section, we assume you have a basic
    understanding of the programming language being discussed. If you don’t, you can
    safely skip the section.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下：在每个特定语言的部分中，我们假设你对所讨论的编程语言有基本的了解。如果没有，你可以安全地跳过该部分。
- en: Using the OpenAI API with Python
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 的 OpenAI API
- en: Python is the most popular language for data science and machine learning tasks.
    Compared to conventional data science programming languages like R and Stata,
    Python shines because it’s scalable and integrates well with databases. It is
    widely used and has a flourishing community of developers keeping its ecosystem
    up to date. Python is easy to learn and comes with useful data science libraries
    like NumPy and pandas.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是数据科学和机器学习任务中最流行的语言。与传统的数据科学编程语言（如 R 和 Stata）相比，Python 的优势在于其可扩展性和与数据库的良好集成。它被广泛使用，并有一个蓬勃发展的开发者社区，使其生态系统保持更新。Python
    容易学习，并且带有诸如 NumPy 和 pandas 等有用的数据科学库。
- en: 'You can pair GPT-3 with Python using a library called [Chronology](https://oreil.ly/9eULI)
    that provides a simple, intuitive interface. Chronology can mitigate the monotonous
    work of writing all of your code from scratch every time. Its features include
    the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用一个叫做 [Chronology](https://oreil.ly/9eULI) 的库将 GPT-3 与 Python 配对，该库提供了一个简单直观的接口。Chronology
    可以减轻每次编写所有代码的单调工作。它的特点包括以下内容：
- en: It calls the OpenAI API asynchronously, allowing you to generate multiple prompt
    completions at the same time.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它异步调用 OpenAI API，允许你同时生成多个提示完成。
- en: You can create and modify training prompts easily; for example, modifying a
    training prompt used by a different example is fairly straightforward.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以轻松创建和修改训练提示；例如，修改一个不同示例中使用的训练提示相对比较简单。
- en: It allows you to chain prompts together by plugging the output of one prompt
    into another.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它允许你通过将一个提示的输出插入到另一个提示中来链接提示。
- en: 'Chronology is hosted on PyPI and supports Python 3.6 and above. To install
    the library, run the following command:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Chronology 托管在 PyPI 上，并支持 Python 3.6 及以上版本。要安装该库，请运行以下命令：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After you install the Python library via PyPI, let’s look at an example of how
    to prime GPT-3 to summarize a given text document at a second-grade reading level.
    We’ll show you how to call the API, send the training prompt as a request, and
    get the summarized completion as an output. We’ve posted the code for you in a
    [GitHub repository](https://oreil.ly/nVaC9).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过 PyPI 安装 Python 库之后，让我们看一下如何通过 GPT-3 来总结一个给定文本文档的二年级阅读水平的示例。我们将向你展示如何调用 API，将训练提示作为请求发送，并将总结完成作为输出。我们已经在
    [GitHub 存储库](https://oreil.ly/nVaC9) 中为你发布了代码。
- en: 'In this example, we will use the following training prompt:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将使用以下训练提示：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'First, import the following dependencies:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入以下依赖项：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we can create a function that reads the training prompt and provides the
    completion output. We have made this function asynchronous, which allows us to
    carry out parallel function calls. We will use the following configuration for
    the API parameters:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建一个函数，该函数读取训练提示并提供完成输出。我们将此函数异步化，这允许我们进行并行函数调用。我们将使用以下 API 参数配置：
- en: Maximum tokens=100
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大标记数=100
- en: Execution Engine=“Davinci”
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行引擎=“Davinci”
- en: Temperature=0.5
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温度=0.5
- en: Top-p=1
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶部-p=1
- en: Frequency Penalty=0.2
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率惩罚=0.2
- en: Stop Sequence=[“\n\n”]
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止序列=[“\n\n”]
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can create an asynchronous workflow, invoke that workflow using the
    `main` function provided by the library, and print the output in the console:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建一个异步工作流，使用库提供的`main`函数调用该工作流，并在控制台中打印输出：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Save it as a Python script with the name *text_summarization.py* and run it
    from the terminal to generate the output. You can run the following command from
    your root folder:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 将其保存为名为*text_summarization.py*的 Python 脚本，并从终端运行以生成输出。您可以从根目录运行以下命令：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once you execute the script, your console should print the following summary
    of the prompt:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 执行脚本后，您的控制台应打印出以下提示的摘要：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you are not well-versed in Python and want to chain different prompts without
    writing code, you can use the [no-code interface](https://oreil.ly/L2TUK) built
    on top of the [Chronology library](https://oreil.ly/f02Cx) to create the prompt
    workflow using drag-and-drop. See our GitHub [repository](https://oreil.ly/AfTQM)
    for more examples of how you can use Python programming to interact with GPT-3.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对 Python 不熟悉并且想要在不编写代码的情况下链式连接不同的提示，您可以使用基于[Chronology 库](https://oreil.ly/f02Cx)构建的[无代码界面](https://oreil.ly/L2TUK)来通过拖放创建提示工作流程。请查看我们的
    GitHub[存储库](https://oreil.ly/AfTQM)以了解更多您可以如何使用 Python 编程与 GPT-3 进行交互的示例。
- en: Using the OpenAI API with Go
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Go 调用 OpenAI API
- en: Go is an open source programming language that combines the best features of
    other programming languages, blending the ease of programming of an interpreted,
    dynamically typed language with the efficiency and safety of a statically typed,
    compiled language. Developers often call it “C for the 21st century.”
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Go 是一种开源编程语言，结合了其他编程语言的最佳特性，将解释的、动态类型的语言的编程便利性与静态类型的、编译的语言的效率和安全性结合在一起。开发人员通常称其为“21世纪的
    C 语言”。
- en: 'Go is the language of preference for building projects that require high security,
    high speed, and high modularity. This makes it an attractive option for many projects
    in the fintech industry. Key features of Go are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Go 是构建需要高安全性、高速度和高模块化的项目的首选语言。这使得它成为金融科技行业许多项目的有吸引力的选择。Go 的主要特点如下：
- en: Ease of use
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用便捷
- en: State-of-the-art productivity
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最先进的生产力
- en: High-efficiency Static typing
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效的静态类型化
- en: Advanced performance for networking
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络高效性能
- en: Full use of multicore power
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 充分利用多核处理能力
- en: If you are completely new to Go and want to give it a try, you can [follow the
    documentation](https://oreil.ly/3ZjiB) to get started.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您完全不熟悉 Go 并想试试，您可以[查看文档](https://oreil.ly/3ZjiB)开始使用。
- en: Once you are done with the installation and understand the basics of Go programming,
    you can follow these steps to use the [Go API wrapper for GPT-3](https://oreil.ly/j6lUY).
    To learn more about creating Go modules, see [this tutorial](https://oreil.ly/w1334).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成并且了解了 Go 编程的基础知识后，您可以按照以下步骤使用[用于 GPT-3 的 Go API 包装器](https://oreil.ly/j6lUY)。要了解更多关于创建
    Go 模块的信息，请参阅[本教程](https://oreil.ly/w1334)。
- en: 'First, you’ll create a module to track and import code dependencies. Create
    and initialize the `gogpt` module using the following command:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您将创建一个模块来跟踪和导入代码依赖项。使用以下命令创建并初始化`gogpt`模块：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After creating the `gogpt` module, let’s point it to [this GitHub repository](https://oreil.ly/6o2Hj)
    to download the necessary dependencies and packages for working with the API.
    Use the following command:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`gogpt`模块后，让我们将其指向[此 GitHub 存储库](https://oreil.ly/6o2Hj)以下载使用 API 的必要依赖项和包。使用以下命令：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We’ll use the same text summarization example as in the previous section. (You
    can find all the code in the following [repository](https://oreil.ly/r5HhV).)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一节相同的文本摘要示例。（您可以在以下[存储库](https://oreil.ly/r5HhV)中找到所有代码。）
- en: 'Let’s import the necessary dependencies and packages for starters:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先导入必要的依赖和包：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Go programming organizes source files into system directories called *packages*,
    which makes it easier to reuse code across Go applications. In the first line
    of the code we call the package `main`, which tells the Go compiler that the package
    should compile as an executable program instead of a shared library.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Go 编程将源文件组织成称为*包*的系统目录，这使得在 Go 应用程序之间重用代码变得更容易。在代码的第一行中，我们调用`main`包，告诉 Go 编译器该包应该编译为可执行程序，而不是共享库。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In Go, whenever you build reusable pieces of code, you will develop a package
    as a shared library. But when you develop executable programs, you will use the
    package `main` to make the package an executable program. Because we are calling
    this package the main function in the package, `main` will be set up as the entry
    point of our executable program.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go 语言中，每当你构建可重用的代码片段时，你会开发一个作为共享库的包。但是当你开发可执行程序时，你将使用 `main` 包来使包成为可执行程序。因为我们将在该包中调用主函数，`main`
    将被设置为我们可执行程序的入口点。
- en: 'Now you’ll create a `main` function that will host the entire logic of reading
    the training prompt and providing the completion output. Use the following configuration
    for the API parameters:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将创建一个 `main` 函数，它将承载读取训练提示和提供完成输出的整个逻辑。使用以下配置作为 API 参数：
- en: Maximum tokens=100
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大标记数=100
- en: Execution Engine=“Davinci”
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行引擎=“Davinci”
- en: Temperature=0.5
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温度=0.5
- en: Top-p=1
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Top-p=1
- en: Frequency Penalty=0.2
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率惩罚=0.2
- en: Stop Sequence=[“\n\n”]
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止序列=[“\n\n”]
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This code performs the following tasks:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码执行以下任务：
- en: Sets up a new API client by providing it with the API token and then leaves
    it to run in the background.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供 API 令牌设置一个新的 API 客户端，然后将其留在后台运行。
- en: Reads the prompt " " in the form of a text file from the *prompts* folder.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以文本文件形式读取 " " 作为提示，从 *prompts* 文件夹中读取。
- en: Creates a completion request by providing the training prompt and specifying
    the values of API parameters (like temperature, Top P, stop sequence, and so forth).
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供训练提示和指定 API 参数值（如温度、Top P、停止序列等）来创建完成请求。
- en: Calls the `create completion` function and provides it with the API client,
    completion request, and execution engine.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 `create completion` 函数，并向其提供 API 客户端、完成请求和执行引擎。
- en: Generates a response in the form of a completion, which prints toward the end
    in the console.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以完成的形式生成响应，该响应朝向控制台的末尾打印。
- en: 'You can then save the code file as *text_summarization.go* and run it from
    the terminal to generate the output. Use the following command to run the file
    from your root folder:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以将代码文件保存为 *text_summarization.go* 并从终端运行它以生成输出。使用以下命令从你的根文件夹运行该文件：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once you execute the file, your console will print the following output:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你执行了该文件，你的控制台将打印出以下输出：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For more examples of how you can use Go programming to interact with GPT-3,
    please visit our GitHub [repository](https://oreil.ly/r5HhV).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用 Go 编程与 GPT-3 进行交互的更多示例，请访问我们的 GitHub [存储库](https://oreil.ly/r5HhV)。
- en: Using the OpenAI API with Java
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Java 调用 OpenAI API
- en: Java is one of the oldest and most popular programming languages for developing
    conventional software systems; it is also a platform that comes with a runtime
    environment. It was developed by Sun Microsystems (now a subsidiary of Oracle)
    in 1995, and as of today more than three billion devices run on it. It is a general-purpose,
    class-based, object-oriented programming language designed to have fewer implementation
    dependencies. Its syntax is similar to that of C and C++. Two-thirds of the software
    industry still uses Java as its core programming language.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Java 是用于开发传统软件系统的最古老和最流行的编程语言之一；它还是一个带有运行时环境的平台。它是由 Sun Microsystems（现在是 Oracle
    的子公司）于 1995 年开发的，截至今天，超过三十亿台设备都在运行它。它是一种通用的、基于类的、面向对象的编程语言，旨在具有较少的实现依赖性。其语法与 C
    和 C++ 类似。三分之二的软件行业仍然将 Java 作为其核心编程语言。
- en: Let’s use our olive oil text summarization example once more. As we did with
    Python and Go, we’ll show you how to call the API, send the training prompt as
    a request, and get the summarized completion as an output using Java.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用橄榄油文本摘要示例。与 Python 和 Go 一样，我们将向你展示如何调用 API、将训练提示作为请求发送，并使用 Java 获取摘要完成作为输出。
- en: For a step-by-step code walk-through on your local machine, clone our GitHub
    [repository](https://oreil.ly/gpt3-repo). In the cloned repository go to the *Programming_with_GPT-3*
    folder and open the *GPT-3_Java* folder.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地计算机上逐步浏览代码，请克隆我们的 GitHub [存储库](https://oreil.ly/gpt3-repo)。在克隆的存储库中转到 *Programming_with_GPT-3*
    文件夹，然后打开 *GPT-3_Java* 文件夹。
- en: 'First, import all the relevant dependencies:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入所有相关的依赖项：
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now you’ll create a class named `OpenAiApiExample`. All of your code will be
    a part of it. Under that class, first create an `OpenAiService` object using the
    API token:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将创建一个名为 `OpenAiApiExample` 的类。你的所有代码都将成为它的一部分。在该类下，首先使用 API 令牌创建一个 `OpenAiService`
    对象：
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The connection to the OpenAI API is now established in the form of a *service
    object*. Read the training prompt from the *prompts* folder:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 OpenAI API 的连接已经建立成一个*service object*的形式。从*prompts*文件夹中读取训练提示：
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then you can create a completion request with the following configuration for
    the API parameters:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用以下配置创建一个 API 参数的完成请求：
- en: Maximum tokens=100
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大令牌数=100
- en: Execution Engine=“Davinci”
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行引擎=“Davinci”
- en: Temperature=0.5
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温度=0.5
- en: Top-p=1
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Top-p=1
- en: Frequency Penalty=0.2
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率惩罚=0.2
- en: Stop Sequence=[“\n\n”]
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止序列=[“\n\n”]
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Save the code file as *text_summarization.java* and run it from the terminal
    to generate the output. You can use the following command to run the file from
    your root folder:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码文件保存为*text_summarization.java*并从终端运行以生成输出。您可以使用以下命令从根文件夹运行文件：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Your console should print the same summary as it did with the previous examples.
    For more examples of how you can use Java to interact with GPT-3, see our GitHub
    [repository](https://oreil.ly/amtjY).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 您的控制台应该打印与以前示例相同的摘要。有关如何使用 Java 与 GPT-3 进行交互的更多示例，请参阅我们的 GitHub [存储库](https://oreil.ly/amtjY)。
- en: GPT-3 Sandbox Powered by Streamlit
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-3 沙盒由 Streamlit 提供支持
- en: In this section we will walk you through the GPT-3 Sandbox, an open source tool
    we’ve created that provides boilerplate code to help you turn your ideas into
    reality with just a few lines of Python code. We’ll show you how to use it and
    how to customize it for your specific application.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将带您了解 GPT-3 沙盒，这是我们创建的一个开源工具，提供样板代码，帮助您只需几行 Python 代码就能将您的想法变为现实。我们将向您展示如何使用它，以及如何根据您的特定应用进行自定义。
- en: The goal of our sandbox is to empower you to create cool web applications, no
    matter what your technical background. It is built on top of the Streamlit framework.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们沙盒的目标是让您能够创建酷炫的 Web 应用程序，无论您的技术背景如何。它是建立在 Streamlit 框架之上的。
- en: To accompany this book, we have also created a [video series](https://oreil.ly/jQrlG)
    with step-by-step instructions for creating and deploying your GPT-3 application,
    which you can access by scanning the QR code in [Figure 3-1](#qr_code_for_gpt_three_sandbox_video_ser).
    Please follow it as you read this chapter.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了配合本书，我们还创建了一个[视频系列](https://oreil.ly/jQrlG)，其中提供了逐步创建和部署 GPT-3 应用程序的说明，您可以通过扫描
    [图 3-1](#qr_code_for_gpt_three_sandbox_video_ser) 中的 QR 码来访问。请在阅读本章时一并参考。
- en: '![](Images/gpt3_0301.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gpt3_0301.png)'
- en: Figure 3-1\. QR code for GPT-3 Sandbox video series
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. GPT-3 沙盒视频系列的 QR 码
- en: 'We use Visual Studio Code as the IDE for our examples, but feel free to use
    any IDE. You’ll need to install the IDE before you start. Please also make sure
    you are running Python version 3.7 or higher. You can confirm which version you
    have installed by running the following command:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在示例中使用 Visual Studio Code 作为 IDE，但您可以随意使用任何 IDE。在开始之前，您需要安装 IDE。请确保您正在运行 Python
    版本为 3.7 或更高版本。您可以通过运行以下命令确认已安装的版本：
- en: '[PRE18]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Clone the code from this [repository](https://oreil.ly/gpt3-repo) by opening
    a new terminal in your IDE and using the following command:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在您的 IDE 中打开新终端并使用以下命令克隆此[存储库](https://oreil.ly/gpt3-repo)的代码：
- en: '[PRE19]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: After you clone the repository, the code structure in your IDE should look like
    [Figure 3-2](#sandbox_file_directory_structure).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在您克隆存储库之后，您 IDE 中的代码结构应该如 [图 3-2](#sandbox_file_directory_structure) 所示。
- en: '![](Images/gpt3_0302.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gpt3_0302.png)'
- en: Figure 3-2\. Sandbox file directory structure
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 沙盒文件目录结构
- en: Everything you need to create and deploy a web application is already present
    in the code. You just need to tweak a few files to customize the sandbox for your
    specific use case.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 您所需要创建和部署 Web 应用程序的一切都已经在代码中存在。您只需要调整一些文件，以定制沙盒以适应您的特定用例。
- en: Create a [Python virtual environment](https://oreil.ly/iUWv4), which you’ll
    name *env*. Then you can install the required dependencies.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个[Python 虚拟环境](https://oreil.ly/iUWv4)，命名为*env*。然后您可以安装所需的依赖项。
- en: 'Go to the *email_generation* folder. Your path should look like this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 转到*email_generation*文件夹。你的路径应该像这样：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'From there, run the following command:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，运行以下命令：
- en: '[PRE21]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now you can start customizing the sandbox code. The first file that you need
    to look at is *training_data.py*. Open that file and replace the default prompt
    with the training prompt you want to use. You can use the GPT-3 Playground to
    experiment with different training prompts (see [Chapter 2](ch02.xhtml#using_the_openai_api)
    and our [video](https://oreil.ly/nCIgG) for more on customizing the sandbox).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以开始定制沙箱代码了。 您需要查看的第一个文件是*training_data.py*。 打开该文件并用您想要使用的训练提示替换默认提示。 您可以使用GPT-3
    Playground尝试不同的训练提示（有关自定义沙箱的更多信息，请参阅[第2章](ch02.xhtml#using_the_openai_api)和我们的[视频](https://oreil.ly/nCIgG)）。
- en: You’re now ready to tweak the API parameters (maximum tokens, execution engine,
    temperature, Top P, frequency penalty, stop sequence) as per the requirements
    of your application use case. We recommend experimenting with different parameter
    values for a given training prompt in the Playground to determine what values
    will work best for your use case. Once you get satisfactory results, then you
    can alter the values in the *model_training_service.py* file.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以根据应用程序用例的要求调整API参数（最大标记数、执行引擎、温度、Top P、频率惩罚、停止序列）。 我们建议您在Playground中尝试不同的参数值以确定哪些值适用于您的用例。
    一旦您获得满意的结果，那么您就可以在*model_training_service.py*文件中更改值。
- en: 'That’s it! Your GPT-3-based web application is now ready. You can run it locally
    using the following command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！ 您的基于GPT-3的Web应用程序现在已准备就绪。 您可以使用以下命令在本地运行它：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Check to make sure it works, and then you can deploy the application to the
    internet using Streamlit sharing to showcase it to a wider audience. Our [video](https://oreil.ly/h5uTe)
    offers a full deployment walk-through.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 确保它正常工作，然后您可以使用Streamlit共享将应用程序部署到互联网，以向更广泛的受众展示它。 我们的[视频](https://oreil.ly/h5uTe)提供了完整的部署演示。
- en: Note
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This application follows a simple workflow, where the training prompt receives
    a single input from the UI and comes up with the response. If your application
    requires a more complex workflow, where the training prompt takes in multiple
    inputs, customize the UI elements by going through the scripts *app1.py*, *app2.py*,
    and *gpt_app.py*. For details, refer to the [Streamlit documentation](https://docs.streamlit.io).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本应用程序遵循一个简单的工作流程，其中训练提示从UI接收单个输入并生成响应。 如果您的应用程序需要更复杂的工作流程，其中训练提示接受多个输入，请通过查看脚本*app1.py*、*app2.py*和*gpt_app.py*来自定义UI元素。
    有关详细信息，请参阅[Streamlit文档](https://docs.streamlit.io)。
- en: In the next few chapters, we will explore different applications of GPT-3 and
    how successful businesses are built on top of it.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将探讨GPT-3的不同应用以及成功的企业是如何基于它构建的。
- en: Going Live with GPT-3-Powered Applications
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基于GPT-3的应用程序上线
- en: Are you ready to put your GPT-3-powered application into production?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您准备好将基于GPT-3的应用程序投入生产了吗？
- en: Before you do, let’s discuss some risk mitigation measures. In [Chapter 6](ch06.xhtml#challengescomma_controversiescomma_and),
    you will learn some of the ways GPT-3 can be used to do harm. To safeguard against
    those malicious practices, OpenAI has created guidelines and procedures that you
    must follow before going live with your application. Currently, you can serve
    the API out to five people without pre-approval, but for more, you’ll need to
    apply for a pre-launch production review. We highly recommend reading the [Usage
    Guidelines](https://oreil.ly/oGBGJ) before you apply.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在您开始之前，让我们讨论一些风险缓解措施。 在[第6章](ch06.xhtml#challengescomma_controversiescomma_and)中，您将了解一些GPT-3可能被用来造成伤害的方法。
    为了防范这些恶意行为，OpenAI已经制定了必须在您的应用程序上线之前遵循的准则和程序。 目前，您可以向五个人提供API而无需事先批准，但是如果需要更多，则需要申请预上线生产审查。
    我们强烈建议您在申请之前阅读[使用指南](https://oreil.ly/oGBGJ)。
- en: When you submit the [Pre-Launch Review Request](https://oreil.ly/SO0VZ), the
    OpenAI team looks into your use case in detail and flags any potential violations
    of the API [Safety Best Practices](https://oreil.ly/gXRhC). If your request is
    approved, OpenAI will grant you a maximum spend limit, which will increase over
    time as you build a track record. As your user base grows, you can submit a [Quota
    Increase Request](https://oreil.ly/b25mG). This gives you freedom to build and
    deploy your application while OpenAI monitors its potential impact on the platform.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当你提交[Pre-Launch Review Request](https://oreil.ly/SO0VZ)时，OpenAI团队会详细审查你的用例，并标记任何潜在违反API
    [安全最佳实践](https://oreil.ly/gXRhC)的行为。如果你的请求被批准，OpenAI将为你提供一个最大的消费限制，随着你建立记录，这个限制会随着时间增加。随着用户基础的增长，你可以提交[Quota
    Increase Request](https://oreil.ly/b25mG)。这样一来，你就可以自由地构建和部署你的应用程序，而OpenAI则会监控其对平台的潜在影响。
- en: Conclusion
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we learned how to use the OpenAI API with the programming languages
    Python, Go, and Java. We also walked through a low-code sandbox environment created
    using Streamlit that will help you to quickly turn your idea into an application.
    Lastly, we looked at the key requirements to go live with a GPT-3 application.
    This chapter provided you with the programming outlook of the API; going forward
    we’ll dive deeper into the burgeoning ecosystem empowered by GPT-3.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用OpenAI API来编程使用Python、Go和Java语言。我们还介绍了使用Streamlit创建的低代码沙盒环境，它将帮助你快速将你的想法变成应用程序。最后，我们查看了上线GPT-3应用程序的关键要求。这一章节为你提供了API的编程前景；未来我们将更深入地探讨GPT-3赋能的蓬勃生态系统。
