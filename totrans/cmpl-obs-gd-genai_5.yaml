- en: 5 Feeding Data to Your Generative AI Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building and then querying an index based on a local data archive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uploading a PDF document to the ChatPDF service to query it the way you’d use
    ChatGPT.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scripting the PDF-querying process using the ChatPDF API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the AutoGPT tool to give a GPT-fueled agent access to the full and open
    internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s only so long you’ll keep at it before the novelty of torturing secrets
    out of an always friendly (and occasionally outrageous) AI gets a bit stale. After
    all, how many versions of the perfect resume do you actually need? And do you
    really *want* to hear how John Lennon would have sounded singing Shakespearian
    sonnets?
  prefs: []
  type: TYPE_NORMAL
- en: 'The real power of an LLM is in how quickly it’s able to process - and "understand"
    - insane volumes of data. It would be a shame to have to limit its scope to just
    the stuff it was shown during its training period. And in any case, you stand
    to gain more from the way that your AI processes *your* data than someone else’s.
    Just imagine how much value can be unleashed by identifying:'
  prefs: []
  type: TYPE_NORMAL
- en: Patterns and trends in health records
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threats and attacks in digital network access logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Potential financial opportunities or risks in banking records
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Opportunities for introducing efficiencies in supply chain, infrastructure,
    and governance operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insurance, tax, or program fraud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Government corruption (and opportunities for operational improvements)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So is it possible to expose GPT to stuff on your computer or, even better, to
    stuff that’s out there on the live internet? The short answer is "yes." And that’ll
    have to do for the long answer, too. In fact, as of a few hours before I sat down
    to write this chapter at any rate, there are a handful of ways to get this done.
    In this chapter I’ll show you how to send LLMs deep into your data-rich documents,
    and out across the live internet.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Indexing local data archives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The full power of even currently available AI systems can hardly be imagined.
    Not a single day has passed over the last year or so when I didn’t hear about
    the discovery of some new and madly creative way of using the tools. But from
    my perspective - at this point in history at least - the greatest potential lies
    in a generative AI’s ability to instantly read, digest, organize, and then explain
    vast volumes of raw data.
  prefs: []
  type: TYPE_NORMAL
- en: Large organizations spend millions of dollars building and maintaining systems
    for managing, parsing, and monitoring the terabytes of data their operations regularly
    spit out at them. Database managers and security analysts don’t come cheap. But
    what choice do those organizations have? Why generate all that data in the first
    place if there’s no way to properly understand it?
  prefs: []
  type: TYPE_NORMAL
- en: But what about those of us who work for organizations that aren’t named "Google",
    "Amazon", or "Government of…​"? Our devices and digital activities are probably
    producing their own data that would love to be read. Well, we may not be able
    to afford our own teams of DB managers, security analysts, or data analytics,
    but we do have plenty of data. And the age of LLMs is officially upon us.
  prefs: []
  type: TYPE_NORMAL
- en: The trick is to to connect our data to a friendly AI. How will we do that? That
    would be the [LlamaIndex project](latest.html) (which we’ve already seen back
    in chapter 3). LlamaIndex maintains the open source GPTSimpleVectorIndex module
    along with a full ecosystem of resources for exposing your own data to GPT.
  prefs: []
  type: TYPE_NORMAL
- en: You can read the full documentation guide on LlamaIndex’s [Read the Docs site](getting_started.html).
    But here’s the quick and dirty version that’ll demonstrate how it works on a Python
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The odds are good that you already have the Python programming language installed
    along with the Python package manager, `pip`. You can confirm that’s the case
    by running these two commands from your command line. Here’s how those looked
    when I ran them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If your system isn’t ready yet, you should head over to the Installing Python
    Appendix at the end of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once everything’s in place, we’ll install the two modules (`os` and `llama-index`)
    we’ll need for this particular project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Pro tip!
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The first troubleshooting step if a llama-index operation ever fails is to
    make sure you’ve got the latest version installed. You can do that with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now we’ll start writing our Python code. You’ll begin by setting up your GPT-enabled
    environment by importing the `os` module and adding your OpenAI key. Since LlamaIndex
    uses the public OpenAI API, nothing will happen without this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If you don’t yet have a valid OpenAI API key, head over to [the API reference
    page](docs.html) and click the Sign up button.
  prefs: []
  type: TYPE_NORMAL
- en: This next code will import the modules that’ll do all the heavy lifting. `pathlib`
    will make it easy for our code to find the location on our local file system where
    we’ve saved our data, `GPTVectorStoreIndex` handles the embeddings representing
    our data that will be generated by `llama_index`, and `download_loader` handles
    the loader file we’ll be working with.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: To keep things simple, you should copy all the documents you want GPT to analyze
    to a directory beneath the directory where your Python code is running. I chose
    to call my directory `data`, but you can use whatever you’d prefer. For this example,
    I downloaded a CSV file from the [Kaggle site](www.kaggle.com.html) containing
    population numbers for each of the world’s nations. ([this was the dataset I used](thabresh.html),
    although I renamed it `population.csv`.)
  prefs: []
  type: TYPE_NORMAL
- en: This code will read the `population.csv` file a variable called `documents`
    and then use that data to build a GPT-friendly index that’ll take the name `index`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: I’ll then submit my query as an argument for the `query_engine.query` method.
    Just to demonstrate that GPT understands both the CSV ("comma separated values")
    data and the question I’m asking, I’ll ask it for the population of Canada as
    of 2010\. Note how my prompt includes instructions for the LLM on what kind of
    data the `pop2010` column contains. This will greatly increase the chances that
    it’ll understand how to answer my questions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The response was correct - although the commas were a bit weird:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let’s run one more request. Sticking with the `pop2010` column, I want to know
    which country’s population was, in 2010, the closest to the median population
    for all countries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what came back: *Poland had the population closest to the median of
    all countries in 2010, with 38,597,353 people.*'
  prefs: []
  type: TYPE_NORMAL
- en: Well, Poland’s 2010 population *was* 38,597,353\. But the actual median population
    of all countries was actually over 49 million, which meant that Myanmar was the
    closest. To be fair, Myanmar was only eights spots off from Poland. And GPT’s
    preference for text analysis over simple math operations is well known. I’d say
    that things will only improve with time.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, here’s another example of an LLM that does *seem* to understand
    what we’re after, but doesn’t get the job done quite right. And, of course, it’s
    a healthy reminder to always manually confirm that what you’re getting from your
    AI actually makes real-world sense.
  prefs: []
  type: TYPE_NORMAL
- en: Dig around and you’ll find much more to the LllamaIndex project. For instance,
    [Llama Hub](llamahub.ai.html) is an archive of "loaders" containing code snippets
    you can use to connect Llama to your own data that’s maintained within any one
    of hundreds of popular frameworks, including Wikipedia, Trello, Reddit, and Jira.
    Those loaders simplify the process of giving GPT access to real-world data in
    a wide range of environments.
  prefs: []
  type: TYPE_NORMAL
- en: This is about way more than just summarizing stand alone spreadsheets. Bearing
    in mind the use-case scenarios I listed at the start of this chpater, just imagine
    how tools like this can be put to work aggregating data in multiple formats and
    then mining the data for deep insights.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Seeding a chat session with private data (ChatPDF)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let me give you an example of just how much better GPT is when working with
    text than with numbers - at least so far. We’re going to take advantage of one
    of the countless businesses that are rushing to offer value-added GPT-based services.
    ChatPDF provides a browser-based interface to which you can upload and "chat with"
    any PDF document.
  prefs: []
  type: TYPE_NORMAL
- en: Just point your browser to [chatpdf.com](www.chatpdf.com.html), drag your PDF
    document to the box labeled "Drop PDF here" that’s visible in the image below,
    and start asking questions. It works just like a ChatGPT session.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 The ChatPDF webpage
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 5 1](images/gai-5-1.png)'
  prefs: []
  type: TYPE_IMG
- en: But where’s the fun of that? Instead, there’s no reason why you shouldn’t automate
    and integrate your prompts into sophisticated and efficient scripts. To do that,
    you’ll need to request an API key from ChatPDF using the dialog box that appears
    when you click the `API` link at the bottom of the page. If you get access, you’ll
    be all set for some serious scripting.
  prefs: []
  type: TYPE_NORMAL
- en: The [ChatPDF API documentation](api.html) - at least in its current iteration
    - provides code snippets for Node.js, Python, and curl requests. For this example,
    I’m going to use the `curl` command line data transfer tool that we saw back in
    chapter two.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, sending API requests using `curl` will take two steps, which means
    you’ll run two variations of the `curl` command. The figure illustrates the process:'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 The request/response process using the ChatPDF API
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 5 2](images/gai-5-2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here’s how that first step will work:'
  prefs: []
  type: TYPE_NORMAL
- en: Authenticate with the ChatPDF API server using the POST method that points to
    the ChatPDF API address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Include the `-H` argument containing your API key (insert in place of the `sec_xxxxxx`
    dummy code)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Include the `-d` argument to pass the URL where ChatPDF can find the PDF document
    you want to query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And here’s the actual code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: That URL in my sample code points to a real PDF document, by the way. It’s just
    some slides from a video course on [the LPI Security Essentials certification](complete-lpi-security-essentials-exam-study-guide.html)
    that I recently published. Since, however, that document doesn’t have all that
    much text in it, you might want to substitute it for your own PDF.
  prefs: []
  type: TYPE_NORMAL
- en: You could also have run that command as a single line, but formatting it over
    multiple lines makes it much easier to read. In Bash shell sessions, make sure
    that the `\` backslash at the end of each line (which tells the interpreter that
    the command continues on to the next line) is the last character on that line.
    Even an invisible space character will mess everything up.
  prefs: []
  type: TYPE_NORMAL
- en: If that command is successful, it’ll return a `sourceID` value, which is the
    session identifier you’ll use going forward when you want to query your PDF. You’ll
    paste that identifier into the second `curl` command. In this example, we use
    the `-d` argument to send a question ("What is the main topic of this document?")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the response I got back:'
  prefs: []
  type: TYPE_NORMAL
- en: Response
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '{"content":"The main topic of this document is not specified on the given pages.
    However, based on the topics listed on page 50, it appears to be related to networking
    protocols, routing, risk categories, and best practices."}'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a more complex example based on something I myself did recently.
  prefs: []
  type: TYPE_NORMAL
- en: It was all about solving a long-standing personal problem that’s caused me suffering
    for three decades now. You see, I’ve always hated having to come up with assessment
    questions. This was true during those years when I taught high school, and it’s
    even more true now.
  prefs: []
  type: TYPE_NORMAL
- en: AI to the rescue! Why not convert the transcript for the new video course I’m
    creating to a single PDF document and see what ChatPDF has to say about it?
  prefs: []
  type: TYPE_NORMAL
- en: Consider it done. I seeded ChatPDF with that new PDF document exactly the way
    I showed you earlier. But the request will be a bit more complicated. You see,
    I need to make sure that I get assessment questions that address all the course
    topics, and that they comply with some basic formatting needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll have to create a Bash script that will send the ChatPDF API individual
    prompts for *each* set of course topics and then append the output to a file.
    This diagram should help you visualize what we’re doing here:'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 Process for feeding the ChatPDF API with unique, topic-informed requests
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![gai 5 3](images/gai-5-3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To solve the first problem, I created a single text file containing a list
    of all the course topics with about four or five topics per line. I then created
    a Bash script that would expect to be run with the name of that text file as the
    single argument. Running the script from the command line would look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now here’s the script itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Let’s break that down into steps. Since the `curl` command is so complicated,
    the script will iterate through all the lines of the text file as part of a `while`
    loop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: For each iteration, it will execute our `curl` command within a `heredoc` format
    (`$(cat <<EOF…​`).
  prefs: []
  type: TYPE_NORMAL
- en: The `content` argument within the `curl` command lays out how I’d like the assessments
    formatted by ChatPDF.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: By the way, I didn’t include the actual URL for the PDF - you’ll just have to
    pay for the course yourself!
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the script will append (`>> multi_select_raw`) the assessments that
    come back with each iteration to a file called `multi_select_raw`. The output
    came in JSON format which required a bit of manipulation to get it into the shape
    I wanted. But I guess that’s why they pay me the big bucks.
  prefs: []
  type: TYPE_NORMAL
- en: Come to think of it, I could probably have used GPT in one form or another to
    do the formatting for me. See if you can figure that out for yourself
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'You’re not limited to the context provided within short chat prompts: use tools
    like llama_index and ChatPDF (including its API) to train LLMs on as much source
    material as you need to get informed responses to your requests.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Connecting your AI to the internet (Auto-GPT)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our final stop in this chapter will be the big, bad internet itself. That’s
    right. We’re going to find out whether GPT is better at wasting valuable time
    watching cute kitten videos than we are. Also, we’ll see whether giving a very
    smart GAI access to all the world’s knowledge can deliver something valuable in
    return.
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to use the madly popular Auto-GPT project’s Python code - provided
    through a [GitHub account](Significant-Gravitas.html) called `Significant-Gravitas`.
  prefs: []
  type: TYPE_NORMAL
- en: 'NOTE:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '**Git**, in case you haven’t yet been formally introduced, is a decentralized
    version control system that tracks changes to files in software projects. It allows
    multiple developers to collaborate, work on different features simultaneously,
    and merge their changes seamlessly. It provides a complete history of the project,
    facilitates code reviews, and enables efficient collaboration in both small and
    large-scale software development projects. **GitHub** is a web-based platform
    for version control and collaboration, built on top of Git. It provides a centralized
    hub for hosting repositories, managing code, and facilitating collaboration among
    developers.'
  prefs: []
  type: TYPE_NORMAL
- en: In the unlikely event you don’t yet have Git installed, you can find [excellent
    guides](install-git.html) in many places.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once that’s behind you, run this `git clone` command to download and unpack
    the Auto-GPT software:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: For a minimal configuration that’ll be good enough for many operations, you’ll
    move into the `Auto-GPT` directory that the `git clone` command created and edit
    a hidden file called `.env.template`.
  prefs: []
  type: TYPE_NORMAL
- en: Look for a line in that file containing the text `OPENAI_API_KEY=`. Make sure
    that line is uncommented (i.e., that there’s no `#` at the start) and then add
    your OpenAI API key. Finally, change the name of the saved `.env.template` file
    to just `.env` (i.e., remove the `.template` extension).
  prefs: []
  type: TYPE_NORMAL
- en: With that, you’re all ready to go. Although there are many configuration settings
    you can play with to tweak performance. You’ll find configuration files in the
    root (`Auto-GPT`) directory and in the `autogpt` directory that’s below it. Keep
    in mind the details about settings like, for instance, `Temperature` that you
    already learned about in Chapter two (How We Control Generative Artificial Intelligence).
  prefs: []
  type: TYPE_NORMAL
- en: 'Launching AutoGPT can be as simple as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: But you might want to consult the `run.sh` or `run.bat` files in the `Auto-GPT`
    directory for alternatives. And, as always, the [official documentation](docs.agpt.co.html)
    is going to be helpful.
  prefs: []
  type: TYPE_NORMAL
- en: When AutoGPT launches, you’ll be asked whether you want to reload a previous
    session’s settings (which, if this is your first time using the program, would
    be the pre-set default), or whether you’d prefer to start something new. If you
    go with "new", you’ll be asked for an "AI Name", a description of the role you
    want this AI to play, and then up to five Goals. Sorry. That *was* true a few
    days ago. But stability and predictability aren’t attributes that get along well
    with AI, are they? Instead, just enter a single (detailed) prompt and you’re good
    to go.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve entered your goals, AutoGPT will head off to figure out how it should
    solve the problem and come back with its thinking and recommendations. AutoGPT
    is verbose. It’ll tell you what it thinks about the task you’ve given it, what
    potential problems it might face, and how it might be able to solve those problems.
    It’ll also present a multi-step plan of action. All those discussions will, by
    default, be saved to a JSON-formatted file in the `AutoGPT` directory called `auto-gpt.json`.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, it’ll wait for you to approve each new next step of its plan. Alternatively,
    although there is some risk involved, you can give it permission to perform, say,
    the next ten steps without asking permission by responding with something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: I should note that the process I’m going to describe did end up costing me around
    $3.00 in OpenAI API costs.
  prefs: []
  type: TYPE_NORMAL
- en: So let’s see what we can do here. I recently used the tool for some serious
    research for my business. I’ve been debating whether I should create a book and
    course covering the objectives for a relatively new technology certification.
    My doubts center around the question of whether there will be enough demand from
    students planning to earn the certification to make my new content useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'I asked AutoGPT to use the internet to rank the popularity of this particular
    certification against a couple of other older certs (whose value I’m in a better
    position to gauge). Here - in slightly modified form - is how I framed my request:'
  prefs: []
  type: TYPE_NORMAL
- en: '*AI Name: Assess popularity of […​] certifications Description: Assess the
    relative popularity of the […​] certifications to know which one might be the
    most profitable for a new certification study guide course Goal 1: Compare the
    popularity of following certification programs: […​]. Goal 2: Estimate the likely
    future demand for each of the certification programs among potential students.
    Goal 3: Estimate the likely demand for training programs (like Udemy courses,
    books) for each certification programs. Goal 4: Estimate each certification’s
    popularity using a scale of 0 - 100 and save the results to a local file. Goal
    5: Shut down.*'
  prefs: []
  type: TYPE_NORMAL
- en: After around four hours(!) of independently thinking, browsing, and searching,
    AutoGPT gave me a file that ranked three certifications - including the new one
    I’m considering - by scores between 0 and 100\. For context, I copied the enormous
    raw output it generated (there was nearly 200k of it) and converted it to a PDF.
    I then uploaded that PDF to ChatPDF to try to discover more about the methodology.
  prefs: []
  type: TYPE_NORMAL
- en: After all the dust had settled, I was actually impressed with the results. Based
    on AutoGPT’s in-process output, it seems to have leveraged a wide range of online
    resources, including social media discussions, Amazon reviews, and content nested
    deeply within the web sites of various related organizations. Those four hours
    did seem to stretch on, but I’m happy with what that bought me.
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, AutoGPT can sometimes lose its way. The most common (and frustrating)
    problem I’ve faced is its tendency to fail with the same futile operation over
    and over again. At this point, if the agent is just going round and round in circles,
    your best bet is to simply shut it down.
  prefs: []
  type: TYPE_NORMAL
- en: And while we’re on the subject of giving LLMs internet access, ChatGPT (using
    GPT-4) can, from time to time, be convinced to access live internet URLs. Although
    it’s been known to get cranky when it’s just not in the mood.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used the `GPTVectorStoreIndex` from LlamaIndex to get GPT to read amd analyze
    locally-hosted data - which can include CSV and PDF files (among others).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We used ChatPDF to assess and query our own PDF documents, both through the
    web interface and, programmatically, through the ChatPDF API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We used AutoGPT to created a GPT-fueled agent capable of searching the live
    internet for data of all kinds in order to answer complex sequences of questions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5.5 Try this for yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identify a PDF file containing, say, the many objectives for an IT-related certification
    program (something like the [AWS Certified Cloud Practitioner](docs-cloud-practitioner.html),
    perhaps).
  prefs: []
  type: TYPE_NORMAL
- en: Feed the PDF to both ChatPDF and LlamaIndex and ask for a detailed summary of
    the exam objectives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare the results you get.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask AutoGPT for a summary of that certification’s objectives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
