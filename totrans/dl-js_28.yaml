- en: B.2\. Basic tensor operations
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.2\.基础张量操作
- en: 'Tensors wouldn’t be of much use if we couldn’t perform operations on them.
    TensorFlow.js supports a large number of tensor operations. You can see a list
    of them, along with their documentation, at [https://js.tensorflow.org/api/latest](https://js.tensorflow.org/api/latest).
    Describing every single one of them would be tedious and redundant. Therefore,
    we will highlight some of the most frequently used operations as examples. Frequently
    used operations can be categorized into two types: unary and binary. A *unary*
    operation takes one tensor as input and returns a new tensor, while a *binary*
    operation takes two tensors as its inputs and returns a new tensor.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们无法在张量上执行操作，那么张量就不会有什么用处。TensorFlow.js支持大量的张量操作。您可以在 [https://js.tensorflow.org/api/latest](https://js.tensorflow.org/api/latest)
    查看它们的列表以及它们的文档。描述每一个操作都会很枯燥而冗余。因此，我们将突出一些常用的操作作为示例。常用操作可以分为两种类型：一元和二元。*一元运算*以一个张量作为输入并返回一个新张量，而*二元运算*以两个张量作为输入并返回一个新张量。
- en: B.2.1\. Unary operations
  id: totrans-2
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.2.1\.一元操作
- en: 'Let’s consider the operation of taking the negative of a tensor—that is, using
    the negative value of every element of the input tensor—and forming a new tensor
    of the same shape and dtype. This can be done with `tf.neg()`:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑将张量取反的操作——即使用每个输入张量元素的负值——并形成一个具有相同形状和数据类型的新张量。这可以使用 `tf.neg()` 完成：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Functional API vs. chaining API
  id: totrans-5
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 函数式API与链式API
- en: 'In the previous example, we invoked the function `tf.neg()` with the tensor
    `x` as the input argument. TensorFlow.js provides a more concise way to perform
    the mathematically equivalent operation: using the `neg()` method, which is a
    method of the tensor object itself, instead of a function under the `tf.*` namespace:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，我们使用张量`x`作为输入参数调用函数`tf.neg()`。TensorFlow.js提供了一种更简洁的执行数学等价操作的方法：使用张量对象本身的`neg()`方法，而不是`tf.*`命名空间下的函数：
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this simple example, the amount of saved typing due to the new API may not
    seem that impressive. However, in cases where a number of operations need to be
    applied one after another, the second API will show considerable advantages over
    the first one. For instance, consider a hypothetical algorithm in which you want
    to take the negative of `x`, calculate the reciprocal (1 divided by every element),
    and apply the `relu` activation function on it. This is the code it takes to implement
    the algorithm in the first API:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的例子中，由于新API的存在，由于键入次数较少而节省的打字量可能不会显得那么令人印象深刻。然而，在需要一个接一个地应用多个操作的情况下，第二个API将比第一个API表现出更大的优势。例如，考虑一个假设的算法，您想要将`x`取反，计算倒数（每个元素都被1除），并在上面应用`relu`激活函数。这是在第一个API中实现算法所需的代码：
- en: '[PRE2]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By contrast, in the second API, the implementing code looks like
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在第二个API中，实现代码如下：
- en: '[PRE3]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The second implementation outshines the first one in these aspects:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种实现在以下几个方面优于第一种实现：
- en: There are fewer characters, less typing, and hence a smaller chance of making
    mistakes.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符较少，输入更少，因此制造错误的机会更小。
- en: There is no need to balance the nested pairs of opening and closing parentheses
    (although most modern code editors will help you do this).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有必要平衡嵌套的开放和关闭括号（尽管大多数现代代码编辑器都会帮助您完成此操作）。
- en: More importantly, the order in which the methods appear in the code matches
    the order in which the underlying mathematical operations happen. (Notice that
    in the first implementation, the order is reversed.) This leads to better code
    readability in the second implementation.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更重要的是，方法出现在代码中的顺序与底层数学操作发生的顺序相匹配。（注意在第一种实现中，顺序被颠倒了。）这在第二种实现中会导致更好的代码可读性。
- en: We will refer to the first API as the *functional* API because it is based on
    calling functions under the `tf.*` namespace. The second API will be referred
    to as the *chaining* API, owing to the fact that operations appear in a sequence
    like a chain (as you can see in the previous example). Most operations in TensorFlow.js
    are accessible as both the functional version under the `tf.*` namespace and the
    chaining version as a method of tensor objects. You can choose between the two
    APIs based on your needs. Throughout this book, we use both APIs in different
    places, with a preference for the chaining API for cases that involve serial operations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第一个API称为*函数式*API，因为它基于在`tf.`命名空间下调用函数。第二个API将称为*链式*API，因为操作按照链式顺序出现（正如您在前面的示例中所看到的）。在TensorFlow.js中，大多数操作都可以作为`tf.*`命名空间下的函数版本和作为张量对象方法的链式版本来访问。您可以根据自己的需求选择这两个API。在本书中，我们在不同的地方同时使用这两个API，但对于涉及连续操作的情况，我们更偏向于使用链式API。
- en: Element-wise vs. reduction operations
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 元素级与约减操作
- en: The examples of unary operations we mentioned (`tf.neg()`, `tf.reciprocal()`,
    and `tf.relu()`) have the common property that the operation happens on individual
    elements of the input tensor independently. As a result, the returned tensor of
    such an operation preserves the shape of the input tensor. However, other unary
    operations in TensorFlow.js lead to a tensor shape smaller than the original one.
    What does “smaller” mean in the context of tensor shape? In some cases, it means
    a lower rank. For example, a unary operation may return a scalar (rank-0) tensor
    given a 3D (rank-3) tensor. In other cases, it means the size of a certain dimension
    is smaller than the original one. For instance, a unary operation may return a
    tensor of shape `[3, 1]` given an input of shape `[3, 20]`. Regardless of how
    the shape shrinks, these operations are referred to as *reduction operations*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到的一元操作的示例（`tf.neg()`、`tf.reciprocal()` 和 `tf.relu()`）具有一个共同特点，即操作独立地应用在输入张量的每个元素上。因此，这类操作返回的张量保留了输入张量的形状。然而，在
    TensorFlow.js 中，其他一元操作会导致张量形状比原来的更小。在张量形状的背景下，"更小" 是什么意思呢？在某些情况下，它表示较低的秩。例如，一元操作可能返回一个标量（秩为0的张量），而原来的张量是一个3D张量（秩为3）。在其他情况下，它表示某个维度的大小比原来的更小。例如，一元操作可能对一个形状为`[3,
    20]`的输入返回一个形状为`[3, 1]`的张量。无论形状如何收缩，这些操作都被称为*约减操作*。
- en: '`tf.mean()` is one of the most frequently used reduction operations. It appears
    as the `mean()` method of the `Tensor` class in the chaining API. When invoked
    without any additional arguments, it computes the arithmetic mean of all elements
    of the input tensor, regardless of its shape, and returns a scalar. Its usage
    in the chaining API looks like'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.mean()`是最常用的约减操作之一。在链式API中，它作为`Tensor`类的`mean()`方法出现。当没有附加参数时，它计算输入张量的所有元素的算术平均值，而无论其形状如何，并返回一个标量。在链式API中，使用它的方式如下所示：'
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Sometimes, we require the mean to be calculated separately over the rows of
    the 2D tensor (matrix) instead of over the whole tensor. This can be achieved
    by providing an additional argument to the `mean()` method:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们需要单独计算2D张量（矩阵）的每一行的均值，而不是整个张量上的均值。可以通过向`mean()`方法提供附加参数来实现：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The argument `-1` indicates that the `mean()` method should calculate the arithmetic
    means along the last dimension of the tensor.^([[4](#app02fn4)]) This dimension
    is referred to as the *reduction dimension*, as it will be “reduced away” in the
    output tensor, which becomes a rank-1 tensor. An alternative way to specify the
    reduction dimension is to use the actual index of the dimension:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参数`-1`表示`mean()`方法应该计算张量的最后一个维度的算术平均值。([[4](#app02fn4)]) 这个维度被称为*约减维度*，因为它将在输出张量中被“减少”，输出张量的秩变为1。指定约减维度的另一种方式是使用实际的维度索引：
- en: ⁴
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁴
- en: ''
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This follows the indexing convention of Python.
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这遵循了Python的索引约定。
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that `mean()` also supports multiple reduction dimensions. For example,
    if you have a 3D tensor of shape `[10, 6, 3]`, and you want the arithmetic mean
    to be calculated over the last two dimensions, yielding a 1D tensor of shape `[10]`,
    you can call `mean()` as `x.mean([-2, -1])` or `x.mean([1, 2])`. We leave this
    as an exercise at the end of this appendix.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`mean()`还支持多个约减维度。例如，如果您有一个形状为`[10, 6, 3]`的3D张量，并且希望计算其算术平均值在最后两个维度上进行计算，得到一个形状为`[10]`的1D张量，则可以调用`mean()`方法，如`x.mean([-2,
    -1])`或`x.mean([1, 2])`。我们在附录的最后给出这个方法作为一个练习。
- en: Other frequently used reduction unary operations include
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其他经常使用的约简一元操作包括
- en: '`tf.sum()`, which is almost identical to `tf.mean()`, but it computes the sum,
    instead of the arithmetic mean, over elements.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.sum()` 几乎与 `tf.mean()` 相同，但它计算的是和，而不是算术平均值，而是元素。'
- en: '`tf.norm()`, which computes the norm over elements. There are different kinds
    of norms. For example, a 1-norm is a sum of the absolute values of elements. A
    2-norm is calculated by taking the square root of the sum over the squared elements.
    In other words, it is the length of a vector in a Euclidean space. `tf.norm()`
    can be used to calculate the variance or the standard deviation of a list of numbers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.norm()`，用于计算元素的范数。有不同类型的范数。例如，1-范数是元素绝对值的总和。2-范数通过对平方元素求和然后取平方根来计算。换句话说，它是欧几里德空间中向量的长度。`tf.norm()`可用于计算一组数字的方差或标准差。'
- en: '`tf.min()` and `tf.max()`, which calculate the minimum and maximum value over
    elements, respectively.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.min()` 和 `tf.max()`，分别计算元素的最小值和最大值。'
- en: '`tf.argMax()`, which returns the index of the maximum element over a reduction
    axis. This operation is frequently used to convert the probability output of a
    classification mode into the winning class’s index (for example, see the iris-flower
    classification problem in [section 3.3.2](kindle_split_014.html#ch03lev2sec8)).
    `tf.argMin()` provides similar functionality for finding the minimum value.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.argMax()` 返回沿减少轴的最大元素的索引。此操作经常用于将分类模型的概率输出转换为获胜类别的索引（例如，请参阅[第3.3.2节](kindle_split_014.html#ch03lev2sec8)中的鸢尾花分类问题）。`tf.argMin()`
    提供了类似的功能以找到最小值。'
- en: We mentioned that element-wise operations preserve the shape of the input tensor.
    But the converse is not true. Some shape-preserving operations are not element-wise.
    For instance, the `tf.transpose()` operation can perform matrix transpose, in
    which the element at indices `[i, j]` in the input 2D tensor is mapped onto the
    indices `[j, i]` in the output 2D tensor. The input and output shapes of `tf.transpose()`
    will be identical if the input is a square matrix, but this is not an element-wise
    operation, as the value at `[i, j]` of the output tensor does not depend only
    on the value at `[i, j]` in the input tensor, but instead depends on values at
    other indices.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到逐元素操作保留输入张量的形状。但反之不成立。有些保持形状的操作不是逐元素的。例如，`tf.transpose()` 操作可以执行矩阵转置，其中输入2D张量中的索引
    `[i, j]` 的元素被映射到输出2D张量中的索引 `[j, i]`。如果输入是一个方阵，`tf.transpose()` 的输入和输出形状将相同，但这不是一个逐元素操作，因为输出张量中
    `[i, j]` 处的值不仅取决于输入张量中 `[i, j]` 处的值，而是取决于其他索引处的值。
- en: B.2.2\. Binary operations
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.2.2\. 二元操作
- en: Unlike unary operations, a binary operation requires two input arguments. `tf.add()`
    is perhaps the most frequently used binary operation. It is perhaps also the simplest,
    as it simply adds two tensors together. For example,
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与一元操作不同，二元操作需要两个输入参数。`tf.add()` 可能是最常用的二元操作。它可能也是最简单的，因为它只是简单地将两个张量相加。例如，
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Similar binary operations include
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的二元操作包括
- en: '`tf.sub()` for subtracting two tensors'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.sub()` 用于两个张量的减法'
- en: '`tf.mul()` for multiplying two tensors'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.mul()` 用于两个张量的乘法'
- en: '`tf.matMul()` for computing the matrix product between two tensors'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.matMul()` 用于计算两个张量之间的矩阵积'
- en: '`tf.logicalAnd()`, `tf.logicalOr()`, and `tf.logicaXor()` for performing AND,
    OR, and XOR operations on bool-type tensors, respectively.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.logicalAnd()`、`tf.logicalOr()` 和 `tf.logicalXor()` 用于在布尔类型张量上执行 AND、OR
    和 XOR 操作。'
- en: Some binary operations support *broadcasting*, or operating on two input tensors
    of different shapes and applying an element in the input of a smaller shape over
    multiple elements in the other input according to a certain rule. See [info box
    2.4](kindle_split_013.html#ch02sb04) in [chapter 2](kindle_split_013.html#ch02)
    for a detailed discussion.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一些二元操作支持 *广播*，或者对不同形状的两个输入张量进行操作，并根据某种规则将较小形状的输入元素应用于另一个输入的多个元素。详细讨论请参阅[信息框2.4](kindle_split_013.html#ch02sb04)中的[第2章](kindle_split_013.html#ch02)。
- en: B.2.3\. Concatenation and slicing of tensors
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.2.3\. 张量的拼接和切片
- en: 'Unary and binary operations are tensor-in-tensor-out (TITO), in the sense that
    they take one or more tensors as the input and return a tensor as the output.
    Some frequently used operations in TensorFlow.js are not TITO because they take
    a tensor, along with another nontensor argument, as their inputs. `tf.concat()`
    is perhaps the most frequently used function in this category. It allows you to
    concatenate multiple tensors of compatible shape into a single tensor. Concatenation
    is possible only if the shape of the tensors satisfies certain constraints. For
    example, it is possible to combine a `[5, 3]` tensor and a `[4, 3]` tensor along
    the first axis to get a `[9, 3]` tensor, but it isn’t possible to combine the
    tensors if their shapes are `[5, 3]` and `[4, 2]`! Given shape compatibility,
    you can use the `tf.concat()` function to concatenate tensors. For example, the
    following code concatenates an all-zero `[2, 2]` tensor with an all-one `[2, 2]`
    tensor along the first axis, which gives a `[4, 2]` tensor in which the “top”
    half is all-zero and the “bottom” half is all-one:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一元和二元操作是张量输入张量输出（TITO）的，它们以一个或多个张量作为输入，并返回一个张量作为输出。 TensorFlow.js 中的一些常用操作不是
    TITO，因为它们将张量与另一个非张量参数一起作为输入。`tf.concat()`可能是这类函数中最常用的函数。它允许你将多个形状兼容的张量连接成一个单一的张量。只有当张量的形状满足某些约束条件时才能进行连接。例如，可以将`[5,
    3]`张量和`[4, 3]`张量沿第一个轴合并以得到`[9, 3]`张量，但如果它们的形状分别为`[5, 3]`和`[4, 2]`，则无法将它们组合在一起！在给定的形状合法性的情况下，你可以使用`tf.concat()`函数来连接张量。例如，以下代码沿第一个轴连接一个全零`[2,
    2]`张量和一个全一`[2, 2]`张量，则得到一个`[4, 2]`张量，其中“顶部”是全零，而“底部”则是全一：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Because the shapes of the two input tensors are identical, it is possible to
    concatenate them differently: that is, along the second axis. The axis can be
    specified as the second input argument to `tf.concat()`. This will give us a `[2,
    4]` tensor in which the left half is all-zero and the right half is all-one:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个输入张量的形状相同，可以以不同的方式对它们进行连接：即沿第二个轴进行连接。轴可以作为第二个输入参数传递给`tf.concat()`。这将给我们一个`[2,
    4]`张量，在这个张量中，左半部分都是零，右半部分都是一：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Apart from concatenating multiple tensors into one, sometimes we want to perform
    the “reverse” operation, retrieving a part of a tensor. For example, suppose you
    have created a 2D tensor (matrix) of shape `[3, 2]`,
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将多个张量连接成一个以外，有时我们希望执行“反向”操作，检索张量的一部分。例如，假设你创建了一个形状为`[3, 2]`的二维张量（矩阵），
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'and you would like to get the second row of the matrix. For that, you can use
    the chaining version of `tf.slice()`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 而你想要获取矩阵的第二行。为此，可以使用`tf.slice()`的链式版本：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The first argument to `slice()` indicates that the part of the input tensor
    we want starts at index 1 along the first dimension and index 0 of the second
    dimension. In other words, it should start from the second row and the first column,
    since the 2D tensor we are dealing with here is a matrix. The second argument
    specifies the shape of the desired output: `[1, 2]` or, in matrix language, 1
    row and 2 columns.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`slice()`的第一个参数指示我们想要的输入张量部分从第一个维度的索引1和第二个维度的索引0开始。换句话说，它应该从第二行和第一列开始，因为我们在这里处理的二维张量是一个矩阵。第二个参数指定所需输出的形状：`[1,
    2]`或在矩阵语言中，1行2列。'
- en: 'As you can verify by looking at the printed values, we have successfully retrieved
    the second row of the 3 × 2 matrix. The shape of the output has the same rank
    as the input (2), but the size of the first dimension is 1\. In this case, we
    are retrieving the entirety of the second dimension (all columns) and a subset
    of the first dimension (a subset of the rows). This is a special case that allows
    us to achieve the same effect with a simpler syntax:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所看到的，通过查看打印的值，我们成功地检索了3×2矩阵的第二行。输出的形状与输入的秩相同（2），但第一个维度的大小为1。在这种情况下，我们检索第二个维度的全部（所有列）和第一个维度的子集（行的一部分）。这是一种特殊情况，可以使用更简单的语法实现相同的效果：
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this simpler syntax, we just need to specify the starting index and the
    size of the requested chunk along the first dimension. If 2 is passed instead
    of 1 as the second input argument, the output will contain the second and third
    rows of the matrix:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更简单的语法中，我们只需要指定请求的块沿第一个维度的起始索引和大小。如果将第二个输入参数传递为1而不是2，则输出将包含矩阵的第一行和第二行：
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you may have guessed, this simpler syntax is related to the batching convention.
    It makes it easier to get the data for individual examples out of a batched tensor.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能猜到的那样，这种更简单的语法与批处理约定有关。它使得从批处理张量中获取单个示例的数据更容易。
- en: But what if we want to access *columns* of the matrix instead of rows? In this
    case, we would have to use the more complex syntax. For example, suppose we want
    the second column of the matrix. It can be achieved by
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们想要访问矩阵的 *列* 呢？在这种情况下，我们将不得不使用更复杂的语法。例如，假设我们想要矩阵的第二列。可以通过以下方式实现
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, the first argument (`[0, 1]`) is an array representing the beginning indices
    of the slice we want. It is the first index along the first dimension and the
    second index along the second dimension. Put more simply, we want our slice to
    begin at the first row and the second column. The second argument (`[-1, 1]`)
    specifies the size of the slice we want. The first number (–1) indicates that
    we want all indices along the first dimension (we want all rows starting), while
    the second number (1) means we want only one index along the second dimension
    (we want only one column). The result is the second column of the matrix.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，第一个参数（`[0, 1]`）是表示我们想要的切片的起始索引的数组。它是沿第一维的第一个索引和第二维的第二个索引。更简单地说，我们希望我们的切片从第一行和第二列开始。第二个参数（`[-1,
    1]`）指定了我们想要的切片的大小。第一个数字（-1）表示我们想要沿第一维的所有索引（我们想要所有起始行），而第二个数字（1）表示我们只想要沿第二维的一个索引（我们只想要一列）。结果是矩阵的第二列。
- en: Looking at the syntax of `slice()`, you may have realized that `slice()` is
    not limited to retrieving just rows or columns. In fact, it is flexible enough
    to let you retrieve any “submatrix” of the input 2D tensor (any consecutive rectangular
    area within the matrix), if the beginning indices and size array are specified
    properly. More generally, for tensors of any rank greater than 0, `slice()` allows
    you to retrieve any consecutive subtensor of the same rank inside the input tensor.
    We leave this as an exercise for you at the end of this appendix.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下 `slice()` 的语法，你可能已经意识到 `slice()` 不仅限于检索行或列。事实上，如果开始索引和大小数组被正确指定，它足够灵活，可以让你检索输入二维张量中的任何“子矩阵”（矩阵内的任何连续矩形区域）。更一般地，对于秩大于
    0 的张量，`slice()` 允许你检索输入张量中的任何连续子张量。我们将这留作附录末尾的练习。
- en: 'Apart from `tf.slice()` and `tf.concat()`, two other frequently used operations
    that split a tensor into parts or combine multiple tensors into one are `tf.unstack()`
    and `tf.stack()`. `tf.unstack()` splits a tensor into multiple “pieces” along
    the first dimension. Each of those pieces has a size of 1 along the first dimension.
    For example, we can use the chaining API of `tf.unstack()`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `tf.slice()` 和 `tf.concat()`，另外两个经常用于将张量分割成部分或将多个张量合并成一个的操作是 `tf.unstack()`
    和 `tf.stack()`。 `tf.unstack()` 将张量沿着第一维分割成多个“pieces”。每个片段在第一维上的尺寸为 1。例如，我们可以使用
    `tf.unstack()` 的链式 API：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can notice, the “pieces” returned by `unstack()` have a rank one less
    than that of the input tensor.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，`unstack()` 返回的“pieces”比输入张量的秩少一。
- en: '`tf.stack()` is the reverse of `tf.unstack()`. As its name suggests, it “stacks”
    a number of tensors with identical shapes into a new tensor. Following the prior
    example code snippet, we stack the pieces back together:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.stack()` 是 `tf.unstack()` 的反向操作。顾名思义，它将具有相同形状的多个张量“堆叠”到一个新张量中。根据先前的示例代码片段，我们将片段重新堆叠在一起：'
- en: '[PRE16]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`tf.unstack()` is useful for getting the data corresponding to individual examples
    from a batched tensor; `tf.stack()` is useful for combining the data for individual
    examples into a batched tensor.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.unstack()` 用于从批处理张量中获取与各个示例对应的数据；`tf.stack()` 用于将各个示例的数据合并成一个批处理张量。'
