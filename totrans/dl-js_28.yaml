- en: B.2\. Basic tensor operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Tensors wouldn’t be of much use if we couldn’t perform operations on them.
    TensorFlow.js supports a large number of tensor operations. You can see a list
    of them, along with their documentation, at [https://js.tensorflow.org/api/latest](https://js.tensorflow.org/api/latest).
    Describing every single one of them would be tedious and redundant. Therefore,
    we will highlight some of the most frequently used operations as examples. Frequently
    used operations can be categorized into two types: unary and binary. A *unary*
    operation takes one tensor as input and returns a new tensor, while a *binary*
    operation takes two tensors as its inputs and returns a new tensor.'
  prefs: []
  type: TYPE_NORMAL
- en: B.2.1\. Unary operations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s consider the operation of taking the negative of a tensor—that is, using
    the negative value of every element of the input tensor—and forming a new tensor
    of the same shape and dtype. This can be done with `tf.neg()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Functional API vs. chaining API
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In the previous example, we invoked the function `tf.neg()` with the tensor
    `x` as the input argument. TensorFlow.js provides a more concise way to perform
    the mathematically equivalent operation: using the `neg()` method, which is a
    method of the tensor object itself, instead of a function under the `tf.*` namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple example, the amount of saved typing due to the new API may not
    seem that impressive. However, in cases where a number of operations need to be
    applied one after another, the second API will show considerable advantages over
    the first one. For instance, consider a hypothetical algorithm in which you want
    to take the negative of `x`, calculate the reciprocal (1 divided by every element),
    and apply the `relu` activation function on it. This is the code it takes to implement
    the algorithm in the first API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: By contrast, in the second API, the implementing code looks like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The second implementation outshines the first one in these aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: There are fewer characters, less typing, and hence a smaller chance of making
    mistakes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no need to balance the nested pairs of opening and closing parentheses
    (although most modern code editors will help you do this).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More importantly, the order in which the methods appear in the code matches
    the order in which the underlying mathematical operations happen. (Notice that
    in the first implementation, the order is reversed.) This leads to better code
    readability in the second implementation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will refer to the first API as the *functional* API because it is based on
    calling functions under the `tf.*` namespace. The second API will be referred
    to as the *chaining* API, owing to the fact that operations appear in a sequence
    like a chain (as you can see in the previous example). Most operations in TensorFlow.js
    are accessible as both the functional version under the `tf.*` namespace and the
    chaining version as a method of tensor objects. You can choose between the two
    APIs based on your needs. Throughout this book, we use both APIs in different
    places, with a preference for the chaining API for cases that involve serial operations.
  prefs: []
  type: TYPE_NORMAL
- en: Element-wise vs. reduction operations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The examples of unary operations we mentioned (`tf.neg()`, `tf.reciprocal()`,
    and `tf.relu()`) have the common property that the operation happens on individual
    elements of the input tensor independently. As a result, the returned tensor of
    such an operation preserves the shape of the input tensor. However, other unary
    operations in TensorFlow.js lead to a tensor shape smaller than the original one.
    What does “smaller” mean in the context of tensor shape? In some cases, it means
    a lower rank. For example, a unary operation may return a scalar (rank-0) tensor
    given a 3D (rank-3) tensor. In other cases, it means the size of a certain dimension
    is smaller than the original one. For instance, a unary operation may return a
    tensor of shape `[3, 1]` given an input of shape `[3, 20]`. Regardless of how
    the shape shrinks, these operations are referred to as *reduction operations*.
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.mean()` is one of the most frequently used reduction operations. It appears
    as the `mean()` method of the `Tensor` class in the chaining API. When invoked
    without any additional arguments, it computes the arithmetic mean of all elements
    of the input tensor, regardless of its shape, and returns a scalar. Its usage
    in the chaining API looks like'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes, we require the mean to be calculated separately over the rows of
    the 2D tensor (matrix) instead of over the whole tensor. This can be achieved
    by providing an additional argument to the `mean()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The argument `-1` indicates that the `mean()` method should calculate the arithmetic
    means along the last dimension of the tensor.^([[4](#app02fn4)]) This dimension
    is referred to as the *reduction dimension*, as it will be “reduced away” in the
    output tensor, which becomes a rank-1 tensor. An alternative way to specify the
    reduction dimension is to use the actual index of the dimension:'
  prefs: []
  type: TYPE_NORMAL
- en: ⁴
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This follows the indexing convention of Python.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note that `mean()` also supports multiple reduction dimensions. For example,
    if you have a 3D tensor of shape `[10, 6, 3]`, and you want the arithmetic mean
    to be calculated over the last two dimensions, yielding a 1D tensor of shape `[10]`,
    you can call `mean()` as `x.mean([-2, -1])` or `x.mean([1, 2])`. We leave this
    as an exercise at the end of this appendix.
  prefs: []
  type: TYPE_NORMAL
- en: Other frequently used reduction unary operations include
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.sum()`, which is almost identical to `tf.mean()`, but it computes the sum,
    instead of the arithmetic mean, over elements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.norm()`, which computes the norm over elements. There are different kinds
    of norms. For example, a 1-norm is a sum of the absolute values of elements. A
    2-norm is calculated by taking the square root of the sum over the squared elements.
    In other words, it is the length of a vector in a Euclidean space. `tf.norm()`
    can be used to calculate the variance or the standard deviation of a list of numbers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.min()` and `tf.max()`, which calculate the minimum and maximum value over
    elements, respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.argMax()`, which returns the index of the maximum element over a reduction
    axis. This operation is frequently used to convert the probability output of a
    classification mode into the winning class’s index (for example, see the iris-flower
    classification problem in [section 3.3.2](kindle_split_014.html#ch03lev2sec8)).
    `tf.argMin()` provides similar functionality for finding the minimum value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We mentioned that element-wise operations preserve the shape of the input tensor.
    But the converse is not true. Some shape-preserving operations are not element-wise.
    For instance, the `tf.transpose()` operation can perform matrix transpose, in
    which the element at indices `[i, j]` in the input 2D tensor is mapped onto the
    indices `[j, i]` in the output 2D tensor. The input and output shapes of `tf.transpose()`
    will be identical if the input is a square matrix, but this is not an element-wise
    operation, as the value at `[i, j]` of the output tensor does not depend only
    on the value at `[i, j]` in the input tensor, but instead depends on values at
    other indices.
  prefs: []
  type: TYPE_NORMAL
- en: B.2.2\. Binary operations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Unlike unary operations, a binary operation requires two input arguments. `tf.add()`
    is perhaps the most frequently used binary operation. It is perhaps also the simplest,
    as it simply adds two tensors together. For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Similar binary operations include
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.sub()` for subtracting two tensors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.mul()` for multiplying two tensors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.matMul()` for computing the matrix product between two tensors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tf.logicalAnd()`, `tf.logicalOr()`, and `tf.logicaXor()` for performing AND,
    OR, and XOR operations on bool-type tensors, respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some binary operations support *broadcasting*, or operating on two input tensors
    of different shapes and applying an element in the input of a smaller shape over
    multiple elements in the other input according to a certain rule. See [info box
    2.4](kindle_split_013.html#ch02sb04) in [chapter 2](kindle_split_013.html#ch02)
    for a detailed discussion.
  prefs: []
  type: TYPE_NORMAL
- en: B.2.3\. Concatenation and slicing of tensors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Unary and binary operations are tensor-in-tensor-out (TITO), in the sense that
    they take one or more tensors as the input and return a tensor as the output.
    Some frequently used operations in TensorFlow.js are not TITO because they take
    a tensor, along with another nontensor argument, as their inputs. `tf.concat()`
    is perhaps the most frequently used function in this category. It allows you to
    concatenate multiple tensors of compatible shape into a single tensor. Concatenation
    is possible only if the shape of the tensors satisfies certain constraints. For
    example, it is possible to combine a `[5, 3]` tensor and a `[4, 3]` tensor along
    the first axis to get a `[9, 3]` tensor, but it isn’t possible to combine the
    tensors if their shapes are `[5, 3]` and `[4, 2]`! Given shape compatibility,
    you can use the `tf.concat()` function to concatenate tensors. For example, the
    following code concatenates an all-zero `[2, 2]` tensor with an all-one `[2, 2]`
    tensor along the first axis, which gives a `[4, 2]` tensor in which the “top”
    half is all-zero and the “bottom” half is all-one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the shapes of the two input tensors are identical, it is possible to
    concatenate them differently: that is, along the second axis. The axis can be
    specified as the second input argument to `tf.concat()`. This will give us a `[2,
    4]` tensor in which the left half is all-zero and the right half is all-one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Apart from concatenating multiple tensors into one, sometimes we want to perform
    the “reverse” operation, retrieving a part of a tensor. For example, suppose you
    have created a 2D tensor (matrix) of shape `[3, 2]`,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'and you would like to get the second row of the matrix. For that, you can use
    the chaining version of `tf.slice()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The first argument to `slice()` indicates that the part of the input tensor
    we want starts at index 1 along the first dimension and index 0 of the second
    dimension. In other words, it should start from the second row and the first column,
    since the 2D tensor we are dealing with here is a matrix. The second argument
    specifies the shape of the desired output: `[1, 2]` or, in matrix language, 1
    row and 2 columns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can verify by looking at the printed values, we have successfully retrieved
    the second row of the 3 × 2 matrix. The shape of the output has the same rank
    as the input (2), but the size of the first dimension is 1\. In this case, we
    are retrieving the entirety of the second dimension (all columns) and a subset
    of the first dimension (a subset of the rows). This is a special case that allows
    us to achieve the same effect with a simpler syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simpler syntax, we just need to specify the starting index and the
    size of the requested chunk along the first dimension. If 2 is passed instead
    of 1 as the second input argument, the output will contain the second and third
    rows of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As you may have guessed, this simpler syntax is related to the batching convention.
    It makes it easier to get the data for individual examples out of a batched tensor.
  prefs: []
  type: TYPE_NORMAL
- en: But what if we want to access *columns* of the matrix instead of rows? In this
    case, we would have to use the more complex syntax. For example, suppose we want
    the second column of the matrix. It can be achieved by
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, the first argument (`[0, 1]`) is an array representing the beginning indices
    of the slice we want. It is the first index along the first dimension and the
    second index along the second dimension. Put more simply, we want our slice to
    begin at the first row and the second column. The second argument (`[-1, 1]`)
    specifies the size of the slice we want. The first number (–1) indicates that
    we want all indices along the first dimension (we want all rows starting), while
    the second number (1) means we want only one index along the second dimension
    (we want only one column). The result is the second column of the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the syntax of `slice()`, you may have realized that `slice()` is
    not limited to retrieving just rows or columns. In fact, it is flexible enough
    to let you retrieve any “submatrix” of the input 2D tensor (any consecutive rectangular
    area within the matrix), if the beginning indices and size array are specified
    properly. More generally, for tensors of any rank greater than 0, `slice()` allows
    you to retrieve any consecutive subtensor of the same rank inside the input tensor.
    We leave this as an exercise for you at the end of this appendix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from `tf.slice()` and `tf.concat()`, two other frequently used operations
    that split a tensor into parts or combine multiple tensors into one are `tf.unstack()`
    and `tf.stack()`. `tf.unstack()` splits a tensor into multiple “pieces” along
    the first dimension. Each of those pieces has a size of 1 along the first dimension.
    For example, we can use the chaining API of `tf.unstack()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can notice, the “pieces” returned by `unstack()` have a rank one less
    than that of the input tensor.
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.stack()` is the reverse of `tf.unstack()`. As its name suggests, it “stacks”
    a number of tensors with identical shapes into a new tensor. Following the prior
    example code snippet, we stack the pieces back together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`tf.unstack()` is useful for getting the data corresponding to individual examples
    from a batched tensor; `tf.stack()` is useful for combining the data for individual
    examples into a batched tensor.'
  prefs: []
  type: TYPE_NORMAL
