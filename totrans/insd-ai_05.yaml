- en: 5 Generative AI and large language models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 生成人工智能和大型语言模型
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章包括
- en: Generative artificial intelligence
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成人工智能
- en: Reflections on human communication and speech
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对人类沟通与语音的思考
- en: The benefits, limitations, and risks of generative AI and large language models
    such as ChatGPT
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成人工智能和ChatGPT等大型语言模型的优点、局限性和风险
- en: Differences between human and generative AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类与生成人工智能之间的差异
- en: Artificial intelligence has witnessed numerous ups and downs, but the release
    of ChatGPT represents a pivotal moment in the field of AI for several compelling
    reasons. First, it signifies a significant leap forward in natural language understanding
    and generation, demonstrating the remarkable progress AI has made in processing
    and generating human-like text. ChatGPT’s ability to engage in coherent and contextually
    relevant conversations with users across a wide range of topics showcases the
    potential for AI to be integrated into various applications, from customer support
    to content creation. Furthermore, ChatGPT embodies the power of large-scale pretrained
    models. Its capabilities highlight the potential for AI to augment human endeavors,
    improving efficiency and offering valuable insights across industries.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能经历了许多起伏，但ChatGPT的发布代表了人工智能领域的一个关键时刻，有几个引人注目的原因。首先，它标志着自然语言理解和生成的重大进步，展示了人工智能在处理和生成类似人类文本方面取得的显著进步。ChatGPT能够与用户就各种话题进行连贯而相关的对话，展示了人工智能被整合到各种应用中的潜力，从客户支持到内容创作。此外，ChatGPT体现了大规模预训练模型的力量。其能力突显了人工智能增强人类努力的潜力，提高效率并为各行各业提供宝贵的见解。
- en: Additionally, ChatGPT is the first product that led to democratizing the use
    of AI by providing a user-friendly interface that enables people without extensive
    technical expertise to harness the benefits of AI and integrate it into their
    work and daily lives. This democratization of AI usage fosters innovation, creativity,
    and collaboration across diverse fields and industries.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，ChatGPT还是第一个通过提供用户友好界面而使人工智能使用民主化的产品，使不具备广泛技术专业知识的人能够利用人工智能的好处并将其整合到他们的工作和日常生活中。这种人工智能使用的民主化促进了创新、创造力和跨领域、跨行业的合作。
- en: In this chapter, we will introduce generative AI, a remarkable technology that
    offers a multitude of benefits across various domains and holds great potential
    for revolutionizing many industries. We will also examine its limitations and
    the potential risks associated with its use.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍生成人工智能，这是一种卓越的技术，在各个领域都提供了许多好处，并且具有彻底改变许多行业的巨大潜力。我们还将检查其局限性以及与其使用相关的潜在风险。
- en: 5.1 Generative artificial intelligence
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 生成人工智能
- en: Generative AI represents a cutting-edge branch of AI that uses deep learning
    algorithms on extensive datasets. Its primary function is to create entirely new
    content across various mediums, ranging from textual narratives to realistic images,
    audio, and even lifelike video. What distinguishes generative AI is its remarkable
    capacity to produce outputs of astonishing realism, often blurring the lines between
    machine-generated and human creativity. This remarkable success is achieved by
    the AI system through a process of learning and discerning patterns within existing
    data and extrapolating them to produce novel and distinctive creations. This innovation
    has its roots in the long-standing use of generative models within statistical
    frameworks, primarily employed for the exploration of numerical data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 生成人工智能代表着人工智能的前沿分支，它利用深度学习算法在广泛的数据集上。其主要功能是在各种媒介上创建全新的内容，从文本叙事到逼真的图像、音频，甚至逼真的视频。生成人工智能的区别在于其出色的产出能力，常常模糊了机器生成和人类创造力之间的界限。这一显著的成功是通过人工智能系统学习和识别现有数据中的模式，并推断出产生新颖而独特的创作。这一创新根植于统计框架中长期使用的生成模型，主要用于对数值数据的探索。
- en: However, the true transformative leap occurred with the advent of deep learning,
    enabling its applications to extend well beyond numbers and into images, speech,
    and other unstructured data types. One of the most impressive facets of generative
    AI is its adaptability. It can be trained to mimic the style of a specific artist,
    write in the voice of a particular author, or generate music reminiscent of a
    favorite composer. These models have found applications in a wide range of domains,
    from art and entertainment to natural language processing (NLP) and numerous other
    fields.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，真正的变革性飞跃发生在深度学习的出现时，使其应用范围远远超出数字，扩展到图像、语音和其他非结构化数据类型。生成式人工智能最令人印象深刻的一面之一是其适应性。它可以被训练成模仿特定艺术家的风格，以某位特定作者的语调写作，或者生成类似于喜爱的作曲家的音乐。这些模型已经在从艺术和娱乐到自然语言处理（NLP）和许多其他领域的广泛应用中找到了应用。
- en: 5.2 Large language models
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 大型语言模型
- en: Large language models (LLMs) comprise a subset of generative AI designed to
    understand and generate human-like text. These models are characterized by their
    immense scale, with billions of parameters, which act as their knowledge base
    for language understanding and generation. LLMs undergo a two-step training process,
    starting with pretraining, where they learn the fundamentals of language, including
    grammar, syntax, and semantics by analyzing vast amounts of text data from the
    internet. Afterward, they are fine-tuned on specific tasks to tailor their language
    skills for specific applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是生成式人工智能的一个子集，旨在理解和生成类似人类的文本。这些模型以其庞大的规模而闻名，拥有数十亿个参数，这些参数充当了它们的语言理解和生成的知识库。LLMs经历了一个两步训练过程，首先是预训练，在这一步中，它们通过分析来自互联网的大量文本数据学习语言的基础知识，包括语法、句法和语义。之后，它们被针对特定任务进行微调，以定制其语言技能以适用于特定应用场景。
- en: One prominent capability of LLMs is text generation. These models can produce
    human-like text in various forms, from articles and essays to creative works like
    poetry. For instance, LLMs can generate poetry that rhymes and evokes emotions,
    showcasing their creative potential. They excel in producing text that reads convincingly
    as if written by a human, making them valuable for content creation and storytelling.
    Additionally, LLMs are adept at language translation and text summarization. They
    can accurately translate text from one language to another, breaking down language
    barriers and facilitating global communication. Moreover, LLMs can summarize lengthy
    documents, a skill particularly useful in tasks such as news article summarization,
    enabling readers to quickly grasp the key points of a story. They can also provide
    coding assistance by generating code snippets in various programming languages,
    simplifying coding tasks. For example, an LLM can generate Python code to perform
    specific operations, enhancing efficiency and productivity. Furthermore, these
    models can answer questions using the knowledge they gained during training, responding
    accurately to factual queries or complex questions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的一个显著能力是文本生成。这些模型可以以各种形式生成类似人类的文本，从文章和论文到诗歌等创意作品。例如，LLMs可以生成押韵并引起情感共鸣的诗歌，展示了它们的创造潜力。它们擅长生成看起来像人类写作的文本，使它们在内容创作和讲故事方面非常有价值。此外，LLMs擅长语言翻译和文本摘要。它们可以准确地将文本从一种语言翻译成另一种语言，打破语言障碍，促进全球交流。此外，LLMs还可以总结冗长的文档，这在新闻文章摘要等任务中特别有用，使读者能够快速了解故事的要点。它们还可以通过生成各种编程语言的代码片段来提供编码帮助，简化编码任务。例如，LLM可以生成Python代码来执行特定操作，提高效率和生产率。此外，这些模型可以利用它们在训练过程中获得的知识来回答问题，对事实查询或复杂问题做出准确回应。
- en: The pivotal moment of large language models happened when OpenAI introduced
    GPT-3 to select partners and developers in June 2020, followed by broader availability
    to the public in November 2022\. This release generated significant excitement
    on the internet because of GPT-3’s remarkable ability to mimic human-like conversation.
    GPT-3 was a computational powerhouse, boasting an impressive 175 billion parameters.
    It had undergone extensive training on a diverse dataset sourced from various
    online resources. The model’s proficiency in engaging in coherent, context-aware
    conversations made it appear exceptionally intelligent.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型的关键时刻是当 OpenAI 在 2020 年 6 月向选择的合作伙伴和开发者介绍 GPT-3，然后在 2022 年 11 月向公众提供更广泛的可用性时发生的。这一发布在互联网上引起了极大的兴奋，因为
    GPT-3 具有模仿人类对话的remarkable 能力。GPT-3 是一个计算强大的机器，拥有令人印象深刻的 1750 亿个参数。它在来自各种在线资源的多样化数据集上进行了广泛的训练。该模型在进行连贯、上下文感知的对话方面的熟练程度使其看起来异常智能。
- en: 'Like many groundbreaking technologies, ChatGPT-3’s debut was accompanied by
    hype and exaggeration. The media, often drawn to sensationalism, didn’t miss the
    opportunity to capitalize on the excitement. In April 2023, a pair of Fox News
    journalists ran a headline that raised alarm with its dramatic assertion: “VERY
    SCARY: AI Bot Lays Out Plans to Destroy Humanity” [1]. This headline, coupled
    with sensationalist reporting, contributed to public anxiety about AI. The conversation
    between the two journalists and the guest expert voiced a fearful perspective,
    linking AI and ChatGPT to negative human traits and citing an incident involving
    a chatbot generating content related to nuclear devices. The news segment heightened
    the drama by featuring footage of Boston Dynamics’ dancing humanoid robots, misleadingly
    implying that the AI threats were associated with human-like, superintelligent
    robots with malevolent intentions. This sensationalized style of reporting stands
    as a notable illustration of how misinformation and fearmongering can skew the
    public’s understanding of AI. Even individuals with significant expertise occasionally
    make statements that are challenging to substantiate, thereby inflating the capabilities
    of AI algorithms. As an illustration, Sam Altman, the CEO of OpenAI, the entity
    behind ChatGPT, issued the following statement on March 16, 2021:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多开创性的技术一样，ChatGPT-3 的首次亮相伴随着夸大和炒作。媒体，通常倾向于轰动性新闻，没有错过利用兴奋情绪的机会。2023 年 4 月，一对福克斯新闻的记者发布了一个标题，通过其夸张的断言引起了警惕：“非常可怕：AI
    机器人制定了摧毁人类的计划”[1]。这个标题，加上夸张的报道，加剧了公众对人工智能的焦虑。两名记者和客座专家之间的对话表达了一种恐惧的观点，将人工智能和 ChatGPT
    与负面的人类特征联系起来，并引用了一个涉及聊天机器人生成与核设备相关内容的事件。新闻片段通过展示波士顿动力的跳舞仿人机器人的镜头，误导性地暗示 AI 威胁与类似人类、超级智能、恶意意图的机器人有关。这种轰动性报道风格是对如何误导和煽动恐慌的显著说明。即使具有重要专业知识的个人偶尔也会发表难以证实的声明，从而夸大了
    AI 算法的能力。举例来说，OpenAI CEO 萨姆·奥特曼于 2021 年 3 月 16 日发表了以下声明：
- en: In the next five years, computer programs that can think will read legal documents
    and give medical advice. In the next decade, they will do assembly-line work and
    maybe even become companions. And in the decades after that, they will do almost
    everything, including making new scientific discoveries that will expand our concept
    of everything. This technological revolution is unstoppable. [2]
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在未来五年内，能够思考的计算机程序将阅读法律文件并提供建议。在接下来的十年里，它们将进行流水线作业，甚至可能成为伴侣。在此之后的几十年里，它们将做几乎所有的事情，包括进行新的科学发现，扩展我们对一切的概念。这场技术革命势不可挡。[2]
- en: In the preceding chapters, I alluded to comparable exaggerated statements from
    the past that ultimately proved untrue.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我提到了过去类似夸大的陈述，最终证明是不真实的。
- en: 5.3 ChatGPT
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 聊天 GPT
- en: 'Throughout the history of AI, there has been a recurring theme: the aspiration
    to empower machines with the ability to engage in meaningful conversations using
    natural language. The complexity of natural language is a formidable obstacle
    that AI researchers have faced since the inception of the discipline. In 2020,
    OpenAI unveiled GPT-3 [3]. Alongside GPT-3, other LLMs like BERT [4], T5 [5],
    and OPT [6] are often seen as significant advancements in the field of NLP. OpenAI
    researchers [7] stated:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能的历史上，有一个经常出现的主题：赋予机器使用自然语言进行有意义对话的能力的愿望。自然语言的复杂性是自学科成立以来 AI 研究人员面临的一大难题。2020
    年，OpenAI 推出了 GPT-3。除了 GPT-3，像 BERT、T5 和 OPT 这样的其他大型语言模型也被视为自然语言处理领域的重大进展。OpenAI
    的研究人员表示：
- en: GPT-3 excels in various NLP tasks, including translation, question-answering,
    cloze tasks, as well as tasks involving on-the-fly reasoning or domain adaptation,
    such as unscrambling words, using a new word in a sentence, or performing 3-digit
    arithmetic.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-3 在各种 NLP 任务中表现出色，包括翻译、问答、填空任务，以及涉及即时推理或领域适应的任务，比如拼字、在句子中使用新单词，或进行 3 位数的算术运算等。
- en: 'OpenAI offers four primary GPT-3 models: Davinci, Curie, Babbage, and ADA [8].
    These models are characterized by different power levels and suitability for various
    tasks. For instance, Davinci, while more resource-intensive and slower than the
    others, is considered the most capable and is recommended for applications requiring
    deep understanding, such as generating creative content or summarizing existing
    content for specific audiences.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 提供了四个主要的 GPT-3 模型：Davinci、Curie、Babbage 和 ADA。这些模型具有不同的功率水平和适用于各种任务的性能。例如，Davinci
    虽然比其他模型更需要资源并且速度较慢，但被认为是最能胜任的，适用于需要深度理解的应用，比如生成创意内容或为特定受众总结现有内容。
- en: 'Recent years have witnessed substantial improvements in NLP applications, thanks
    to the utilization of large text corpora during model training and the fine-tuning
    of models for specific tasks. As of the time of writing, OpenAI’s ChatGPT stands
    as the most advanced AI language generator and chatbot. The free version was made
    accessible to the public in November 2022, with over 1 million users having utilized
    it. On March 13, 2023, OpenAI introduced GPT-4, the latest milestone in its journey
    to scale up deep learning. GPT-4 is a large multimodal model capable of accepting
    both image and text inputs and generating text outputs. While it falls short of
    human-level performance in many real-world scenarios, it demonstrates human-level
    performance on various professional and academic benchmarks [9]. Concerning benchmarks,
    the GPT-4 technical report [10] states:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，由于在模型训练过程中利用了大量的文本语料库，并对模型进行了特定任务的微调，自然语言处理（NLP）应用得到了显著改进。截至撰写本文时，OpenAI
    的 ChatGPT 是最先进的人工智能语言生成器和聊天机器人。免费版本于 2022 年 11 月向公众开放，已有超过 100 万用户使用。2023 年 3
    月 13 日，OpenAI 推出了 GPT-4，这是其扩展深度学习旅程的最新里程碑。GPT-4 是一个大型多模态模型，能够接受图像和文本输入，并生成文本输出。虽然在许多现实场景中未达到人类水平的性能，但在各种专业和学术基准测试中表现出人类水平的性能。有关基准测试，GPT-4
    技术报告指出：
- en: We tested GPT-4 on a diverse set of benchmarks, including simulating exams originally
    designed for humans. We did not specifically train the model for these exams.
    A minority of the problems in the exams were encountered by the model during training.
    For each exam, we ran a variant with these questions removed and reported the
    lower score of the two.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在各种基准测试中对 GPT-4 进行了测试，包括模拟原本为人类设计的考试。我们并没有专门为这些考试训练模型。模型在训练过程中只遇到了少量考试中的问题。对于每个考试，我们运行了一个删除了这些问题的变体，并报告两者中较低的分数。
- en: Since late 2022, the media’s excitement about ChatGPT has spurred the release
    of several significant language models.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2022 年末以来，媒体对 ChatGPT 的兴奋激发了几个重要语言模型的发布。
- en: In my experience, ChatGPT-4’s capabilities have been truly impressive. Its ability
    to produce text that closely resembles human writing is remarkable. This proficiency
    creates a fascinating challenge in distinguishing between content generated by
    the machine and content crafted by a human hand.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，ChatGPT-4 的能力真的令人印象深刻。它能够产生与人类写作非常相似的文本是非常了不起的。这种熟练程度带来了一个有趣的挑战，即区分机器生成的内容和人工制作的内容。
- en: 5.3.1 How ChatGPT creates human-like text
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 ChatGPT 如何生成类似人类的文本
- en: Language models like ChatGPT operate on the fundamental principle of predicting
    the next word or token in a sequence of text based on the preceding words. This
    predictive capability is the result of training on vast amounts of textual data
    from the internet. Let’s explore further the workings of this process.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型如ChatGPT的运行基本原理是根据前面的单词或标记来预测文本序列中的下一个单词或标记。这种预测能力是通过在互联网上的大量文本数据上进行训练得出的。让我们进一步探讨这个过程的运作方式。
- en: Imagine we start with a text prompt, such as “The benefits of electric vehicles
    are …” The model, in essence, plays a game of probability, attempting to guess
    the most likely word or token to follow. To make this prediction, it learns from
    the patterns in language found across the internet. The model creates a ranked
    list of potential words that could logically follow *are*. In this example, it
    might suggest words like *plentiful*, *numerous*, *economic*, *clear*, or *not*.
    Importantly, the model doesn’t just deal with complete words but also with tokens,
    which are sequences of characters or word fragments. Tokens can include not only
    whole words but also sub-words and trailing spaces. A useful rule of thumb is
    that one token typically represents about four characters of standard English
    text. This tokenization process allows the model to process and analyze text efficiently.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们从一个文本提示开始，比如“电动车的好处是……”。模型本质上是在进行概率游戏，试图猜测最可能跟随的单词或标记。为了进行这种预测，它从互联网上找到的语言模式中学习。模型创建了一个潜在单词的排序列表，这些单词可能逻辑上跟随*are*。在这个例子中，它可能建议像*丰富*，*众多*，*经济*，*明确*或*不*这样的单词。重要的是，模型不仅仅处理完整的单词，还处理标记，这是字符或单词片段的序列。标记不仅可以包括完整的单词，还可以包括子单词和尾随空格。一个有用的经验法则是，一个标记通常代表标准英文文本的约四个字符。这个标记化过程使模型能够有效地处理和分析文本。
- en: What sets language models like ChatGPT apart is their ability to generate responses
    that aren’t solely driven by the highest probability choice. Instead, they sometimes
    introduce a creative touch by selecting words with lower probabilities. This creative
    element often results in responses that feel more human-like and less formulaic.
    One remarkable aspect of these language models is their capacity to understand
    context. They achieve this by learning from a vast and diverse range of texts,
    encompassing billions of sources. This learning includes exposure to text where
    certain words are omitted or paraphrased, allowing the model to predict semantically
    similar text. This mimics an understanding of context and meaning in human language.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT等语言模型的独特之处在于它们能够生成不仅仅由最高概率选择驱动的响应。相反，它们有时通过选择具有较低概率的单词来引入创造性的触摸。这种创造性元素通常导致响应更具人类化，
    less公式化。这些语言模型的一个显着特点是它们理解上下文的能力。它们通过学习来自广泛而多样化的文本范围的文本，包括数十亿的来源。这种学习包括暴露于某些单词被省略或改写的文本，使得模型能够预测语义上类似的文本。这模仿了对人类语言中上下文和含义的理解。
- en: The training process for models like ChatGPT is extensive and meticulous. It
    begins with training on a large dataset comprising internet text. During training,
    the model’s predictions for the next token are compared to human-written text.
    The model then adjusts its internal structure and performance to minimize discrepancies
    and improve its predictive capabilities. For instance, GPT-2, a predecessor of
    ChatGPT, featured 1.5 billion parameters and was trained on 40 GB of internet
    text. The subsequent iteration, GPT-3, took a substantial leap in complexity with
    175 billion parameters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT等模型的训练过程是广泛而细致的。它始于对包含互联网文本的大型数据集进行训练。在训练过程中，模型对下一个标记的预测与人类编写的文本进行比较。然后，模型调整其内部结构和性能，以最小化差异并提高其预测能力。例如，ChatGPT的前身GPT-2具有15亿个参数，并且在40
    GB的互联网文本上进行了训练。随后的迭代版本GPT-3在复杂性上有了显著的飞跃，拥有1750亿个参数。
- en: The training process for AI models is a complex and essential step in their
    development. It involves the iterative adjustment of the numerous weights and
    parameters within the model through the application of deep learning algorithms.
    This fine-tuning process allows the model to learn from vast datasets and improve
    its performance over time. One key factor in the recent advancements in AI training
    is the utilization of modern GPUs (graphics processing units) and hardware enhancements.
    These powerful computational tools have revolutionized the field by enabling models
    to process millions of training examples simultaneously, significantly accelerating
    the training process. This parallel processing capability is particularly crucial
    because it allows AI researchers and engineers to train increasingly large and
    complex models efficiently. Moreover, the use of distributed computing and specialized
    hardware has further enhanced the speed and efficiency of AI model training. These
    advancements have opened the door to solving complex problems that were once considered
    computationally infeasible.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能模型的训练过程是其发展中复杂且必不可少的一步。它涉及通过应用深度学习算法对模型内部的众多权重和参数进行迭代调整。这种微调过程使得模型能够从大量数据集中学习，并随着时间不断提高其性能。在人工智能训练方面的最新进展的一个关键因素是利用现代GPU（图形处理单元）和硬件增强技术。这些强大的计算工具通过使模型能够同时处理数百万个训练示例，彻底改变了该领域，极大地加速了训练过程。这种并行处理能力尤为关键，因为它使得人工智能研究人员和工程师能够高效地训练越来越大和复杂的模型。此外，分布式计算和专用硬件的使用进一步提高了人工智能模型训练的速度和效率。这些进步已经打开了解决曾经被认为是计算上不可行的复杂问题的大门。
- en: In essence, language models such as ChatGPT represent a remarkable advancement
    in the field of NLP. These models are powered by deep learning algorithms and
    have been meticulously trained on vast and diverse datasets sourced from the internet.
    At their core, these models employ a form of predictive intelligence that enables
    them to understand and generate text with a level of proficiency that was once
    the exclusive domain of human authors. They not only follow the rules of grammar
    but also have the capacity to mimic the nuanced style of human-written text. This
    predictive prowess is a result of their ability to capture complex patterns and
    relationships within language. For example, when presented with a sentence fragment
    like “The sun is shining, and the birds are,” these models can accurately predict
    that the next word might be “singing” or “flying,” depending on the context. This
    capacity to simulate human-like language use makes them invaluable in a wide array
    of language-related applications. For instance, they serve as the backbone for
    chatbots, providing users with responses that are not only grammatically correct
    but also contextually relevant. They are adept at adjusting to different conversational
    tones, styles, and domains, making them versatile tools for tasks such as customer
    support, where they can handle a range of inquiries and issues while maintaining
    a consistent and human-like tone. Language models are equally proficient in summarizing
    lengthy documents and facilitating efficient information retrieval. With the ability
    to generate creative content, they can write articles, generate poetry, and compose
    music lyrics, all while adhering to the desired tone and style.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，像ChatGPT这样的语言模型代表了自然语言处理领域的重大进展。这些模型由深度学习算法驱动，并经过对互联网上的广泛和多样化数据集的精心训练。在核心的部分，这些模型采用了一种预测智能的形式，使它们能够理解并生成文本，这曾经是人类作者的专属领域。它们不仅遵循语法规则，还具有模仿人类书面文本的细微风格的能力。这种预测能力是它们能够捕捉语言中复杂模式和关系的结果。例如，当给出像“太阳正闪耀，鸟儿在...”这样的句子片段时，这些模型可以准确预测下一个词可能是“歌唱”或“飞行”，这取决于上下文。这种模拟人类语言使用的能力使它们在各种与语言相关的应用中尤为重要。例如，它们作为聊天机器人的核心，为用户提供不仅在语法上正确而且在语境上相关的回应。它们擅长适应不同的会话语调、风格和领域，使其成为客户支持等任务的多功能工具，在这些任务中，它们可以处理各种查询和问题，并保持一致的人类化语调。语言模型同样擅长总结冗长的文件，并促进高效的信息检索。由于能够生成创意内容，它们可以写文章、生成诗歌，并撰写音乐歌词，而且同时能够遵循所需的语气和风格。
- en: 5.3.2 ChatGPT hallucination
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 ChatGPT幻觉
- en: Like any other deep learning model, ChatGPT lacks the capacity to grasp its
    own statements or the meanings of the words it employs. Its primary function is
    to generate words in response to given inputs, and its proficiency in predicting
    word combinations does not guarantee the accuracy of the generated text. In the
    following examples, I will illustrate that ChatGPT is incapable of comprehending
    human language and struggles with its complexities. To commence, I posed factual
    questions related to subjects I am well-versed in, specifically, myself and Brighterion,
    the company I established after relocating to the United States. On July 7, 2023,
    I inquired, “Who is Akli Adjaoute?” To my astonishment, the response identified
    me as the founder of “Brighter IA,” a privacy-focused video company (figure 5.1).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何其他深度学习模型一样，ChatGPT缺乏理解自己陈述或所使用单词含义的能力。它的主要功能是根据给定的输入生成单词，并且它在预测单词组合方面的熟练程度并不保证生成文本的准确性。在接下来的例子中，我将说明ChatGPT无法理解人类语言并且在处理其复杂性时遇到困难。首先，我提出了与我熟悉的主题相关的事实性问题，具体来说，是关于我自己和我在移居美国后建立的公司Brighterion。2023年7月7日，我询问：“Akli
    Adjaoute是谁？”令我惊讶的是，回答将我标识为“Brighter IA”的创始人，这是一个以隐私为重点的视频公司（见图5.1）。
- en: '![figure](../Images/5-1.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-1.png)'
- en: Figure 5.1 ChatGPT prompt, which resulted in incorrectly identifying the author
    as the founder and CEO of a company he was not affiliated with.
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 ChatGPT提示，导致错误地将作者识别为他与之无关的一家公司的创始人兼CEO。
- en: I became intrigued by how ChatGPT generated its responses, so I closed the session
    and initiated a new one, asking the same question. The answer I received was different,
    yet still incorrect. It contained numerous fabricated details, including the claim
    that I had received the prestigious Innovators Under 35 award from *MIT Technology
    Review*. Perplexed, I closed the session and started a new one once again. On
    my third attempt with the same question, I received yet another set of invented
    facts. This time, it included claims about me holding a PhD from the University
    of Illinois and having held positions at prominent technology companies and research
    institutions like IBM and Yahoo. It struck me as odd to receive three distinct
    fictitious responses.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我对 ChatGPT 如何生成其回复产生了兴趣，于是我关闭了会话并启动了一个新会话，询问同样的问题。我收到的回答不同，但仍然是错误的。它包含了许多捏造的细节，包括声称我曾获得过*麻省理工技术评论*的著名的35岁以下创新者奖。我感到困惑，于是我关闭了会话，再次启动了一个新的会话。第三次尝试同样的问题时，我收到了另一组虚构的事实。这次，它包括关于我在伊利诺伊大学获得博士学位并曾在IBM和雅虎等知名科技公司和研究机构担任职位的声称。收到三个不同的虚构回答让我感到很奇怪。
- en: I continued to ask the same question, and on the fifth attempt, I finally received
    an accurate response (figure 5.2). It left me wondering how anyone could rely
    on a program that consistently generated random and incorrect responses to the
    same question.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我继续问同样的问题，在第五次尝试时，我终于收到了准确的回答（见图5.2）。这让我想知道，任何人怎么能依赖一个始终生成随机和错误回答的程序来获取信息呢？
- en: '![figure](../Images/5-2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-2.png)'
- en: Figure 5.2 ChatGPT prompt and output required five attempts to generate correct
    information.
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 ChatGPT提示和输出需要五次尝试才能生成正确的信息。
- en: It’s worth noting that my question was not obscure; it pertained to Brighterion,
    a well-known company that offers enterprise AI applications for payment service
    providers, financial institutions, healthcare payers, and merchants. Furthermore,
    Brighterion has been extensively covered in the media, so information on the subject
    is widely available. As for myself, while I’m not a public figure, my first and
    last names are both highly unusual and unlikely to be confused with someone else.
    Moreover, I’ve been credited as the founder of Brighterion in numerous reputable
    sources, including the *Wall Street Journal*, *Forbes*, *USA TODAY*, CNBC, and
    various others. The point is to emphasize that this information is neither obscure
    nor difficult to find.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我的问题并不晦涩；它涉及Brighterion，这是一家为支付服务提供商、金融机构、医疗支付者和商家提供企业AI应用的知名公司。此外，Brighterion已经被媒体广泛报道，因此关于这个主题的信息是广泛可得的。至于我自己，虽然我不是公众人物，但我的名字和姓氏都非常不寻常，不太可能与其他人混淆。此外，我在许多权威来源中都被认定为Brighterion的创始人，包括*华尔街日报*、*福布斯*、*今日美国*、CNBC等等。重点是强调这些信息既不晦涩也不难找到。
- en: On April 9, 2023, during another set of tests, ChatGPT made an incorrect statement
    suggesting that I played football for Marseille in 1994\. When I mentioned my
    affiliation with FC Rouen, ChatGPT insisted that its records confirmed this erroneous
    claim (figure 5.3).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年4月9日的另一轮测试中，ChatGPT做出了一个错误的声明，声称我在1994年为马赛足球队踢球。当我提到我与FC Rouen的关系时，ChatGPT坚称其记录证实了这一错误的说法（见图5.3）。
- en: '![figure](../Images/5-3.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3](../Images/5-3.png)'
- en: Figure 5.3 ChatGPT insisted that the author played for a football team that
    he was never a part of.
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3 ChatGPT坚称作者曾为他从未参加过的足球队效力。
- en: The amalgamation of factual information with elements of fiction can render
    these programs significantly dangerous when utilized as sources of verifiable
    facts. This danger arises from the potential for such programs to blur the lines
    between reality and imagination, which, in turn, can have profound consequences
    on individuals and society as a whole. When truth and fiction intertwine within
    these programs, they often create a distorted version of reality that can easily
    mislead and confuse consumers of the content. This distortion can range from relatively
    harmless misinformation to more harmful disinformation, with the latter intentionally
    spreading false narratives to manipulate public perception or achieve specific
    agendas. One of the primary concerns is that when individuals encounter such content,
    they may unknowingly accept the fictional elements as truth, leading to misinformed
    beliefs and decisions. This can manifest in various ways, such as forming inaccurate
    opinions about current events, making misguided health choices, and even affecting
    political and social discourse. When people can’t distinguish between genuine
    and fabricated content, they become increasingly skeptical of news organizations,
    government bodies, and scientific authorities. Furthermore, the spread of false
    information can erode social cohesion and sow division within communities. It
    has the potential to amplify existing fault lines and create new ones, leading
    to polarization and animosity among different groups.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 将事实信息与虚构元素融合在一起会使这些程序在被用作可验证事实来源时变得非常危险。这种危险来自于这些程序有可能模糊现实与想象之间的界限，进而对个人和整个社会产生深远的影响。当真实和虚构交织在这些程序中时，它们经常会创造出一个扭曲的现实版本，很容易误导和混淆内容的消费者。这种扭曲范围从相对无害的错误信息到更有害的虚假信息，后者有意传播虚假叙述以操纵公众观念或实现特定议程。主要的担忧之一是，当个人遇到这样的内容时，他们可能会不知不觉地将虚构元素当作真理接受，导致错误的信念和决策。这可能以各种方式表现出来，例如对当前事件形成不准确的观点，做出错误的健康选择，甚至影响政治和社会话语。当人们无法区分真实和虚构的内容时，他们会对新闻机构、政府机构和科学当局变得越来越怀疑。此外，错误信息的传播可能会侵蚀社会凝聚力，并在社区内播下分裂的种子。它有可能加剧现有的分歧，并制造新的分歧，导致不同群体之间的极化和敌意。
- en: 5.4 Bard
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 巴德
- en: During the 2023 I/O event, Google introduced Bard, a competitor to ChatGPT.
    (Please note that Google has recently released a new version named Gemini.) On
    July 8 of that year, I initiated a prompt to Bard with the phrase “Akli Adjaoute
    20 awards.” Unfortunately, much like with ChatGPT, a substantial portion of the
    Bard’s response was found to be fictional (figure 5.4).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年的I/O活动期间，谷歌推出了巴德，这是ChatGPT的一位竞争对手。（请注意，谷歌最近推出了名为Gemini的新版本。）当年7月8日，我向巴德发出了一个提示：“Akli
    Adjaoute 20 awards”。不幸的是，与ChatGPT一样，巴德的大部分回应被发现是虚构的（见图5.4）。
- en: '![figure](../Images/5-4.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图5.4](../Images/5-4.png)'
- en: '**Figure 5.4 Bard attributed a combination of factual and fictional awards
    to the author, rendering the output unreliable.**'
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**图5.4 巴德将一系列真实和虚构的奖项归因于作者，使输出不可靠。**'
- en: As previously mentioned, my first and last names are quite uncommon. Nevertheless,
    the AI consistently confused me with other individuals and attributed their accomplishments
    and careers to me. I have never been honored with the IEEE Longuet-Higgins Prize,
    the ACM Paris Kanellakis Award, or the IEEE Computer Society Technical Achievement
    Award.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，我的名字和姓氏都非常不常见。尽管如此，人工智能始终将我与其他人混淆，并将他们的成就和职业归功于我。我从未荣获过IEEE Longuet-Higgins奖，ACM
    Paris Kanellakis奖或IEEE计算机协会技术成就奖。
- en: Following an initial unreliable response, I terminated the session and rephrased
    my question with “12” instead of “20.” To my dismay, I received a different but
    equally dubious response. The AI provided a new list of accolades I have never
    earned, and to compound matters, it now falsely asserted that I hold the position
    of a computer science professor at Stanford University and am a co-founder of
    the Stanford Center for Artificial Intelligence in Finance.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在最初的不可靠回答之后，我终止了会话，并重新提出了我的问题，改用“12”代替“20”。令我沮丧的是，我收到了一个不同但同样可疑的回答。人工智能提供了一个我从未获得过的新的荣誉列表，更糟糕的是，它现在虚假地声称我是斯坦福大学的计算机科学教授，并且是斯坦福人工智能金融中心的联合创始人。
- en: Throughout my career, I have been an entrepreneur and, as such, have not authored
    over 100 papers in esteemed academic journals. My research has never received
    funding from the National Science Foundation, the Department of Defense, or the
    European Union.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我整个职业生涯中，我都是一位企业家，因此从未在著名的学术期刊上撰写过100多篇论文。我的研究从未获得过美国国家科学基金会、国防部或欧盟的资助。
- en: I have never been recognized as one of the “Top 50 AI Leaders in the World”
    by the *MIT Technology Review*, and I am not affiliated with the Association for
    the Advancement of Artificial Intelligence (AAAI) or the Institute of Electrical
    and Electronics Engineers (IEEE).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我从未被 *MIT Technology Review* 认可为“世界前50名人工智能领袖”，并且我与美国人工智能进步协会（AAAI）或美国电气和电子工程师协会（IEEE）没有任何关联。
- en: Not only did the AI make inaccurate assertions and misrepresent facts, but it
    also attributed its errors to an irrelevant primary source. Such misinformation
    raises concerns about the reliability of citations, which are fundamental to academic
    work (figure 5.5).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能不仅提出了不准确的主张，歪曲了事实，而且将其错误归因于一个不相关的主要来源。这种错误信息引发了对引文可靠性的担忧，而引文对学术工作至关重要（图5.5）。
- en: '![figure](../Images/5-5.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-5.png)'
- en: Figure 5.5 AI made inaccurate assertions attributed to an irrelevant citation.
    This information raises concerns about the reliability of citations.
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.5 人工智能做出了不准确的主张，并将其归因于不相关的引文。这一信息引发了对引文可靠性的担忧。
- en: Distinguishing between facts and falsehoods can be challenging, especially for
    those who lack familiarity with a subject. Accepting fabricated information can
    lead to significant and harmful consequences. For instance, a mayor in Australia
    named Brian Hood is threatening to file a defamation lawsuit against OpenAI’s
    ChatGPT for falsely suggesting that he went to prison for a bribery scandal involving
    a subsidiary of the Reserve Bank of Australia (figure 5.6). Hood was, in fact,
    a whistleblower in this case [11].
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 区分事实和谬误可能很具有挑战性，尤其是对于那些对某个主题缺乏熟悉度的人。接受捏造的信息可能会导致重大且有害的后果。例如，澳大利亚的一位名叫布赖恩·胡德的市长威胁要起诉OpenAI的ChatGPT，因为它虚假地暗示他因澳大利亚储备银行的一个子公司的贿赂丑闻而入狱（图5.6）。事实上，胡德在这个案子中是一个告密者
    [11]。
- en: '![figure](../Images/5-6.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-6.png)'
- en: Figure 5.6 Australian mayor Brian Hood is threatening a lawsuit over ChatGPT
    falsely stating that he went to prison for bribery when, in fact, he was the whistleblower,
    not the criminal.
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.6 澳大利亚市长布赖恩·胡德威胁要因ChatGPT错误地声称他因贿赂入狱而提起诉讼，事实上，他是告密者，而不是罪犯。
- en: Software capable of generating fabricated information poses a significant threat
    to both individuals and society as a whole. To address these challenges, it is
    imperative that we demand that technology be developed and utilized in ways that
    prioritize accuracy, transparency, and responsible information sharing. This means
    holding tech companies accountable for the content on their platforms and implementing
    mechanisms to verify the authenticity of information.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 能够生成捏造信息的软件对个人和整个社会构成重大威胁。为了应对这些挑战，我们必须要求技术以优先考虑准确性、透明度和负责任的信息分享的方式进行开发和利用。这意味着要求科技公司对其平台上的内容负责，并实施机制来验证信息的真实性。
- en: 5.5 Humans vs. LLMs
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 人类 vs. LLMs
- en: In October 2011, Apple unveiled the iPhone 4S, which marked the debut of Siri,
    a virtual personal assistant. Apple acquired the technology behind Siri in 2010
    through its acquisition of a startup with the same name. This startup originated
    from the SRI International Artificial Intelligence Center, an institution tracing
    its roots back to the Stanford Research Institute (SRI). The name “Siri” is essentially
    a phonetic representation of “SRI.”
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 2011年10月，苹果推出了iPhone 4S，这标志着Siri虚拟个人助理的首次亮相。苹果通过收购一家同名初创公司于2010年获得了Siri背后的技术。这家初创公司起源于SRI国际人工智能中心，这个机构可以追溯到斯坦福研究所（SRI）。“Siri”这个名字本质上是“SRI”的语音表示。
- en: Siri gained recognition for its hands-free functionality, which allows it to
    continuously monitor the microphone of the host device. Using a deep neural network,
    it analyzes sounds from its environment. When it identifies the phrase “Hey Siri”
    with a high level of confidence, the full application becomes active and processes
    and responds to subsequent sounds as questions.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Siri因其免提功能而受到认可，允许其持续监控主机设备的麦克风。使用深度神经网络，它分析其环境中的声音。当它以高度的自信度识别出短语“嘿 Siri”时，整个应用程序变得活跃，并处理和回答后续的声音作为问题。
- en: 'In October 2017, the Siri development team provided a detailed explanation
    of this functionality in an article titled “Deep Learning for Siri’s Voice: On-Device
    Deep Mixture Density Networks for Hybrid Unit Selection Synthesis” [12]:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年10月，Siri开发团队在一篇名为“Siri语音的深度学习：基于设备的混合单元选择合成的深度混合密度网络”[12]的文章中提供了对这一功能的详细解释：
- en: 'The microphone in an iPhone or Apple Watch turns your voice into a stream of
    instantaneous waveform samples, at a rate of 16,000 per second. A spectrum analysis
    stage converts the waveform sample stream to a sequence of frames, each describing
    the sound spectrum of approximately 0.01 sec. About 20 of these frames at a time
    (0.2 sec of audio) are fed to the acoustic model, a Deep Neural Network (DNN),
    which converts each of these acoustic patterns into a probability distribution
    over a set of speech sound classes: those used in the “Hey Siri” phrase, plus
    silence and other speech, for a total of about 20 sound classes. The DNN consists
    mainly of matrix multiplications and logistic nonlinearities. The training process
    adjusts the weights using standard Backpropagation and stochastic gradient descent.
    … Next time you say, “Hey Siri,” you may think of all that goes on to make responding
    to that phrase happen, but we hope that it “just works!”'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: iPhone或Apple Watch中的麦克风将您的声音转换为瞬时波形样本流，每秒16,000个样本。频谱分析阶段将波形样本流转换为帧序列，每个帧描述大约0.01秒的声音频谱。每次大约20个这样的帧（0.2秒音频）被馈送到声学模型，即深度神经网络（DNN），该模型将每个声学模式转换为一组语音声音类别的概率分布：在“嘿
    Siri”短语中使用的声音，以及静音和其他语音，总共约20个声音类别。DNN主要由矩阵乘法和逻辑非线性组成。训练过程使用标准的反向传播和随机梯度下降来调整权重。…下次你说“嘿
    Siri”时，你可能会想到所有这些内容是如何使得对该短语的响应发生的，但我们希望它“只是工作”！
- en: 'This article should serve as an indispensable reference point for any educational
    material on artificial intelligence. In particular, it sheds light on the formidable
    challenge faced by personal assistant programs when attempting to engage in genuinely
    meaningful conversations. Although these AI systems may initially appear clever,
    they function much like well-trained parrots, lacking a genuine understanding
    of the words they process or produce. This deficiency becomes evident with even
    a modest degree of experimentation. Consider the scenario in which you ask Siri
    to recommend a restaurant. If you repeatedly respond with, “No, I don’t like that,”
    Siri will persist in offering new suggestions. However, if you veer off-topic
    by asking an unrelated question and then return to your restaurant inquiry, Siri
    will present the same list of options in the same order despite your prior expressions
    of dissatisfaction. Such rigid behavior is in stark contrast to the adaptability
    and comprehension exhibited by humans in similar situations. The lesson here is
    clear: communication transcends mere words.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章应该成为任何人工智能教材的不可或缺的参考点。特别是，它揭示了个人助理程序在试图进行真正有意义的对话时面临的巨大挑战。尽管这些人工智能系统起初可能显得聪明，但它们的功能与训练有素的鹦鹉类似，缺乏对其处理或产生的文字的真正理解。这种不足在进行了轻度实验后就变得明显起来。考虑这样一个情景，你让
    Siri 推荐一家餐馆。如果你不断回答“不，我不喜欢那个”，Siri 将继续提供新的建议。然而，如果你离题问一个不相关的问题，然后再回到你的餐馆询问，Siri
    将以相同的顺序呈现相同的选项列表，尽管你之前表示过不满。这种僵化的行为与人类在类似情况下所表现出的适应性和理解力形成鲜明对比。这里的教训是清楚的：沟通超越了单纯的文字。
- en: The gift of language endows us with the ability to share an endlessly diverse
    array of complex ideas and profound emotions with others. Through language, we
    can convey what we know and extract knowledge by posing questions. When someone
    speaks to us, our brains perform an almost magical exploit by instantaneously
    translating auditory sounds into coherent concepts, emotions, and vivid sensory
    experiences. For example, when the word *book* is uttered in a conversation, our
    minds swiftly decipher its meaning from its context and conjure up imagery of
    bound pages filled with text. It is indeed remarkable that we can communicate
    at all when each word within a sentence may possess numerous possible meanings.
    Take, for instance, the sentence, “The mining equipment at this gold mine is mine!”
    In this case, there is no ambiguity in the intended meaning, as our brains seamlessly
    distinguish whether *mine* functions as an adjective, a noun, or a possessive
    pronoun. Yet, the complexity of language comprehension extends far beyond these
    apparent challenges.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 语言的赐予使我们能够与他人分享各种各样的复杂思想和深刻情感。通过语言，我们可以传达我们所知道的，并通过提问来提取知识。当有人对我们说话时，我们的大脑几乎像是进行了一种魔术般的壮举，将听觉声音瞬间转化为连贯的概念、情感和生动的感官体验。例如，当在谈话中提到
    *book* 这个词时，我们的思维迅速从上下文中解读其含义，并想象出装订页面填满文本的图像。令人惊奇的是，当句子中的每个单词可能具有多种可能的含义时，我们仍然可以进行交流。例如，句子，“这座金矿的采矿设备是我的！”在这种情况下，我们的大脑无缝地区分出
    *mine* 是形容词、名词还是所有格代词。然而，语言理解的复杂性远不止这些明显的挑战。
- en: Words possess the remarkable ability to evoke sensations and emotions through
    association. Take, for instance, the phrase “ocean breeze.” Even without explicitly
    mentioning the coldness of the sea air or the sound of crashing waves, these words
    conjure up a vivid sense of freshness, tranquility, and perhaps even a hint of
    adventure. Similarly, the phrase “crimson autumn leaves” transports us to a scene
    of vibrant foliage, crisp air, and the cozy embrace of fall, all without directly
    detailing the temperature or scenery. Moreover, words can be used metaphorically
    to express things that would make no sense if we only processed literal meaning.
    Consider the phrase “time flies.” This expression doesn’t imply that time possesses
    wings or takes flight like a bird; instead, it captures the concept of how time
    seems to pass swiftly and imperceptibly, emphasizing its fleeting nature. Likewise,
    when we say someone is “walking on air,” it doesn’t mean they are defying gravity
    but suggests an overwhelming sense of happiness and euphoria that seems almost
    weightless.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 词语通过联想具有唤起感觉和情感的非凡能力。例如，“海风”这个词组，即使没有明确提到海风的冷酷或海浪拍打的声音，这些词语也会唤起清新、宁静，甚至是一丝冒险的生动感觉。同样，“深红色的秋叶”这个词组将我们带到了一个充满着生机勃勃的树叶、清新的空气和秋天温暖拥抱的场景，而又不直接描述温度或风景。此外，单词还可以用作隐喻，表达如果我们仅处理文字意义就没有意义的事物。考虑一下“时光飞逝”这个短语。这个表达并不意味着时间拥有翅膀或像鸟一样飞翔；相反，它捕捉了时间似乎迅速而不可察觉地流逝的概念，强调了它的短暂性。同样，当我们说某人“步行在空中”时，并不意味着他们违反了重力，而是暗示着一种无法抗拒的幸福和欢愉感，几乎是无重力的。
- en: Even more astonishing is our capacity to employ words symbolically to communicate
    memories and experiences, with certain words holding a deeply personal significance
    known only to those involved. Take, for example, the phrase “olive oil,” as it
    resonates with my memories of Kabylia. Mentioned in a conversation, it instantly
    transports me back to the rolling hills and picturesque groves of olive trees,
    where the very air seemed to be infused with the rich, earthy aroma of freshly
    harvested olives. The scent alone carries the essence of that place and time,
    a sensory time machine that brings back the warm, sun-drenched days spent amidst
    the olive orchards. But it’s not just the scent; it’s the sense of community and
    tradition that olive oil represents for me. The olive harvest in Kabylia was a
    magical communion among people of all ages, coming together to gather the precious
    fruits of the land. I remember the laughter of children as they scampered between
    the trees, the wisdom shared by the elders about the art of olive harvesting,
    and the bonds that formed as we worked side by side, all united in the age-old
    ritual of collecting olives. In those moments, “olive oil” embodies not just a
    culinary ingredient but the collective spirit of a community, a tradition passed
    down through generations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 更令人惊讶的是我们运用符号化的词语来沟通记忆和经历的能力，某些词语对于参与其中的人来说具有深层次的个人意义。举个例子，“橄榄油”这个词组，它与我在卡比利亚的记忆产生共鸣。在谈话中提到，它立即将我带回到连绵起伏的山丘和风景如画的橄榄树林中，那里的空气似乎充满了新鲜收获的橄榄的浓郁、土地的气息。单单是气味就带有那个地方和时间的本质，一台感官时光机器，带回了在橄榄园中度过的温暖、被阳光晒满的日子。但不仅仅是气味；对我来说，橄榄油还代表着社区和传统的感觉。在卡比利亚的橄榄收获是各个年龄段的人们齐聚一堂，共同收获这片土地宝贵水果的一个神奇的交流。我记得孩子们在树林间奔跑的欢笑声，长者们分享的有关橄榄收获艺术的智慧，以及我们肩并肩工作时形成的纽带，所有人都融入了收获橄榄的古老仪式中。在那些时刻，“橄榄油”不仅仅是一种烹饪成分，更是一个社区的集体精神，代代相传的传统。
- en: 'In addition to navigating the complexities of multiple meanings, associations,
    metaphors, and symbolism, our minds also possess the unique ability to anticipate
    and infer meaning from unspoken words. For instance, imagine yourself in a grocery
    aisle, and someone is obstructing your path to the item you seek. By uttering
    the phrase “Can I jus… .” with the appropriate tone, you convey not just your
    intention to retrieve an item but also your politeness, acknowledgment of their
    presence, and assurance that you’ll be quick. These unspoken nuances of communication
    are remarkably clear, with no confusion over whether you are asking for a dollar
    or attempting to take a nap where they stand. The grocery store scenario also
    illustrates another intriguing phenomenon: subtext and our capacity to “read between
    the lines.” A subtle shift in the tone of your voice while using the same words,
    “Can I jus… .,” can dramatically alter their meaning. Instead of conveying politeness
    and cooperation, a harsh tone can signal frustration and impatience, effectively
    demanding that the other person move aside. Their failure to comply could result
    in you uttering a polite-sounding “Thank you,” masking the true message conveyed
    by your tone and body language, which is quite the opposite of gratitude. Moreover,
    our ability to infer substantial information beyond the explicit words spoken
    is equally remarkable. For instance, if someone mentions having a “café au lait
    and scrambled eggs” for breakfast over a phone call, it offers a plethora of insights.
    This snippet of conversation hints at the time of day, the use of a cup, the presence
    of utensils, and proximity to a kitchen and even provides a sense of taste and
    aroma.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 除了应对多重含义、联想、隐喻和象征的复杂性之外，我们的思维还具有独特的能力，可以预测并从未说出的话语中推断出含义。例如，想象一下自己站在杂货走廊上，有人挡住了你去找的物品的路。通过用适当的语气说出“Can
    I jus… .”，你传达的不仅仅是你取得物品的意图，还有你的礼貌、对他们存在的承认以及你会快速的保证。这种交流中的非言语细微差别非常清晰，没有混淆你是在要求一美元还是试图在他们站立的地方小睡。杂货店的情景也展示了另一个有趣的现象：暗示和我们阅读“行间”的能力。在使用相同的词语“Can
    I jus… .”的同时声音语调略微改变，可能会极大地改变它们的含义。与传达礼貌和合作相反，一种严厉的语气可能会表达出沮丧和不耐烦，有效地要求对方让路。他们不遵守可能会导致你说出一声听起来很礼貌的“谢谢”，掩盖了你的语气和肢体语言传达的真正信息，这与感激的真实信息相反。此外，我们推断出远远超出了明确言辞的实质信息的能力同样令人称奇。例如，如果有人在电话中提到早餐吃了“奶咖和炒蛋”，这提供了丰富的信息。这段对话的片段暗示了一天中的时间、杯子的使用、餐具的存在、接近厨房甚至提供了味道和香气的感觉。
- en: Human communication is a remarkably multifaceted phenomenon, capable of conveying
    messages through not only words but also nonverbal cues, gestures, and various
    forms of expression. In fact, our ability to communicate extends beyond the literal
    words we use, often involving subtle nuances and indirect strategies. This indirect
    communication can serve various purposes, such as safeguarding someone’s feelings
    or imparting valuable lessons. For instance, consider a scenario in a corporate
    setting where a manager is working with an employee who needs to improve their
    time management skills. Instead of directly telling the employee to be more punctual
    and organized, the manager might employ a more indirect approach. They could share
    a story about a successful colleague known for their exceptional time management
    and how it positively affected their career. The manager might mention books or
    articles on effective time management techniques and suggest that the employee
    could find them interesting. By doing so, the manager guides the employee toward
    the realization that improved time management is crucial for career growth, encouraging
    them to work on it independently. In this way, the manager has effectively communicated
    a message without explicitly stating it.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 人类的交流是一种非常多方面的现象，能够通过不仅仅是词语，还有非言语暗示、手势和各种表达形式传递信息。事实上，我们的交流能力不仅限于我们使用的字面意思，通常涉及微妙的细微差别和间接策略。这种间接交流可以服务于各种目的，例如保护某人的感情或传授宝贵的教训。例如，在企业环境中考虑一个情景，其中经理正在与需要提高时间管理技能的员工合作。经理可能不直接告诉员工要更加准时和有条理，而是采取更间接的方式。他们可以分享一个关于一个成功同事的故事，该同事以其出色的时间管理而闻名，并且这如何积极影响了他们的职业生涯。经理可能会提到关于有效时间管理技巧的书籍或文章，并建议员工可能会觉得有趣。通过这样做，经理引导员工意识到改善时间管理对职业发展至关重要，并鼓励他们独立解决问题。通过这种方式，经理有效地传达了一条信息，而没有明确陈述。
- en: Communication itself extends to a wide array of nonverbal cues and signals.
    In business presentations, the use of visuals like graphs and charts can convey
    complex data and ideas more effectively than words alone. In negotiations, a firm
    handshake or a well-timed pause during a conversation can communicate confidence
    and control. Even something as simple as the choice of attire in a professional
    setting can send signals about one’s professionalism and attention to detail without
    the need for explicit statements.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 交流本身延伸至广泛的非言语暗示和信号。在商业演示中，像图表和图表这样的视觉工具可以比单纯的文字更有效地传达复杂的数据和观念。在谈判中，坚定的握手或者对话中恰到好处的停顿可以传达自信和控制。甚至在专业环境中衣着的选择也能在不需要明确陈述的情况下传递关于一个人的专业素养和对细节的关注的信号。
- en: Machines and artificial intelligence have not reached the level of human proficiency.
    Perhaps the most compelling evidence of AI’s limitations in communication is its
    inability to engage in meaningful conversation for extended periods. The Loebner
    Prize, a competition resembling the Turing test, ran for nearly three decades,
    challenging AI systems to simulate human conversation via text and audiovisual
    input. Despite significant advancements in AI, no system convincingly passed as
    human during these tests. Even the most advanced chatbots reveal their limitations
    after brief interactions, highlighting the vast gap between machine learning and
    true understanding. Alan Turing, the pioneer of computer science, would likely
    be disappointed by our limited progress in this area, considering the substantial
    investments made in AI development.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 机器和人工智能尚未达到人类熟练程度。也许AI在交流方面的局限性最具有说服力的证据是其无法长时间进行有意义的对话。洛布纳奖是一个类似于图灵测试的竞赛，持续了近三十年，挑战AI系统通过文本和视听输入模拟人类对话。尽管人工智能取得了显著进步，但在这些测试中没有任何系统能够令人信服地被认为是人类。即使是最先进的聊天机器人在短暂的互动之后也会显示出其局限性，突显了机器学习和真正理解之间的巨大差距。计算机科学的先驱艾伦·图灵可能会对我们在这一领域的有限进展感到失望，考虑到人工智能发展所做的大量投资。
- en: To facilitate effective communication, machines must not only recognize the
    individual meanings of words but also interpret the complex structure of sentences,
    consider the contextual nuances, and discern the underlying intentions and objectives
    behind the communication. Achieving this level of comprehension and proficiency
    in language understanding has proven to be a Herculean task. Despite decades of
    relentless efforts, it’s important to recognize that although there has been significant
    advancement in NLP, it has yet to bridge the gap in communication. True understanding
    remains the elusive key to meaningful communication, a milestone that AI has yet
    to achieve.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进有效的交流，机器不仅必须识别单词的个别含义，还必须解释句子的复杂结构，考虑到语境的微妙之处，并辨别出交流背后的意图和目标。达到这种程度的理解和语言技能已被证明是一项艰巨的任务。尽管经过几十年的不懈努力，但我们必须认识到，尽管自然语言处理取得了显著进步，但它仍未填补交流中的差距。真正的理解仍然是有意义交流的难以捉摸的关键，这是人工智能尚未实现的一个里程碑。
- en: 5.6 AI does not understand
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 AI 不理解
- en: Let’s take a moment to revisit the analogy between the game of chess and the
    complexity of language. Chess, a classic board game, comprises various pieces,
    a structured playing board, and a set of well-defined rules that dictate how players
    can move from one state of the game to another. Similarly, language, the cornerstone
    of human communication, involves a diverse set of linguistic units (the alphabet)
    and sophisticated syntactical rules that govern how we construct meaningful sentences.
    It’s tempting to draw parallels between these two seemingly disparate domains
    and question whether the alphabet could be akin to chess pieces and syntax rules
    could serve as our strategic moves in forming coherent sentences. Indeed, all
    languages, much like games, adhere to their own unique sets of rules, even if
    languages are not just about following syntactical rules as it demands a profound
    understanding of the meaning conveyed by those words and sentences.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花一点时间重新思考象棋游戏与语言复杂性之间的类比。 象棋，一种经典的棋盘游戏，包括各种棋子、一个结构化的游戏板和一套明确定义的规则，规定了玩家如何从游戏的一个状态移动到另一个状态。
    类似地，语言，人类沟通的基石，涉及多样的语言单元（字母表）和复杂的句法规则，这些规则指导我们如何构造有意义的句子。 引人注目的是，所有语言，就像游戏一样，都遵循它们自己独特的规则集，即使语言不仅仅是遵循句法规则，因为它要求对单词和句子传达的意义有深刻的理解。
- en: 'Consider the remarkable achievements of AI, such as IBM’s Deep Blue defeating
    the world chess champion or AlphaGo outwitting the Go champion. While these accomplishments
    are undoubtedly impressive, they don’t signify the presence of genuine intelligence
    or understanding in the machines. Rather, they demonstrate the application of
    brute-force computing power and specialized AI algorithms to large datasets. These
    algorithms excel in specific tasks, like mathematical calculations or data sorting,
    surpassing human capabilities. In the same vein, LLMs trained on vast datasets
    from the internet exhibit the ability to generate coherent text that appears sensible.
    Yet, they also lack a genuine understanding as language understanding transcends
    mere pattern recognition or rule adherence. True understanding involves the capacity
    to conceptually associate words with objects, actions, and events in the real
    world. Consider these illustrative examples:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑人工智能的显著成就，如IBM的深蓝击败世界象棋冠军或AlphaGo智胜围棋冠军。 虽然这些成就无疑令人印象深刻，但它们并不表示机器具有真正的智能或理解。
    相反，它们展示了将大规模数据集上的蛮力计算能力和专门的人工智能算法应用于实践的能力。 这些算法在特定任务中表现出色，如数学计算或数据排序，超越了人类的能力。
    同样地，通过互联网的广泛数据集训练的LLM表现出生成连贯文字的能力，看起来合情合理。 然而，它们也缺乏对语言的真正理解，因为语言理解超越了简单的模式识别或规则遵从。
    真正的理解涉及将单词与现实世界中的对象、动作和事件概念上联系起来的能力。 考虑这些说明性的例子：
- en: '*Punctuation can drastically alter meaning*. “Let’s eat Grandma” and “Let’s
    eat, Grandma.” Here, a simple comma has the power to save lives by clarifying
    the intended meaning.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标点符号可以极大地改变意义。 "让我们吃奶奶" 和 "让我们吃，奶奶"。 这里，一个简单的逗号有能力通过澄清预期的意义来挽救生命。
- en: '*Language can have implicit meanings*. When a person says, “I waited an hour
    for you last night in the restaurant” to their date, it’s not just about the words
    spoken. The true essence of this statement lies in the unspoken desperation and
    emotion, a level of nuance that eludes current AI systems.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言可以有含蓄的意义。 当一个人对他们的约会对象说，“我昨晚在餐馆等了你一个小时” ，不仅仅是说的话。 这个声明的真正本质在于未说出的绝望和情感，这是当前人工智能系统所不具备的细微差别。
- en: '*Word order changes meaning*. “Jim was furious, and Jenny ended the call” conveys
    a different narrative than “Jenny ended the call, and Jim was furious.” In both
    cases, the same words are used, but the sequencing of these words fundamentally
    alters the meaning.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单词顺序改变了含义。 "吉姆很生气，珍妮结束了通话" 传达的叙事与 "珍妮结束了通话，吉姆很生气" 不同。 在这两种情况下，使用相同的词，但这些词的排序根本改变了含义。
- en: The analogy between chess and language serves as a thought-provoking starting
    point to explore the capabilities and limitations of AI in understanding language.
    While AI systems, including LLMs, exhibit remarkable prowess in generating text,
    they are fundamentally pattern-matching tools, and genuine language understanding
    remains an elusive frontier to current artificial intelligence.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 国际象棋和语言之间的类比作为探索人工智能在理解语言方面的能力和局限性的思考起点。虽然包括LLMs在内的AI系统展现出在生成文本方面出色的能力，但它们基本上是模式匹配工具，而真正的语言理解仍然是当前人工智能的一个难以抓住的前沿。
- en: Attempting to attribute understanding to algorithms that primarily learn patterns
    to produce text is analogous to attributing mathematical understanding to a pocket
    calculator that rapidly performs arithmetic calculations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试将主要学习模式以产生文本的算法归因为具有理解能力，就好比将快速执行算术计算的口袋计算器归因为具有数学理解能力是类似的。
- en: The two questions that follow could have been easily answered if ChatGPT possessed
    the ability to understand their meaning and relate them to real-world knowledge.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ChatGPT具有理解意义并将其与现实世界知识联系起来的能力，接下来的两个问题将很容易回答。
- en: 'Question 1: A hunter shoots a branch with three birds and kills one. How many
    are left? (figure 5.7)'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 问题1：一个猎人朝一棵有三只鸟的树枝开了一枪，打死了一只。还剩下多少只鸟？（图5.7）
- en: '![figure](../Images/5-7.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-7.png)'
- en: Figure 5.7 AI missed the subtlety of the question and returned an incorrect
    response.
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.7 AI错过了问题的微妙之处，并返回了错误的响应。
- en: Although the answer to this question is available online, ChatGPT’s response
    was “If the hunter shoots a branch with three birds and kills one, then there
    will be two birds left on the branch.” However, the correct answer is zero, as
    other birds would likely fly away due to the noise of the gunshot. ChatGPT’s response
    illustrates its reliance on pattern-matching and a lack of the ability to infer
    context as a human would. Furthermore, providing the correct response to ChatGPT
    does not necessarily lead to genuine learning or understanding on the AI’s part.
    While it may increase the probability of the correct response being generated
    in similar situations, it does not indicate true comprehension or reasoning. This
    highlights a challenge in AI development, where models like ChatGPT can generate
    seemingly plausible answers without a deep understanding of the content or context.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个问题的答案可以在网上找到，但ChatGPT的回应是“如果猎人打了一根有三只鸟的树枝并打死了一只，那么树枝上会剩下两只鸟。”然而，正确的答案是零，因为其他鸟可能会因枪声飞走。ChatGPT的回应说明了它对模式匹配的依赖和缺乏像人一样推断上下文的能力。此外，提供正确的答复给ChatGPT并不一定导致AI真正的学习或理解。尽管这可能增加在类似情况下生成正确响应的概率，但它并不表明真正的理解或推理。这突显了AI发展中的一项挑战，在那里像ChatGPT这样的模型可以生成看似合理的答案，而不必深刻理解内容或上下文。
- en: 'Question 2: Suppose I’m on the 10th floor, and I ask someone, could you please
    take this bucketful of water and run to the reception area on the first floor?
    What happens?'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 问题2：假设我在第10层，我让某人拿着一桶水跑到一楼的接待区。会发生什么？
- en: I submitted the query “running with a bucket full of water splash” to Google
    and obtained more than 16 million search results (figure 5.8). Consequently, it’s
    reasonable to assume that ChatGPT had access to ample information to deduce the
    fundamental outcomes associated with running while carrying a bucket full of water
    (figure 5.9).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我向谷歌提交了查询“拿着一桶水跑溅开”并获得了超过1600万条搜索结果（图5.8）。因此，合理地假设ChatGPT可以获得充分的信息来推断在拿着一桶水奔跑时可能出现的基本结果（图5.9）。
- en: '![figure](../Images/5-8.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-8.png)'
- en: Figure 5.8 Illustration of information readily available in Google (16.2 million
    results)
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.8 谷歌提供的信息示例（1600万条结果）
- en: '![figure](../Images/5-9.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-9.png)'
- en: Figure 5.9 AI returns results unrelated to the query, making it evident that
    the response was computer-generated.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.9 AI返回与查询无关的结果，表明响应是由计算机生成的。
- en: The reply is self-explanatory. Although the algorithm appeared to recognize
    the concept of sloshing, its emphasis on gravity and acceleration was completely
    unrelated, making it evident that the response was computer generated. Substituting
    the term “bucketful” with “glass” only made the response appear even more bizarre
    (figure 5.10).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 回答不言自明。尽管算法似乎识别到了"泼溅"这个概念，但它对重力和加速度的强调完全无关紧要，这表明响应是由计算机生成的。将术语"桶装满"替换为"玻璃"只会使响应看起来更加离奇（图5.10）。
- en: '![figure](../Images/5-10.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-10.png)'
- en: Figure 5.10 AI returns an unclear and logically incoherent response.
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.10 人工智能返回的回答不清晰且逻辑上不连贯。
- en: Once more, the algorithm’s reply remains disconnected from the subject, unclear,
    and devoid of logical coherence. Human understanding encompasses a substantial
    nonlinguistic component, which AI struggles to encompass, given the vast complexity
    of reality and its myriad subtleties. In our human interactions, we possess an
    understanding of our intended message, carefully selecting words in response to
    the context and considering the potential consequences and reactions. We convey
    not only the dictionary definitions of our words but also imply deeper nuances
    and infer meanings beyond their literal interpretations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，算法的回答仍然与主题无关，不清晰，并且缺乏逻辑连贯性。人类的理解涵盖了相当大的非语言成分，而人工智能难以涵盖，考虑到现实的巨大复杂性及其无数的微妙之处。在我们的人际交往中，我们对我们打算传达的信息有理解，在回应上下文时精选单词，并考虑潜在的后果和反应。我们传达的不仅是词语的词典定义，还暗示着更深层次的细微差别，并推断出超出字面解释的含义。
- en: 5.7 Benefits of LLMs
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.7 LLMs 的优势
- en: Generative AI stands as a remarkable technological advancement with the potential
    to bring about a transformative effect across a multitude of industries. Its far-reaching
    implications signify a significant milestone in the evolution of AI algorithms,
    offering the promise of enhanced productivity and innovation in various domains.
    One of the most compelling aspects of generative AI is its capacity to revolutionize
    content creation. This technology empowers creative professionals, such as designers,
    writers, and artists, by enabling the generation of highly realistic images, videos,
    and text. By automating the creative process, it streamlines workflows, potentially
    freeing up valuable time for these creators to focus on refining their ideas rather
    than grappling with the complexity of content generation. Furthermore, generative
    AI is transforming natural language understanding and generation. Chatbots and
    virtual assistants powered by these models can have more context-aware and human-like
    conversations, improving customer support and user interaction across various
    industries.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能是一项令人瞩目的技术进步，有潜力在多个行业带来变革性影响。其深远的影响意味着AI算法演进的重要里程碑，提供了增强生产力和创新的承诺，涉及各种领域。生成式人工智能最引人注目的一个方面之一是其改变内容创作的能力。这项技术使创意专业人士，如设计师、作家和艺术家能够生成高度逼真的图像、视频和文本。通过自动化创意过程，它简化了工作流程，潜在地为这些创作者节省宝贵的时间，使他们能够专注于完善他们的想法，而不是应对内容生成的复杂性。此外，生成式人工智能正在改变自然语言理解和生成。由这些模型驱动的聊天机器人和虚拟助手可以进行更具上下文感知性和人性化的对话，改善了各行各业的客户支持和用户互动。
- en: Education is another domain where generative AI has the potential to have a
    substantial effect. Students can benefit from quick access to synthesized information
    on various subjects, significantly reducing the time needed to acquire knowledge.
    For instance, asking questions about history or geography can yield summarized
    information drawn from numerous sources.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 教育是另一个领域，生成式人工智能有潜力产生重大影响。学生可以从快速获取各种主题的综合信息中受益，大大减少获取知识所需的时间。例如，询问历史或地理方面的问题可以得到总结自多个来源的信息。
- en: In the field of computer programming, generative AI could potentially eliminate
    the need for extensive reference manuals. These systems can use their extensive
    knowledge base to swiftly generate code solutions, a process that might take a
    junior programmer hours of trial and error. By learning from specialized resources
    like StackOverflow, LLMs can become invaluable tools for developers seeking to
    solve complex coding challenges efficiently.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机编程领域，生成式人工智能可能会消除对广泛参考手册的需求。这些系统可以利用它们丰富的知识库快速生成代码解决方案，这个过程可能会让初级程序员花费数小时进行试错。通过从诸如StackOverflow之类的专业资源学习，LLMs可以成为寻求高效解决复杂编码挑战的开发人员的无价工具。
- en: Moreover, in the business of customer support, generative AI can be harnessed
    to provide procedural responses to common user inquiries. These responses can
    be derived from extensive training with software documentation, ensuring consistency
    and efficiency in addressing user needs. In conclusion, generative AI represents
    a paradigm shift in how we approach creativity, communication, education, and
    problem-solving.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在客户支持业务中，生成AI可以用于对常见用户查询提供程序化响应。这些响应可以通过与软件文档的广泛培训而获得，以确保在满足用户需求方面的一致性和效率。总之，生成AI代表了我们在创造性、沟通、教育和问题解决方面的一种范式转变。
- en: 5.8 LLM limits
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8 LLM限制
- en: 'While LLMs exhibit remarkable capabilities in pattern recognition, they also
    exhibit certain limitations:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LLM在模式识别方面表现出卓越的能力，但它们也表现出一定的局限性：
- en: '*Dependence on input quality* —The quality of LLM-generated outputs is heavily
    reliant on the quality of the input data. Concerns about the “garbage-in, garbage-out”
    (GIGO) principle persist, as large datasets may lack diversity, and online data
    often contains negative or false information. Consequently, there is a risk that
    biased or erroneous training data can influence the LLM’s outputs.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*依赖输入质量* —LLM生成的输出质量严重依赖于输入数据的质量。对于“垃圾进，垃圾出”（GIGO）原则的担忧仍然存在，因为大型数据集可能缺乏多样性，而在线数据通常包含负面或虚假信息。因此，存在有偏见或错误的训练数据可能会影响LLM的输出。'
- en: '*Computational intensity* —LLMs demand significant computational resources
    for both training and operation due to their reliance on vast datasets and substantial
    computing power.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算密集度* —LLM对于训练和运算都需要大量的计算资源，因为它们依赖于庞大的数据集和大量的计算能力。'
- en: '*Hallucinations and incoherent text* —LLMs can generate text that lacks coherence
    and context, often producing content that doesn’t make sense due to their limited
    understanding of human language.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*幻觉和不连贯的文本* —LLM可以生成缺乏连贯性和上下文的文本，通常生成由于其对人类语言的理解有限而毫无意义的内容。'
- en: '*Repetition and lack of creativity* —LLM-generated content can be repetitive
    and lack creativity, resulting in outputs that feel formulaic or uninspired.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*重复和缺乏创造性* —由LLM生成的内容可能会重复，缺乏创意，导致产出的内容感觉呆板或乏味。'
- en: '*Lack of interpretability* —Since LLMs are based on deep learning, a technology
    that doesn’t provide insights into decision-making processes or output generation,
    their results are challenging to interpret or explain.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缺乏可解释性* —由于LLM是基于深度学习的，深度学习技术并不提供对决策过程或输出生成的洞察，所以它们的结果很难解释或解释。'
- en: '*Security concerns* —LLMs can be harnessed to create harmful content, such
    as deepfakes and disinformation, posing significant security risks.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安全问题* —LLM可以被利用来创建有害内容，如Deepfake和虚假信息，从而构成重大的安全风险。'
- en: '*Limited learning capacity* —LLMs have a constrained learning capacity because
    they do not possess inherent expertise. As demonstrated in chapter 3, many domains,
    including medicine, involve implicit knowledge that isn’t readily captured by
    LLMs, highlighting the limits of their learning capabilities.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习能力有限* —LLM的学习能力受到限制，因为它们没有固有的专业知识。正如第3章所示，许多领域，包括医学，在LLM无法轻松捕捉的隐含知识方面，突显了它们学习能力的限制。'
- en: 5.9 Generative AI and intellectual property
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.9 生成AI与知识产权
- en: Concerns have arisen among artists, authors, and news publishers regarding the
    utilization of their intellectual property in the training of generative AI (figure
    5.11). On July 7, 2023, ChatGPT4 acknowledged that its training procedure incorporated
    an extensive corpus of text data sourced from diverse internet outlets, encompassing
    books, articles, websites, and assorted written content.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 艺术家、作家和新闻出版商对于生成AI在训练中利用他们的知识产权的利用引发了关注（图5.11）。2023年7月7日，ChatGPT4承认，其训练过程包括了源自各种互联网渠道的大量文本数据，涵盖了书籍、文章、网站和各种书面内容。
- en: '![figure](../Images/5-11.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-11.png)'
- en: Figure 5.11 ChatGPT’s answer to a query about the source of the data it uses
    raises concerns about IP rights and accuracy.
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.11 ChatGPT对于其所使用的数据来源的查询的回答引发了关于知识产权和准确性的担忧。
- en: 'Robert Thomson, the CEO of News Corp, issued a warning regarding the potential
    jeopardy to intellectual property rights. He stated [13]:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 罗伯特·汤姆森，新闻集团的首席执行官，发出了关于知识产权潜在危险的警告。他声明[13]：
- en: To begin with, our content is being collected, scraped, and otherwise absorbed
    for the purpose of training AI systems. Secondly, individual stories may emerge
    prominently in specific searches. And, thirdly, our content could be synthesized
    and presented as original when, in reality, it is an extraction of editorial essence.
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 首先，我们的内容正在被收集、抓取和其他方式吸收，目的是用于训练 AI 系统。其次，个别故事可能会在特定搜索中突出出现。第三，我们的内容可能被合成并呈现为原创，而实际上它是编辑精髓的提取。
- en: The concerns surrounding intellectual property are well-founded, as some AI
    companies derive their value from the utilization and repurposing of creative
    works produced by countless individuals. Without access to such content, the existence
    of generative AI models like ChatGPT might be doubtful. It presents a paradox
    that companies reusing the contributions of artists, advertisers, and writers
    could inadvertently jeopardize the livelihoods of these very creators.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕知识产权的担忧是有根据的，因为一些 AI 公司从数以千计的个人创作的作品的利用和重新利用中获得价值。如果没有这些内容的访问权限，像 ChatGPT
    这样的生成式 AI 模型的存在可能是值得怀疑的。这提出了一个悖论，即公司重新利用艺术家、广告商和作家的贡献可能会无意中危及这些创作者的生计。
- en: 5.10 Risks of generative AI
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.10 生成式 AI 的风险
- en: Generative AI programs pose a significant risk due to their propensity for fabricating
    information. A recent case reported by the BBC highlights this concern, where
    a New York lawyer is facing a lawsuit for utilizing ChatGPT in his legal research.
    The lawyer’s firm submitted a brief referencing various past court cases, six
    of which were later identified as fictitious, complete with fabricated quotes
    and citations. ChatGPT generated this false information. Attached screenshots
    from the conversation between the lawyer and ChatGPT reveal the lawyer inquiring,
    “Is Varghese a real case?” to which ChatGPT affirmed, and when pressed for its
    source, ChatGPT reiterated that the case was genuine and accessible on legal databases
    like LexisNexis and Westlaw. The authenticity of the other five made-up cases
    was similarly asserted. The lawyer informed the court that he was “unaware that
    its content could be false” but now faces potential disciplinary action from the
    judge.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 程序由于其制造信息的倾向而构成重大风险。BBC 最近报道的一个案例突显了这一担忧，一位纽约律师因在其法律研究中使用 ChatGPT 而面临诉讼。该律师所在的律所提交了一份引用了各种过去法庭案件的简要文件，其中六个后来被确认为虚构的，包括虚构的引语和引文。ChatGPT
    生成了这些虚假信息。律师和 ChatGPT 之间的对话截图显示了律师询问：“Varghese 是真实的案例吗？” ChatGPT 确认，当被追问其来源时，ChatGPT
    重申该案例是真实的，并且可以在 LexisNexis 和 Westlaw 等法律数据库上找到。另外五个捏造的案例的真实性也得到了类似的断言。律师通知法庭，他“不知道其内容可能是虚假的”，但现在可能面临法官的纪律行动。
- en: A second instance of this risk was reported by *The Wall Street Journal* [14]
    regarding a chatbot designed to assist individuals with eating disorders like
    anorexia. Following an update with generative AI, the bot started advocating for
    dieting and calorie reduction. Clearly, such recommendations could be highly detrimental
    to individuals struggling with eating disorders, prompting the National Eating
    Disorders Association to quickly remove the bot from its platform.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个此风险的实例由《华尔街日报》[14] 报告，涉及一个设计用于协助患有厌食症等进食障碍的聊天机器人。在进行了生成式 AI 的更新后，该机器人开始主张节食和减少卡路里摄入。显然，这样的建议可能对于与进食障碍抗争的个人具有极大的危害，促使国家进食障碍协会迅速将机器人从其平台上移除。
- en: The present inability of generative AI to reason or comprehend can lead to adverse
    outcomes in various ways. For instance, despite incorporating explicit safety
    protocols and impressive generative capabilities, ChatGPT was manipulated into
    displaying instructions for constructing explosive devices, a feature learned
    from its training data [15]. While the ChatGPT team swiftly addressed this issue
    by implementing safeguards, it’s essential to acknowledge the resourcefulness
    of ill-intentioned individuals in devising new methods to exploit such programs,
    akin to the sophistication demonstrated by certain cybercriminals who continually
    innovate hacking techniques and fraudulent schemes. Given ChatGPT’s inability
    to discern that disseminating instructions for creating a harmful device contradicts
    its safety mandate, it may be prudent to reassess our optimism regarding some
    of its other achievements.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能目前无法推理或理解可能导致各种不良结果。例如，尽管ChatGPT融合了明确的安全协议和令人印象深刻的生成能力，但它被操纵成显示制造爆炸装置的指示，这是从其训练数据中学习到的功能。尽管ChatGPT团队迅速采取了措施解决了这个问题，但我们必须承认恶意个体在想出利用这种程序的新方法方面的足智多谋，类似于某些网络犯罪分子不断创新的黑客技术和欺诈计划所展示的复杂性。鉴于ChatGPT无法辨别传播制造有害装置指令与其安全任务相矛盾的事实，重新评估我们对其其他成就的乐观态度可能是明智的。
- en: 'There is also the risk of individuals unquestioningly accepting all generative
    AI outputs at face value. In his 1976 book *Computer Power and Human Reason* [16],
    Joseph Weizenbaum, the creator of the first chatbot, ELIZA in 1966 emphasized
    this concern:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 个体毫无疑问地接受所有生成式人工智能产出的风险也存在着。在他1976年的著作《计算机力量与人类理性》中，首个聊天机器人ELIZA的创造者约瑟夫·韦泽那鲍姆强调了这一问题：
- en: ELIZA created the most remarkable illusion of having understood in the minds
    of the many people who conversed with it. People who knew very well that they
    were conversing with a machine soon forgot that fact, just as theatergoers, in
    the grip of suspended disbelief, soon forget that the action they are witnessing
    is not “real.”
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ELIZA在与它交谈的许多人心中创造了最令人瞩目的假象，即它理解了他们的思想。那些非常清楚他们正在与一台机器交谈的人很快就会忘记这个事实，就像戏剧观众在悬念中的虚构中很快忘记他们所见的行动并非“真实”一样。
- en: Weizenbaum further pointed out that individuals with limited or no knowledge
    of computers tended to be particularly susceptible to this illusion. They frequently
    insisted on engaging with the system in private, and despite any objections from
    the program’s creator, they would firmly maintain that they had been understood.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Weizenbaum进一步指出，那些对计算机知识有限或根本没有知识的个人往往对这种幻觉特别容易受到影响。他们经常坚持在私下与系统交流，尽管程序的创建者可能提出异议，但他们仍然坚决地声称他们被理解了。
- en: Increasingly, both institutions and individuals are becoming reliant on automated
    systems and AI in their daily operations. It’s common for people to unquestionably
    accept the results generated by their computers, assuming that AI will always
    provide truthful information. However, our world is plagued by the proliferation
    of fake news, and the rise of generative AI technology poses a serious concern.
    It has the potential to flood the internet with text, images, and videos that
    are nearly indistinguishable from genuine content, making it difficult to discern
    what is real and what is fake. The dangers extend to the manipulation of public
    opinion through propaganda, which often relies on repeated messaging.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越多的机构和个人在日常运营中依赖自动化系统和人工智能。人们普遍会毫不犹豫地接受计算机生成的结果，并假设人工智能总是会提供真实的信息。然而，我们的世界受到虚假新闻的泛滥困扰，生成式人工智能技术的崛起引起了严重关注。它有可能在互联网上充斥着几乎无法辨别真假的文本、图片和视频，使人们难以分辨什么是真实的，什么是虚假的。危险还延伸到通过宣传操纵公众舆论，这种宣传往往依赖于重复的信息。
- en: Consider the catastrophic consequences that could arise from the fusion of disinformation
    and AI-generated content. Imagine someone using generative AI to fabricate a video
    depicting a group of individuals burning a sacred book, potentially inciting extreme
    reactions from fanatical groups. Furthermore, there have been instances where
    LLMs have provided fabricated responses and inappropriate suggestions, raising
    concerns about their use in critical applications such as emergency response or
    law enforcement. Relying on a system that consistently generates nonsensical answers
    is clearly untenable. Imagine employing such a system for medical recommendations;
    the risks are evident. Another worrisome aspect is the possibility that students
    may turn to generative AI tools for their academic assignments. Since these programs
    can only regurgitate information that has already been conceived, written, or
    created by humans, there is a legitimate concern that we might foster a generation
    of students who mindlessly echo “Chat GPT told me so” in unison.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，虚假信息和人工智能生成内容相结合可能带来的灾难性后果。想象一下，有人使用生成式人工智能来制造一个视频，描绘一群人焚烧一本神圣的书，这可能引发狂热团体的极端反应。此外，已经发生过
    LLM 提供虚假回答和不当建议的情况，引发了人们对其在紧急响应或执法等关键应用中使用的担忧。依赖于一个持续生成荒谬答案的系统显然是不可行的。想象一下，将这样的系统用于医疗建议；风险是明显的。另一个令人担忧的方面是，学生可能会求助于生成式人工智能工具完成他们的学术作业。由于这些程序只能重复人类已经构思、编写或创建的信息，人们担心我们可能会培养一代学生，他们心不在焉地异口同声地重复“Chat
    GPT 告诉我的”。
- en: 'An article in the British newspaper *The Guardian*, titled “The Stupidity of
    AI” [17], succinctly summarizes the risks associated with placing unwavering trust
    in this type of technology:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇英国《卫报》（*The Guardian*）的文章，题为《人工智能的愚蠢》[17]，简洁地总结了对这种类型技术产生盲目信任所带来的风险：
- en: The belief in this kind of AI as actually knowledgeable or meaningful is actively
    dangerous. It risks poisoning the well of collective thought, and of our ability
    to think at all. If, as is being proposed by technology companies, the results
    of ChatGPT queries will be provided as answers to those seeking knowledge online,
    and if, as has been proposed by some commentators, ChatGPT is used in the classroom
    as a teaching aide, then its hallucinations will enter the permanent record, effectively
    coming between us and more legitimate, testable sources of information, until
    the line between the two is so blurred as to be invisible.
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 相信这种人工智能实际上是有知识或有意义的是极其危险的。它有可能毒化我们集体思维的源泉，以及我们思考的能力。如果像技术公司所提议的那样，ChatGPT 的查询结果将作为在线寻求知识的人的答案提供，如果像一些评论员所提议的那样，在课堂上作为教学辅助工具使用
    ChatGPT，那么它的幻觉将进入永久记录，有效地阻碍我们与更合法、可测试的信息源之间的接触，直到两者之间的界限变得如此模糊以至于看不见。
- en: 5.11 LLMs and the Illusion of Understanding
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.11 LLM 和理解的幻觉
- en: LLM technology stands as a testament to the ever-expanding horizons of AI, consistently
    pushing the boundaries of what was once thought to be exclusive to human capabilities.
    Nevertheless, the current fervor surrounding LLMs echoes the excitement witnessed
    in 2011 when IBM’s Watson outperformed two of Jeopardy’s top champions. At that
    time, Watson gained acclaim for its adept handling of complex questions and optimal
    answer-finding abilities [18]. Bold declarations hailed Watson as a game-changer,
    with assertions that it could revolutionize information-rich sectors, particularly
    those inundated with vast volumes of unstructured and semi-structured data, such
    as healthcare, banking, insurance, and telecommunications. Have these predictions
    come to fruition? Not entirely, and similar outcomes are expected for numerous
    ambitious predictions regarding LLMs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 技术是人工智能不断拓展边界的明证，始终在推动曾被认为是人类专属能力的界限。然而，当前围绕 LLM 的热情与 2011 年 IBM 的沃森（Watson）击败两位“危险边缘”（Jeopardy）的顶尖冠军所见的激动相呼应。当时，沃森因其处理复杂问题的娴熟技巧和优秀的答案找寻能力而赢得赞誉
    [18]。大胆的宣言称沃森将改变游戏规则，断言它可以彻底改革信息丰富的领域，特别是那些充斥着大量非结构化和半结构化数据的领域，如医疗保健、银行业、保险业和电信业。这些预测是否应验？并非完全如此，对于
    LLM 的众多雄心勃勃的预测也有类似的结果预期。
- en: 'Much like other AI programs, LLMs essentially execute a predetermined set of
    logical operations. Earlier iterations of neural networks and algorithms, like
    backpropagation, were characterized by limited layers, parameters, and data-processing
    capabilities. Present-day deep learning algorithms rely on supercomputers to train
    on extensive datasets, yet the core outcome remains fairly consistent: they discern
    patterns without genuine reasoning or understanding. To draw a comparison, consider
    the evolution of pocket calculators over the past half-century. The initial models
    could solely perform basic arithmetic operations like addition, subtraction, multiplication,
    and division. However, modern calculators rely on enhanced memory and powerful
    hardware to perform complex functions such as logarithms, trigonometric operations,
    and hyperbolic functions. Some can even generate colorful 3D surface graphs.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他人工智能程序类似，LLMs本质上执行一组预定的逻辑操作。神经网络和算法的早期版本，如反向传播，以有限的层次、参数和数据处理能力为特征。现今的深度学习算法依赖于超级计算机对庞大数据集进行训练，然而核心结果仍然相当一致：它们在没有真正推理或理解的情况下识别模式。为了进行比较，考虑一下过去半个世纪口袋计算器的发展。最初的型号只能执行基本的算术运算，如加法、减法、乘法和除法。然而，现代计算器依赖于增强的存储器和强大的硬件来执行诸如对数、三角函数运算和双曲函数等复杂功能。一些甚至可以生成彩色的3D曲面图。
- en: It is well-established that the English language contains dictionaries with
    fewer than 500,000 entries, and most English speakers employ only a fraction of
    those words in their daily communication. Consequently, achieving a competent
    command of English seems to be a relatively modest objective, given the millions
    who achieve it annually. Additionally, human-generated text exhibits a high degree
    of correlation, making it easily predictable. The patterns and statistical relationships
    are inherent in the data, and individuals can accurately anticipate sentence completions
    based on these cues. In stark contrast, LLMs function as advanced predictive text
    systems, analyzing preceding words to generate the most probable following word.
    While this automated process might appear to produce intelligent outputs, it is
    essentially an artificial imitation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，英语词典的词条少于50万个，而大多数英语使用者在日常交流中只使用其中的一小部分。因此，获得英语的熟练掌握似乎是一个相对较为温和的目标，考虑到每年能够实现这一目标的人数有数百万人。此外，人类生成的文本表现出高度的相关性，使其易于预测。这些模式和统计关系固有于数据中，个体可以根据这些线索准确地预测句子的完成。与此形成鲜明对比的是，LLMs作为高级预测文本系统，分析前面的词以生成最可能的后续词。虽然这一自动化过程似乎会产生智能输出，但实质上它只是人工模拟。
- en: Human communication relies on innate knowledge encompassing space, time, and
    various fundamental aspects of the world. For instance, when someone types “The
    sky is blue,” we comprehend it due to our familiarity with the sensations and
    meanings associated with the words *sky* and *blue*. In contrast, LLMs glean their
    understanding from conversations, comments, books, and websites, where the co-occurrence
    of certain words is observed. The essence of human text, which comprises nuanced
    context, eludes deep learning algorithms, regardless of their extensive parameter
    count and impressive pattern recognition capabilities. Generative AI lacks the
    capacity to introduce entirely novel concepts or ideas; it merely rearranges existing
    elements.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 人类沟通依赖于囊括空间、时间和世界各种基本方面的内在知识。例如，当有人输入“天空是蓝色”的时候，我们理解这句话是因为我们熟悉与“天空”和“蓝色”这两个词相关的感觉和含义。相比之下，LLMs从对话、评论、书籍和网站中获取理解，那里观察到了某些词的共现。人类文本的本质，包括细微的语境，无论其参数数量和出色的模式识别能力如何丰富，深度学习算法都无法捕捉到。生成式人工智能缺乏引入全新概念或想法的能力；它只是重新排列现有元素。
- en: In my perspective, embracing these systems carries the risk of transitioning
    from a world where knowledge is cumulative and rigorously validated to one where
    knowledge is approximated and challenging to verify. I believe that LLMs serve
    as a striking example of the “AI illusions” alluded to in the title of this book.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 从我的角度来看，拥抱这些系统存在着从知识是累积的且严格验证的世界过渡到知识是近似的且难以验证的世界的风险。我认为LLMs是本书标题中提到的“AI幻觉”的一个鲜明例子。
- en: Summary
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative AI relies on vast datasets and substantial computing resources.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能依赖于庞大的数据集和大量的计算资源。
- en: LLMs like ChatGPT often produce repetitive text and can generate content that
    isn’t accurate, a phenomenon known as *hallucination*.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs如ChatGPT经常产生重复的文本，并且可能生成不准确的内容，这种现象被称为*幻觉*。
- en: Generative AI programs are rooted in deep learning, lacking the capability to
    explain their output-generation process.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI程序根植于深度学习，缺乏解释其输出生成过程的能力。
- en: LLMs can be manipulated to generate harmful content, including deepfakes and
    various forms of disinformation.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs可以被操纵以生成有害的内容，包括深度伪造和各种形式的虚假信息。
- en: AI communication is notably limited compared to human interaction, as AI lacks
    a genuine understanding of text, audio, or images.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与人类互动相比，AI通信明显受限，因为AI缺乏对文本、音频或图像的真正理解。
- en: Human communication encompasses more than words; it relies heavily on context
    and concepts such as metaphor, analogy, and sarcasm, which are challenging for
    AI to grasp.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类交流不仅仅是言辞; 它在很大程度上依赖于上下文和诸如隐喻、类比和讽刺等概念，这些概念对于AI来说是具有挑战性的。
- en: While generative AI marks significant progress, it is still subject to numerous
    limitations and associated risks.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管生成式AI标志着重大进展，但它仍然受到许多限制和相关风险的影响。
- en: Like other AI algorithms, the quality of generative AI output is heavily influenced
    by the quality of the input data and prompts.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他AI算法一样，生成式AI输出的质量受输入数据和提示的质量的重大影响。
- en: Despite advancements, AI lacks the human ability to generalize and adapt to
    diverse contexts effectively.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管有所进展，AI缺乏人类的泛化能力，并不能有效地适应多样的情境。
