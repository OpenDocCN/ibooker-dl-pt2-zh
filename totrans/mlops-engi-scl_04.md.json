["```py\nwget -q https://gist.githubusercontent.com/osipov/ \n➥ 1fc0265f8f829d9d9eee8393657423a9/ \n➥ raw/9957c1f09cdfa64f8b8d89cfec532a0e150d5178/trips_sample.csv\n\nls -ltr trips_sample.csv\n\ncat trips_sample.csv\n```", "```py\naws s3 cp trips_sample.csv s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION\n➥ /samples/trips_sample.csv\n\naws s3 ls s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/samples/\n➥ trips_sample.csv\n```", "```py\necho s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/athena/\n```", "```py\naws athena create-work-group --name dc_taxi_athena_workgroup \\\n--configuration \"ResultConfiguration={OutputLocation=\n➥ s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/athena},\n➥ EnforceWorkGroupConfiguration=false,PublishCloudWatchMetricsEnabled=false\"\n```", "```py\nCREATE EXTERNAL TABLE IF NOT EXISTS dc_taxi_db.dc_taxi_csv_sample_strings(\n        fareamount STRING,\n        origin_block_latitude STRING,\n        origin_block_longitude STRING,\n        destination_block_latitude STRING,\n        destination_block_longitude STRING\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nLOCATION 's3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/samples/'\nTBLPROPERTIES ('skip.header.line.count'='1');\n```", "```py\nSQL=\"                                                     ❶\nCREATE EXTERNAL TABLE IF NOT EXISTS dc_taxi_db.dc_taxi_csv_sample_strings(\n        fareamount STRING,\n        origin_block_latitude STRING,\n        origin_block_longitude STRING,\n        destination_block_latitude STRING,\n        destination_block_longitude STRING\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nLOCATION 's3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/samples/'\nTBLPROPERTIES ('skip.header.line.count'='1');\"\n\nATHENA_QUERY_ID=$(aws athena start-query-execution \\\n--work-group dc_taxi_athena_workgroup \\\n--query 'QueryExecutionId' \\\n--output text \\\n--query-string \"$SQL\")                                   ❷\n\necho $SQL\n\necho $ATHENA_QUERY_ID\nuntil aws athena get-query-execution \\                   ❸\n  --query 'QueryExecution.Status.State' \\\n  --output text \\\n  --query-execution-id $ATHENA_QUERY_ID | grep -v \"RUNNING\";\ndo\n  printf '.'\n  sleep 1;\ndone\n```", "```py\nwget -q https://raw.githubusercontent.com/osipov/smlbook/master/utils.sh\nls -l utils.sh\n```", "```py\nsource utils.sh\nSQL=\"\nSELECT\n\norigin_block_latitude || ' , ' || origin_block_longitude\n    AS origin,\n\ndestination_block_latitude || '  , ' || destination_block_longitude\n    AS destination\n\nFROM\n    dc_taxi_db.dc_taxi_csv_sample_strings\n\"\nathena_query_to_table \"$SQL\" \\\n\"ResultSet.Rows[*].[Data[0].VarCharValue,Data[1].VarCharValue]\"\n```", "```py\n%%bash\nsource utils.sh ; athena_query \"\nCREATE EXTERNAL TABLE IF NOT EXISTS dc_taxi_db.dc_taxi_csv_sample_double(\n        fareamount DOUBLE,\n        origin_block_latitude DOUBLE,\n        origin_block_longitude DOUBLE,\n        destination_block_latitude DOUBLE,\n        destination_block_longitude DOUBLE\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nLOCATION 's3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/samples/'\nTBLPROPERTIES ('skip.header.line.count'='1');\n\"\n```", "```py\nsource utils.sh ; athena_query_to_pandas \"\nSELECT ROUND(MAX(fareamount) - MIN(fareamount), 2)\nFROM dc_taxi_db.dc_taxi_csv_sample_double\n\"\n```", "```py\nimport pandas as pd\ndef awscli_to_df():\n  json_df = pd.read_json('/tmp/awscli.json')\n  df = pd.DataFrame(json_df[0].tolist(), index = json_df.index, \\\n    columns = json_df[0].tolist()[0]).drop(0, axis = 0)\n\n  return df\n```", "```py\nsource utils.sh ; athena_query_to_pandas \"\nSELECT fareamount_double,\n         origindatetime_tr,\n         origin_block_latitude_double,\n         origin_block_longitude_double,\n         destination_block_latitude_double,\n         destination_block_longitude_double\nFROM dc_taxi_db.dc_taxi_parquet\nLIMIT 10\n\"\n```", "```py\nsource utils.sh ; athena_query_to_pandas \"\nSELECT\n    (SELECT COUNT(*) FROM dc_taxi_db.dc_taxi_parquet) AS total,\n    COUNT(*) AS null_origindate_time_total\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE\n    origindatetime_tr IS NULL\n\"\n```", "```py\nSELECT\n    (SELECT COUNT(*) FROM dc_taxi_db.dc_taxi_parquet)\n    - COUNT(DATE_PARSE(origindatetime_tr, '%m/%d/%Y %H:%i'))\n    AS origindatetime_not_parsed\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE\n    origindatetime_tr IS NOT NULL;\n```", "```py\nSELECT\n    ROUND(100.0 * COUNT(*) / (SELECT COUNT(*)\n                        FROM dc_taxi_db.dc_taxi_parquet), 2)\n\n        AS percentage_null,\n\n    (SELECT COUNT(*)\n     FROM dc_taxi_db.dc_taxi_parquet\n     WHERE origin_block_longitude_double IS NULL\n     OR origin_block_latitude_double IS NULL)\n\n        AS either_null,\n\n    (SELECT COUNT(*)\n     FROM dc_taxi_db.dc_taxi_parquet\n     WHERE origin_block_longitude_double IS NULL\n     AND origin_block_latitude_double IS NULL)\n\n        AS both_null\n\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE\n    origin_block_longitude_double IS NULL\n    OR origin_block_latitude_double IS NULL\n```", "```py\nSELECT\n    ROUND(100.0 * COUNT(*) / (SELECT COUNT(*)\n                        FROM dc_taxi_db.dc_taxi_parquet), 2)\n\n        AS percentage_null,\n\n    (SELECT COUNT(*)\n     FROM dc_taxi_db.dc_taxi_parquet\n     WHERE destination_block_longitude_double IS NULL\n     OR destination_block_latitude_double IS NULL)\n\n        AS either_null,\n\n    (SELECT COUNT(*)\n     FROM dc_taxi_db.dc_taxi_parquet\n     WHERE destination_block_longitude_double IS NULL\n     AND destination_block_latitude_double IS NULL)\n\n        AS both_null\n\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE\n    destination_block_longitude_double IS NULL\n    OR destination_block_latitude_double IS NULL\n```", "```py\nSELECT\n    COUNT(*)\n      AS total,\n\n    ROUND(100.0 * COUNT(*) / (SELECT COUNT(*)\n                              FROM dc_taxi_db.dc_taxi_parquet), 2)\n      AS percent\n\nFROM\n    dc_taxi_db.dc_taxi_parquet\n\nWHERE\n    origin_block_latitude_double IS NULL\n    OR origin_block_longitude_double IS NULL\n    OR destination_block_latitude_double IS NULL\n    OR destination_block_longitude_double IS NULL\n```", "```py\nSELECT\n    fareamount_string,\n    COUNT(fareamount_string) AS rows,\n    ROUND(100.0 * COUNT(fareamount_string) /\n          ( SELECT COUNT(*)\n            FROM dc_taxi_db.dc_taxi_parquet), 2)\n      AS percent\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE\n    fareamount_double IS NULL\n    AND fareamount_string IS NOT NULL\nGROUP BY\n    fareamount_string;\n```", "```py\nWITH\nsrc AS (SELECT\n            fareamount_double AS val\n        FROM\n            dc_taxi_db.dc_taxi_parquet),\n\nstats AS\n    (SELECT\n        MIN(val) AS min,\n        APPROX_PERCENTILE(val, 0.25) AS q1,\n        APPROX_PERCENTILE(val ,0.5) AS q2,\n        APPROX_PERCENTILE(val, 0.75) AS q3,\n        AVG(val) AS mean,\n        STDDEV(val) AS std,\n        MAX(val) AS max\n    FROM\n        src)\n\nSELECT\n    DISTINCT min, q1, q2, q3, max\n\nFROM\n    dc_taxi_db.dc_taxi_parquet, stats\n```", "```py\nWITH\nsrc AS (SELECT\n            COUNT(*) AS total\n        FROM\n            dc_taxi_db.dc_taxi_parquet\n        WHERE\n            fareamount_double IS NOT NULL)\n\nSELECT\n    ROUND(100.0 * COUNT(fareamount_double) / MIN(total), 2) AS percent\nFROM\n    dc_taxi_db.dc_taxi_parquet, src\nWHERE\n    fareamount_double < 3.25\n    AND fareamount_double IS NOT NULL\n```", "```py\nSELECT\n    fareamount_string,\n    ROUND( MIN(mileage_double), 2) AS min,\n    ROUND( APPROX_PERCENTILE(mileage_double, 0.25), 2) AS q1,\n    ROUND( APPROX_PERCENTILE(mileage_double ,0.5), 2) AS q2,\n    ROUND( APPROX_PERCENTILE(mileage_double, 0.75), 2) AS q3,\n    ROUND( MAX(mileage_double), 2) AS max\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE\n    fareamount_string LIKE 'NULL'\nGROUP BY\n    fareamount_string\n```", "```py\n    SELECT\n      MIN(lat) AS lower_left_latitude,\n      MIN(lon) AS lower_left_longitude,\n      MAX(lat) AS upper_right_latitude,\n      MAX(lon) AS upper_right_longitude\n\n     FROM (\n      SELECT\n        MIN(origin_block_latitude_double) AS lat,\n        MIN(origin_block_longitude_double) AS lon\n      FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n      UNION\n\n      SELECT\n        MIN(destination_block_latitude_double) AS lat,\n        MIN(destination_block_longitude_double) AS lon\n      FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n      UNION\n\n      SELECT\n        MAX(origin_block_latitude_double) AS lat,\n        MAX(origin_block_longitude_double) AS lon\n      FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n      UNION\n\n      SELECT\n        MAX(destination_block_latitude_double) AS lat,\n        MAX(destination_block_longitude_double) AS lon\n      FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n    )\n    ```", "```py\nWITH dc_taxi AS\n(SELECT *,\n    origindatetime_tr\n    || fareamount_string\n    || origin_block_latitude_string\n    || origin_block_longitude_string\n    || destination_block_latitude_string\n    || destination_block_longitude_string\n    || mileage_string AS objectid\n\n    FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n    WHERE fareamount_double >= 3.25\n            AND fareamount_double IS NOT NULL\n            AND mileage_double > 0 )\n\nSELECT AVG(mileage_double) AS average_mileage\nFROM dc_taxi\nWHERE objectid IS NOT NULL\nGROUP BY \n➥ MOD( ABS( from_big_endian_64( xxhash64( to_utf8( objectid ) ) ) ), 1000)\n```", "```py\nGROUP BY MOD(ABS(RAND()), 1000)\n```", "```py\nGROUP BY MOD(ABS(from_big_endian_64(xxhash64(to_utf8(objectid)))), 1000)\n```", "```py\nWITH dc_taxi AS\n(SELECT *,\n    origindatetime_tr\n    || fareamount_string\n    || origin_block_latitude_string\n    || origin_block_longitude_string\n    || destination_block_latitude_string\n    || destination_block_longitude_string\n    || mileage_string AS objectid\n\n    FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n    WHERE fareamount_double >= 3.25\n            AND fareamount_double IS NOT NULL\n            AND mileage_double > 0 ),\n\ndc_taxi_samples AS (\n    SELECT AVG(mileage_double) AS average_mileage\n    FROM dc_taxi\n    WHERE objectid IS NOT NULL\n    GROUP BY \n➥     MOD( ABS( from_big_endian_64( xxhash64( to_utf8( objectid ) ) ) ), 1000)\n)\nSELECT AVG(average_mileage) + 4 * STDDEV(average_mileage)\nFROM dc_taxi_samples\n```", "```py\nWITH dc_taxi AS\n(SELECT *,\n    origindatetime_tr\n    || fareamount_string\n    || origin_block_latitude_string\n    || origin_block_longitude_string\n    || destination_block_latitude_string\n    || destination_block_longitude_string\n    || mileage_string AS objectid\n\n    FROM \"dc_taxi_db\".\"dc_taxi_parquet\"\n\n    WHERE fareamount_double >= 3.25\n            AND fareamount_double IS NOT NULL\n            AND mileage_double > 0 ),\n\ndc_taxi_samples AS (\n    SELECT AVG(fareamount_double) AS average_fareamount\n    FROM dc_taxi\n    WHERE objectid IS NOT NULL\n    GROUP BY \n➥     MOD( ABS( from_big_endian_64( xxhash64( to_utf8( objectid ) ) ) ), 1000)\n)\nSELECT AVG(average_fareamount) + 4 * STDDEV(average_fareamount)\nFROM dc_taxi_samples\n```", "```py\nmeans = [15.96, 29.19, 48.89, 560, 2,422.45]\nsum(means) / len(means)\n\n179.748\n```", "```py\nSELECT\n    100.0 * COUNT(fareamount_double) /\n      (SELECT COUNT(*)\n      FROM dc_taxi_db.dc_taxi_parquet\n      WHERE fareamount_double IS NOT NULL) AS percent\nFROM\n    dc_taxi_db.dc_taxi_parquet\nWHERE (fareamount_double < 3.25 OR fareamount_double > 179.75)\n        AND fareamount_double IS NOT NULL;\n```", "```py\nWITH src AS (SELECT fareamount_double AS val\n             FROM dc_taxi_db.dc_taxi_parquet\n             WHERE fareamount_double IS NOT NULL\n             AND fareamount_double >= 3.25\n             AND fareamount_double <= 180.0),\nstats AS\n    (SELECT\n     ROUND(MIN(val), 2) AS min,\n     ROUND(APPROX_PERCENTILE(val, 0.25), 2) AS q1,\n     ROUND(APPROX_PERCENTILE(val, 0.5), 2) AS q2,\n     ROUND(APPROX_PERCENTILE(val, 0.75), 2) AS q3,\n     ROUND(AVG(val), 2) AS mean,\n     ROUND(STDDEV(val), 2) AS std,\n     ROUND(MAX(val), 2) AS max\n    FROM src)\nSELECT min, q1, q2, q3, max, mean, std\nFROM stats;\n```", "```py\nSELECT\n    MIN(origin_block_latitude_double) AS olat_min,\n    MIN(origin_block_longitude_double) AS olon_min,\n    MAX(origin_block_latitude_double) AS olat_max,\n    MAX(origin_block_longitude_double) AS olon_max,\n    MIN(destination_block_latitude_double) AS dlat_min,\n    MIN(destination_block_longitude_double) AS dlon_min,\n    MAX(destination_block_latitude_double) AS dlat_max,\n    MAX(destination_block_longitude_double) AS dlon_max,\nFROM\n    dc_taxi_db.dc_taxi_parquet\n```", "```py\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nargs = getResolvedOptions(sys.argv, ['JOB_NAME',\n                                     'BUCKET_SRC_PATH',\n                                     'BUCKET_DST_PATH',\n                                     ])\nBUCKET_SRC_PATH = args['BUCKET_SRC_PATH']\nBUCKET_DST_PATH = args['BUCKET_DST_PATH']\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\nlogger = glueContext.get_logger()\nspark = glueContext.spark_session\n\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n\ndf = ( spark\n        .read\n        .parquet(f\"{BUCKET_SRC_PATH}\") )    ❶\n```", "```py\ndf.createOrReplaceTempView(\"dc_taxi_parquet\")    ❶\n\nquery_df = spark.sql(\"\"\"                         ❷\nSELECT\n    origindatetime_tr,\n    fareamount_double,\n    origin_block_latitude,\n    origin_block_longitude,\n    destination_block_latitude,\n    destination_block_longitude\n\nFROM\n    dc_taxi_parquet                              ❸\n\nWHERE                                            ❹\n    origindatetime_tr IS NOT NULL\n    AND fareamount_double IS NOT NULL\n    AND fareamount_double >= 3.25\n    AND fareamount_double <= 180.0\n    AND origin_block_latitude IS NOT NULL\n    AND origin_block_longitude IS NOT NULL\n    AND destination_block_latitude IS NOT NULL\n    AND destination_block_longitude IS NOT NULL\n\n\"\"\".replace('\\n', ''))                          ❺\n```", "```py\n#parse to check for valid value of the original timestamp\nfrom pyspark.sql.functions import col, to_timestamp, \\\n    dayofweek, year, month, hour\nfrom pyspark.sql.types import IntegerType\n\n#convert the source timestamp into numeric data needed for machine learning\nquery_df = (query_df\n  .withColumn(\"origindatetime_ts\", \\                      ❶\n    to_timestamp(\"origindatetime_tr\", \"dd/MM/yyyy HH:mm\"))\n  .where(col(\"origindatetime_ts\").isNotNull())\n  .drop(\"origindatetime_tr\")\n  .withColumn( 'year_integer',                            ❷\n    year('origindatetime_ts').cast(IntegerType()) )\n  .withColumn( 'month_integer',\n    month('origindatetime_ts').cast(IntegerType()) )\n  .withColumn( 'dow_integer',\n    dayofweek('origindatetime_ts').cast(IntegerType()) )\n  .withColumn( 'hour_integer',\n    hour('origindatetime_ts').cast(IntegerType()) )\n  .drop('origindatetime_ts') )\n\n#drop missing data and duplicates\nquery_df = ( query_df                                     ❸\n            .dropna()\n            .drop_duplicates() )\n```", "```py\n(query_df\n .write\n .parquet(f\"{BUCKET_DST_PATH}\", mode=\"overwrite\"))      ❶\ndef save_stats_metadata(df, dest, header = 'true', mode = 'overwrite'):\n  return (df.describe()\n    .coalesce(1)\n    .write\n    .option(\"header\", header)\n    .csv( dest, mode = mode ) )\n\nsave_stats_metadata(query_df,\n    f\"{BUCKET_DST_PATH}/.meta/stats\")                   ❷\n\njob.commit()\n```", "```py\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nargs = getResolvedOptions(sys.argv, ['JOB_NAME',\n                                     'BUCKET_SRC_PATH',\n                                     'BUCKET_DST_PATH',\n                                     ])\n\nBUCKET_SRC_PATH = args['BUCKET_SRC_PATH']\nBUCKET_DST_PATH = args['BUCKET_DST_PATH']\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\nlogger = glueContext.get_logger()\nspark = glueContext.spark_session\n\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n\ndf = ( spark\n        .read\n        .parquet(f\"{BUCKET_SRC_PATH}\") )\ndf.createOrReplaceTempView(\"dc_taxi_parquet\")\nquery_df = spark.sql(\"\"\"\nSELECT\n    fareamount_double,\n    origindatetime_tr,\n    origin_block_latitude_double,\n    origin_block_longitude_double,\n    destination_block_latitude_double,\n    destination_block_longitude_double\nFROM\n  dc_taxi_parquet\nWHERE\n    origindatetime_tr IS NOT NULL\n    AND fareamount_double IS NOT NULL\n    AND fareamount_double >= 3.25\n    AND fareamount_double <= 180.0\n    AND origin_block_latitude_double IS NOT NULL\n    AND origin_block_longitude_double IS NOT NULL\n    AND destination_block_latitude_double IS NOT NULL\n    AND destination_block_longitude_double IS NOT NULL\n\"\"\".replace('\\n', ''))\n\n#parse to check for valid value of the original timestamp\nfrom pyspark.sql.functions import col, to_timestamp, \\\n    dayofweek, year, month, hour\nfrom pyspark.sql.types import IntegerType\n\n#convert the source timestamp into numeric data needed for machine learning\nquery_df = (query_df\n  .withColumn(\"origindatetime_ts\",\n    to_timestamp(\"origindatetime_tr\", \"dd/MM/yyyy HH:mm\"))\n  .where(col(\"origindatetime_ts\").isNotNull())\n  .drop(\"origindatetime_tr\")\n  .withColumn( 'year_integer',\n    year('origindatetime_ts').cast(IntegerType()) )\n  .withColumn( 'month_integer',\n    month('origindatetime_ts').cast(IntegerType()) )\n  .withColumn( 'dow_integer',\n    dayofweek('origindatetime_ts').cast(IntegerType()) )\n  .withColumn( 'hour_integer',\n    hour('origindatetime_ts').cast(IntegerType()) )\n  .drop('origindatetime_ts') )\n\n#drop missing data and duplicates\nquery_df = ( query_df\n            .dropna()\n            .drop_duplicates() )\n\n(query_df\n .write\n .parquet(f\"{BUCKET_DST_PATH}\", mode=\"overwrite\"))\n\ndef save_stats_metadata(df, dest, header = 'true', mode = 'overwrite'):\n  return (df.describe()\n    .coalesce(1)\n    .write\n    .option(\"header\", header)\n    .csv(dest, mode = mode))\n\nsave_stats_metadata(query_df, f\"{BUCKET_DST_PATH}/.meta/stats\")\n\njob.commit()\n```", "```py\n%%bash\nwget -q https://raw.githubusercontent.com/osipov/smlbook/master/utils.sh\nsource utils.sh\n\nPYSPARK_SRC_NAME=dctaxi_parquet_vacuum.py \\\nPYSPARK_JOB_NAME=dc-taxi-parquet-vacuum-job \\\nBUCKET_SRC_PATH=s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/parquet \\\nBUCKET_DST_PATH=s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/parquet/vacuum \\\nrun_job\n```", "```py\n{\n    \"JobName\": \"dc-taxi-parquet-vacuum-job\"\n}\n{\n    \"Name\": \"dc-taxi-parquet-vacuum-job\"\n}\n{\n    \"JobRunId\": \n➥     \"jr_8a157e870bb6915eef3b8c0c280d1d8596613f6ad79dd27e3699115b7a3eb55d\"\n}\nWaiting for the job to finish..................SUCCEEDED\n```"]