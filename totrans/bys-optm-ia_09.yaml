- en: Part 3\. Extending Bayesian optimization to specialized settings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The BayesOpt loop we have learned represents a wide range of optimization problems.
    However, real-life scenarios often don’t follow this highly idealized model. What
    if you can run multiple function evaluations at the same time, which is common
    in hyperparameter tuning applications where multiple GPUs are available? What
    if you have multiple, competing objectives you’d like to optimize for? This part
    presents some of the most common optimization scenarios you might encounter in
    the real world and discusses how to extend BayesOpt to these settings.
  prefs: []
  type: TYPE_NORMAL
- en: To increase throughput, many settings allow experiments to run in parallel.
    Chapter 7 introduces the batch BayesOpt framework, in which function evaluations
    are made in batches. We learn how to extend the decision-making policies we have
    learned in part 2 to this setting, while ensuring we fully take advantage of the
    parallelism of the system.
  prefs: []
  type: TYPE_NORMAL
- en: In safety-critical use cases, we cannot explore the search space freely, as
    some function evaluations may have detrimental effects. This motivates the setting
    where there are constraints on how the function in question should behave and
    there is a need to factor in these constraints in the design of optimization policies.
    Chapter 8 deals with this setting, called constrained optimization, and develops
    the necessary machinery to apply BayesOpt.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 9 explores the setting in which we have access to multiple ways of observing
    the function’s values at different levels of cost and accuracy; this is commonly
    known as multifidelity BayesOpt. We discuss the natural extension of entropy to
    quantify the value of making an evaluation at various levels of fidelity and apply
    the algorithm to balance information and cost.
  prefs: []
  type: TYPE_NORMAL
- en: Pairwise comparisons have been shown to reflect one’s preference more accurately
    than number evaluations or ratings, as they are simpler and pose a lighter cognitive
    load on the labeler. Chapter 10 applies BayesOpt to this setting, first by using
    a special GP model and then by modifying existing policies to fit into this pairwise
    comparison workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Multiobjective optimization is a common use case in which we aim to optimize
    multiple potentially conflicting objectives at the same time. We study this problem
    of multiobjective optimization and develop a BayesOpt solution that jointly optimizes
    the multiple objectives we have.
  prefs: []
  type: TYPE_NORMAL
- en: 'Across this diverse set of special optimization settings is a common theme:
    trading off exploration and exploitation when accounting for the structures of
    the problem. By seeing how BayesOpt is applied to a wide range of settings in
    this part, we not only solidify our understanding of this technique but also make
    the technique more applicable in practical scenarios. The code developed in these
    chapters will help you hit the ground running right away with any optimization
    problem you might have in real life.'
  prefs: []
  type: TYPE_NORMAL
