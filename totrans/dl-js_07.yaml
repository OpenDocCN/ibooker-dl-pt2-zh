- en: Chapter 1\. Deep learning and JavaScript
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*This chapter covers*'
  prefs: []
  type: TYPE_NORMAL
- en: What deep learning is and how it is related to artificial intelligence (AI)
    and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What makes deep learning stand out among various machine-learning techniques,
    and the factors that led to the current “deep-learning revolution”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reasons for doing deep learning in JavaScript using TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The overall organization of this book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All the buzz around artificial intelligence (AI) is happening for a good reason:
    the deep-learning revolution, as it is sometimes called, has indeed happened.
    *Deep-learning revolution* refers to the rapid progress made in the speed and
    techniques of deep neural networks that started around 2012 and is still ongoing.
    Since then, deep neural networks have been applied to an increasingly wide range
    of problems, enabling machines to solve previously unsolvable problems in some
    cases and dramatically improving solution accuracy in others (see [table 1.1](#ch01table01)
    for examples). To experts in AI, many of these breakthroughs in neural networks
    were stunning. To engineers who use neural networks, the opportunities this progress
    has created are galvanizing.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1.1\. Examples of tasks in which accuracy improved significantly thanks
    to deep-learning techniques since the beginning of the deep-learning revolution
    around 2012\. This list is by no means comprehensive. The pace of progress will
    undoubtedly continue in the coming months and years.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Machine-learning task | Representative deep-learning technology | Where we
    use TensorFlow.js to perform a similar task in this book |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Categorizing the content of images | Deep convolutional neural networks (convnets)
    such as ResNet^([[a](#ch01table01fn01)]) and Inception^([[b](#ch01table01fn02)])
    reduced the error rate in the ImageNet classification task from ~25% in 2011 to
    below 5% in 2017.^([[c](#ch01table01fn03)]) | Training convnets for MNIST ([chapter
    4](kindle_split_015.html#ch04)); MobileNet inference and transfer learning ([chapter
    5](kindle_split_016.html#ch05)) |'
  prefs: []
  type: TYPE_TB
- en: '| Localizing objects and images | Variants of deep convnets^([[d](#ch01table01fn04)])
    reduced localization error from 0.33 in 2012 to 0.06 in 2017. | YOLO in TensorFlow.js
    ([section 5.2](kindle_split_016.html#ch05lev1sec2)) |'
  prefs: []
  type: TYPE_TB
- en: '| Translating one natural language to another | Google’s neural machine translation
    (GNMT) reduced translation error by ~60% compared to the best traditional machine-translation
    techniques.^([[e](#ch01table01fn05)]) | Long Short-Term Memory (LSTM)-based sequence-to-sequence
    models with attention mechanisms ([chapter 9](kindle_split_021.html#ch09)) |'
  prefs: []
  type: TYPE_TB
- en: '| Recognizing large-vocabulary, continuous speech | An LSTM-based encoder-attention-decoder
    architecture achieves a lower word-error rate than the best non-deep-learning
    speech recognition system.^([[f](#ch01table01fn06)]) | Attention-based LSTM small-vocabulary
    continuous speech recognition ([chapter 9](kindle_split_021.html#ch09)) |'
  prefs: []
  type: TYPE_TB
- en: '| Generating realistic-looking images | Generative adversarial networks (GANs)
    are now capable of generating realistic-looking images based on training data
    (see [https://github.com/junyanz/CycleGAN](https://github.com/junyanz/CycleGAN)).
    | Generating images using variational autoencoders (VAEs) and GANs ([chapter 9](kindle_split_021.html#ch09))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Generating music | Recurrent neural networks (RNNs) and VAEs are helping
    create music scores and novel instrument sounds (see [https://magenta.tensorflow.org/demos](https://magenta.tensorflow.org/demos)).
    | Training LSTMs to generate text ([chapter 9](kindle_split_021.html#ch09)) |'
  prefs: []
  type: TYPE_TB
- en: '| Learning to play games | Deep learning combined with reinforcement learning
    (RL) lets machines learn to play simple Atari games using raw pixels as the only
    input.^([[g](#ch01table01fn07)]) Combining deep learning and Monte Carlo tree
    search, Alpha-Zero reached a super-human level of Go purely through self-play.^([[h](#ch01table01fn08)])
    | Using RL to solve the cart-pole control problem and a snake video game ([chapter
    11](kindle_split_023.html#ch11)) |'
  prefs: []
  type: TYPE_TB
- en: '| Diagnosing diseases using medical images | Deep convnets were able to achieve
    specificity and sensitivity comparable to trained human ophthalmologists in diagnosing
    diabetic retinopathy based on images of patients’ retinas.^([[i](#ch01table01fn09)])
    | Transfer learning using a pretrained MobileNet image model ([chapter 5](kindle_split_016.html#ch05)).
    |'
  prefs: []
  type: TYPE_TB
- en: ^a
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Kaiming He et al., “Deep Residual Learning for Image Recognition,” *Proc. IEEE
    Conference Computer Vision and Pattern Recognition* (CVPR), 2016, pp. 770–778,
    [http://mng.bz/PO5P](http://mng.bz/PO5P).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^b
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Christian Szegedy et al., “Going Deeper with Convolutions,” *Proc. IEEE Conference
    Computer Vision and Pattern Recognition* (CVPR), 2015, pp. 1–9, [http://mng.bz/JzGv](http://mng.bz/JzGv).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^c
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Large Scale Visual Recognition Challenge 2017 (ILSVRC2017) results, [http://image-net.org/challenges/LSVRC/2017/results](http://image-net.org/challenges/LSVRC/2017/results).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^d
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yunpeng Chen et al., “Dual Path Networks,” [https://arxiv.org/pdf/1707.01629.pdf](https://arxiv.org/pdf/1707.01629.pdf).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^e
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Yonghui Wu et al., “Google’s Neural Machine Translation System: Bridging the
    Gap between Human and Machine Translation,” submitted 26 Sept. 2016, [https://arxiv.org/abs/1609.08144](https://arxiv.org/abs/1609.08144).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^f
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chung-Cheng Chiu et al., “State-of-the-Art Speech Recognition with Sequence-to-Sequence
    Models,” submitted 5 Dec. 2017, [https://arxiv.org/abs/1712.01769](https://arxiv.org/abs/1712.01769).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^g
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Volodymyr Mnih et al., “Playing Atari with Deep Reinforcement Learning,” NIPS
    Deep Learning Workshop 2013, [https://arxiv.org/abs/1312.5602](https://arxiv.org/abs/1312.5602).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^h
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: David Silver et al., “Mastering Chess and Shogi by Self-Play with a General
    Reinforcement Learning Algorithm,” submitted 5 Dec. 2017, [https://arxiv.org/abs/1712.01815](https://arxiv.org/abs/1712.01815).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ^i
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Varun Gulshan et al., “Development and Validation of a Deep Learning Algorithm
    for Detection of Diabetic Retinopathy in Retinal Fundus Photographs,” JAMA, vol.
    316, no. 22, 2016, pp. 2402–2410, [http://mng.bz/wlDQ](http://mng.bz/wlDQ).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: JavaScript is a language traditionally devoted to creating web browser UI and
    backend business logic (with Node.js). As someone who expresses ideas and creativity
    in JavaScript, you may feel a little left out by the deep-learning revolution,
    which seems to be the exclusive territory of languages such as Python, R, and
    C++. This book aims at bringing deep learning and JavaScript together through
    the JavaScript deep-learning library called TensorFlow.js. We do this so that
    JavaScript developers like you can learn how to write deep neural networks without
    learning a new language; more importantly, we believe deep learning and JavaScript
    belong together.
  prefs: []
  type: TYPE_NORMAL
- en: The cross-pollination will create unique opportunities, ones unavailable in
    any other programming language. It goes both ways for JavaScript and deep learning.
    With JavaScript, deep-learning applications can run on more platforms, reach a
    wider audience, and become more visual and interactive. With deep learning, JavaScript
    developers can make their web apps more intelligent. We will describe how later
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 1.1](#ch01table01) lists some of the most exciting achievements of deep
    learning that we’ve seen in this deep-learning revolution so far. In this book,
    we have selected a number of these applications and created examples of how to
    implement them in TensorFlow.js, either in their full glory or in reduced form.
    These examples will be covered in depth in the coming chapters. Therefore, you
    will not stop at marveling at the breakthroughs: you can learn about them, understand
    them, and implement them all in JavaScript.'
  prefs: []
  type: TYPE_NORMAL
- en: But before you dive into these exciting, hands-on deep-learning examples, we
    need to introduce the essential context around AI, deep learning, and neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1\. Artificial intelligence, machine learning, neural networks, and deep learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Phrases like *AI*, *machine learning*, *neural networks*, and *deep learning*
    mean related but different things. To orient yourself in the dazzling world of
    AI, you need to understand what they refer to. Let’s define these terms and the
    relations among them.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.1\. Artificial intelligence
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As the Venn diagram in [figure 1.1](#ch01fig01) shows, AI is a broad field.
    A concise definition of the field would be as follows: *the effort to automate
    intellectual tasks normally performed by humans*. As such, AI encompasses machine
    learning, neural networks, and deep learning, but it also includes many approaches
    distinct from machine learning. Early chess programs, for instance, involved hard-coded
    rules crafted by programmers. Those didn’t qualify as machine learning because
    the machines were programmed explicitly to solve the problems instead of being
    allowed to discover strategies for solving the problems by learning from the data.
    For a long time, many experts believed that human-level AI could be achieved through
    handcrafting a sufficiently large set of explicit rules for manipulating knowledge
    and making decisions. This approach is known as *symbolic AI*, and it was the
    dominant paradigm in AI from the 1950s to the late 1980s.^([[1](#ch01fn1)])'
  prefs: []
  type: TYPE_NORMAL
- en: ¹
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'An important type of symbolic AI is *expert systems*. See this Britannica article
    to learn about them: [http://mng.bz/7zmy](http://mng.bz/7zmy).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Figure 1.1\. Relations between AI, machine learning, neural networks, and deep
    learning. As this Venn diagram shows, machine learning is a subfield of AI. Some
    areas of AI use approaches different from machine learning, such as symbolic AI.
    Neural networks are a subfield of machine learning. There exist non-neural-network
    machine-learning techniques, such as decision trees. Deep learning is the science
    and art of creating and applying “deep” neural networks—neural networks with multiple
    “layers”— versus “shallow” neural networks—neural networks with fewer layers.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig01_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '1.1.2\. Machine learning: How it differs from traditional programming'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Machine learning, as a subfield of AI distinct from symbolic AI, arises from
    a question: Could a computer go beyond what a programmer knows how to program
    it to perform, and learn on its own how to perform a specific task? As you can
    see, the approach of machine learning is fundamentally different from that of
    symbolic AI. Whereas symbolic AI relies on hard-coding knowledge and rules, machine
    learning seeks to avoid this hard-coding. So, if a machine isn’t explicitly instructed
    on how to perform a task, how would it learn how to do so? The answer is by learning
    from examples in the data.'
  prefs: []
  type: TYPE_NORMAL
- en: This opened the door to a new programming paradigm ([figure 1.2](#ch01fig02)).
    To give an example of the machine-learning paradigm, let’s suppose you are working
    on a web app that handles photos uploaded by users. A feature you want in the
    app is automatic classification of photos into ones that contain human faces and
    ones that don’t. The app will take different actions on face images and no-face
    images. To this end, you want to create a program to output a binary face/no-face
    answer given any input image (made of an array of pixels).
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.2\. Comparing the classical programming paradigm and the machine-learning
    paradigm
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig02_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We humans can perform this task in a split second: our brains’ genetic hardwiring
    and life experience give us the ability to do so. However, it is hard for any
    programmer, no matter how smart and experienced, to write an explicit set of rules
    in a programming language (the only practical way for humans to communicate with
    a computer) on how to accurately decide whether an image contains a human face.
    You can spend days poring over code that does arithmetic on the RGB (red-green-blue)
    values of pixels to detect elliptic contours that look like faces, eyes, and mouths,
    as well as devising heuristic rules on the geometric relations between the contours.
    But you will soon realize that such effort is laden with arbitrary choices of
    logic and parameters that are hard to justify. More importantly, it is hard to
    make it work well!^([[2](#ch01fn2)]) Any heuristic you come up with is likely
    to fall short when facing the myriad variations that faces can present in real-life
    images, such as differences in the size, shape, and details of the face; facial
    expression; hairstyle; skin color; orientation; the presence or absence of partial
    obscuring; glasses; lighting conditions; objects in the background; and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: ²
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In fact, such approaches have indeed been attempted before and did not work
    very well. This survey paper provides good examples of handcrafting rules for
    face detection before the advent of deep learning: Erik Hjelmås and Boon Kee Low,
    “Face Detection: A Survey,” *Computer Vision and Image Understanding*, Sept. 2001,
    pp. 236–274, [http://mng.bz/m4d2](http://mng.bz/m4d2).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the machine-learning paradigm, you recognize that handcrafting a set of rules
    for such a task is futile. Instead, you find a set of images, some with faces
    in them and some without. Then you enter the desired (that is, correct) face or
    no-face answer for each one. These answers are referred to as *labels*. This is
    a much more tractable (in fact, trivial) task. It may take some time to label
    all the images if there are a lot of them, but the labeling task can be divided
    among several humans and can proceed in parallel. Once you have the images labeled,
    you apply machine learning and let machines discover the set of rules on their
    own. If you use the correct machine-learning techniques, you will arrive at a
    trained set of rules capable of performing the face/no-face task with an accuracy
    > 99%—far better than anything you can hope to achieve with handcrafted rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the previous example, we can see that machine learning is the process
    of automating the discovery of rules for solving complex problems. This automation
    is beneficial for problems like face detection, in which humans know the rules
    intuitively and can easily label the data. For other problems, the rules are not
    known intuitively. For example, consider the problem of predicting whether a user
    will click an ad displayed on a web page, given the page’s and the ad’s contents
    and other information, such as time and location. No human has a good sense about
    how to make accurate predictions for such problems in general. Even if one does,
    the pattern will probably change with time and with the appearance of new content
    and new ads. But the labeled training data is available from the ad service’s
    history: it is available from the ad servers’ logs. The availability of the data
    and labels alone makes machine learning a good fit for problems like this.'
  prefs: []
  type: TYPE_NORMAL
- en: In [figure 1.3](#ch01fig03), we take a closer look at the steps involved in
    machine learning. There are two important phases. The first is the *training phase*.
    This phase takes the data and answers, together referred to as the *training data*.
    Each pair of input data and the desired answer is called an *example*. With the
    help of the examples, the training process produces the automatically discovered
    *rules*. Although the rules are discovered automatically, they are not discovered
    entirely from scratch. In other words, machine-learning algorithms are not creative
    in coming up with rules. In particular, a human engineer provides a blueprint
    for the rules at the outset of training. The blueprint is encapsulated in a *model*,
    which forms a *hypothesis space* for the rules the machine may possibly learn.
    Without this hypothesis space, there is a completely unconstrained and infinite
    space of possible rules to search in, which is not conducive to finding good rules
    in a limited amount of time. We will describe in great detail the kinds of models
    available and how to choose the best ones based on the problem at hand. For now,
    it suffices to say that in the context of deep learning, models vary in terms
    of how many layers the neural network consists of, what types of layers they are,
    and how they are wired together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.3\. A more detailed view of the machine-learning paradigm than that
    in [figure 1.2](#ch01fig02). The workflow of machine learning consists of two
    phases: training and inference. Training is the process of the machine automatically
    discovering the rules that convert the data into answers. The learned rules, encapsulated
    in a trained “model,” are the fruit of the training phase and form the basis of
    the inference phase. Inference means using the model to obtain answers for new
    data.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig03_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With the training data and the model architecture, the training process produces
    the learned rules, encapsulated in a trained model. This process takes the blueprint
    and alters (or tunes) it in ways that nudge the model’s output closer and closer
    to the desired output. The training phase can take anywhere from milliseconds
    to days, depending on the amount of training data, the complexity of the model
    architecture, and how fast the hardware is. This style of machine learning—namely,
    using labeled examples to progressively reduce the error in a model’s outputs—is
    known as *supervised learning*.^([[3](#ch01fn3)]) Most of the deep-learning algorithms
    we cover in this book are supervised learning. Once we have the trained model,
    we are ready to apply the learned rules on new data—data that the training process
    has never seen. This is the second phase, or *inference phase*. The inference
    phase is less computationally intensive than the training phase because 1) inference
    usually happens on one input (for instance, one image) at a time, whereas training
    involves going through all the training data; and 2) during inference, the model
    does not need to be altered.
  prefs: []
  type: TYPE_NORMAL
- en: ³
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Another style of machine learning is *unsupervised learning*, in which unlabeled
    data is used. Examples of unsupervised learning are clustering (discovering distinct
    subsets of examples in a dataset) and anomaly detection (determining if a given
    example is sufficiently different from the examples in the training set).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learning representations of data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Machine learning is about learning from data. But *what* exactly is learned?
    The answer: a way to effectively transform the data or, in other words, to change
    the old representations of the data into a new one that gets us closer to solving
    the problem at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go any further, what is a representation? At its core, it is a way
    to look at the data. The same data can be looked at in different ways, leading
    to different representations. For example, a color image can have an RGB or HSV
    (hue-saturation-value) encoding. Here, the words *encoding* and *representation*
    mean essentially the same thing and can be used interchangeably. When encoded
    in these two different formats, the numerical values that represent the pixels
    are completely different, even though they are for the same image. Different representations
    are useful for solving different problems. For example, to find all the red parts
    of an image, the RGB representation is more useful; but to find color-saturated
    parts of the same image, the HSV representation is more useful. This is essentially
    what machine learning is all about: finding an appropriate transformation that
    turns the old representation of the input data into a new one—one that is amenable
    to solving the specific task at hand, such as detecting the location of cars in
    an image or deciding whether an image contains a cat and a dog.'
  prefs: []
  type: TYPE_NORMAL
- en: To give a visual example, we have a collection of white points and several black
    points in a plane ([figure 1.4](#ch01fig04)). Let’s say we want to develop an
    algorithm that can take the 2D (x, y) coordinates of a point and predict whether
    that point is black or white. In this case,
  prefs: []
  type: TYPE_NORMAL
- en: The input data is the two-dimensional Cartesian coordinates (x and y) of a point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output is the predicted color of the point (whether it’s black or white).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 1.4\. A toy example of the representation transformations that machine
    learning is about. Panel A: the original representation of a dataset consisting
    of black and white points in a plane. Panels B and C: two successive transformation
    steps turn the original representation into one that is more amenable to the color-classification
    task.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig04_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The data shows a pattern in panel A of [figure 1.4](#ch01fig04). How would the
    machine decide the color of a point given the x- and y-coordinates? It cannot
    simply compare x with a number, because the range of the x-coordinates of the
    white points overlaps with the range of the x-coordinates of the black ones! Similarly,
    the algorithm cannot rely on the y-coordinate. Therefore, we can see that the
    original representation of the points is not a good one for the black-white classification
    task.
  prefs: []
  type: TYPE_NORMAL
- en: What we need is a new representation that separates the two colors in a more
    straightforward way. Here, we transform the original Cartesian x-y representation
    into a polar-coordinate-system representation. In other words, we represent a
    point by 1) its angle—the angle formed by the x-axis and the line that connects
    the origin with the point (see the example in panel A of [figure 1.4](#ch01fig04))
    and 2) its radius—its distance from the origin. After this transformation, we
    arrive at a new representation of the same set of data, as panel B of [figure
    1.4](#ch01fig04) shows. This representation is more amenable to our task, in that
    the angle values of the black and white points are now completely nonoverlapping.
    However, this new representation is still not an ideal one in that the black-white
    color classification cannot be made into a simple comparison with a threshold
    value (like zero).
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, we can apply a second transformation to get us there. This transformation
    is based on the simple formula
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting representation, as shown in panel C, is one-dimensional. Compared
    to the representation in panel B, it throws away the irrelevant information about
    the distance of the points to the origin. But it is a perfect representation in
    that it allows a completely straightforward decision process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we manually defined a two-step transform of the data representation.
    But if instead we tried automated searching for different possible coordinate
    transforms using feedback about the percentage of points classified correctly,
    then we would be doing machine learning. The number of transformation steps involved
    in solving real machine-learning problems is usually much greater than two, especially
    in deep learning, where it can reach hundreds. Also, the kind of representation
    transformations seen in real machine learning can be much more complex compared
    to those seen in this simple example. Ongoing research in deep learning keeps
    discovering more sophisticated and powerful transformations. But the example in
    [figure 1.4](#ch01fig04) captures the essence of searching for better representations.
    This applies to all machine-learning algorithms, including neural networks, decision
    trees, kernel methods, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.3\. Neural networks and deep learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Neural networks are a subfield of machine learning, one in which the transformation
    of the data representation is done by a system with an architecture loosely inspired
    by how neurons are connected in human and animal brains. How are neurons connected
    to each other in brains? It varies among species and brain regions. But a frequently
    encountered theme of neuronal connection is the layer organization. Many parts
    of the mammalian brain are organized in a layered fashion. Examples include the
    retina, the cerebral cortex, and the cerebellar cortex.
  prefs: []
  type: TYPE_NORMAL
- en: At least on a superficial level, this pattern is somewhat similar to the general
    organization of *artificial neural networks* (simply called *neural networks*
    in the world of computing, where there is little risk of confusion), in which
    the data is processed in multiple separable stages, aptly named *layers*. These
    layers are usually stacked on top of each other, with connections only between
    adjacent ones. [Figure 1.5](#ch01fig05) shows a simple (artificial) neural network
    with four layers. The input data (an image, in this case) feeds into the first
    layer (on the left side of the figure), then flows sequentially from one layer
    to the next. Each layer applies a new transformation on the representation of
    the data. As the data flows through the layers, the representation becomes increasingly
    different from the original and gets closer and closer to the goal of the neural
    network—namely, applying a correct label to the input image. The last layer (on
    the right side of the figure) emits the neural network’s final output, which is
    the result of the image-classification task.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.5\. The schematic diagram of a neural network, organized in layers.
    This neural network classifies images of hand-written digits. In between the layers,
    you can see the intermediate representation of the original data. Reproduced with
    permission from François Chollet, *Deep Learning with Python*, Manning Publications,
    2017.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig05_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A layer of neural networks is similar to a mathematical function in that it
    is a mapping from an input value to an output value. However, neural network layers
    are different from pure mathematical functions in that they are generally *stateful*.
    In other words, they hold internal memory. A layer’s memory is captured in its
    *weights*. What are weights? They are simply a set of numerical values that belong
    to the layer and govern the details of how each input representation is transformed
    by the layer into an output representation. For example, the frequently used *dense*
    layer transforms its input data by multiplying it with a matrix and adding a vector
    to the result of the matrix multiplication. The matrix and the vector are the
    dense layer’s weights. When a neural network is trained through exposure to training
    data, the weights get altered systematically in a way that minimizes a certain
    value called the *loss function*, which we will cover in detail using concrete
    examples in [chapters 2](kindle_split_013.html#ch02) and [3](kindle_split_014.html#ch03).
  prefs: []
  type: TYPE_NORMAL
- en: Although neural networks are inspired by the brain, we should be careful not
    to overly humanize them. The purpose of neural networks is *not* to study or mimic
    how the brain works. That is the realm of neuroscience, a separate academic discipline.
    Neural networks are about enabling machines to perform interesting practical tasks
    by learning from data. The fact that some neural networks show resemblance to
    some parts of the biological brain, both in structure and in function,^([[4](#ch01fn4)])
    is indeed remarkable. But whether this is a coincidence is beyond the scope of
    this book. In any case, the resemblance should not be overread. Importantly, there
    is no evidence that the brain learns through any form of gradient descent, the
    primary way in which neural networks are trained (covered in the next chapter).
    Many important techniques in neural networks that helped usher in the deep-learning
    revolution were invented and adopted not because they were backed by neuroscience,
    but instead because they helped neural networks solve practical learning tasks
    better and faster.
  prefs: []
  type: TYPE_NORMAL
- en: ⁴
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a compelling example of similarity in functions, see the inputs that maximally
    activate various layers of a convolutional neural network (see [chapter 4](kindle_split_015.html#ch04)),
    which closely resemble the neuronal receptive fields of various parts of the human
    visual system.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that you know what neural networks are, we can tell you what *deep learning*
    is. Deep learning is the study and application of *deep neural networks*, which
    are, quite simply, neural networks with *many layers* (typically, from a dozen
    to hundreds of layers). Here, the word *deep* refers to the idea of a large number
    of successive layers of representations. The number of layers that form a model
    of the data is called the model’s *depth*. Other appropriate names for the field
    could have been “layered representation learning” or “hierarchical representation
    learning.” Modern deep learning often involves tens or hundreds of successive
    layers of representations—and they are all learned automatically from exposure
    to training data. Meanwhile, other approaches to machine learning tend to focus
    on learning only one or two layers of representations of the data; hence, they
    are sometimes called *shallow learning*.
  prefs: []
  type: TYPE_NORMAL
- en: It is a misconception that the “deep” in deep learning is about any kind of
    deep understanding of data—that is, “deep” in the sense of understanding the meaning
    behind sentences like “freedom is not free” or savoring the contradictions and
    self-references in M.C. Escher’s drawings. That kind of “deep” remains an elusive
    goal for AI researchers.^([[5](#ch01fn5)]) In the future, deep learning may bring
    us closer to this sort of depth, but that will certainly be harder to quantify
    and achieve than adding layers to neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: ⁵
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Douglas Hofstadter, “The Shallowness of Google Translate,” *The Atlantic*, 30
    Jan. 2018, [http://mng.bz/5AE1](http://mng.bz/5AE1).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '|  |'
  prefs: []
  type: TYPE_TB
- en: '**Not just neural networks: Other popular machine-learning techniques**'
  prefs: []
  type: TYPE_NORMAL
- en: We went directly from the “machine learning” circle of the Venn diagram in [figure
    1.1](#ch01fig01) to the “neural network” circle inside. However, it is worthwhile
    for us to briefly visit the machine-learning techniques that are not neural networks,
    not only because doing so will give us a better historical context but also because
    you may run into some of the techniques in existing code.
  prefs: []
  type: TYPE_NORMAL
- en: The *Naive Bayes classifier* is one of the earliest forms of machine learning.
    Put simply, Bayes’ theorem is about how to estimate the probability of an event
    given 1) the a priori belief of how likely the event is and 2) the observed facts
    (called *features*) relating to the event. This theorem can be used to classify
    observed data points into one of many known categories by choosing the category
    with the highest probability (likelihood) given the observed facts. Naive Bayes
    is based on the assumption that the observed facts are mutually independent (a
    strong and naive assumption, hence the name).
  prefs: []
  type: TYPE_NORMAL
- en: '*Logistic regression* (or *logreg*) is also a classification technique. Thanks
    to its simple and versatile nature, it is still popular and often the first thing
    a data scientist will try in order to get a feel for the classification task at
    hand.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Kernel methods*, of which support vector machines (SVMs) are the best-known
    examples, tackle binary (that is, two-class) classification problems by mapping
    the original data into spaces of higher dimensionality and finding a transformation
    that maximizes a distance (called a *margin*) between two classes of examples.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Decision trees* are flowchart-like structures that let you classify input
    data points or predict output values given inputs. At each step of the flowchart,
    you answer a simple yes/no question, such as, “Is feature X greater than a certain
    threshold?” Depending on whether the answer is yes or no, you advance to one of
    two possible next questions, which is just another yes/no question, and so forth.
    Once you reach the end of the flowchart, you will get the final answer. As such,
    decision trees are easy for humans to visualize and iterpret.'
  prefs: []
  type: TYPE_NORMAL
- en: Random forests and gradient-boosted machines increase the accuracy of decision
    trees by forming an ensemble of a large number of specialized, individual decision
    trees. *Ensembling*, also known as *ensemble learning*, is the technique of training
    a collection (that is, an ensemble) of individual machine-learning models and
    using an aggregate of their outputs during inference. Today, gradient boosting
    may be one of the best algorithms, if not the best, for dealing with nonperceptual
    data (for example, credit card fraud detection). Alongside deep learning, it is
    one of the most commonly used techniques in data science competitions, such as
    those on Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: '|  |'
  prefs: []
  type: TYPE_TB
- en: The rise, fall, and rise of neural networks, and the reasons behind them
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The core ideas of neural networks were formed as early as the 1950s. The key
    techniques for training neural networks, including backpropagation, were invented
    in the 1980s. However, for a long period of time between the 1980s and the 2010s,
    neural networks were almost completely shunned by the research community, partly
    because of the popularity of competing methods such as SVMs and partly because
    of the lack of an ability to train deep (many-layered) neural networks. But around
    2010, a number of people still working on neural networks started to make important
    breakthroughs: the groups of Geoffrey Hinton at the University of Toronto, Yoshua
    Bengio at the University of Montreal, and Yann LeCun at New York University, as
    well as researchers at the Dalle Molle Institute for Artificial Intelligence Research
    (IDSIA) in Switzerland. These groups achieved important milestones, including
    the first practical implementations of deep neural networks on graphics processing
    units (GPUs) and driving the error rate from about 25% down to less than 5% in
    the ImageNet computer vision challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: Since 2012, deep *convolutional neural networks* (convnets) have become the
    go-to algorithm for all computer-vision tasks; more generally, they work on all
    perceptual tasks. Examples of non-computer-vision perceptual tasks include speech
    recognition. At major computer vision conferences in 2015 and 2016, it was nearly
    impossible to find presentations that didn’t involve convnets in some form. At
    the same time, deep learning has also found applications in many other types of
    problems, such as natural language processing. It has completely replaced SVMs
    and decision trees in a wide range of applications. For instance, for several
    years, the European Organization for Nuclear Research, CERN, used decision-tree-based
    methods to analyze particle data from the ATLAS detector at the Large Hadron Collider;
    but CERN eventually switched to deep neural networks due to their higher performance
    and ease of training on large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what makes deep learning stand out from the range of available machine-learning
    algorithms? (See [info box 1.1](#ch01sb01) for a list of some popular machine-learning
    techniques that are not deep neural networks.) The primary reason deep learning
    took off so quickly is that it offered better performance on many problems. But
    that’s not the only reason. Deep learning also makes problem-solving much easier
    because it automates what used to be the most crucial and difficult step in a
    machine-learning workflow: *feature engineering*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Previous machine-learning techniques—shallow learning—only involved transforming
    the input data into one or two successive representation spaces, usually via simple
    transformations such as high-dimensional nonlinear projections (kernel methods)
    or decision trees. But the refined representations required by complex problems
    generally can’t be attained by such techniques. As such, human engineers had to
    go to great lengths to make the initial input data more amenable to processing
    by these methods: they had to manually engineer good layers of representations
    for their data. This is called *feature engineering*. Deep learning, on the other
    hand, automates this step: with deep learning, you learn all features in one pass
    rather than having to engineer them yourself. This has greatly simplified machine-learning
    workflows, often replacing sophisticated multistage pipelines with a single, simple,
    end-to-end deep-learning model. Through automating feature engineering, deep learning
    makes machine learning less labor-intensive and more robust—two birds with one
    stone.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the two essential characteristics of how deep learning learns from
    data: the incremental, layer-by-layer way in which increasingly complex representations
    are developed; and the fact that these intermediate incremental representations
    are learned jointly, each layer being updated to follow both the representational
    needs of the layer above and the needs of the layer below. Together, these two
    properties have made deep learning vastly more successful than previous approaches
    to machine learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.4\. Why deep learning? Why now?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If basic ideas and core techniques for neural networks already existed as early
    as the 1980s, why did the deep-learning revolution start to happen only after
    2012? What changed in the two decades in between? In general, three technical
    forces drive advances in machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Hardware
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets and benchmarks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithmic advances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s visit these factors one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Deep learning is an engineering science guided by experimental findings rather
    than by theory. Algorithmic advances become possible only when appropriate hardware
    are available to try new ideas (or to scale up old ideas, as is often the case).
    Typical deep-learning models used in computer vision or speech recognition require
    orders of magnitude more computational power than what your laptop can deliver.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the 2000s, companies like NVIDIA and AMD invested billions of dollars
    in developing fast, massively parallel chips (GPUs) to power the graphics of increasingly
    photorealistic video games—cheap, single-purpose supercomputers designed to render
    complex 3D scenes on your screen in real time. This investment came to benefit
    the scientific community when, in 2007, NVIDIA launched CUDA (short for Compute
    Unified Device Architecture), a general-purpose programming interface for its
    line of GPUs. A small number of GPUs started replacing massive clusters of CPUs
    in various highly parallelizable applications, beginning with physics modeling.
    Deep neural networks, consisting mostly of many matrix multiplications and additions,
    are also highly parallelizable.
  prefs: []
  type: TYPE_NORMAL
- en: Around 2011, some researchers began to write CUDA implementations of neural
    nets—Dan Ciresan and Alex Krizhevsky were among the first. Today, high-end GPUs
    can deliver hundreds of times more parallel computation power when training deep
    neural networks than what a typical CPU is capable of. Without the sheer computational
    power of modern GPUs, it would be impossible to train many state-of-the-art deep
    neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Data and benchmarks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'If hardware and algorithms are the steam engine of the deep-learning revolution,
    then data is its coal: the raw material that powers our intelligent machines,
    without which nothing would be possible. When it comes to data, in addition to
    the exponential progress in storage hardware over the past 20 years (following
    Moore’s law), the game changer has been the rise of the internet, which has made
    it feasible to collect and distribute very large datasets for machine learning.
    Today, large companies work with image datasets, video datasets, and natural language
    datasets that couldn’t have been collected without the internet. User-generated
    image tags on Flickr, for instance, have been a treasure trove of data for computer
    vision. So are YouTube videos. And Wikipedia is a key dataset for natural language
    processing.'
  prefs: []
  type: TYPE_NORMAL
- en: If there’s one dataset that has been a catalyst for the rise of deep learning,
    it’s ImageNet, which consists of 1.4 million images that have been hand annotated
    with 1,000 image categories. What makes ImageNet special isn’t just its large
    size; it is also the yearly competition associated with it. As ImageNet and Kaggle
    have been demonstrating since 2010, public competitions are an excellent way to
    motivate researchers and engineers to push the envelope. Having common benchmarks
    that researchers compete to beat has greatly helped the recent rise of deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithmic advances
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In addition to hardware and data, until the late 2000s, we were missing a reliable
    way to train very deep neural networks. As a result, neural networks were still
    fairly shallow, using only one or two layers of representations; thus, they couldn’t
    shine against more refined shallow methods such as SVMs and random forests. The
    key issue was that of gradient propagation through deep stacks of layers. The
    feedback signal used to train neural networks would fade away as the number of
    layers increased.
  prefs: []
  type: TYPE_NORMAL
- en: 'This changed around 2009 to 2010 with the advent of several simple but important
    algorithmic improvements that allowed for better gradient propagation:'
  prefs: []
  type: TYPE_NORMAL
- en: Better activation functions for neural network layers (such as the rectified
    linear unit, or relu)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better weight-initialization schemes (for example, Glorot initialization)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better optimization schemes (for example, RMSProp and ADAM optimizers)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only when these improvements began to allow for training models with 10 or more
    layers did deep learning start to shine. Finally, in 2014, 2015, and 2016, even
    more advanced ways to help gradient propagation were discovered, such as batch
    normalization, residual connections, and depthwise separable convolutions. Today
    we can train from scratch models that are thousands of layers deep.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2\. Why combine JavaScript and machine learning?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Machine learning, like other branches of AI and data science, is usually done
    with traditionally backend-focused languages, such as Python and R, running on
    servers or workstations outside the web browser.^([[6](#ch01fn6)]) This status
    quo is not surprising. The training of deep neural networks often requires the
    kind of multicore and GPU-accelerated computation not directly available in a
    browser tab; the enormous amount of data that it sometimes takes to train such
    models is most conveniently ingested in the backend: for example, from a native
    file system of virtually unlimited size. Until recently, many regarded “deep learning
    in JavaScript” as a novelty. In this section, we will present reasons why, for
    many kinds of applications, performing deep learning in the browser environment
    with JavaScript is a wise choice, and explain how combining the power of deep
    learning and the web browser creates unique opportunities, especially with the
    help of TensorFlow.js.'
  prefs: []
  type: TYPE_NORMAL
- en: ⁶
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Srishti Deoras, “Top 10 Programming Languages for Data Scientists to Learn in
    2018,” *Analytics India Magazine*, 25 Jan. 2018, [http://mng.bz/6wrD](http://mng.bz/6wrD).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: First, once a machine-learning model is trained, it must be deployed somewhere
    in order to make predictions on real data (such as classifying images and text,
    detecting events in audio or video streams, and so on). Without deployment, training
    a model is just a waste of compute power. It is often desirable or imperative
    that the “somewhere” is a web frontend. Readers of this book are likely to appreciate
    the overall importance of the web browser. On desktops and laptops, the web browser
    is the dominant means through which users access content and services on the internet.
    It is how desktop and laptop users spend most of their time using those devices,
    exceeding the second place by a large margin. It is how users get vast amounts
    of their daily work done, stay connected, and entertain themselves. The wide range
    of applications that run in the web browser provide rich opportunities for applying
    client-side machine learning. For the mobile frontend, the web browser trails
    behind native mobile apps in terms of user engagement and time spent. But mobile
    browsers are nonetheless a force to be reckoned with because of their broader
    reach, instant access, and faster development cycles.^([[7](#ch01fn7)]) In fact,
    because of their flexibility and ease of use, many mobile apps, such as Twitter
    and Facebook, drop into a JavaScript-enabled web view for certain types of content.
  prefs: []
  type: TYPE_NORMAL
- en: ⁷
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Rishabh Borde, “Internet Time Spend in Mobile Apps, 2017–19: It’s 8x than Mobile
    Web,” DazeInfo, 12 Apr. 2017, [http://mng.bz/omDr](http://mng.bz/omDr).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Due to this broad reach, the web browser is a logical choice for deploying
    deep-learning models, as long as the kinds of data the models expect are available
    in the browser. But what kinds of data are available in the browser? The answer
    is, many! Take, for example, the most popular applications of deep learning: classifying
    and detecting objects in images and videos, transcribing speech, translating languages,
    and analyzing text content. Web browsers are equipped with arguably the most comprehensive
    technologies and APIs for presenting (and, with user permission, for capturing)
    textual, image, audio, and video data. As a result, powerful machine-learning
    models can be directly used in the browser, for example, with TensorFlow.js and
    straightforward conversion processes. In the later chapters of this book, we will
    cover many concrete examples of deploying deep-learning models in the browser.
    For example, once you have captured images from a webcam, you can use TensorFlow.js
    to run MobileNet to label objects, run YOLO2 to put bounding boxes around detected
    objects, run Lipnet to do lipreading, or run a CNN-LSTM network to apply captions
    to images.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you have captured audio from the microphone using the browser’s WebAudio
    API, TensorFlow.js can run models to perform real-time spoken-word recognition.
    There are exciting applications with textual data as well, such as assigning sentiment
    scores to user text like movie reviews ([chapter 9](kindle_split_021.html#ch09)).
    Beyond these data modalities, the modern web browser can access a range of sensors
    on mobile devices. For example, HTML5 provides API access to geolocation (latitude
    and longitude), motion (device orientation and acceleration), and ambient light
    (see [http://mobilehtml5.org](http://mobilehtml5.org)). Combined with deep learning
    and other data modalities, data from such sensors opens doors to many exciting
    new applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Browser-based application of deep learning comes with five additional benefits:
    reduced server cost, lowered inference latency, data privacy, instant GPU acceleration,
    and instant access:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Server cost* is often an important consideration when designing and scaling
    web services. The computation required to run deep-learning models in a timely
    manner is often significant, necessitating the use of GPU acceleration. If models
    are not deployed to the client side, they need to be deployed on GPU-backed machines,
    such as virtual machines with CUDA GPUs from Google Cloud or Amazon Web Services.
    Such cloud GPU machines are often costly. Even the most basic GPU machines presently
    cost in the neighborhood of $0.5–1 per hour (see [https://www.ec2instances.info](https://www.ec2instances.info)
    and [https://cloud.google.com/gpu](https://cloud.google.com/gpu)). With increasing
    traffic, the cost of running a fleet of cloud GPU machines gets higher, not to
    mention the challenge of scalability and the added complexity of your server stack.
    All these concerns can be eliminated by deploying the model to the client. The
    overhead of client-side downloading of the model (which is often several megabytes
    or more) can be alleviated by the browser’s caching and local storage capabilities
    ([chapter 2](kindle_split_013.html#ch02)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lowered inference latency*—For certain types of applications, the requirement
    for latency is so stringent that the deep-learning models must be run on the client
    side. Any applications that involve real-time audio, image, and video data fall
    into this category. Consider what will happen if image frames need to be transferred
    to the server for inference. Suppose images are captured from a webcam at a modest
    size of 400 × 400 pixels with three color channels (RGB) and an 8-bit depth per
    color channel at a rate of 10 frames per second. Even with JPEG compression, each
    image has a size of about 150 Kb. On a typical mobile network with an approximately
    300-Kbps upload bandwidth, it can take more than 500 milliseconds to upload each
    image, leading to a latency that is noticeable and perhaps unacceptable for certain
    applications (for example, games). This calculation doesn’t take into account
    the fluctuation in (and possible loss of) network connectivity, the additional
    time it takes to download the inference results, and the vast amount of mobile
    data usage, each of which can be a showstopper. Client-side inference addresses
    these potential latency and connectivity concerns by keeping the data and the
    computation on the device. It is impossible to run real-time machine-learning
    applications such as labeling objects and detecting poses in webcam images without
    the model running purely on the client. Even for applications without latency
    requirements, the reduction in model inference latency can lead to greater responsiveness
    and hence an improved user experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data privacy*—Another benefit of leaving the training and inference data on
    the client is the protection of users’ privacy. The topic of data privacy is becoming
    increasingly important today. For certain types of applications, data privacy
    is an absolute requirement. Applications related to health and medical data are
    a prominent example. Consider a “skin disease diagnosis aid” that collects images
    of a patient’s skin from their webcam and uses deep learning to generate possible
    diagnoses of the skin condition. Health information privacy regulations in many
    countries will not allow the images to be transferred to a centralized server
    for inference. By running the model inference in the browser, no data needs to
    ever leave the user’s phone or be stored anywhere, ensuring the privacy of the
    user’s health data. Consider another browser-based application that uses deep
    learning to provide users with suggestions on how to improve the text they write
    in the application. Some users may use this application to write sensitive content
    such as legal documents and will not be comfortable with the data being transferred
    to a remote server via the public internet. Running the model purely in client-side
    browser JavaScript is an effective way to address this concern.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Instant WebGL acceleration*—In addition to the availability of data, another
    prerequisite for running machine-learning models in the web browser is sufficient
    compute power through GPU acceleration. As mentioned earlier, many state-of-the-art
    deep-learning models are so computationally intensive that acceleration through
    parallel computation on the GPU is a must (unless you are willing to let users
    wait for minutes for a single inference result, which rarely happens in real applications).
    Fortunately, modern web browsers come equipped with the WebGL API, which, even
    though it was originally designed for accelerated rendering of 2D and 3D graphics,
    can be ingeniously leveraged for the kind of parallel computation required for
    accelerating neural networks. The authors of TensorFlow.js painstakingly wrapped
    WebGL-based acceleration of the deep-learning components in the library, so the
    acceleration is available to you through a single line of JavaScript import. WebGL-based
    acceleration of neural networks may not be perfectly on par with native, tailored
    GPU acceleration such as NVIDIA’s CUDA and CuDNN (used by Python deep-learning
    libraries such as TensorFlow and PyTorch), but it still leads to orders of magnitude
    speedup of neural networks and enables real-time inference such as what PoseNet
    extraction of a human-body pose offers. If performing inference on pretrained
    models is expensive, performing training or transfer learning on such models is
    even more so. Training and transfer learning enable exciting applications such
    as personalization of deep-learning models, frontend visualization of deep learning,
    and federated learning (training the same model on many devices, then aggregating
    the results of the training to obtain a good model). The WebGL acceleration of
    TensorFlow.js makes it possible to train or fine-tune neural networks with sufficient
    speed, purely inside the web browser.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Instant access*—Generally speaking, applications that run in the browser have
    the natural advantage of “zero install:” all it takes to access the app is typing
    a URL or clicking a link. This forgoes any potentially tedious and error-prone
    installation steps, along with possibly risky access control when installing new
    software. In the context of deep learning in the browser, the WebGL-based neural
    network acceleration that TensorFlow.js provides does not require special kinds
    of graphics cards or installation of drivers for such cards, which is often a
    nontrivial process. Most reasonably up-to-date desktop, laptop, and mobile devices
    come with graphics cards available to the browser and WebGL. Such devices, as
    long as they have a TensorFlow.js-compatible web browser installed (a low bar),
    are automatically ready to run WebGL-accelerated neural networks. This is an especially
    attractive feature in places where ease of access is vital—for example, the education
    of deep learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|  |'
  prefs: []
  type: TYPE_TB
- en: '**Accelerating computation using GPU and WebGL**'
  prefs: []
  type: TYPE_NORMAL
- en: It takes a massive number of math operations to train machine-learning models
    and use them for inference. For example, the widely used “dense” neural network
    layers involve multiplying a large matrix with a vector and adding the result
    to another vector. A typical operation of this sort involves thousands or millions
    of floating-point operations. An important fact about such operations is that
    they are often *parallelizable*. For instance, adding two vectors can be divided
    into many smaller operations, such as adding two individual numbers. These smaller
    operations do not depend on each other. For example, you don’t need to know the
    sum of the two elements of the two vectors at index 0 to compute the sum of the
    two elements at index 1\. As a result, the smaller operations can be performed
    at the same time, instead of one at a time, no matter how large the vectors are.
    Serial computation, such as a naive CPU implementation of vector addition, is
    known as Single Instruction Single Data (SISD). Parallel computation on the GPU
    is known as Single Instruction Multiple Data (SIMD). It typically takes the CPU
    less time to compute each individual addition than a GPU takes. But the total
    cost over this large amount of data leads the GPU’s SIMD to outperform the CPU’s
    SISD. A deep neural network can contain millions of parameters. For a given input,
    it might take billions of element-by-element math operations to run (if not more).
    The massively parallel computation that GPUs are capable of really shines at this
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Task: Add two vectors, element by element:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](f0022_01_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Computation on a CPU
  prefs: []
  type: TYPE_NORMAL
- en: '![](f0022_02_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Computation on a GPU
  prefs: []
  type: TYPE_NORMAL
- en: '![](f0022_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**How WebGL acceleration leverages a GPU’s parallel computation capability
    to achieve faster vector operation than a CPU**'
  prefs: []
  type: TYPE_NORMAL
- en: To be precise, modern CPUs are capable of certain levels of SIMD instructions,
    too. However, a GPU comes with a much greater number of processing units (on the
    order of hundreds or thousands) and can execute instructions on many slices of
    the input data at the same time. Vector addition is a relatively simple SIMD task
    in that each step of computation looks at only a single index, and the results
    at different indices are independent of each other. Other SIMD tasks seen in machine
    learning are more complex. For example, in matrix multiplication, each step of
    computation uses data from multiple indices, and there are dependencies between
    the indices. But the basic idea of acceleration through parallelization remains
    the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is interesting to note that GPUs were not originally designed for accelerating
    neural networks. This can be seen in the name: *graphics processing unit*. The
    primary purpose of GPUs is processing 2D and 3D graphics. In many graphical applications,
    such as 3D gaming, it is critical that the processing be done in as little time
    as possible so that the images on the screen can be updated at a sufficiently
    high frame rate for smooth gaming experiences. This was the original motivation
    when the creators of the GPU exploited SIMD parallelization. But, as a pleasant
    surprise, the kind of parallel computing GPUs are capable of also suits the needs
    of machine learning.'
  prefs: []
  type: TYPE_NORMAL
- en: The WebGL library TensorFlow.js uses for GPU acceleration was originally designed
    for tasks such as rendering textures (surface patterns) on 3D objects in the web
    browser. But textures are just arrays of numbers! Hence, we can pretend that the
    numbers are neural network weights or activations and repurpose WebGL’s SIMD texture
    operations to run neural networks. This is exactly how TensorFlow.js accelerates
    neural networks in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: '|  |'
  prefs: []
  type: TYPE_TB
- en: 'In addition to the advantages we have described, web-based machine-learning
    applications enjoy the same benefits as generic web applications that do not involve
    machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike native app development, the JavaScript application you write with TensorFlow.js
    will work on many families of devices, ranging from Mac, Windows, and Linux desktops
    to Android and iOS devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With its optimized 2D and 3D graphical capabilities, the web browser is the
    richest and most mature environment for data visualization and interactivity.
    In places where people would like to present the behavior and internals of neural
    networks to humans, it is hard to think of any environment that beats the browser.
    Take TensorFlow Playground, for example ([https://playground.tensorflow.org](https://playground.tensorflow.org)).
    It is a highly popular web app in which you can interactively solve classification
    problems with neural networks. You can tune the structure and hyperparameters
    of the neural network and observe how its hidden layers and outputs change as
    a result (see [figure 1.6](#ch01fig06)). If you have not played with it before,
    we highly recommend you give it a try. Many have expressed the view that this
    is among the most instructive and delightful educational materials they’ve seen
    on the topic of neural networks. TensorFlow Playground is, in fact, an important
    forebearer of TensorFlow.js. As an offspring of the Playground, TensorFlow.js
    is powered by a far wider range of deep-learning capabilities and far more optimized
    performance. In addition, it is equipped with a dedicated component for visualization
    of deep-learning models (covered in [chapter 7](kindle_split_019.html#ch07) in
    detail). No matter whether you want to build basic educational applications along
    the lines of TensorFlow Playground or present your cutting-edge deep-learning
    research in a visually appealing and intuitive fashion, TensorFlow.js will help
    you go a long way toward your goals (see examples such as real-time tSNE embedding
    visualization^([[8](#ch01fn8)])).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⁸
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: See Nicola Pezzotti, “Realtime tSNE Visualizations with TensorFlow.js,” *googblogs*,
    [http://mng.bz/nvDg](http://mng.bz/nvDg).
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Figure 1.6\. A screenshot of TensorFlow Playground ([https://playground.tensorflow.org](https://playground.tensorflow.org)),
    a popular browser-based UI for teaching how neural networks work from Daniel Smilkov
    and his colleagues at Google. TensorFlow Playground was also an important precursor
    of the later TensorFlow.js project.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig06_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 1.2.1\. Deep learning with Node.js
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For security and performance reasons, the web browser is designed to be a resource-constrained
    environment in terms of limited memory and storage quota. This means that the
    browser is not an ideal environment for training large machine-learning models
    with large amounts of data, despite the fact that it is ideal for many types of
    inference, small-scale training, and transfer-learning tasks, which require fewer
    resources. However, Node.js alters the equation entirely. Node.js enables JavaScript
    to be run outside the web browser, thus granting it access to all the native resources,
    such as RAM and the file system. TensorFlow.js comes with a Node.js version, called
    *tfjs-node*. It binds directly to the native TensorFlow libraries compiled from
    C++ and CUDA code, and so enables users to use the same parallelized CPU and GPU
    operation kernels as used under the hood by TensorFlow (in Python). As can be
    shown empirically, the speed of model training in tfjs-node is on par with the
    speed of Keras in Python. So, tfjs-node is an appropriate environment for training
    large machine-learning models with large amounts of data. In this book, you will
    see examples in which we use tfjs-node to train the kind of large models that
    are beyond the browser’s capability (for example, the word recognizer in [chapter
    5](kindle_split_016.html#ch05) and the text-sentiment analyzer in [chapter 9](kindle_split_021.html#ch09)).
  prefs: []
  type: TYPE_NORMAL
- en: But what are the possible reasons to choose Node.js over the more established
    Python environment for training machine-learning models? The answers are 1) performance
    and 2) compatibility with existing stack and developer skill sets. First, in terms
    of performance, the state-of-the-art JavaScript interpreters, such as the V8 engine
    Node.js uses, perform just-in-time (JIT) compilation of JavaScript code, leading
    to superior performance over Python. As a result, it is often faster to train
    models in tfjs-node than in Keras (Python), as long as the model is small enough
    for the language interpreter performance to be the determining factor.
  prefs: []
  type: TYPE_NORMAL
- en: Second, Node.js is a very popular environment for building server-side applications.
    If your backend is already written in Node.js, and you would like to add machine
    learning to your stack, using tfjs-node is usually a better choice than using
    Python. By keeping code in a single language, you can directly reuse large portions
    of your code base, including those bits for loading and formatting the data. This
    will help you set up the model-training pipeline faster. By not adding a new language
    to your stack, you also keep its complexity and maintenance costs down, possibly
    saving the time and cost of hiring a Python programmer.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the machine-learning code written in TensorFlow.js will work in both
    the browser environment and Node.js, with the possible exception of data-related
    code that relies on browser-only or Node-only APIs. Most of the code examples
    you will encounter in this book will work in both environments. We have made efforts
    to separate the environment-independent, machine-learning-centric part of the
    code from the environment-specific data-ingestion and UI code. The added benefit
    is that you get the ability to do deep learning on both the server and client
    sides by learning only one library.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.2\. The JavaScript ecosystem
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When assessing the suitability of JavaScript for a certain type of application
    such as deep learning, we should not ignore the factor that JavaScript is a language
    with an exceptionally strong ecosystem. For years, JavaScript has been consistently
    ranked number one among a few dozen programming languages in terms of repository
    count and pull activities on GitHub (see [http://githut.info](http://githut.info)).
    On npm, the de facto public repository of JavaScript packages, there are more
    than 600,000 packages as of July 2018\. This more than quadruples the number of
    packages in PyPI, the de facto public repository of Python packages ([www.modulecounts.com](http://www.modulecounts.com)).
    Despite the fact that Python and R have a better-established community for machine
    learning and data science, the JavaScript community is building up support for
    machine-learning-related data pipelines as well.
  prefs: []
  type: TYPE_NORMAL
- en: Want to ingest data from cloud storage and databases? Both Google Cloud and
    Amazon Web Services provide Node.js APIs. Most popular database systems today,
    such as MongoDB and RethinkDB, have first-class support for Node.js drivers. Want
    to wrangle data in JavaScript? We recommend the book *Data Wrangling with JavaScript*
    by Ashley Davis (Manning Publications, 2018, [www.manning.com/books/data-wrangling-with-javascript](http://www.manning.com/books/data-wrangling-with-javascript)).
    Want to visualize your data? There are mature and powerful libraries such as d3.js,
    vega.js, and plotly.js that outshine Python visualization libraries in many regards.
    Once you have your input data ready, TensorFlow.js, the main topic of this book,
    will take it from there and help you create, train, and execute your deep-learning
    models, as well as save, load, and visualize them.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the JavaScript ecosystem is still constantly evolving in exciting ways.
    Its reach is being extended from its traditional strongholds—namely, the web browser
    and Node.js backend environments—to new territories such as desktop applications
    (for example, Electron) and native mobile applications (for instance, React Native
    and Ionic). It is often easier to write UIs and apps for such frameworks than
    to use myriad platform-specific app creation tools. JavaScript is a language that
    has the potential to bring the power of deep learning to all major platforms.
    We summarize the main benefits of combining JavaScript and deep learning in [table
    1.2](#ch01table02).
  prefs: []
  type: TYPE_NORMAL
- en: Table 1.2\. A brief summary of the benefits of doing deep learning in JavaScript
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Consideration | Examples |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Reasons related to the client side |'
  prefs: []
  type: TYPE_TB
- en: Reduced inference and training latency due to the locality of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to run models when the client is offline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy protection (data never leaves the browser)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduced server cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplified deployment stack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reasons related to the web browser |'
  prefs: []
  type: TYPE_TB
- en: Availability of multiple modalities of data (HTML5 video, audio, and sensor
    APIs) for inference and training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The zero-install user experience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The zero-install access to parallel computation via the WebGL API on a wide
    range of GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-platform support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideal environment for visualization and interactivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inherently interconnected environment opens direct access to various sources
    of machine-learning data and resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reasons related to JavaScript |'
  prefs: []
  type: TYPE_TB
- en: JavaScript is the most popular open source programming language by many measures,
    so there is an abundance of JavaScript talent and enthusiasm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JavaScript has a vibrant ecosystem and wide applications at both client and
    server sides.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node.js allows applications to run on the server side without the resource constraints
    of the browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The V8 engine makes JavaScript code run fast.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 1.3\. Why TensorFlow.js?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To do deep learning in JavaScript, you need to select a library. TensorFlow.js
    is our choice for this book. In this section, we will describe what TensorFlow.js
    is and the reasons we selected it.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.1\. A brief history of TensorFlow, Keras, and TensorFlow.js
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: TensorFlow.js is a library that enables you to do deep learning in JavaScript.
    As its name suggests, TensorFlow.js is designed to be consistent and compatible
    with TensorFlow, the Python framework for deep learning. To understand TensorFlow.js,
    we need to briefly examine the history of TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow was made open source in November 2015 by a team of engineers working
    on deep learning at Google. The authors of this book are members of this team.
    Since its open source debut, TensorFlow has gained immense popularity. It is now
    being used for a wide range of industrial applications and research projects both
    at Google and in the larger technical community. The name “TensorFlow” was coined
    to reflect what happens inside a typical program written with the framework: data
    representations called *tensors* flow through layers and other data-processing
    nodes, allowing inference and training to happen on machine-learning models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First off, what is a tensor? It is just a computer scientist’s way of saying
    “multidimensional array” concisely. In neural networks and deep learning, every
    piece of data and every computation result is represented as a tensor. For example,
    a grayscale image can be represented as a 2D array of numbers—a 2D tensor; a color
    image is usually represented as a 3D tensor, with the extra dimension being the
    color channels. Sounds, videos, text, and any other types of data can all be represented
    as tensors. Each tensor has two basic properties: the data type (such as float32
    or int32) and the shape. Shape describes the size of the tensor along all its
    dimensions. For instance, a 2D tensor may have the shape `[128, 256]`, and a 3D
    tensor may have the shape `[10, 20, 128]`. Once data is turned into a tensor of
    a given data type and shape, it can be fed into any type of layer that accepts
    that data type and shape, regardless of the data’s original meaning. Therefore,
    the tensor is the lingua franca of deep-learning models.'
  prefs: []
  type: TYPE_NORMAL
- en: But *why* tensors? In the previous section, we learned that the bulk of the
    computations involved in running a deep neural network are performed as massively
    parallelized operations, commonly on GPUs, which require performing the same computation
    on multiple pieces of data. Tensors are containers that organize our data into
    structures that can be processed efficiently in parallel. When we add tensor A
    with shape `[128, 128]` to tensor B with shape `[128, 128]`, it is very clear
    that there are `128 * 128` independent additions that need to take place.
  prefs: []
  type: TYPE_NORMAL
- en: 'How about the “flow” part? Imagine a tensor as a kind of fluid that carries
    data. In TensorFlow, it flows through a *graph*—a data structure consisting of
    interconnected mathematical operations (called *nodes*). As [figure 1.7](#ch01fig07)
    shows, the node can be successive layers in a neural network. Each node takes
    tensors as inputs and produces tensors as outputs. The “tensor fluid” gets transformed
    into different shapes and different values as it “flows” through the TensorFlow
    graph. This corresponds to the transformation of representations: that is, the
    crux of what neural networks do, as we have described in previous sections. Using
    TensorFlow, machine-learning engineers can write all kinds of neural networks,
    ranging from shallow ones to very deep ones, from convnets for computer vision
    to recurrent neural networks (RNNs) for sequence tasks. The graph data structure
    can be serialized and deployed to run many types of devices, from mainframes to
    mobile phones.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.7\. Tensors “flow” through a number of layers, a common scenario in
    TensorFlow and TensorFlow.js.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig07_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'At its core, TensorFlow was designed to be very general and flexible: the operations
    can be any well-defined mathematical functions, not just layers of neural networks.
    For example, they can be low-level mathematical operations such as adding and
    multiplying two tensors—the kind of operations that happen *inside* a neural network
    layer. This gives deep-learning engineers and researchers great power to define
    arbitrary and novel operations for deep learning. However, for a large fraction
    of deep-learning practitioners, manipulating such low-level machinery is more
    trouble than it’s worth. It leads to bloated and more error-prone code and longer
    development cycles. Most deep-learning engineers use a handful of fixed layer
    types (for instance, convolution, pooling, or dense, as you will learn in detail
    in later chapters). Rarely do they need to create new layer types. This is where
    the LEGO analogy is appropriate. With LEGOs, there are only a small number of
    block types. LEGO builders don’t need to think about what it takes to make a LEGO
    block. This is different from a toy like, say, Play-Doh, which is analogous to
    TensorFlow’s low-level API. Yet the ability to connect LEGO blocks leads to a
    combinatorially large number of possibilities and virtually infinite power. It
    is possible to build a toy house with either LEGOs or Play-Doh, but unless you
    have very special requirements for the house’s size, shape, texture, or material,
    it is much easier and faster to build it with LEGOs. For most of us, the LEGO
    house we build will stand more stably and look nicer than the Play-Doh house we’d
    make.'
  prefs: []
  type: TYPE_NORMAL
- en: In the world of TensorFlow, the LEGO equivalent is the high-level API called
    Keras.^([[9](#ch01fn9)]) Keras provides a set of the most frequently used types
    of neural network layers, each with configurable parameters. It also allows users
    to connect the layers together to form neural networks. Furthermore, Keras also
    comes with APIs for
  prefs: []
  type: TYPE_NORMAL
- en: ⁹
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In fact, since the introduction of TensorFlow, a number of high-level APIs have
    emerged, some created by Google engineers and others by the open source community.
    Among the most popular ones are Keras, tf.Estimator, tf.contrib.slim, and TensorLayers.
    For the readers of this book, the most relevant high-level API to TensorFlow.js
    is Keras by far, because the high-level API of TensorFlow.js is modeled after
    Keras and because TensorFlow.js provides two-way compatibility in model saving
    and loading with Keras.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Specifying how the neural network will be trained (loss functions, metrics,
    and optimizers)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feeding data to train or evaluate the neural network or use the model for inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring the ongoing training process (callbacks)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving and loading models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Printing or plotting the architecture of models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With Keras, users can perform the full deep-learning workflow with very few
    lines of code. With the flexibility of the low-level API and the usability of
    the high-level API, TensorFlow and Keras form an ecosystem that leads the field
    of deep-learning frameworks in terms of industrial and academic adoption (see
    the tweet at [http://mng.bz/vlDJ](http://mng.bz/vlDJ)). As a part of the ongoing
    deep-learning revolution, their role in making deep learning accessible to a wider
    audience should not be underestimated. Before frameworks such as TensorFlow and
    Keras, only those with CUDA programming skills and extensive experience in writing
    neural networks in C++ were able to do practical deep learning. With TensorFlow
    and Keras, it takes much less skill and effort to create GPU-accelerated deep
    neural networks. But there was one problem: it was not possible to run TensorFlow
    or Keras models in JavaScript or directly in the web browser. To serve trained
    deep-learning models in the browser, we had to do it via HTTP requests to a backend
    server. This is where TensorFlow.js comes into the picture. TensorFlow.js was
    an effort started by Nikhil Thorat and Daniel Smilkov, two experts in deep-learning-related
    data visualization and human-computer interaction^([[10](#ch01fn10)]) at Google.
    As we have mentioned, the highly popular TensorFlow Playground demo of a deep
    neural network planted the initial seed of the TensorFlow.js project. In September
    2017, a library called deeplearn.js was released that has a low-level API analogous
    to the TensorFlow low-level API. Deeplearn.js championed WebGL-accelerated neural
    network operations, making it possible to run real neural networks with low inference
    latencies in the web browser.'
  prefs: []
  type: TYPE_NORMAL
- en: ^(10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As an interesting historical note, these authors also played key roles in creating
    TensorBoard, the popular visualization tool for TensorFlow models.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Following the initial success of deeplearn.js, more members of the Google Brain
    team joined the project, and it was renamed TensorFlow.js. The JavaScript API
    underwent significant revamping, boosting API compatibility with TensorFlow. In
    addition, a Keras-like high-level API was built on top of the low-level core,
    making it much easier for users to define, train, and run deep-learning models
    in the JavaScript library. Today, what we said earlier about the power and usability
    of Keras is all true for TensorFlow.js as well. To further enhance interoperability,
    converters were built so that TensorFlow.js can import models saved from TensorFlow
    and Keras and export models to them. Since its debut at the worldwide TensorFlow
    Developer Summit and Google I/O in the spring of 2018 (see [www.youtube.com/watch?v=YB-kfeNIPCE](http://www.youtube.com/watch?v=YB-kfeNIPCE)
    and [www.youtube.com/watch?v=OmofOvMApTU](http://www.youtube.com/watch?v=OmofOvMApTU)),
    TensorFlow.js has quickly become a highly popular JavaScript deep-learning library,
    with currently the highest number of stars and forks among similar libraries on
    GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1.8](#ch01fig08) presents an overview of the TensorFlow.js architecture.
    The lowest level is responsible for parallel computing for fast mathematical operations.
    Although this layer is not visible to most users, it is critical that it have
    high performance so that model training and inference in higher levels of the
    API can be as fast as possible. In the browser, it leverages WebGL to achieve
    GPU acceleration (see [info box 1.2](#ch01sb02)). In Node.js, direct binding to
    the multicore CPU parallelization and CUDA GPU acceleration are both available.
    These are the same math backends used by TensorFlow and Keras in Python. Built
    on top of the lowest math level is the *Ops API*, which has good parity with the
    low-level API of TensorFlow and supports loading SavedModels from TensorFlow.
    On the highest level is the Keras-like *Layers API*. The Layers API is the right
    API choice for most programmers using TensorFlow.js and will be the main focus
    of this book. The Layers API also supports two-way model importing/exporting with
    Keras.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.8\. The architecture of TensorFlow.js at a glance. Its relationship
    to Python TensorFlow and Keras is also shown.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](01fig08_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '1.3.2\. Why TensorFlow.js: A brief comparison with similar libraries'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'TensorFlow.js is not the only JavaScript library for deep learning; neither
    was it the first one to appear (for example, brain.js and ConvNetJS have a much
    longer history). So, why does TensorFlow.js stand out among similar libraries?
    The first reason is its comprehensiveness—TensorFlow.js is the only currently
    available library that supports all key parts of the production deep-learning
    workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: Supports both inference and training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports web browsers and Node.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverages GPU acceleration (WebGL in browsers and CUDA kernels in Node.js)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports definition of neural network model architectures in JavaScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports serialization and deserialization of models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports conversions to and from Python deep-learning frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compatible in API with Python deep-learning frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equipped with built-in support for data ingestion and with an API for visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second reason is the ecosystem. Most JavaScript deep-learning libraries
    define their own unique API, whereas TensorFlow.js is tightly integrated with
    TensorFlow and Keras. You have a trained model from Python TensorFlow or Keras
    and want to use it in the browser? No problem. You have created a TensorFlow.js
    model in the browser and want to take it into Keras for access to faster accelerators
    such as Google TPUs? That works, too! Tight integration with non-JavaScript frameworks
    not only boosts interoperability but also makes it easier for developers to migrate
    between the worlds of programming languages and infrastructure stacks. For example,
    once you have mastered TensorFlow.js from reading this book, it will be smooth
    sailing if you want to start using Keras in Python. The reverse journey is as
    easy: someone with good knowledge of Keras should be able to learn TensorFlow.js
    quickly (assuming sufficient JavaScript skills). Last but not least, the popularity
    of TensorFlow.js and the strength of its community should not be overlooked. The
    developers of TensorFlow.js are committed to long-term maintenance and support
    of the library. From GitHub star and fork counts to number of external contributors,
    from the liveliness of the discussion to the number of questions and answers on
    Stack Overflow, TensorFlow.js is shadowed by none of the competing libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.3\. How is TensorFlow.js being used by the world?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There is no more convincing testimony to the power and popularity of a library
    than the way in which it is used in real-world applications. A few noteworthy
    applications of TensorFlow.js include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Google’s Project Magenta uses TensorFlow.js to run RNNs and other kinds of deep
    neural networks to generate musical scores and novel instrument sounds in the
    browser ([https://magenta.tensorflow.org/demos/](https://magenta.tensorflow.org/demos/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dan Shiffman and his colleagues at New York University built ML5.js, an easy-to-use,
    higher-level API for various out-of-the-box deep-learning models for the browser,
    such as object detection and image style transfer ([https://ml5js.org](https://ml5js.org)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abhishek Singh, an open source developer, created a browser-based interface
    that translates American Sign Language into speech to help people who can’t speak
    or hear use smart speakers such as Amazon Echo.^([[11](#ch01fn11)])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^(11)
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Abhishek Singh, “Getting Alexa to Respond to Sign Language Using Your Webcam
    and TensorFlow.js,” *Medium*, 8 Aug. 2018, [http://mng.bz/4eEa](http://mng.bz/4eEa).
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Canvas Friends is a game-like web app based on TensorFlow.js that helps users
    improve their drawing and artistic skills ([www.y8.com/games/canvas_friends](http://www.y8.com/games/canvas_friends)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MetaCar, a self-driving car simulator that runs in the browser, uses TensorFlow.js
    to implement reinforcement learning algorithms that are critical to its simulations
    ([www.metacar-project.com](http://www.metacar-project.com)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clinic doctor, a Node.js-based application that monitors the performance of
    server-side programs, implemented a Hidden Markov Model with TensorFlow.js and
    is using it to detect spikes in CPU usage.^([[12](#ch01fn12)])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^(12)
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: Andreas Madsen, “Clinic.js Doctor Just Got More Advanced with TensorFlow.js,”
    *Clinic.js* blog, 22 Aug. 2018, [http://mng.bz/Q06w](http://mng.bz/Q06w).
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: See TensorFlow.js’s gallery of other outstanding applications built by the open
    source community at [https://github.com/tensorflow/tfjs/blob/master/GALLERY.md](https://github.com/tensorflow/tfjs/blob/master/GALLERY.md).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1.3.4\. What this book will and will not teach you about TensorFlow.js
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Through studying the materials in this book, you should be able to build applications
    like the following using TensorFlow.js:'
  prefs: []
  type: TYPE_NORMAL
- en: A website that classifies images uploaded by a user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep neural networks that ingest image and audio data from browser-attached
    sensors and perform real-time machine-learning tasks, such as recognition and
    transfer learning, on them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Client-side natural language AI such as a comment-sentiment classifier to assist
    with comment moderation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Node.js (backend) machine-learning model trainer that uses gigabyte-scale
    data and GPU acceleration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A TensorFlow.js-powered reinforcement learner that can solve small-scale control
    and game problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dashboard to illustrate the internals of trained models and the results of
    machine-learning experiments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Importantly, not only will you know how to build and run such applications,
    but you will also understand how they work. For instance, you will have practical
    knowledge of the strategies and constraints involved in creating deep-learning
    models for various types of problems, as well as the steps and gotchas in training
    and deploying such models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning is a wide field; TensorFlow.js is a versatile library. Therefore,
    some applications are entirely doable with existing TensorFlow.js technology but
    are beyond what is covered in the book. Examples are:'
  prefs: []
  type: TYPE_NORMAL
- en: High-performance, distributed training of deep neural networks that involve
    a huge amount of data (on the order of terabytes) in the Node.js environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-neural-network techniques, such as SVMs, decision trees, and random forests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced deep-learning applications such as text-summarization engines that
    reduce large documents into a few representative sentences, image-to-text engines
    that generate text summary from input images, and generative image models that
    enhance the resolution of input images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This book will, however, give you foundational knowledge of deep learning with
    which you will be prepared to learn about the code and articles related to those
    advanced applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like any other technology, TensorFlow.js has its limits. Some tasks are beyond
    what it can do. Even though these limits are likely to be pushed in the future,
    it is good to be aware of where the boundaries are at the time of writing:'
  prefs: []
  type: TYPE_NORMAL
- en: Running deep-learning models with memory requirements that exceed the RAM and
    WebGL limits in a browser tab. For in-browser inference, this typically means
    a model with a total weight size above ~100 MB. For training, more memory and
    compute power is required, so it is possible that even smaller models will be
    too slow to train in a browser tab. Model training also typically involves larger
    amounts of data than inference, which is another limiting factor that should be
    taken into account when assessing the feasibility of in-browser training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a high-end reinforcement learner, such as the kind that can defeat
    human players at the game of Go.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training deep-learning models with a distributed (multimachine) setup using
    Node.js.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Whether you are a frontend JavaScript developer or a Node.js developer, based
    on what you learned in this chapter, brainstorm a few possible cases in which
    you can apply machine learning to the system you are working on to make it more
    intelligent. For inspiration, refer to [tables 1.1](#ch01table01) and [1.2](#ch01table02),
    as well as [section 1.3.3](#ch01lev2sec9). Some further examples include the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A fashion website that sells accessories such as sunglasses captures images
    of users’ faces using the webcam and detects facial landmark points using a deep
    neural network running on TensorFlow.js. The detected landmarks are then used
    to synthesize an image of the sunglasses overlaid on the user’s face to simulate
    a try-on experience in the web page. The experience is realistic because the simulated
    try-on can run with low latency and at a high frame rate thanks to client-side
    inference. The user’s data privacy is respected because the captured facial image
    never leaves the browser.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A mobile sports app written in React Native (a cross-platform JavaScript library
    for creating native mobile apps) tracks users’ exercise. Using the HTML5 API,
    the app accesses real-time data from the phone’s gyroscope and accelerometer.
    The data is run through a TensorFlow.js-powered model that automatically detects
    the user’s current activity type (for example, resting versus walking versus jogging
    versus sprinting).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A browser extension automatically detects whether the person using the device
    is a child or an adult (by using images captured from the webcam at a frame rate
    of once per 5 seconds and a computer-vision model powered by TensorFlow.js) and
    uses the information to block or grant access to certain websites accordingly.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A browser-based programming environment uses a recurrent neural network implemented
    with TensorFlow.js to detect typos in code comments.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A Node.js-based server-side application that coordinates a cargo logistics service
    uses real-time signals such as carrier status, cargo type and quantity, date/time,
    and traffic information to predict the estimated time of arrival (ETA) for each
    transaction. The training and inference pipelines are all written in Node.js,
    using TensorFlow.js, simplifying the server stack.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI is the study of automating cognitive tasks. Machine learning is a subfield
    of AI in which rules for performing a task such as image classification are discovered
    automatically by learning from examples in the training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A central problem in machine learning is how to transform the original representation
    of data into a representation more amenable to solving the task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are an approach in machine learning wherein the transformation
    of data representation is performed by successive steps (or layers) of mathematical
    operations. The field of deep learning concerns deep neural networks— neural networks
    with many layers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks to enhancements in hardware, increased availability of labeled data,
    and advances in algorithms, the field of deep learning has made astonishing progress
    since the early 2010s, solving previously unsolvable problems and creating exciting
    new opportunities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JavaScript and the web browser are a suitable environment for deploying and
    training deep neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow.js, the focus of this book, is a comprehensive, versatile, and powerful
    open source library for deep learning in JavaScript.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
