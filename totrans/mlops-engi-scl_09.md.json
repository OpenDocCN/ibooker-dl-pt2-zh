["```py\nimport torch.utils.data.IterableDataset\n\nclass MyIterableDataset(Dataset):\n    def __init__(self, ...):\n      ...\n    def __iter__(self):\n      ...\n```", "```py\nbatch = next(iter(MyIterableDataset(...)))\n```", "```py\npip install kaen[osds]\n```", "```py\nfrom kaen.torch import ObjectStorageDataset as osds\n```", "```py\nbatch = next(iter(osds(...)))\n\ndef batchToXy(batch):\n  batch = batch.squeeze_()             ❶\n  return batch[:, 1:], batch[:, 0]     ❷\n\nX_batch, y_batch = batchToXy(batch)\n```", "```py\nimport os\nBUCKET_ID = os.environ['BUCKET_ID']\nAWS_DEFAULT_REGION = os.environ['AWS_DEFAULT_REGION']\nBATCH_SIZE = 1_048_576 # = 2 ** 20\n\ntrain_ds = \\\n  osds(f\"s3://dc-taxi-{BUCKET_ID}-{AWS_DEFAULT_REGION}/csv/dev/part*.csv\",\n        partitions_glob = f\"s3://dc-taxi-{BUCKET_ID}-\n➥           {AWS_DEFAULT_REGION}/csv/dev/.meta/shards/*.csv\",\n        storage_options = {'anon': False},\n        batch_size = BATCH_SIZE)\n```", "```py\nimport pandas as pd\npartitions_df = pd.read_csv(f\"s3://dc-taxi-{BUCKET_ID}-\n➥ {AWS_DEFAULT_REGION}/csv/dev/.meta/shards/*.csv\")\nprint(partitions_df[:5])\n```", "```py\nid   count\n77  164315\n10  165314\n31  165168\n 1  165436\n65  164777\n```", "```py\n    osds(f\"gcs://dc-taxi-${BUCKET_ID}-${AWS_DEFAULT_REGION}/test/part*.csv\")\n    ```", "```py\n    osds(f\"abfs://dc-taxi-${BUCKET_ID}-${AWS_DEFAULT_REGION}/test/part*.csv\")\n    ```", "```py\n    osds(\"file://home/user/test/part*.csv\")\n    ```", "```py\npt.set_default_dtype(pt.float64)                                        ❶\n\nFEATURE_COUNT = 8\n\nw = pt.nn.init.kaiming_uniform_(pt.empty(FEATURE_COUNT,\n                                            1, requires_grad=True))     ❷\n\nb = pt.nn.init.kaiming_uniform_(pt.empty(1,\n                                            1, requires_grad = True))   ❸\n```", "```py\ndef forward(X):\n  y_est = X @ w + b\n  return y_est.squeeze_()\n```", "```py\nimport os\nimport time\nimport torch as pt\n\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom kaen.torch import ObjectStorageDataset as osds\n\npt.manual_seed(0);\npt.set_default_dtype(pt.float64)   \n\nBUCKET_ID = os.environ['BUCKET_ID']\nAWS_DEFAULT_REGION = os.environ['AWS_DEFAULT_REGION']\n\nBATCH_SIZE = 2 ** 20 #evaluates to 1_048_576\ntrain_ds = osds(f\"s3://dc-taxi-{BUCKET_ID}-\n➥              {AWS_DEFAULT_REGION}/csv/dev/part*.csv\",\n                storage_options = {'anon': False},\n                batch_size = BATCH_SIZE)\n\ntrain_dl = DataLoader(train_ds, batch_size=None)\n\nFEATURE_COUNT = 8\n\nw = pt.nn.init.kaiming_uniform_(pt.empty(FEATURE_COUNT,\n                                            1, requires_grad=True))\nb = pt.nn.init.kaiming_uniform_(pt.empty(1,\n                                            1, requires_grad = True))\n\ndef batchToXy(batch):\n  batch = batch.squeeze_()\n  return batch[:, 1:], batch[:, 0]\n\ndef forward(X):\n  y_est = X @ w + b\n  return y_est.squeeze_()\n\nLEARNING_RATE = 0.03\noptimizer = pt.optim.SGD([w, b], lr = LEARNING_RATE)\n\nGRADIENT_NORM = None                                                       ❶\n\nITERATION_COUNT = 5\n\nfor iter_idx, batch in zip(range(ITERATION_COUNT), train_dl):\n  start_ts = time.perf_counter()\n\n  X, y = batchToXy(batch)\n\n  y_est = forward(X)\n  mse = pt.nn.functional.mse_loss(y_est, y)\n  mse.backward()\n\n  pt.nn.utils.clip_grad_norm_([w, b],                                      ❷\n                                GRADIENT_NORM) if GRADIENT_NORM else None  ❸\n\n  optimizer.step()\n  optimizer.zero_grad()\n\n  sec_iter = time.perf_counter() - start_ts\n\n  print(f\"Iteration: {iter_idx:03d}, Seconds/Iteration: {sec_iter:.3f} \n➥   MSE: {mse.data.item():.2f}\")\n```", "```py\nWARNING:root:defaulting to batch_size of 1048576\nWARNING:root:stats_glob is not specified at initialization, defaulting to\nstats_glob=s3://dc-taxi-c6e91f06095c3d7c61bcc0af33d68382-us-west-2/csv/dev/.meta/stats/part-00000-e4fcf448-1123-4bf4-b2bc-9768d30c6dd6-c000.csv\nIteration: 000, Seconds/Iteration: 0.020 MSE: 1590566.22\nIteration: 001, Seconds/Iteration: 0.024 MSE: 95402822161212448.00\nIteration: 002, Seconds/Iteration: 0.021 MSE: \n➥ 5722549747136962931644694528.00\nIteration: 003, Seconds/Iteration: 0.023 MSE: \n➥ 343256645163430856187799115795093520384.00\nIteration: 004, Seconds/Iteration: 0.021 MSE: \n➥ 20589650711877918152593680659301796448689601904640.00\n```", "```py\nIteration: 040, Seconds/Iteration: 0.027 MSE: 2450.01\nIteration: 041, Seconds/Iteration: 0.026 MSE: 416.45\nIteration: 042, Seconds/Iteration: 0.026 MSE: 218.96\nIteration: 043, Seconds/Iteration: 0.026 MSE: 416.74\nIteration: 044, Seconds/Iteration: 0.026 MSE: 214.22\nIteration: 045, Seconds/Iteration: 0.027 MSE: 407.82\nIteration: 046, Seconds/Iteration: 0.029 MSE: 216.30\nIteration: 047, Seconds/Iteration: 0.026 MSE: 415.99\nIteration: 048, Seconds/Iteration: 0.026 MSE: 223.59\nIteration: 049, Seconds/Iteration: 0.026 MSE: 421.73\n```", "```py\nimport os\nos.cpu_count()\n```", "```py\ndevice = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n```", "```py\n[pt.cuda.get_device_properties(i) for i in range(pt.cuda.device_count())]\n```", "```py\n[_CudaDeviceProperties(name='Tesla P100-PCIE-16GB',\n  major=6, minor=0, total_memory=16280MB, multi_processor_count=56)]\n```", "```py\npt.set_default_dtype(pt.float64)\n\ntensor = pt.empty(1)\nprint(tensor.dtype, tensor.device)\n```", "```py\ntorch.float64 cpu\n```", "```py\npt.set_default_tensor_type(pt.cuda.FloatTensor)      ❶\npt.set_default_dtype(pt.float64)\n\ntensor = pt.empty(1)\nprint(tensor.dtype, tensor.device)\n```", "```py\ntorch.float64 cuda:0\n```", "```py\npt.set_default_tensor_type(pt.cuda.FloatTensor)\npt.set_default_dtype(pt.float64)\n\ntensor = pt.empty(1, dtype=int)\nprint(tensor.dtype, tensor.device)\n```", "```py\ntorch.int64 cuda:0\n```", "```py\ndevice = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n\ntensor = pt.empty(1, dtype=int, device=device)\nprint(tensor.dtype, tensor.device)\n```", "```py\ntorch.int64 cuda:0\n```", "```py\ntorch.int64 cpu\n```", "```py\na = pt.randn(100).to(device)\n```", "```py\nb = pt.randn(100).to(device)\na + b\n```", "```py\nc = pt.randn(100)\na + c\n```", "```py\nimport timeit\nMAX_SIZE = 28\ndef benchmark_cpu_gpu(n, sizes):\n  for device in [\"cpu\", \"cuda\"]:\n    for size in sizes:\n      a = pt.randn(size).to(device)\n      b = pt.randn(size).to(device)\n      yield timeit.timeit(lambda: a + b, number = n)\n\nsizes = [2 ** i for i in range(MAX_SIZE)]\nmeasurements = list(benchmark_cpu_gpu(1, sizes))\ncpu = measurements[:MAX_SIZE]\ngpu = measurements[MAX_SIZE:]\nratios = [cpu[i] / gpu[i] for i in range(len(cpu))]\n```", "```py\niimport os\nimport torch as pt\nfrom torch.utils.data import DataLoader\nfrom kaen.torch import ObjectStorageDataset as osds\n\npt.manual_seed(0);\npt.set_default_dtype(pt.float64)\n\ndevice = pt.device(\"cuda\" \\                                                \n                      if pt.cuda.is_available() else \"cpu\")                ❶\n\nBATCH_SIZE = 1_048_576 # = 2 ** 20\n\ntrain_ds = osds(f\"s3://dc-taxi-{os.environ['BUCKET_ID']}-\n➥                 {os.environ['AWS_DEFAULT_REGION']}/csv/dev/part*.csv\",\n    storage_options = {'anon': False},\n    batch_size = BATCH_SIZE)\n\ntrain_dl = DataLoader(train_ds,\n                      pin_memory = True)                                   ❷\n\nFEATURE_COUNT = 8\nw = \\                                                                      ❷'\n\n  pt.nn.init.kaiming_uniform_(pt.empty(FEATURE_COUNT, 1,\n                                        requires_grad=True, device=device))❸\nb = \\                                                                      \n  pt.nn.init.kaiming_uniform_(pt.empty(1, 1,\n                                      requires_grad = True, device=device))❹\n\ndef batchToXy(batch):\n  batch = batch.squeeze_().to(device)                                      ❽\n  return batch[:, 1:], batch[:, 0]\n\ndef forward(X):\n  y_pred = X @ w + b\n  return y_pred.squeeze_()\n\ndef loss(y_est, y):\n  mse_loss = pt.mean((y_est - y) ** 2)\n  return mse_loss\n\nLEARNING_RATE = 0.03\noptimizer = pt.optim.SGD([w, b], lr = LEARNING_RATE)\n\nGRADIENT_NORM = 0.5\n\nITERATION_COUNT = 50\n\nfor iter_idx, batch in zip(range(ITERATION_COUNT), train_dl):              ❺\n  start_ts = time.perf_counter()\n\n  X, y = batchToXy(batch)\n\n  y_est = forward(X)\n  mse = loss(y_est, y)\n  mse.backward()\n\n  pt.nn.utils.clip_grad_norm_([w, b],\n                              GRADIENT_NORM) if GRADIENT_NORM else None\n\n  optimizer.step()\n  optimizer.zero_grad()\n\n  sec_iter = time.perf_counter() - start_ts\n\n  print(f\"Iteration: {iter_idx:03d}, Seconds/Iteration: {sec_iter:.3f} \n➥   MSE: {mse.data.item():.2f}\")\n```", "```py\nIteration: 040, Seconds/Iteration: 0.009 MSE: 865.98\nIteration: 041, Seconds/Iteration: 0.009 MSE: 36.48\nIteration: 042, Seconds/Iteration: 0.009 MSE: 857.78\nIteration: 043, Seconds/Iteration: 0.009 MSE: 39.33\nIteration: 044, Seconds/Iteration: 0.009 MSE: 868.70\nIteration: 045, Seconds/Iteration: 0.009 MSE: 37.57\nIteration: 046, Seconds/Iteration: 0.009 MSE: 870.87\nIteration: 047, Seconds/Iteration: 0.009 MSE: 36.42\nIteration: 048, Seconds/Iteration: 0.009 MSE: 852.75\nIteration: 049, Seconds/Iteration: 0.009 MSE: 36.37\n```"]