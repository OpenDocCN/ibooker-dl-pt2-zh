- en: 9 Balancing utility and cost with multifidelity optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: The problem of multifidelity optimization with variable cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a GP on data from multiple sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a cost-aware multifidelity BayesOpt policy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Should you trust the online reviews saying that the newest season of your favorite
    TV show isn’t as good as the previous ones and you should quit watching the show,
    or should you spend your next few weekends watching it to find out for yourself
    whether you will like the new season?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After seeing that their neural network model doesn’t perform well after being
    trained for a few epochs, should an ML engineer cut their losses and switch to
    a different model, or should they keep training for more epochs in the hope of
    achieving better performance?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a physicist wants to understand a physical phenomenon, can they use a computer
    simulation to gain insights, or are real, physical experiments necessary to study
    the phenomenon?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These questions are similar in that they demand that the person in question
    choose between two possible actions that can help them answer a question they’re
    interested in. On one hand, the person can take an action with a relatively low
    cost, but the answer generated from the action might be corrupted by noise and,
    therefore, not necessarily true. On the other hand, the person can opt for the
    action with a higher cost, which will help them arrive at a more definite conclusion:'
  prefs: []
  type: TYPE_NORMAL
- en: Reading the online reviews about the newest season of your TV shows would only
    take a few minutes, but there’s a chance the reviewers don’t have the same taste
    as you and you will still enjoy the show anyway. The only way to know for sure
    is to watch it yourself, but it’s a huge time commitment to do so.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of a neural network after being trained for a few epochs may
    be, but is not necessarily, indicative of its true performance. However, more
    training means more time and resources spent on a potentially non-value-adding
    task if the model ends up performing poorly in the end.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A computer simulation can tell a physicist many things about a phenomenon but
    cannot capture everything in the real world, so it’s possible the simulation cannot
    offer the right insight. Performing physical experiments, on the other hand, will
    certainly answer the physicist’s question but will cost a lot of money and effort.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These situations belong to a class of problems called *multifidelity* decision-making,
    where we can decide to observe some phenomenon at various levels of granularity
    and cost. Observing the phenomenon on a shallow level may be inexpensive and easy
    to do, but it doesn’t give us as much information as possible. On the other hand,
    inspecting the phenomenon closely might entail more effort. The term *fidelity*
    here refers to how closely an observation reflects the truth about the phenomenon
    in question. An inexpensive, low-fidelity observation is noisy and, thus, can
    lead us to the wrong conclusion, while high-quality (or high-fidelity) observations
    are expensive and, therefore, cannot be made liberally. Black box optimization
    has its own multifidelity variant.
  prefs: []
  type: TYPE_NORMAL
- en: Definition *Multifidelity optimization* is an optimization problem where in
    addition to the true objective function to be maximized, we can observe approximations
    that do not exactly match but still offer information about the objective function.
    These low-fidelity approximations can be evaluated at lower costs than the true
    objective function.
  prefs: []
  type: TYPE_NORMAL
- en: In a multifidelity optimization, we need to use these multiple sources of data
    simultaneously to gain the most information about what we’re interested in, which
    is the optimum of the objective function. In this chapter, we go into more detail
    about the problem of multifidelity optimization and how to approach it from the
    angle of BayesOpt. We learn about a strategy that balances learning about the
    objective function and cost, which results in a cost-aware BayesOpt policy for
    the multifidelity setting. We then see how to implement this optimization problem
    and the cost-aware policy in Python. By the end of this chapter, we learn how
    to perform multifidelity BayesOpt and see that our cost-aware strategy is more
    efficient at optimization than algorithms that only use the ground-truth function.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Using low-fidelity approximations to study expensive phenomena
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We first discuss the motivation of a multifidelity BayesOpt problem, its setup,
    and real-world examples of the problem. This discussion will help clarify what
    we look for in a decision-making policy for this setting.
  prefs: []
  type: TYPE_NORMAL
- en: In the simplest setting of BayesOpt, we evaluate the objective function at each
    search iteration, each time carefully reasoning about where to make this evaluation
    to make the most optimization progress. The need for this careful reasoning stems
    from the high cost of making function evaluations, as is typical in an expensive
    black box optimization problem. This cost can refer to the amount of time we spend
    waiting for a large neural network to finish training while searching for the
    best network architecture or, in a drug discovery procedure, the money and effort
    needed to synthesize an experimental drug and conduct experiments to test its
    effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what if there are ways to gauge the result of a function evaluation without
    actually evaluating the objective function, denoted as *f*(*x*)? That is, in addition
    to the objective function, we can query an inexpensive surrogate *f̄*(*x*). This
    surrogate *f̄*(*x*) is an inexact approximation to the objective function, so
    evaluating it won’t tell us everything about the true objective function *f*(*x*).
    However, since *f̄*(*x*) is an approximation of *f*(*x*), knowledge about the
    former still offers us insight into the latter. The question we need to ask ourselves
    is this: How should we balance using the true objective function *f*(*x*), which
    is expensive to query but offers exact information, and using the surrogate *f̄*(*x*),
    which is inaccurate but inexpensive to query? This balance is illustrated in figure
    9.1, where the ground truth *f*(*x*) is the high-fidelity data source and the
    surrogate *f̄* *(x)* is the low-fidelity approximation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 Model of a multifidelity decision-making problem, where the agent
    needs to balance querying the true objective function *f*(*x*) for accurate information
    and querying the inexpensive surrogate *f̄*(*x*)
  prefs: []
  type: TYPE_NORMAL
- en: 'As noted in the introduction, using a low-fidelity approximation is common
    in the real world, as in the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Training a neural network only for a small number of epochs to gauge its performance
    on some dataset.* The performance of the neural network over, for example, 5 epochs
    is a low-fidelity approximation of its optimized performance that can be achieved
    after 50 epochs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Running a computer simulation in lieu of a real experiment to study some scientific
    phenomenon.* This computer simulation imitates the physical processes happening
    in the real world and approximates the phenomenon the physicist wants to study.
    However, this approximation is low fidelity because the computer cannot accurately
    mirror the real world.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a multifidelity optimization problem where we aim to optimize the objective
    function *f*(*x*), we get to choose between querying the high-fidelity *f*(*x*)
    or the low-fidelity *f̄*(*x*) to best learn about and optimize *f*(*x*). Of course,
    querying *f*(*x*) will offer more information about *f*(*x*) itself, but the querying
    cost prevents us from making such queries many times. Instead, we can choose to
    take advantage of the low-fidelity approximation *f̄*(*x*) to learn as much as
    possible about our target *f*(*x*) while minimizing our querying cost.
  prefs: []
  type: TYPE_NORMAL
- en: Having multiple low-fidelity approximations
  prefs: []
  type: TYPE_NORMAL
- en: To keep things simple, we only work with one low-fidelity approximation *f̄*(*x*)
    in the examples in this chapter. However, many real-world settings offer multiple
    low-fidelity approximations *f̄* [1](*x*), *f̄* [2](*x*), ..., *f̄[k]*(*x*) to
    the objective function, each having its own querying cost and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The Bayesian approach we learn in the next section doesn’t limit how many low-fidelity
    approximations we have access to, and we solve a multifidelity optimization with
    two low-fidelity approximations *f̄* [1](*x*) and *f̄* [2](*x*) in this chapter’s
    exercise 2.
  prefs: []
  type: TYPE_NORMAL
- en: Having multiple low-fidelity approximations is applicable when, for example,
    the computer simulation approximating the real experiment has a setting that controls
    the quality of the approximation. If one were to set the simulation quality to
    low, the computer program would run a coarse simulation of the real world and
    return the result more quickly. On the other hand, if the simulation quality is
    set to high, the program might need to run for a longer duration to better approximate
    a real experiment. For now, we stick with one objective function and one low-fidelity
    approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Consider figure 9.2, where in addition to the Forrester function as an example
    objective function in BayesOpt, denoted as the solid line, we also have a low-fidelity
    approximation to the objective, denoted as the dotted line. Here, although the
    low-fidelity approximation doesn’t exactly match the ground truth, the former
    captures the general shape of the latter and can, therefore, be helpful in the
    search for the objective’s optimum.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 The Forrester function (solid line) and a low-fidelity approximation
    to the function (dotted line). Although the low-fidelity approximation doesn’t
    exactly match the ground truth, the former offers information about the latter,
    as the two functions have roughly the same shape.
  prefs: []
  type: TYPE_NORMAL
- en: For example, since the low-fidelity approximation is informative of the true
    objective function, we could query the approximation many times to study its behavior
    across the search space, only querying the ground truth when we want to “zero
    in” on the objective’s optimum. Our goal in this chapter is to design a BayesOpt
    policy that navigates this search for us and decides where and which function
    to query to optimize our objective function as quickly and cheaply as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'The multifidelity BayesOpt loop is summarized in figure 9.3 with the following
    notable changes from the traditional BayesOpt loop in figure 1.6:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In step 1, the GP is trained on data from *both* sources: the high-fidelity,
    or ground truth, function and the low-fidelity approximation. That is, our data
    is split into two sets: the set of data points evaluated on the ground truth *f*(*x*)
    and the set of points evaluated on the approximation *f̄*(*x*). Training on both
    datasets ensures the predictive model can reason about the objective function
    in regions where there is low-fidelity data but no high-fidelity data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In step 2, the BayesOpt policy generates an acquisition score for each data
    point in the search space to quantify the data point’s value in helping us identify
    the objective’s optimum. However, it’s not just the data points that are scored
    but the data point–fidelity pairs; that is, the policy quantifies the value of
    querying a given data point on a particular function (either the high- or low-fidelity
    function). This score needs to balance the optimization of the objective and the
    querying cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In step 3, we query the data point on the fidelity corresponding to the pair
    maximizing the acquisition score of the BayesOpt policy. We then update our training
    datasets with the new observation and loop back to step 1 to continue our BayesOpt
    procedure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the remainder of this chapter, we learn about the components of the multifidelity
    BayesOpt loop and how to implement them in Python, starting with training a GP
    on a dataset that includes both high- and low-fidelity observations.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Multifidelity modeling with GPs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As noted in figure 9.3, our GP model is trained on a combined dataset that includes
    observations from multiple fidelities. This combined training allows the GP to
    make predictions about the objective function, even in regions where there are
    only low-fidelity observations, which subsequently informs the BayesOpt policy
    that makes optimization-related decisions. In the next section, we learn how to
    represent a multifidelity dataset and train a special variant of the GP on the
    dataset; the code we use is included in CH09/01 - Multifidelity modeling.ipynb.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-03.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 The multifidelity BayesOpt loop. The GP trains on data from both
    the high- and low-fidelity functions, and the BayesOpt policy decides where and
    which function to query at each iteration of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Formatting a multifidelity dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To set up the multifidelity optimization problem, we use the following code
    for our one-dimensional Forrester objective function and its low-fidelity approximation
    in figure 9.2; our search space is between –5 and 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The true objective function
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The low-fidelity approximation to the objective function
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Bounds of the search space, to be used by optimization policies later on
  prefs: []
  type: TYPE_NORMAL
- en: 'Of particular importance is a PyTorch tensor that stores the information about
    the correlation between each fidelity function we have access to and the true
    objective function, which we aim to maximize. We assume we know the values of
    these correlations and declare this tensor `fidelities` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This tensor has two elements corresponding to the two fidelities we have access
    to: 0.5, which we use to indicate the correlation between the Forrester function
    *f*(*x*) and its low-fidelity approximation *f̄*(*x*) (the solid and dotted lines
    in figure 9.2), and exactly 1, which is the correlation between the Forrester
    function and itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These correlation values are important because they inform how much the GP
    we will train later should rely on data from a particular fidelity:'
  prefs: []
  type: TYPE_NORMAL
- en: If the correlation to the true objective function of a low-fidelity approximation
    is high, then that approximation offers a lot of information about the objective.
    An extreme example of this is the objective function itself, which offers perfect
    information about what we’re interested in and, therefore, has a correlation value
    of 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A low-fidelity approximation with a correlation value of 0.5, which we have
    in our example, offers information about the objective that is inexact but still
    valuable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the other end of the spectrum, an approximation with a correlation value
    of 0 doesn’t tell us anything about the objective function; a perfectly horizontal
    line is an example, since this “approximation” is constant across the domain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 9.4 illustrates this scale of correlation: the higher a correlation
    is, the more information about the ground truth a low-fidelity approximation offers.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting the fidelities variable
  prefs: []
  type: TYPE_NORMAL
- en: In general, `fidelities` is a tensor with *k* elements, where *k* is the number
    of functions we can query, including the objective. The elements are numbers between
    0 and 1 denoting the correlation between the functions and the objective. It’s
    more convenient for the subsequent learning and decision-making tasks to have
    1, the correlation between the true objective and itself, at the end of the tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there is no concrete rule on how to set these fidelity values;
    the decision is left to the BayesOpt engineer. If these values are not known in
    your own use case, you can make a rough estimate based on figure 9.4 by estimating
    where your low-fidelity function lies between the high-fidelity function (the
    ground truth) and an uninformative data source.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-04.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 The scale of correlation from 0 to 1 between a low-fidelity approximation
    and the ground truth. The higher the correlation, the more information about the
    ground truth the low-fidelity approximation offers.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the functions and correlation values in hand, let’s now create an example
    training dataset. We first randomly sample 10 locations inside the search space
    and store them as a tensor in `train_x`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The size of the training set
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Fixes the random seed for reproducibility
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Draws points uniformly at random from the space
  prefs: []
  type: TYPE_NORMAL
- en: The tensor `train_x` has 10 rows and 1 column since we have 10 data points within
    a one-dimensional space. Each of these data points is associated with a fidelity
    from which the observation comes (that is, each data point is either a high-fidelity
    or a low-fidelity observation). We encode this information in our dataset by adding
    in an extra column to `train_x` to indicate the fidelity of each data points,
    as illustrated in figure 9.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-05.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 Formatting the features in a multifidelity dataset. Each data point
    is associated with a fidelity; these fidelity values are stored in an extra column
    in the training set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note Remember that we aim to train a GP on data coming from both sources: the
    ground truth and the low-fidelity function. To this end, we will randomly assign
    each of the 10 data points we have to either fidelity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use `torch.randint(2)` to randomly pick out an integer between 0 (inclusive)
    and 2 (exclusive), effectively choosing between 0 and 1\. This number determines
    from which function each data point comes: 0 means that the data point is evaluated
    on the low-fidelity approximation *f̄*(*x*); 1 means the data point is evaluated
    on the objective function *f*(*x*). We then extract the corresponding correlation
    values in `fidelities` for each data point and concatenate this array of correlation
    values to our training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Randomly selects the fidelity (and therefore the correlation value) of each
    data point
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Adds the correlation values to the training data
  prefs: []
  type: TYPE_NORMAL
- en: Taking a look at the full training data `train_x_full`, we see the first two
    data points are
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The first data point is evaluated on f(x).
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The second data point is evaluated on *f̄* (x).
  prefs: []
  type: TYPE_NORMAL
- en: The first column of `train_x_full` contains the locations of the data points
    between –5 and 5, while the second column contains the correlation values. This
    output means our first training point is at –0.0374, and it’s evaluated on *f*(*x*).
    On the other hand, the second training point is at 2.6822, this time evaluated
    on *f̄*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to generate the observations `train_y` appropriately so that the
    observations are computed with the correct function: the first element of `train_y`
    is equal to *f*(–0.0374), the second element is *f̄* (2.6822), and so on. To do
    this, we write a helper function that takes in the full training set, where the
    last column contains the correlation values, and call the appropriate function
    to generate `train_y`. That is, if the correlation value is 1, we call `objective()`,
    which is *f*(*x*), as previously defined; if the correlation value is 0.5, we
    call `approx_objective()` for *f̄*(*x*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Iterates through the data points
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Queries f(x) if the correlation value is 1
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Queries *f̄* (x) if the correlation value is 0.5
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Reshapes the observation tensor to be of the correct shape
  prefs: []
  type: TYPE_NORMAL
- en: Calling `evaluate_all_functions()` on `train_x_full` gives us the observed value
    `train_y`, evaluated on appropriate functions. Our training set is visualized
    in figure 9.6, where there are three high-fidelity observations and seven low-fidelity
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-06.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 A randomly sampled, multifidelity training dataset from the Forrester
    function and its low-fidelity approximation. This training set contains three
    high-fidelity observations and seven low-fidelity observations.
  prefs: []
  type: TYPE_NORMAL
- en: That’s how we generate and format a training set in multifidelity BayesOpt.
    Our next task is to train a GP on this dataset in a way that uses both the ground
    truth and the low-fidelity approximation.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.2 Training a multifidelity GP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our goal in this section is to have a GP that takes in a set of multifidelity
    observations and outputs probabilistic predictions about the target function—that
    is, the objective function *f*(*x*) to be maximized.
  prefs: []
  type: TYPE_NORMAL
- en: Remember from section 2.2 that a GP is an MVN distribution of infinitely many
    variables. The GP models the covariance (and, therefore, correlation) between
    any pair of variables using the covariance function. It’s with this correlation
    between any two variables that the GP can make predictions about one variable
    when the value of the other is observed.
  prefs: []
  type: TYPE_NORMAL
- en: A refresher on correlation and updated belief about a variable
  prefs: []
  type: TYPE_NORMAL
- en: Say there are three variables *A*, *B*, and *C*, jointly modeled with a tri-variate
    Gaussian distribution, where the correlation between *A* and *B* is high, but
    the correlation between *A* and *C* and between *B* and *C* are both low.
  prefs: []
  type: TYPE_NORMAL
- en: Now, when we observe the value of *A*, the uncertainty in our updated belief
    about *B* (represented as the posterior distribution of the value of *B*) significantly
    reduces. This is because the correlation between *A* and *B* is high, so observing
    the value *A* gives us a lot of information about the value of *B*. This is not
    the case for *C*, however, since the correlation between *A* and *C* is low, so
    the updated belief about *C* still has considerable uncertainty. See section 2.2.2
    for a similar and detailed discussion about housing prices.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we learned in section 2.2.2, as long as we have a way to model the correlation
    between any pair of variables (that is, the function values at any two given locations),
    we can update the GP accordingly to reflect our updated belief about the function
    anywhere in the domain. This is still true in the multifidelity setting: as long
    as we have a way to model the correlation between two observations, even if one
    is from the high fidelity *f*(*x*) and the other is from the low fidelity *f̄*(*x*),
    we can update the GP on the objective function *f*(*x*).'
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s left for us to do is use a covariance function that can compute the
    covariance between two given observations, which may or may not be from the same
    fidelity. Fortunately for us, BoTorch offers a modified version of the Matérn
    kernel that accounts for the fidelity correlation value associated with each data
    point in our training set:'
  prefs: []
  type: TYPE_NORMAL
- en: If the correlation value of a data point is high, the kernel will produce a
    high covariance between that observed data point and any nearby point, thus allowing
    us to reduce the GP’s uncertainty with an informative observation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the correlation value is low, the kernel will output a low covariance, and
    the posterior uncertainty will remain high.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note We first learned about the Matérn kernel in section 3.4.2\. While we won’t
    go into the details about the multifidelity Matérn kernel here, the interested
    reader can find more information in BoTorch’s documentation ([http://mng.bz/81ZB](http://mng.bz/81ZB)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the GP with the multifidelity kernel is implemented as a special GP class,
    we can import it from BoTorch without having to write our own class implementation.
    Specifically, this GP is an instance of the `SingleTaskMultiFidelityGP` class,
    which takes in a multifidelity training set `train_x_full` and `train_y`. The
    initialization also has a `data_fidelity` argument, which should be set to the
    index of the column in `train_x_full` that contains the correlation values; this,
    in our case, is `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Imports the GP class implementation
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Initializes a multifidelity GP
  prefs: []
  type: TYPE_NORMAL
- en: 'After initializing the model, we now need to train it by maximizing the likelihood
    of the observed data. (Refer to section 3.3.2 for more on why we choose to maximize
    the likelihood to train a GP.) Since the GP we have is an instance of a special
    class from BoTorch, we can take advantage of BoTorch’s helper function `fit_gpytorch_mll()`,
    which facilitates the training process behind the scenes. All we need to do is
    initialize a (log) likelihood object as our training objective and pass it to
    the helper function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Imports the log likelihood objective and the helper function for training
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Initializes the log likelihood objective
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Trains the GP to maximize the log likelihood
  prefs: []
  type: TYPE_NORMAL
- en: These surprisingly few lines of code are all we need to train a multifidelity
    GP on a set of observations.
  prefs: []
  type: TYPE_NORMAL
- en: BoTorch warnings about data type and scaling
  prefs: []
  type: TYPE_NORMAL
- en: When running the previous code, newer versions of GPyTorch and BoTorch might
    display two warnings, the first of which is
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This warning indicates that we should use a different data type for `train_x`
    and `train_y` from the default `torch.float32` to improve numerical precision
    and stability. To do this, we can add the following to our code (at the beginning
    of the script):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The second warning concerns scaling the input features `train_x` to be in the
    unit cube (each feature value being between 0 and 1) and the response values `train_y`
    to be standardized to have zero mean and unit variance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Scaling `train_x` and `train_y` this way helps us fit the GP more easily and
    in a more numerically stable way. To keep our code simple, we won’t implement
    such scaling here and will be filtering out these warnings using the `warnings`
    module. The interested reader can refer to chapter 2’s exercise for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to verify whether this trained GP is able to learn about the training set,
    we visualize the GP’s predictions about *f*(*x*) between –5 and 5 with the mean
    and the 95% CIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our test set `xs` is a dense grid (with over 200 elements) between –5 and 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike what we’ve seen in previous chapters, we need to augment this test set
    with an extra column denoting the fidelity on which we’d like to predict. In other
    words, the test set `xs` needs to be in the same format as the training set `train_x_full`.
    Since we’re interested in the GP’s predictions about *f*(*x*), we add in an extra
    column full of ones (as 1 is the correlation value of *f*(*x*)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Disables gradient tracking
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Augments the test set with the fidelity column and passes it to the model
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Computes the mean predictions
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Computes the 95% CIs
  prefs: []
  type: TYPE_NORMAL
- en: 'These predictions are visualized in figure 9.7, which illustrates a number
    of important features about our multifidelity GP:'
  prefs: []
  type: TYPE_NORMAL
- en: The mean predictions about *f*(*x*) go through the high-fidelity observations
    at roughly –3.6, 0, and 1.3\. This interpolation makes sense as these data points
    were indeed evaluated on *f*(*x*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In regions where we have low-fidelity observations but not high-fidelity observations
    (e.g., at –2 and around 2.7), our uncertainty about *f*(*x*) still decreased.
    This is because the low-fidelity observations offer information about *f*(*x*),
    even though they weren’t evaluated on *f*(*x*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Among these low-fidelity observations, we see that the data point at 4 could
    offer valuable information to an optimization policy since the data point captures
    the upward trend of the objective function around that region. By exploiting this
    information, an optimization policy could discover the global optimum nearby,
    around 4.5.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-07.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 The multifidelity GP’s predictions about the objective function (ground
    truth). The mean predictions appropriately go through the high-fidelity observations,
    but uncertainty is still reduced around low-fidelity observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.7 shows that the GP successfully learned from a multifidelity data
    set. To push our ability to learn from low-fidelity observations and predict *f*(*x*)
    to the extreme, we could modify the way we generate our training set so it only
    contains low-fidelity observations. We do this by setting the correlation values
    in the extra column in `train_x_full` to `0.5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The correlation values are all 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Adds the correlation values to the training set
  prefs: []
  type: TYPE_NORMAL
- en: Rerunning the last of the code so far will generate the left panel of figure
    9.8, where we see that all data points are, indeed, from the low-fidelity approximation
    *f̄*(*x*). Compared to figure 9.7, we are more uncertain about our predictions
    here, which is appropriate because having observed only low-fidelity observations,
    the GP doesn’t learn as much about the objective function *f*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-08.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 The predictions about the objective function (ground truth) by a
    GP trained on only low-fidelity observations. The left panel shows the result
    when the correlation value is 0.5; the right shows the result when the correlation
    value is 0.9, which exhibits less uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: To further show the flexibility of our multifidelity GP, we can play around
    with the correlation values stored in `fidelities` (while assuming we know how
    to appropriately set these correlation values). As we learned in section 9.2.1,
    the first element in this tensor denotes the correlation between *f*(*x*) and
    *f̄*(*x*), which roughly translates to how much the GP should “trust” the low-fidelity
    observations. By setting this first element to 0.9 (as opposed to 0.5, as we currently
    do), we can assign more importance to the low-fidelity observations. That is,
    we are telling the GP to learn more from the low-fidelity data, as it offers a
    lot of information about *f*(*x*). The right panel of figure 9.8 shows the resulting
    GP, where our uncertainty is, indeed, lower than in the left panel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from the flexibility of the multifidelity GP model, figure 9.8 also shows
    how important it is to have the correct correlation values in the `fidelities`
    tensor. Comparing the two panels in figure 9.8, we see that 0.5 is a better value
    for the correlation value between two fidelities than 0.9:'
  prefs: []
  type: TYPE_NORMAL
- en: In the right panel, our predictions miss the true objective *f*(*x*) in most
    of the space due to our overreliance on and trust in the low-fidelity observations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the left panel, the 95% CIs are appropriately wider to reflect our uncertainty
    about *f*(*x*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other words, we don’t want to overestimate how informative the low-fidelity
    approximation *f̄*(*x*) is about the objective *f*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we have learned how to model a function with a multifidelity
    GP. For the remainder of this chapter, we discuss the second part of the multifidelity
    optimization problem: decision-making. More specifically, we learn how to design
    a multifidelity optimization policy that selects at which location and which function
    to query at each step of the BayesOpt loop.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.3 Balancing information and cost in multifidelity optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To be able to trade off between the informativeness of a query (low or high
    fidelity) and the cost of running that query, we need to have a way to model and
    reason about the querying cost. In the next section, we learn how to represent
    the cost of querying a given fidelity with a linear model. Using this cost model,
    we then implement a multifidelity BayesOpt policy that trades off cost and making
    optimization progress. The code we use is stored in the CH09/02 - Multi-fidelity
    optimization.ipynb notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.1 Modeling the costs of querying different fidelities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the multifidelity optimization problem, we assume we know how much it costs
    to query each of the functions we have access to, either the objective function
    *f*(*x*) itself or the low-fidelity approximation *f̄*(*x*). To facilitate a modular
    optimization workflow, we need to represent this information about the cost of
    querying each function as a cost model. This model takes in a given data point
    (with an extra feature containing the correlation value, as we saw in section
    9.2.1) and returns the known cost of querying that data point on the specified
    fidelity.
  prefs: []
  type: TYPE_NORMAL
- en: Note Since the cost of querying a fidelity is known, there’s no prediction involved
    in this cost model. We just need this model formulation to keep the optimization
    procedure we learn about in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: BoTorch provides the class implementation for a linear cost model named `AffineFidelityCostModel`
    from the `botorch.models.cost` module. This linear cost model assumes the querying
    costs obey the relationships shown in figure 9.9, where the cost of querying a
    data point on a fidelity scales linearly with the correlation between that fidelity
    and the ground truth *f*(*x*). The slope of this linear trend is the weight parameter
    in figure 9.9, and there’s a fixed cost to making any query.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-09.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 The linear cost model for multifidelity optimization. The cost of
    querying a data point on a fidelity scales linearly with the correlation between
    that fidelity and the ground truth *f*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: 'We initialize this linear cost model with the following code, where we set
    the fixed cost at 0 and the weight at 1\. This means querying a low-fidelity data
    point will cost us exactly the correlation value of the low-fidelity approximation,
    which is 0.5 (units of cost). Similarly, querying a high-fidelity data point will
    cost 1 (unit of cost). Here, the `fidelity_weights` argument takes in a dictionary
    mapping the index of the column containing the correlation values in `train_x_full`
    (`1` in our case) to the weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The fixed querying cost
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The linear weight to be multiplied with the correlation values
  prefs: []
  type: TYPE_NORMAL
- en: Note The unit of cost being used depends on the specific application. This cost
    comes down to the difference in “convenience” between querying the objective and
    querying the low-fidelity approximation, which can be time (the unit would be
    minutes, hours, or days), money (in dollars), or some measure of effort, and should
    be set by the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'The linear trend captures the relationship between the correlation value and
    cost: a high-fidelity function with a high correlation value should have a high
    querying cost, while a low-fidelity function should have a lower cost to query.
    The two settable parameters—the fixed cost and weight—allow us to flexibly model
    many types of querying costs. (We see how different types of querying costs can
    lead to different decisions being made in the next section.) With this cost model
    in hand, we are now ready to learn how to balance cost and progress in a multifidelity
    optimization problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling nonlinear querying costs
  prefs: []
  type: TYPE_NORMAL
- en: We only use the linear cost model in this chapter. If your use case demands
    the querying costs to be modeled by a nonlinear trend (e.g., a quadratic or an
    exponential trend), you can implement your own cost model.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is done by extending the `AffineFidelityCostModel` class we are using
    and rewriting its `forward()` method. The implementation of the `AffineFidelityCostModel`
    class is shown in BoTorch’s official documentation ([https://botorch.org/api/_modules/botorch/models/cost.xhtml](https://botorch.org/api/_modules/botorch/models/cost.xhtml)),
    where we see the `forward()` method implements the linear relationship between
    querying cost and correlation value, as in figure 9.9:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Multiplies the correlation values with the weight
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Adds the fixed cost
  prefs: []
  type: TYPE_NORMAL
- en: In a new class for the custom cost model, you can then rewrite this `forward()`
    method to implement the relationship between querying cost and correlation value
    that you need. Even with a custom cost model, the rest of the code we use in this
    chapter doesn’t need to be modified, which illustrates the benefit of BoTorch’s
    modular design.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.2 Optimizing the amount of information per dollar to guide optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We now return to the question posed at the beginning of this chapter: How should
    we balance the amount of information we can gain by querying a function and the
    cost of querying that function? In multifidelity optimization, a high-fidelity
    function (the ground truth) offers us exact information about the objective *f*(*x*)
    to optimize *f*(*x*), but the querying cost is high. On the other hand, a low-fidelity
    approximation is inexpensive to evaluate but can only provide inexact information
    about *f*(*x*). It is the job of a multifidelity BayesOpt policy to decide how
    this balancing is done.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-09-unnumb.png)'
  prefs: []
  type: TYPE_IMG
- en: We already have a model from section 9.3.1 that computes the cost of querying
    any given data point. As for the other side of the scale, we need a method of
    quantifying how much we will learn about the objective function from a given query
    that can either be from the objective *f*(*x*) itself or from the low-fidelity
    approximation *f̄*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: Note How much information about *f*(*x*) or, more specifically, about the optimum
    of *f*(*x*), we will gain from a query is exactly what the Max-value Entropy Search
    (MES) policy, which we learned about in chapter 6, uses to rank its queries. MES
    chooses the query that gives us the most information about the highest value of
    *f*(*x*) in the single-fidelity setting, where we can only query the objective.
  prefs: []
  type: TYPE_NORMAL
- en: As this information gain measure is a general information-theoretic concept,
    it can be applied to the multifidelity setting as well. In other words, we use
    MES as the base policy to compute how much information about the optimum of *f*(*x*)
    we gain with each query during optimization. With both components, cost and information
    gain, available to us, we now need to design a way to balance the two, which gives
    us a *cost-aware* measure of utility of a query.
  prefs: []
  type: TYPE_NORMAL
- en: The return on investment quantity
  prefs: []
  type: TYPE_NORMAL
- en: To quantify the cost-aware utility of a query, we use a common metric in economics,
    called the return on investment (ROI) measure, which is calculated by dividing
    the profit from an investment by the investing cost. In the context of using MES
    in multifidelity optimization, the profit is the amount of information gained
    from querying a data point, and the cost is the querying cost.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the acquisition score of a BayesOpt policy is the score the policy
    assigns to each data point within the search space to quantify the point’s value
    in helping us optimize the objective function. With the ROI acquisition score
    we use here, each data point is scored by the amount of information it provides
    about the objective’s optimum for each unit of cost. This calculation is visualized
    in figure 9.10.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 The formula of the ROI acquisition score for multifidelity optimization.
    This score quantifies the amount of information a query provides about the objective’s
    optimum for each unit of cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'We see that this ROI score is an appropriate measure that weights the information
    gained from a query by how inexpensive it is to make that query:'
  prefs: []
  type: TYPE_NORMAL
- en: If two queries we can potentially make have the same cost but result in different
    information gains, we should pick the one offering more information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If two queries provide the same amount of information about the objective’s
    optimum, we should pick the one that’s less expensive to make.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This tradeoff allows us to acquire information about the objective function
    *f*(*x*) from inexpensive, low-fidelity approximations if these approximations
    are, indeed, informative. On the other hand, if and when the low-fidelity queries
    stop offering information about *f*(*x*), we will switch to high-fidelity data
    points. Essentially, we always choose the optimal cost-aware decision that gives
    “the most bang for our buck.”
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement this cost-aware variant of MES, we can make use of BoTorch’s `qMultiFidelityMaxValueEntropy`
    class implementation. This implementation requires a number of components, which
    it takes in as arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A cost utility object that does the ROI computation in figure 9.10.* This
    object is implemented with the `InverseCostWeightedUtility` class, which weights
    the utility of a query by the inverse of its cost. The initialization takes in
    the cost model we made earlier:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*A Sobol sequence that acts as the candidate set for the entropy computation
    of MES.* We first learned about using Sobol sequences with MES in section 6.2.2,
    and the procedure is the same here, where we draw a 1,000-element Sobol sequence
    from the unit cube (it’s just the segment going from 0 to 1, in our one-dimensional
    case) and scale it to our search space. One more thing we need to do in the multifidelity
    setting is augment this candidate set with the extra column for the correlation
    value of 1 (corresponding to the objective function *f*(*x*)) to denote that we
    want to measure entropy in our target *f*(*x*):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Fixes the random seed for reproducibility
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Draws 1,000 points from a Sobol sequence within the unit cube
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Scales the samples to our search space
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Augments the samples with the index of the ground truth
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Finally, a helper function that projects a given data point from any fidelity
    to the ground truth.* This projection is necessary in the computation of entropy
    that our policy uses to calculate the acquisition scores. Here, BoTorch provides
    that helper function `project_to_target_fidelity`, which doesn’t need any further
    parameterization if the last column in our training set contains the correlation
    values and the correlation value of the ground truth is 1, both of which are true
    in our code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the preceding components, we implement our cost-aware, multifidelity
    MES policy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The samples from the Sobol sequence
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The cost utility object that weights utility by the inverse of the cost
  prefs: []
  type: TYPE_NORMAL
- en: ❸ The projection helper function
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can use this policy object to score each data point from any
    fidelity by its cost-adjusted value in helping us find the objective’s optimum.
    The last piece of the puzzle is the helper function we use to optimize the acquisition
    score of this policy to find the point with the highest ROI score at each iteration
    of the search. In previous chapters, we use `optimize_acqf` from the `botorch.optim.optimize`
    module to optimize the acquisition score in the single-fidelity setting, which
    only works if our search space is continuous.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note In our current multifidelity setting, the search space for the location
    of the query is still continuous, but the choice for the function with which to
    query is discrete. In other words, our search space is mixed. Fortunately, BoTorch
    offers the analogous helper function for a mixed search space: `optimize_acqf_mixed`.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the usual arguments that `optimize_acqf` takes, the new helper
    function, `optimize_acqf_mixed`, also has a `fixed_features_list` argument, which
    should be a list of dictionaries, each mapping the index of a discrete column
    in `train_x_` `full` to the possible values the column contains. In our case,
    we only have one discrete column, the last column containing the correlation values,
    so we use `[{1:` `cost.item()}` `for` `cost` `in` `fidelities]` for the `fixed_features_list`
    argument. Further, the `bounds` variable we usually pass to the helper function
    now needs to contain the bounds for the correlation values as well. Overall, we
    optimize our multifidelity MES acquisition score with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Bounds for the search space, including those for the correlation values
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The discrete values the correlation column could contain
  prefs: []
  type: TYPE_NORMAL
- en: This helper function completes the code we need to use the multifidelity MES
    policy. The bottom panel of figure 9.11 visualizes the acquisition scores computed
    by this policy with the multifidelity GP we trained in section 9.2.2\. In this
    bottom panel, the boundary of the shaded region (denoting the scores of low-fidelity
    queries) exceeds that of the hatch-pattern region (the scores of high-fidelity
    queries), meaning low-fidelity queries are more cost-effective than high-fidelity
    ones, given our current knowledge. Ultimately, the best query we make, denoted
    as the star, is around 3.5 on the low-fidelity approximation *f̄*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 The current GP belief about the objective function (top) and the
    acquisition scores computed by the multifidelity MES policy (bottom). In this
    example, low-fidelity queries are preferred to high-fidelity ones thanks to their
    low cost.
  prefs: []
  type: TYPE_NORMAL
- en: A low-fidelity query is the optimal kind to make in figure 9.11, as it offers
    more information relative to its cost than any high-fidelity query. However, this
    is not always the case. By modifying our data generation procedure from section
    9.2.2 to generate an all-low-fidelity-observation training set and rerunning our
    code, we obtain the left panel of figure 9.12, where this time, the optimal decision
    is to query the high-fidelity function *f*(*x*). This is because according to
    our GP belief, we have sufficiently learned from low-fidelity data, and it’s time
    we inspected the ground truth *f*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 Situations where high-fidelity queries are preferred to low-fidelity
    ones. On the left, the training set contains only low-fidelity observations. On
    the right, low-fidelity queries are almost as expensive as high-fidelity queries.
  prefs: []
  type: TYPE_NORMAL
- en: As a final analysis of the behavior of our policy, we can study the effect of
    the querying costs on how decisions are made. To do this, we change our querying
    costs, so a low-fidelity query won’t be much less expensive than a high-fidelity
    one, specifically by increasing the fixed querying cost described in section 9.3.1
    from 0 to 10\. This change means a low-fidelity query now costs 10.5 units of
    cost, and a high-fidelity query now costs 11\. Compared to the costs of 0.5 and
    1 from before, 10.5 and 11 are much closer to each other, making the denominators
    in figure 9.10 for the two fidelities almost equal. This means the low-fidelity
    approximation *f̄*(*x*) is almost as expensive to query as the objective function
    *f*(*x*) itself. Given these querying costs, the right panel of figure 9.12 shows
    how the MES policy scores potential queries. This time, because high-fidelity
    queries aren’t much more expensive than low-fidelity ones, the former are preferred,
    as they give us more knowledge about *f*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: These examples show that MES can identify the optimal decision that balances
    information and cost appropriately. That is, the policy assigns higher scores
    to low-fidelity queries when they are inexpensive to make and can offer substantial
    information about the objective function. If, on the other hand, high-fidelity
    queries are either significantly more informative or not much more expensive,
    these high-fidelity queries will be preferred by the policy.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4 Measuring performance in multifidelity optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our previous discussion shows that the multifidelity MES policy is able to make
    appropriate decisions when choosing between the two fidelities to query. But is
    this policy better than regular BayesOpt policies that only query the ground truth
    *f*(*x*), and if so, how much better is it? In this section, we learn how to benchmark
    the performance of a BayesOpt policy within the multifidelity setting, which requires
    additional considerations. The code we show can be found in the CH09/03 - Measuring
    performance.ipynb notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Note To measure optimization progress in previous chapters, we recorded the
    highest objective values (aka the *incumbents*) we have collected in the training
    set throughout the search. If the incumbent values collected by policy *A* exceed
    those collected by policy *B*, we say that policy *A* is more effective at optimization
    than policy *B*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recording the incumbent values doesn’t work here in the multifidelity setting.
    First, if we were to record the incumbent value in a training set, it would only
    make sense to pick the high-fidelity data point with the highest-valued label.
    However, this strategy ignores any contribution toward learning about the objective
    *f*(*x*) that low-fidelity queries make. Take the two possible scenarios visualized
    in figure 9.13, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: In the first scenario, on the left, we have made three high-fidelity observations,
    and the highest observed value is roughly 0.8\. Objectively speaking, we have
    made no optimization progress in this situation; we haven’t even explored the
    region where *x* is greater than 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second scenario, on the right, we have only made low-fidelity observations,
    so recording the high-fidelity incumbent value isn’t even applicable. However,
    we see that we are very close to finding the objective function’s optimum here
    as our queries have discovered the function’s peak around 4.5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.13 Measuring performance with the high-fidelity incumbent is inappropriate
    in multifidelity optimization. On the left, the high-fidelity incumbent is roughly
    0.8, while we haven’t discovered the objective’s optimum. On the right, even though
    we are close to locating the objective’s optimum, there’s no high-fidelity query
    to record the incumbent value with.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we should prefer the second scenario to the first, as one illustrates
    near success at optimization, while the other shows little optimization progress.
    However, using the high-fidelity incumbent as a measure of progress doesn’t help
    us make this distinction between the two scenarios. Thus, we need another way
    of measuring optimization progress.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note A common progress measure in the BayesOpt community is the objective function’s
    value at the location that currently gives the highest posterior mean. This measure
    corresponds to the answer to this question: If we were to stop running BayesOpt
    and recommend a point as the solution to the optimization problem, which point
    should we choose? Intuitively, we should choose the point that, in the most plausible
    scenario (according to our GP belief), gives the highest value, which is the posterior
    mean maximizer.'
  prefs: []
  type: TYPE_NORMAL
- en: We see that the posterior mean maximizer facilitates the comparison we made
    in figure 9.13, where on the left, the posterior mean maximizer is at 0, which
    still gives an objective value of 0.8 (the mean maximizer usually corresponds
    to the incumbent in the single-fidelity case), while on the right, the mean maximizer
    is around 4.5\. In other words, the posterior-mean-maximizer metric successfully
    helps us distinguish between the two scenarios and shows that the one on the left
    is less preferable than the one on the right.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement this metric, we make a helper policy that uses the posterior mean
    as its acquisition score. Then, just as we optimize a regular policy’s acquisition
    score in BayesOpt, we optimize the posterior mean using this helper policy. This
    policy requires two components:'
  prefs: []
  type: TYPE_NORMAL
- en: The class implementation of the BayesOpt policy that uses the posterior mean
    as its acquisition score. This class is `PosteriorMean`, which can be imported
    from `botorch.acquisition`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A *wrapper* policy that only optimizes high-fidelity metrics. This wrapper is
    required because our GP model is a multifidelity one, and we always need to specify
    which fidelity we’d like to work with when passing this model to an optimization
    policy. This wrapper policy is implemented as an instance of `FixedFeatureAcquisitionFunction`
    from `botorch.acquisition.fixed_feature`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Overall, we make the posterior-mean-maximizer metric with the following helper
    policy, where the wrapper policy takes in an instance of `PosteriorMean`, and
    we specify the other arguments as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The dimension of the search space is* `d` `=` `2`—Our actual search space
    is one-dimensional, and there’s an additional dimension for the correlation values
    (that is, the fidelity to query).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The index of the dimension to be fixed during optimization,* `columns` `=`
    `[1]` *and its fixed value* `values` `=` `[1]`—Since we only want to find the
    posterior mean maximizer corresponding to the objective function, the high-fidelity
    function, we specify that the second column (index `1`) should always have the
    value 1:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Optimizes the posterior mean
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The number of dimensions of the search space
  prefs: []
  type: TYPE_NORMAL
- en: ❸ The index of the fixed column
  prefs: []
  type: TYPE_NORMAL
- en: ❹ The value of the fixed column
  prefs: []
  type: TYPE_NORMAL
- en: 'We then use the familiar helper function `optimize_acqf` to find the point
    that maximizes the acquisition score, which is the posterior mean of the objective
    function (we first learned about this helper function in section 4.2.2):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Optimize the posterior mean.
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The other arguments are the same as when we optimize another policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'This `final_x` variable is the location that maximizes the posterior mean of
    the objective function. In our Jupyter notebook, we put this code in a helper
    function that returns `final_x`, augmented with a correlation value of 1, indicating
    the true objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Makes the wrapper policy
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Optimizes the acquisition score
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Augments the final recommendation with a correlation value of 1
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, during the BayesOpt loop, instead of recording the incumbent value as
    an indication of optimization progress, we call this `get_final_recommendation`
    helper function. Further, instead of a maximum number of queries to be made in
    each run, we now have a maximum budget, which can be spent on either low- or high-fidelity
    queries. In other words, we keep running our optimization algorithm until the
    cumulative cost exceeds our budget limit. The skeleton of our multifidelity BayesOpt
    loop is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Maximum cost for each optimization run
  prefs: []
  type: TYPE_NORMAL
- en: ❷ To track the recommendation maximizing posterior mean throughout optimization
  prefs: []
  type: TYPE_NORMAL
- en: ❸ To track the spent budget at each iteration
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Generates a random starting observation
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Trains the GP on current data
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Updates record with the newest recommendation
  prefs: []
  type: TYPE_NORMAL
- en: ❼ Initializes the policy and optimizes its acquisition score
  prefs: []
  type: TYPE_NORMAL
- en: ❽ Keeps track of the spent budget
  prefs: []
  type: TYPE_NORMAL
- en: ❾ Updates the training data
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now ready to run multifidelity MES to optimize the Forrester objective
    function. As a benchmark, we will also run the single-fidelity MES policy, which
    only queries the ground truth *f*(*x*). The GP model we have is a multifidelity
    one, so to run a single-fidelity BayesOpt policy with this model, we need a wrapper
    policy of the `FixedFeatureAcquisitionFunction` class to restrict the fidelity
    the policy can query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The wrapped policy is the single-fidelity MES.
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Fixes the correlation value in the second column (index 1) at 1
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Optimizes the acquisition score using the helper function optimize_acqf
  prefs: []
  type: TYPE_NORMAL
- en: Running the two policies generates the result in figure 9.14, where we observe
    that multifidelity MES greatly outperforms the single-fidelity version. The cost-effectiveness
    of multifidelity MES illustrates the benefit of balancing between information
    and cost. However, we note that this is only the result of a single run; in exercise
    1, we run this experiment multiple times with different initial datasets and observe
    the average performance of these policies.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.14 The objective value of the posterior mean maximizer as a function
    of the budget spent by two BayesOpt policies. Here, multifidelity MES greatly
    outperforms the single-fidelity version.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have learned about the problem of multifidelity optimization,
    in which we balance optimizing the objective function with the cost of gaining
    knowledge about the objective. We learned how to implement a GP model that can
    learn from multiple sources of data. This model then allowed us to reason about
    the information-theoretic value of making a query in terms of locating the optimal
    value of the objective. By combining this information-theoretic quantity with
    the querying cost in a return-on-investment measure, we devised a cost-aware,
    multifidelity variant of the MES policy that can trade off knowledge and cost
    automatically.
  prefs: []
  type: TYPE_NORMAL
- en: '9.5 Exercise 1: Visualizing average performance in multifidelity optimization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To compare the performance of our policies, figure 9.14 visualizes the objective
    value of the posterior mean maximizer throughout optimization against the amount
    of budget spent. However, this is the result from just one optimization run, and
    we’d like to show the average performance by each policy from multiple experiments.
    (We first discussed the idea of repeated experiments in exercise 2 of chapter
    4.) In this exercise, we run the optimization loop multiple times and learn how
    to take the average performance to obtain a more holistic comparison. By the end
    of the exercise, we will see that multifidelity MES balances well between information
    and cost and optimizes the objective function more effectively than its single-fidelity
    counterpart. The solution is stored in the CH09/04 - Exercise 1.ipynb notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the problem setup and the multifidelity optimization loop from the CH09/03
    - Measuring performance.ipynb notebook, and add another variable denoting the
    number of experiments we want to run (10, by default).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To facilitate repeated experiments, add an outer loop to the optimization loop
    code. This should be a `for` loop with 10 iterations where a different random
    observation is generated each time. (This random generation could be done by setting
    PyTorch’s random seed to the iteration number, which ensures the random number
    generator returns the same data across different runs with the same seed.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The code in the CH09/03 - Measuring performance.ipynb notebook uses two lists,
    `recommendations` and `spent_budget`, to keep track of optimization progress.
    Make each of these variables a list of lists where each inner-list serves the
    same purpose as the corresponding list in the CH09/03 - Measuring performance.ipynb
    notebook. These lists of lists allow us to keep track of optimization progress
    over the 10 experiments and compare different optimization policies in later steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the multifidelity MES policy and its single-fidelity version on our optimization
    problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the cost of querying the low-fidelity function is different from that
    of querying the high-fidelity function, it’s likely that the lists in `spend_budget`
    don’t exactly match with each other. In other words, the points in the curves
    in figure 9.14 don’t have the same *x*-coordinates across the runs. This mismatch
    prevents us from taking the average progress stored in `recommendations` across
    the multiple runs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To address this problem, we use a linear interpolation for each progress curve,
    which allows us to “fill in” the progress values on a regular grid. It is on this
    regular grid that we will average out the performance of each policy across runs.
    For the linear interpolation, use `np.interp` from NumPy, which takes in a regular
    grid as its first argument; this grid can be an array of integers between 0 and
    `budget_limit`: `np.arange(budget_limit)`. The second and third arguments are
    the *x*- and *y*-coordinates of the points making up each progress curve—that
    is, each inner-list in `spend_budget` and `recommendations`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Use the linearly interpolated values to plot the average performance and error
    bars of the two policies we ran, and compare their performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Due to the way we’re currently measuring optimization performance, it’s possible
    that the list of recommendations we keep track of throughout each run is not monotonically
    increasing. (That is, we might end up with a recommendation that performs worse
    than the previous iteration’s recommendation.) To inspect this phenomenon, we
    can plot the linearly interpolated curves representing individual runs' optimization
    progress, along with the average performance and error bars. Implement this visualization
    for the two policies we ran, and inspect the nonmonotonicity of the resulting
    curves.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '9.6 Exercise 2: Multifidelity optimization with multiple low-fidelity approximations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The approach we learned in this chapter can generalize to scenarios where there
    is more than one low-fidelity approximation to the objective function that we
    can query. Our strategy is the same: divide the amount of information we gain
    from each query by its cost, and then pick the query that gives the highest return
    on investment. This exercise shows us that our multifidelity MES policy can balance
    between multiple low-fidelity functions. The solution is stored in the CH09/05
    - Exercise 2.ipynb notebook.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For our objective function, we use the two-dimensional function named `Branin`,
    which is a common test function for optimization, like the Forrester function.
    BoTorch comes with a multifidelity version of Branin, so we import it to our code
    with `from` `botorch.test_functions.multi_fidelity` `import` `AugmentedBranin`.
    For convenience, we scale the domain and output of this function using the following
    code, which makes `objective` the function to call when we evaluate a query:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Imports the Branin function from BoTorch
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Processes the input and output of the function, mapping the values to a nice
    range
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Define the bounds of our search space to be the unit square. That is, the two
    lower bounds are 0, and the two upper bounds are 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Declare the `fidelities` variable that stores the correlation values of the
    different functions we can query. Here, we have access to two low-fidelity approximations
    with correlation values of 0.1 and 0.3, so `fidelities` should contain these two
    numbers and 1 as the last element.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/09-15.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 9.15 The objective function Branin (right) and two low-fidelity approximations
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The three functions are visualized in figure 9.15, where bright pixels denote
    high objective values. We see that both low-fidelity approximations follow the
    general trend exhibited by the ground truth, and the resemblance to the ground
    truth increases with the fidelity value. That is, the second approximation with
    fidelity 0.3 (middle) is more similar to the true objective function (right) than
    the first approximation with fidelity 0.1 (left).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Set the fixed cost of the linear cost model to 0.2 and the weight to 1\. This
    means the cost of querying the low-fidelity function on the left of figure 9.15
    is 0.2 + 1 × 0.1 = 0.3\. Similarly, the cost of querying the middle function is
    0.5, and that of querying the true objective function is 1.2\. Set the limit of
    our budget in each experiment to 10 and the number of repeated experiments to
    10 as well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the number of candidates drawn from the Sobol sequence to 5,000, and use
    100 restarts and 500 raw samples when using helper functions to optimize the acquisition
    score of a given policy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Redefine the helper function `get_final_recommendation` that finds the posterior
    mean maximizer so that the arguments are appropriately set for our two-dimensional
    objective function: `d` `=` `3` and `columns` `=` `[2]`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the multifidelity Max-value Entropy Search policy and its single-fidelity
    version on the optimization problem, and plot the average optimization progress
    and error bars of each policy using the method described in exercise 1\. Note
    that when creating the wrapper policy for the single-fidelity policy, the arguments
    `d` and `columns` need to be set in the same way as in the previous step. Verify
    that the multifidelity policy performs better than the single-fidelity one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multifidelity optimization is an optimization setting in which we have access
    to multiple sources of information, each with its own level of accuracy and cost.
    In this setting, we need to balance the amount of information gained from taking
    an action and the cost of taking that action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In multifidelity optimization, a high-fidelity function offers exact information
    but is costly to evaluate, while a low-fidelity function is inexpensive to query
    but might give inexact information. At each iteration of the optimization loop,
    we need to decide where and which function to query to find the objective function’s
    optimum as quickly as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The level of information each fidelity provides is quantified by the correlation
    between itself and the ground truth, which is a number between 0 and 1\. The higher
    the correlation, the more closely the fidelity matches the ground truth. In Python,
    we store the correlation value of each data point as an extra column in the feature
    matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A GP with a kernel that can process the correlation values of the training data
    points can be trained on a multifidelity dataset; we can use the multifidelity
    variant of the Matérn kernel for this task. The uncertainty in the predictions
    of the GP depends on which function each observation comes from and, if it comes
    from a low-fidelity function, what the correlation value of that function is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use a linear model to encode the querying cost of each fidelity we have access
    to during optimization. By setting the parameters of this model—the fixed cost
    and the weight—we can model the positively correlated relationship between querying
    cost and the quality of the data. Nonlinear cost models can also be implemented
    using BoTorch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To balance between informativeness and cost, we use a variant of the MES policy
    that weights the amount of information resulting from each query by the inverse
    of the querying cost. This measure is analogous to the return-on-investment concept
    in economics and is implemented with the `InverseCostWeightedUtility` class from
    BoTorch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exact calculation of information gain for the objective function’s optimal value,
    the core task of MES, is intractable due to the non-Gaussian distribution of the
    optimal value. To approximate the information gain, we use a Sobol sequence to
    represent the entire search space, alleviating the computational burden in the
    calculation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The multifidelity MES policy successfully balances information and cost and
    prioritizes cost-effective queries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To optimize the acquisition score of a multifidelity policy, we use the `optimize_
    acqf_mixed` helper function, which can work with a mixed search space whose dimensions
    can be either continuous or discrete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To accurately measure performance in the multifidelity setting, we use the maximizer
    of the posterior mean at each iteration as a final recommendation before termination.
    This quantity captures what we know about the objective function better than the
    high-fidelity incumbent value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To optimize a single-fidelity acquisition score in a multifidelity setting,
    we use a wrapper policy that is an instance of the `FixedFeatureAcquisitionFunction`
    class. To initialize a wrapper policy, we declare which dimension in the search
    space is fixed and at what value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
