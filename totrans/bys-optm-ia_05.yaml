- en: Part 2\. Making decisions with Bayesian optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分。用贝叶斯优化做决策
- en: 'The GP is only one part of the equation. To fully realize the BayesOpt technique,
    we need the second part of the equation: decision-making policies that dictate
    how function evaluations should be carried out to optimize the objective function
    as quickly as possible. This part enumerates the most popular BayesOpt policies,
    including their motivations, mathematical intuitions, and implementations. While
    different policies are motivated by different objectives, they all aim to balance
    the tradeoff between exploration and exploitation—a core challenge in BayesOpt,
    specifically, and decision-making under uncertainty problems, more generally.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: GP 只是方程式的一部分。为了充分实现 BayesOpt 技术，我们需要方程式的第二部分：决策策略，这些策略规定了如何进行函数评估以尽快优化目标函数。本部分列举了最流行的
    BayesOpt 策略，包括它们的动机、数学直觉和实现。虽然不同的策略受到不同目标的驱使，但它们都旨在平衡勘探和开发之间的权衡——这是 BayesOpt 特别是以及不确定性问题下的决策制定的核心挑战。
- en: 'Chapter 4 kicks things off by introducing the idea of an acquisition score
    as a way to quantify the value of making a function evaluation. The chapter also
    describes the heuristic of seeking to improve from the best point we have seen
    so far, which leads to two popular BayesOpt policies: Probability of Improvement
    and Expected Improvement.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 第四章通过引入获取分数的概念来开始介绍事物，这是一种量化进行函数评估价值的方法。该章还描述了一种试图从迄今为止看到的最佳点改进的启发式方法，这导致了两种流行的
    BayesOpt 策略：改进概率和预期改进。
- en: 'Chapter 5 connects BayesOpt with a closely related problem: multi-armed bandits.
    We explore the popular Upper Confidence Bound policy, which uses the optimism
    under uncertainty heuristic, and the Thompson sampling policy, which uses the
    probabilistic nature of the GP to aid decision-making.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 第五章将 BayesOpt 与一个密切相关的问题联系起来：多臂赌博机。我们探索了流行的上置信界限策略，该策略使用乐观主义下的不确定性启发式，以及 Thompson
    抽样策略，该策略利用了 GP 的概率性质来辅助决策。
- en: Chapter 6 introduces us to information theory, a subfield of mathematics that
    has many applications in decision-making problems. Using a central concept of
    information theory called entropy, we design a BayesOpt policy that seeks to gain
    the most information about our search target.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 第六章向我们介绍了信息理论，这是数学的一个子领域，在决策问题中有许多应用。利用信息理论的一个核心概念熵，我们设计了一个名为 BayesOpt 策略，该策略旨在获取关于我们搜索目标的最多信息。
- en: Throughout this part, we learn about the different ways to address the exploration–exploitation
    tradeoff and build a diverse tool set of optimization methods. While we have learned
    to use GPyTorch to implement GPs in the previous part, the premiere BayesOpt library,
    BoTorch, is our focus in this part. We learn how to declare BayesOpt policies,
    use them to facilitate an optimization loop, and compare their performance across
    a wide range of tasks. By the end of this part, you will obtain hands-on knowledge
    regarding implementing and running BayesOpt policies.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们了解了解决勘探-开发权衡的不同方法，并建立了多种优化方法的多样化工具集。虽然我们已经学会了在前一部分中使用 GPyTorch 实现 GPs，但
    BoTorch，首要的 BayesOpt 库，是我们在这一部分的重点。我们学习如何声明 BayesOpt 策略，使用它们来促进优化循环，并比较它们在各种任务中的性能。到本部分结束时，您将获得关于实施和运行
    BayesOpt 策略的实践知识。
