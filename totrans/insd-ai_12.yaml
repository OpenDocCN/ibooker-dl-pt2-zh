- en: 'appendix A Tracing the roots: From mechanical calculators to digital dreams'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To the average person, it might seem that AI is a recent field, given the increased
    public awareness of AI in recent years. However, the foundation of the concepts
    and theories that underpin this discipline can be traced back centuries. This
    chapter embarks on a voyage through time, retracing the footsteps of the pioneers
    who led us to AI as we know today. We will discover visionaries who dreamed of
    machines that could reason and learn: from Pascal’s ingenious mechanical design
    of the mechanical calculator that marked a pivotal moment in the history of human
    interaction with machines, Leibniz’s binary system that still serves as the representational
    basis for today’s digital computing, Babbage’s conception of the Analytical Engine
    as a mechanical brain, and Ada Lovelace’s insights into programming. Understanding
    these historical developments will shed light on where AI has been, where it stands
    today, and its potential future.'
  prefs: []
  type: TYPE_NORMAL
- en: A.1 Can machines think?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The question of whether a machine possesses the capacity for thought was initially
    raised almost four centuries ago, back in 1642\. This inquiry emerged when Blaise
    Pascal (1623–1662) introduced the Pascaline, which stands as the earliest documented
    calculating device. At the tender age of 19, Pascal conceived this machine with
    the primary objective of aiding his father, who worked as a tax collector. Its
    purpose was twofold: to minimize errors and to alleviate the taxing burden of
    monotonous computations.'
  prefs: []
  type: TYPE_NORMAL
- en: The Pascaline significantly enhanced human cognitive capabilities by flawlessly
    executing addition, subtraction, multiplication, and division (figure A.1). This
    mechanical marvel accepted input, executed operations, and produced numerical
    results. By automating these functions, it diminished the necessity for manual
    human labor. This innovation proved especially invaluable to Pascal’s father,
    who would otherwise have been immersed in the arduous and time-consuming task
    of manual calculations.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/A-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.1 Pascaline (CNAM France)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Pascaline also featured a clever carry mechanism (known as *le sautoir*) designed
    to handle carry-over operations (*la retenue*). This innovation addressed one
    of the primary calculation errors that Pascal had observed while assisting his
    father. As you may recall from your own arithmetic lessons, when calculating something
    like 2…9, we start by adding the rightmost digits, writing down 6, and then “carry
    the 1” to the next column. Impressed by this invention, King Louis XIV granted
    Pascal the exclusive right to manufacture his calculating machines in France in
    1649.
  prefs: []
  type: TYPE_NORMAL
- en: In his work “Pensées” [1], which is a compilation of notes and essays exploring
    the complexities of human nature in psychological, social, metaphysical, and theological
    terms, Pascal made some of the earliest significant comparisons between machines
    and sentient beings. For instance, he stated, “The arithmetical machine produces
    effects that come closer to thought than all the actions of animals. However,
    it performs nothing that would allow us to attribute will to it, as we do to animals.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Likewise, in “The Life of Monsieur Pascal” [2], his sister Madame Périer described
    the Pascaline as “performing tasks that reside entirely in the mind.” She recounted
    her brother’s achievements:'
  prefs: []
  type: TYPE_NORMAL
- en: It was at that time (in 1642–1643) and at the age of nineteen that he invented
    this arithmetic machine, by which not only are all kinds of operations performed
    without a pen and without tokens, but we do them even without knowing any arithmetic
    rule and with infallible certainty. This work was considered as a new thing from
    nature, to have reduced to a machine a science which resides entirely in mind
    and to have found the means to carry out all the operations there with complete
    certainty without having the need for reasoning. This work tired him a lot, not
    for the thought nor for the movements which he found without difficulty, but to
    make the workers understand all these things so that it took him two years to
    put it in the perfection where it is now.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'While Pascaline required a human operator skilled in manipulating the machine’s
    controls, it undertook tasks that typically demanded individuals well-versed in
    mathematics. This raises the question: should we classify Pascaline as the inaugural
    AI machine? This consideration is pertinent because, much like Pascaline, contemporary
    computers execute computational tasks rooted in algorithms meticulously crafted
    and encoded by human programmers. Even the most advanced AI systems of today essentially
    represent a compilation of technologies meticulously designed and fine-tuned by
    humans to generate specific behaviors, devoid of genuine comprehension or reasoning
    capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: In 1671, approximately three decades following the creation of the Pascaline,
    Gottfried Wilhelm von Leibniz introduced the Stepped Reckoner, an ingenious calculating
    device that employed decimal number representation and performed multiplication
    through iterative addition, facilitated by a hand-crank mechanism (figure A.2).
    Informed by his endeavors in mechanizing numerical representation, Leibniz penned
    a renowned treatise in 1703, titled “An Explanation of Binary Arithmetic Using
    Only the Characters 0 and 1, with Remarks About Its Utility and the Meaning It
    Gives to the Ancient Chinese Figures of Fuxi” [3]. In this seminal work, he introduced
    the binary number system, which relies exclusively on two digits, 0 and 1\. This
    binary system is now the cornerstone of virtually all modern computers.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/A-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.2 Replica of Leibniz Stepped Reckoner in Deutsches Museum
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We are all acquainted with the decimal number system, commonly referred to as
    “base 10.” This system utilizes the digits 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9, with
    each digit’s position in a number signifying its value in 1s, 10s, 100s, and so
    on. The invention of the decimal system by our ancestors was likely influenced
    by their use of 10 fingers for counting. In our daily calculations, like adding
    … to get 8 or subtracting 7 from 27 to yield 20, we unconsciously employ the base
    10 system. Many people may not realize that this choice is arbitrary and that
    alternative systems, such as binary, exist.
  prefs: []
  type: TYPE_NORMAL
- en: Computers, smartphones, and various digital devices exclusively rely on the
    binary system, using 1 and 0 for all operations. Documents, images, audio, and
    files of all kinds are stored as sequences of 1s and 0s, and computers execute
    mathematical operations by representing numbers as sequences of binary digits
    and performing procedures similar to those in the base 10 system. Given the pivotal
    role of binary in computing, it’s beneficial to acquaint ourselves with it. We
    can start by representing several decimal numbers in the binary system (table
    A.1).
  prefs: []
  type: TYPE_NORMAL
- en: Table A.1 Decimal numbers and their binary equivalents
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| **Decimal number** | **Binary equivalent** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | 10  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | 11  |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | 100  |'
  prefs: []
  type: TYPE_TB
- en: '| 5  | 101  |'
  prefs: []
  type: TYPE_TB
- en: '| 6  | 110  |'
  prefs: []
  type: TYPE_TB
- en: '| 7  | 111  |'
  prefs: []
  type: TYPE_TB
- en: '| 8  | 1000  |'
  prefs: []
  type: TYPE_TB
- en: '| 9  | 1001  |'
  prefs: []
  type: TYPE_TB
- en: Decimal numbers are expressed as a sequence of digits, with the rightmost digit
    representing the units. Each successive digit to the left signifies a multiple
    of a power of 10, where the *n*th power of 10 represents 10 multiplied by itself
    *n* times. For instance, the decimal number 207 can be viewed as 2 × 100 + 0 ×
    10 + 7 × 1, aligning with our understanding of it as two 100s, no 10s, and seven
    1\. In a more concise form, this number can be written using exponents as 2 ×
    102 + 0 × 101 + 7 × 100.
  prefs: []
  type: TYPE_NORMAL
- en: Binary numbers follow a similar concept, but their digits denote multiples of
    powers of two rather than powers of 10\. As an illustration, the decimal number
    27 is expressed in binary as 11011 since 27 can be represented as 16 + 8 + 0 +
    2 + 1 in decimal, and this sum can be expressed as a sum of powers of 2 as 1 ×
    24 + 1 × 23 + 0 × 22 + 1 × 21 + 1 × 20.
  prefs: []
  type: TYPE_NORMAL
- en: 'Text in a computer is stored as binary code, where each letter and typographic
    symbol is assigned a fixed binary string based on a universal convention. For
    instance, the early working title of this book, *AI Reality and Illusion*, is
    stored in computer memory as the following binary sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Each set of numbers represents a letter or a space, with A = 01000001, I = 01001001,
    and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: Any system that relies on just two symbols is considered binary. For instance,
    Louis Braille, who lost his sight at the age of three, invented the Braille code
    in 1824 when he was 15 and a student at the Institute for Blind Children in France
    (figure A.3). The Braille code utilizes raised and unraised dots on a surface
    to convey information through the sense of touch. This system enables blind individuals
    or those with limited sight to read.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/A-3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.3 The Braille code
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Morse code, another form of binary encoding, relies on dots and dashes to represent
    information (figure A.4). Short pulses symbolize dots, while long pulses correspond
    to dashes, and these signals are transmitted over telegraph lines. By assigning
    binary sequences to specific letters, Morse code enables the transmission of information.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/A-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.4 Morse code
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: On May 24, 1844, Samuel Morse successfully employed his code to transmit the
    inaugural telegraph message, “What hath God wrought?” between Washington, D.C.,
    and Baltimore.
  prefs: []
  type: TYPE_NORMAL
- en: Building upon the contributions of Pascal and Leibnitz in the 18th century,
    European innovators crafted a range of remarkable automata designed to mimic human
    actions. The most celebrated of these inventors was Jacques de Vaucanson (1709–1782)
    of France, who, in 1727, created an initial automaton capable of serving meals
    and clearing tables. However, a government official criticized his invention as
    sacrilegious, leading to the closure of Vaucanson’s workshop. Nevertheless, Vaucanson
    later captivated Europe with his mechanical ducks, mechanical flute player, and
    mechanical pipe players.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to his entertaining automata, Vaucanson made a significant contribution
    to the Industrial Revolution. While working as a silk manufacture inspector, he
    revolutionized the French weaving industry in 1745 with the invention of the first
    automated loom. This machine utilized perforated cards to direct hooks connected
    to warp yarns, representing one of the earliest instances of autonomous machines
    following binary instructions. Regrettably, the weavers opposed this invention,
    fearing job displacement, and Vaucanson was compelled to abandon his project and
    flee for his life.
  prefs: []
  type: TYPE_NORMAL
- en: Vaucanson’s concept was further refined and eventually realized in 1804 by the
    French weaver and merchant Joseph-Marie Jacquard. He developed an automated loom
    employing punch cards, with holes on the cards dictating the movements of needles,
    thread, and fabric, resulting in the creation of woven silk fabric with complex
    patterns. This technique enabled the production of tapestry, brocade, and patterned
    knitted fabric. The ingenious use of punch cards later served as inspiration for
    the design of digital computers, with punch cards being utilized for data input
    in early 20th-century computers.
  prefs: []
  type: TYPE_NORMAL
- en: Pierre Jaquet-Droz, a Swiss luxury watchmaker, crafted some of the most remarkable
    automatons of his era. His most sophisticated creation, a mechanical boy seated
    at a desk, was constructed in 1768\. This automaton could write with a pen and
    paper, composing up to 40 preselected characters on a wheel manipulated by its
    operator. It utilized a goose feather pen, dipping it in ink and shaking its wrist
    to prevent smudges. Its eyes followed the text as it wrote, and its head moved
    while taking ink. This writer automaton remains operational and is on display
    at the History Museum in Neuchâtel.
  prefs: []
  type: TYPE_NORMAL
- en: One of the intellectual figures influenced by these increasingly lifelike machines
    was Julien Offroy de La Mettrie, a French physician and philosopher. In his 1747
    book *Man a Machine* [4], he proposed materialist views of psychic sensations
    that laid the foundation for behaviorism, questioning, “What is there absurd in
    thinking that beings, almost as perfect machines as ourselves, are, like us, made
    to understand and to feel nature?”
  prefs: []
  type: TYPE_NORMAL
- en: Further popularizing the concept of human-like machines, Wolfgang von Kempelen
    unveiled an ingenious chess-playing automaton in the court of Empress Maria Theresa
    of Austria-Hungary in 1769\. This machine, known as “The Turk,” fascinated audiences
    and struck fear into its defeated opponents. Its appearance resembled a puppet,
    adorned with gears, cranks, and levers reminiscent of clockwork. Remarkably, The
    Turk not only played chess but also excelled at it, defeating most challengers
    and baffling scientists attempting to explain its prowess. Kempelen toured Europe
    with his automaton, and in Paris, The Turk defeated renowned inventor Charles
    Babbage and even Benjamin Franklin, the U.S. Ambassador to France at the time.
  prefs: []
  type: TYPE_NORMAL
- en: The Turk also embarked on a tour of America, and in early 1826, hundreds gathered
    for its initial exhibition matches in New York City at the National Hotel on Broadway.
    These spectators were promised a glimpse of the first mechanical robot capable
    of outsmarting humans in the intellectually demanding game of chess. However,
    The Turk was, in fact, a hoax. Concealed within the machine’s housing was a diminutive
    chess master who manipulated the chessboard. In the modern era, John Gaughan,
    a creator of magic equipment, constructed a functional replica of The Turk, which
    can be observed in action on the BBC website [5].
  prefs: []
  type: TYPE_NORMAL
- en: What may have contributed to the misconception of The Turk as a genuine chess-playing
    machine was its introduction during the early stages of the Industrial Revolution,
    a period spanning from 1760 to 1850, characterized by significant innovations
    in agriculture, manufacturing, textiles, and transportation.
  prefs: []
  type: TYPE_NORMAL
- en: Although Kempelen is best known for The Turk, he completed numerous other projects
    in his lifetime. One of the most notable was a speaking machine described in his
    1791 book *The Mechanism of Human Speech*. This device synthesized speech sounds,
    words, sentences, and complete phrases in French, Italian, and English. Unlike
    The Turk, this invention operated as advertised, and one of the original machines
    is still on display at the Deutsches Museum in Munich.
  prefs: []
  type: TYPE_NORMAL
- en: In the 18th century, a period marked by rapid technological advancements, people
    found themselves both enthralled and apprehensive about the emerging world of
    inventions. The Turk’s exhibition around Europe coincided with a wave of anti-technology
    sentiments. The Luddite riots, a series of protests and acts of sabotage by textile
    workers in England during the early 19th century, were a manifestation of this
    anxiety. These workers feared that automation would lead to widespread unemployment
    and a decline in wages.
  prefs: []
  type: TYPE_NORMAL
- en: Mary Shelley’s groundbreaking novel *Frankenstein*, published in 1818, added
    to these concerns. The story depicted the creation of life from inanimate matter,
    raising questions about the consequences of unchecked technological advancement.
    In 1811, in Nottinghamshire, England, the introduction of automated machinery
    in the textile industry sparked a violent workers’ riot. This uprising quickly
    spread to other regions as protesters demanded the destruction of machines they
    believed were responsible for their economic woes. Tensions escalated, leading
    to clashes between the Luddites and government armed forces. By 1812, the act
    of destroying machinery was deemed a capital offense, punishable by death. In
    total, 17 men were executed for this crime in 1813, a stark reminder of the social
    upheaval caused by technological progress.
  prefs: []
  type: TYPE_NORMAL
- en: Amidst this turmoil, the foundation of modern technology was also being laid.
    In the mid-19th century, the logician George Boole made significant strides in
    the field of mathematics. His 1853 paper, “An Investigation of the Laws of Thought”
    [6], introduced Boolean algebra. This mathematical framework would later prove
    indispensable in the design and operation of digital computers. Boolean algebra
    deals with systems in which variables can only have two possible values, often
    represented as “truth values,” such as yes/no, true/false, 0/1, or on/off.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another visionary of the time was Charles Babbage (1791–1871), whose work laid
    the groundwork for modern computing. He dedicated years to developing an automatic
    table calculator capable of performing complex calculations required for navigation
    and ballistics. Babbage’s most remarkable concept, however, was the Analytical
    Engine [7]. Envisioned as a mechanical computer, it foreshadowed the computers
    we use today. Inspired by the punch card technology employed by Joseph-Marie Jacquard
    in his programmable loom, Babbage envisioned a general-purpose programmable machine
    that could use punch cards for inputs, outputs, and data storage. Ada Lovelace
    (1815–1852), often recognized as the world’s first computer programmer, recognized
    the potential of Babbage’s Analytical Engine. In her work titled “Lovelace & Babbage
    and the Creation of the 1843 ‘Notes,’” she documented the capabilities and possibilities
    of this remarkable invention, laying the foundation for the future of computing
    [8]:'
  prefs: []
  type: TYPE_NORMAL
- en: In enabling mechanism to combine together general symbols, in successions of
    unlimited variety and extent, a uniting link is established between the operations
    of matter and the abstract mental processes of the most abstract branch of mathematical
    science. A new, a vast, and a powerful language is developed for the future use
    of analysis, in which to wield its truths so that these may become of more speedy
    and accurate practical application for the purposes of mankind than the means
    hitherto in our possession have rendered possible.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'An examination of the Lovelace and Babbage documents unveils the divergence
    in their priorities. Babbage’s primary emphasis was on calculations, whereas Lovelace,
    in her visionary outlook, contemplated the potential for an evolved Analytical
    Engine to not only perform calculations but also to create music and generate
    images. In her writings, she expressed:'
  prefs: []
  type: TYPE_NORMAL
- en: Supposing, for instance, that the fundamental relations of pitched sounds in
    the science of harmony and of musical composition were susceptible of such expression
    and adaptations, the engine might compose elaborate and scientific pieces of music
    of any degree of complexity or extent.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While the Analytical Engine, as conceptualized by Babbage and Lovelace, never
    came into physical existence, their foresight in discussing a general-purpose
    programmable computing machine was remarkably ahead of its time, considering the
    developments that were yet to unfold. One of the earliest realizations of these
    visionary ideas can be attributed to Herman Hollerith (1860–1929), often regarded
    as the pioneer of automated data processing. Hollerith briefly served as a statistician
    at the US Census Office, an experience that underscored the urgent need for improved
    computation methods. Inspired by the Jacquard loom and the practice of using punched
    images in the railroads to encode passengers’ characteristics on tickets, Hollerith
    invented an electronic tabulating machine that would revolutionize data processing
    throughout the first half of the 20th century [9].
  prefs: []
  type: TYPE_NORMAL
- en: For the 1890 census, Hollerith proposed a system where data for each individual
    would be encoded on a separate card, to be subsequently tabulated by his innovative
    machine [10] (figure A.5). This approach significantly accelerated data processing,
    providing more statistics at a reduced cost. The success of this method led to
    contracts with various entities, including railroad companies and foreign governments
    such as Canada, Norway, and Austria. In 1896, building on the triumph of his census
    machines, Hollerith founded the Tabulating Machine Company. In 1924, when salesman
    Thomas J. Watson joined the company, they renamed it International Business Machines
    (IBM). After years of dedicated research and development, IBM enhanced tabulating
    technology to create a machine capable of executing if–then logic operations.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/A-5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.5 Hollerith system of electronic tabulation (Photo courtesy of the
    Library of Congress)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The pivotal breakthrough that paved the way for modern computers was the utilization
    of electromagnetism. Fueled by the demand for computing technology during World
    War II, Professor Howard H. Aiken designed the world’s first large-scale computer,
    the Harvard Mark I. This remarkable machine employed punch cards and magnetic
    tape for data processing and storage. Unlike earlier computers tailored for specific
    tasks, the Harvard Mark I was a versatile, general-purpose computer. The initial
    version of the Mark I weighed five tons and stretched 50 feet in length. When
    unveiled officially in August 1944, it garnered global acclaim as the “world’s
    greatest mathematical calculator,” with some even characterizing it as an “automatic
    brain.”
  prefs: []
  type: TYPE_NORMAL
- en: The next significant advancement in computing marked a conceptual leap forward
    when Claude Shannon proposed the use of Boolean algebra in 1937 to simplify the
    arrangement of relays within electrical networks. His groundbreaking work was
    presented in his 1937 master’s thesis titled “A Symbolic Analysis of Relay and
    Switching Circuits” [11]. Shannon’s contributions laid the foundation for the
    design of modern digital circuits.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, in the late 1940s, John von Neumann made a pioneering contribution
    by devising a way to store both code and data in a computer’s internal memory.
    This innovation was pivotal in the development of computer science as a field
    and led to the creation of the Electronic Discrete Variable Automatic Computer
    (EDVAC), the successor to ENIAC. Although ENIAC is commonly recognized as the
    first digital electronic computer, it’s crucial not to overlook Colossus, a highly
    specialized machine built in Great Britain in 1943 to decrypt the Nazi Enigma
    code. Decoding intercepted messages using Colossus revealed crucial information,
    shortened the war, and hastened the defeat of the Nazis. Winston Churchill aptly
    described the Colossus team as “the geese that laid the golden eggs and never
    cackled” to emphasize their invaluable contribution.
  prefs: []
  type: TYPE_NORMAL
- en: While computers were becoming more advanced and powerful, they were also becoming
    unwieldy. For instance, UNIVAC could perform 1,000 calculations per second but
    required 5,000 vacuum tubes, which were large and generated a significant amount
    of heat. The development of the personal computer necessitated the invention of
    the transistor, a pivotal advancement in the 20th century.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to vacuum tubes, transistors were small, energy efficient, and generated
    minimal heat. These characteristics allowed for the integration of numerous transistors
    into a single device. The first transistor was constructed in 1947 when Bell Labs
    physicists John Bardeen and Walter Brattain connected a germanium amplifier to
    a strip of gold foil. After several years of prototyping and testing, transistors
    began mass production in the early 1950s, becoming an integral part of nearly
    all electronic devices. The profound significance of the transistor was acknowledged
    when John Bardeen, Walter Brattain, and William Shockley were jointly awarded
    the Nobel Prize in Physics in 1956 for their research on semiconductors and the
    discovery of the transistor effect [12].
  prefs: []
  type: TYPE_NORMAL
- en: Another significant breakthrough took place in 1958 when Jack Kilby and Robert
    Noyce manufactured the first integrated circuit, now commonly known as microchips.
    These integrated circuits comprised various circuit elements, including transistors,
    capacitors, and resistors, all fabricated as a single unit on a silicon wafer.
    Noyce went on to found Intel in 1968 in Northern California’s San Jose area, popularizing
    the term “Silicon Valley.” The microchip played a pivotal role in enabling the
    modern computer revolution and the digital age, leading to Kilby’s recognition
    with a Nobel Prize in Physics in 2000.
  prefs: []
  type: TYPE_NORMAL
- en: As semiconductor chip technology rapidly advanced, computers became smaller
    and more affordable, democratizing their accessibility and fostering their widespread
    adoption across various industries. On August 12, 1981, during a press conference
    at the Waldorf Astoria ballroom in New York City, IBM introduced the IBM Personal
    Computer, priced at $1,565\. This marked a stark contrast to the computing landscape
    two decades earlier, where an IBM computer could cost as much as $9 million, requiring
    extensive space and personnel for operation. The IBM Personal Computer was powered
    by an Intel 8088 microprocessor, operated at speeds measured in millionths of
    a second, and was about the size of a portable typewriter. It contained 40K of
    read-only memory and 16K of user memory and even featured a built-in speaker for
    music generation [13] (figure A.6).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/A-6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.6 I started my first company in 1988 with machines that had 1 MB of
    RAM and 40 MB of hard drive space.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: By 2024, it had become a common occurrence for machines to be equipped with
    16 GB of RAM, and numerous companies generously provide their customers with 1
    TB or even greater amounts of free storage space on their servers. To underscore
    the magnitude of these advancements, let’s discuss the primary concepts. A bit
    represents a single 0 or 1 in a computer’s memory, a byte comprises 8 bits, and
    1 kilobyte (kB) consists of 1,024 bytes. Building upon this, 1 MB equals 1024
    kB, 1 GB encompasses 1024 MB, and 1 TB encompasses 1,024 GB.
  prefs: []
  type: TYPE_NORMAL
- en: Over the past four decades, the capacity and processing power of computers have
    escalated by orders of magnitude. The primary catalyst for these remarkable strides
    has been the capacity to fit increasingly more transistors onto a single chip.
    As early as the 1970s, computers were already integrating chips containing over
    100,000 transistors each. Notably, each of these chips boasted 20 times the computing
    power of the UNIVAC, a computer that once filled an entire room and, when adjusted
    for inflation, cost approximately $10 million! It is crucial to recognize that,
    without these chips, modern-day marvels such as the internet, cell phones, and
    laptops, as well as the existence of industry giants like Apple, Microsoft, Facebook,
    and Google, would not have come to fruition.
  prefs: []
  type: TYPE_NORMAL
- en: The count of transistors per chip has continued to double approximately every
    two years since then, a phenomenon commonly referred to as Moore’s Law. By 2018,
    we had crossed the threshold of “seven-nanometer devices,” a designation that
    pertains to the size of these transistors. At this minuscule scale, we can house
    more than 20 billion transistors on a chip no larger than a fingernail. To provide
    some perspective, there are 25,400,000 nanometers in a single inch, and a human
    hair typically spans approximately 80,000 to 100,000 nanometers in width. Consequently,
    a mere 12,000 transistors, embodying the computing power equivalent to over two
    UNIVACs, occupy the width of a human hair.
  prefs: []
  type: TYPE_NORMAL
