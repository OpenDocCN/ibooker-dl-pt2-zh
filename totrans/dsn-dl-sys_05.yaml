- en: 5 Hyperparameter optimization service
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 超参数优化服务
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容包括
- en: Hyperparameters and why they are important
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数及其重要性
- en: Two common approaches to hyperparameter optimization (HPO)
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数优化（HPO）的两种常见方法
- en: Designing an HPO service
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个HPO服务
- en: 'Three popular HPO libraries: Hyperopt, Optuna, and Ray Tune'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个流行的HPO库：Hyperopt、Optuna和Ray Tune
- en: 'In the previous two chapters, we saw how models are trained: a training service
    manages training processes in a remote compute cluster with given model algorithms.
    But model algorithms and training services aren’t all there is to model training.
    There’s one more component we haven’t discussed yet—hyperparameter optimization
    (HPO). Data scientists often overlook the fact that hyperparameter choices can
    influence model training results significantly, especially when these decisions
    can be automated using engineering methods.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两章中，我们看到了模型是如何训练的：一个训练服务管理着远程计算集群中的训练过程，并提供给定的模型算法。但模型算法和训练服务并不是模型训练的全部。还有一个组成部分我们尚未讨论过——超参数优化（HPO）。数据科学家经常忽视这样一个事实，即超参数选择可以显着影响模型训练结果，特别是当这些决策可以使用工程方法自动化时。
- en: Hyperparameters are parameters whose value must be set before the model training
    process starts. Learning rate, batch size, and number of hidden layers are all
    examples of hyperparameters. Unlike the value of *model parameters*—weights and
    bias, for example—hyperparameters cannot be learned during the training process.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是必须在模型训练过程开始之前设置其值的参数。学习率、批量大小和隐藏层数量都是超参数的示例。与模型参数的值（例如权重和偏置）不同，超参数在训练过程中不能被学习。
- en: Research reveals that the chosen value of hyperparameters can affect both the
    quality of the model training as well as the time and memory requirements of the
    training algorithm. Therefore, hyperparameters must be tuned to be optimal for
    model training. Nowadays, HPO has become a standard step in the deep learning
    model development process.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，超参数的选择值可以影响模型训练的质量以及训练算法的时间和内存要求。因此，必须调整超参数以使其对模型训练最优。如今，HPO已经成为深度学习模型开发过程中的标准步骤。
- en: As one of the deep learning components, HPO is very important to software engineers.
    This is because HPO doesn’t require a deep understanding of deep learning algorithms,
    so engineers are often assigned to this task. Most of the time, HPO can run like
    a black box, and the training code does not need to be modified. Furthermore,
    engineers have the capability of building an automatic HPO mechanism, making HPO
    possible. As there are so many hyperparameters to tune (learning rate, number
    of epochs, data batch size, and more) and so many values to try, it is simply
    impractical to manually adjust each hyperparameter value. Software engineers are
    well-suited to create an automated system because of their expertise in microservices,
    distributed computing, and resource management.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为深度学习组件之一，HPO对软件工程师非常重要。这是因为HPO不需要对深度学习算法有深入的理解，所以工程师经常被分配到这项任务。大多数情况下，HPO可以像黑盒子一样运行，训练代码不需要修改。此外，工程师有能力构建一个自动HPO机制，使HPO成为可能。由于要调整的超参数（学习率、epoch数量、数据批量大小等）以及要尝试的值太多，手动调整每个超参数值是不现实的。软件工程师非常适合创建一个自动化系统，因为他们在微服务、分布式计算和资源管理方面有着丰富的经验。
- en: 'In this chapter, we will focus on the engineering of automatic HPO. We first
    introduce the background information necessary to feel comfortable working with
    HPO. We delve into a deeper understanding of hyperparameters and the process of
    tuning or optimizing them. We’ll also meet some popular HPO algorithms and compare
    two common approaches to automating HPO: using a library and building a service.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点介绍自动HPO的工程。我们首先介绍了与使用HPO工作所需的背景信息。我们深入了解超参数及其调整或优化过程。我们还将遇到一些流行的HPO算法，并比较了两种自动化HPO的常见方法：使用库和构建服务。
- en: Then we’ll start designing. We will look at how to design an HPO service, including
    five design principles for creating an HPO service, as well as one general design
    proposal that is particularly important at this stage. Finally, we show you three
    popular open source HPO frameworks that would be a perfect fit if you want to
    optimize your training code locally.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将开始设计。我们将看看如何设计一个HPO服务，包括创建HPO服务的五个设计原则，以及在此阶段特别重要的一个通用设计提案。最后，我们向您展示三个流行的开源HPO框架，如果您想在本地优化训练代码，这些框架将是完美的选择。
- en: Unlike previous chapters, we will not be building a brand new sample service
    in this chapter. Instead, we suggest you use the open source Kubeflow Katib (discussed
    in appendix C). Katib is a well-designed, extensible, and highly portable HPO
    service that can be used for almost any HPO project. Thus, we do not have to build
    one if it is a low-hanging fruit for you.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于之前的章节，本章我们不会构建一个全新的示例服务。相反，我们建议您使用开源的Kubeflow Katib（见附录C中讨论）。Katib是一个设计良好、可扩展且高度可移植的HPO服务，几乎可以用于任何HPO项目。因此，如果对您来说这是一个低成本的解决方案，我们就不需要再构建一个了。
- en: This chapter should give you a holistic view of the HPO domain while also providing
    you with a practical understanding of how to run HPO for your specific needs.
    Whether you decide to run HPO with a remote service or at your local machine with
    libraries/frameworks like Hyperopt, Optuna, or Ray Tune, we’ve got you covered.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章应该为您提供HPO领域的全面视角，同时还为您提供了如何针对您的具体需求运行HPO的实用理解。无论您决定使用远程服务还是在本地机器上使用Hyperopt、Optuna或Ray
    Tune等库/框架来运行HPO，我们都可以为您提供支持。
- en: 5.1 Understanding hyperparameters
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 理解超参数
- en: Before we look at how to tune hyperparameters, let’s get a clearer understanding
    of what hyperparameters are and why they are important.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们学习如何调整超参数之前，让我们更清晰地了解一下超参数是什么以及它们为什么重要。
- en: 5.1.1 What is a hyperparameter?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 什么是超参数？
- en: 'The process of training deep learning models uses two types of parameters,
    or values: *model parameters* and *hyperparameters*. Model parameters are trainable—that
    is, their values are learned during model training—and they change as the model
    iterates. Hyperparameters, in contrast, are static; these configurations are defined
    and set before the training starts. For example, we can set the training epoch
    as 30 and the activation function of the neural network as ReLU (rectified linear
    unit) in the input parameters to kick off a model training process.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 训练深度学习模型的过程使用两种类型的参数或数值：*模型参数*和*超参数*。模型参数是可训练的，也就是说，在模型训练过程中它们的值是学习到的，并且随着模型的迭代而改变。相比之下，超参数是静态的；这些配置在训练开始之前就已经被定义和设置好了。例如，我们可以在输入参数中将训练时期设置为30，并将神经网络的激活函数设置为ReLU（修正线性单元）来启动模型训练过程。
- en: 'In other words, any model training configuration that affects model training
    performance but can’t be estimated from data is a hyperparameter. There can be
    hundreds of hyperparameters in a model training algorithm, including, for example,
    the choice of model optimizer—ADAM (see “Adam: A Method for Stochastic Optimization,”
    by Diederik P. Kingma and Jimmy Ba; [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980))
    or RMSprop (see “A Look at Gradient Descent and RMSprop Optimizers,” by Rohith
    Gandhi; [http://mng.bz/xdZX](http://mng.bz/xdZX))—the number of layers in the
    neural network, the embedding dimensions, the minibatch size, and the learning
    rate.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '换句话说，任何影响模型训练性能但无法从数据中估计的模型训练配置都是超参数。一个模型训练算法中可能有数百个超参数，包括例如模型优化器的选择—ADAM（见“Adam:
    A Method for Stochastic Optimization,” by Diederik P. Kingma and Jimmy Ba; [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980))或RMSprop（见“A
    Look at Gradient Descent and RMSprop Optimizers,” by Rohith Gandhi; [http://mng.bz/xdZX](http://mng.bz/xdZX)）—神经网络中的层数、嵌入维度、小批量大小和学习率。'
- en: 5.1.2 Why are hyperparameters important?
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 超参数为什么重要？
- en: The choice of values for hyperparameters can have a tremendous effect on model
    training results. Typically set manually, the values control the behavior of training
    algorithm execution and determine the speed of model training and the model accuracy.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数的值选择对模型训练结果有巨大影响。通常手动设置，这些值控制着训练算法执行的行为，并确定模型训练的速度和模型的准确度。
- en: To see this effect for yourself, you can experiment with hyperparameter values
    by running model training in the TensorFlow playground ([https://playground.tensorflow.org](https://playground.tensorflow.org)).
    In this online playground, you can design your own neural network and train it
    to recognize four types of graphic patterns. By setting different hyperparameters,
    such as learning rate, regularization method, activation function, neural network
    layer count, and neuron count, you will see not only how the model performance
    varies but also how the learning behavior, such as training time and learning
    curve, can differ. To train a model to recognize a complicated data pattern like
    a spiral shape in this playground, we need to select the hyperparameters very
    carefully. For example, try setting the hidden layer count to 6, the neuron count
    per layer to 5, the activation function to `ReLU`, the data batch size to 10,
    and the regularization method to `L1`. After nearly 500 epochs of training, you’ll
    see that the model can make an accurate classification prediction on a spiral-shaped
    graph.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要亲自看到这种效果，您可以通过在TensorFlow playground（[https://playground.tensorflow.org](https://playground.tensorflow.org)）中运行模型训练来尝试不同的超参数值。在这个在线游乐场中，您可以设计自己的神经网络，并训练它以识别四种类型的图案。通过设置不同的超参数，比如学习率、正则化方法、激活函数、神经网络层数和神经元数量，您不仅会看到模型性能的变化，还会看到学习行为的变化，比如训练时间和学习曲线。要在这个游乐场中训练一个能够识别复杂数据模式（如螺旋形）的模型，我们需要非常小心地选择超参数。例如，尝试将隐藏层数量设置为6，每层神经元数量设置为5，激活函数设置为`ReLU`，数据批量大小设置为10，正则化方法设置为`L1`。经过近500个epochs的训练，您会发现该模型可以对螺旋形图表进行准确的分类预测。
- en: In the research field, the effect of hyperparameter selection on model performance
    has long been documented. Take natural language processing embedding training,
    for instance. One paper, “Improving Distributional Similarity with Lessons Learned
    from Word Embeddings,” by Levy et al. ([https://aclanthology.org/Q15-1016.pdf](https://aclanthology.org/Q15-1016.pdf)),
    reveals that much of the performance gains of word embeddings are due to certain
    system design choices along with the HPOs rather than the embedding algorithms
    themselves. In NLP embedding training, these authors found the selection of hyperparameters
    has more effect than the selection of the training algorithm! Because the hyperparameter
    selection is so crucial to model training performance, hyperparameter tuning has
    now become a standard step in the model training process.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究领域，超参数选择对模型性能的影响早已有据可查。以自然语言处理嵌入训练为例。一篇论文，“Improving Distributional Similarity
    with Lessons Learned from Word Embeddings,”由Levy等人（[https://aclanthology.org/Q15-1016.pdf](https://aclanthology.org/Q15-1016.pdf)）撰写，揭示了词嵌入的许多性能增益都归因于某些系统设计选择以及HPO（Hyperparameter
    Optimization，超参数优化）而不是嵌入算法本身。在NLP嵌入训练中，这些作者发现超参数的选择比训练算法的选择更具影响力！因为超参数选择对模型训练性能非常关键，所以超参数调整现在已经成为模型训练过程中的标准步骤。
- en: 5.2 Understanding hyperparameter optimization
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 理解超参数优化
- en: Now that you have a solid idea of what hyperparameters are and why they are
    so important to model training, let’s turn to the process of optimizing them for
    your model. In this section, we will walk you through the steps for HPO. We will
    also look at HPO algorithms, which are used to optimize hyperparameters, as well
    as common approaches to performing HPO.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经对超参数是什么以及它们为何对模型训练如此重要有了坚实的理解，让我们转向优化这些超参数的过程。在本节中，我们将为您介绍HPO的步骤。我们还将看看用于优化超参数的HPO算法，以及执行HPO的常见方法。
- en: 5.2.1 What is HPO?
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 什么是HPO？
- en: HPO, or tuning, is the process of discovering a set of hyperparameters that
    yields an optimal model. Optimal here means a model that minimizes a predefined
    loss function on a given dataset. In figure 5.1, you can see a high-level view
    of the generic workflow of HPO on the model training process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: HPO，或调整，是发现一组产生最佳模型的超参数的过程。这里的最佳意味着在给定数据集上最小化预定义损失函数的模型。在图5.1中，您可以看到HPO在模型训练过程中的通用工作流程的高级视图。
- en: '![](../Images/05-01.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-01.png)'
- en: Figure 5.1 This high-level view of the HPO workflow shows that the process is
    essentially an experiment to find the optimal hyperparameter values.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 这个HPO工作流程的高级视图显示，该过程本质上是一个实验，旨在找到最佳的超参数值。
- en: From figure 5.1, we see that an HPO workflow can be visualized as a loop made
    with four steps. It shows us that the HPO process is a repetitive model training
    process, except that the neural network is trained each time with a different
    set of hyperparameters. The optimal set of hyperparameters will be discovered
    in this process. We normally call each run of the model training a *trial*. The
    whole HPO experiment is a trial loop in which we run one trial after another until
    the end criteria are met.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 5.1. 可以看出，HPO 工作流程可以被可视化为一个由四个步骤构成的循环。它向我们展示了 HPO 过程是一个重复的模型训练过程，只是每次神经网络都会使用不同的超参数集进行训练。在这个过程中将发现最优的超参数集。我们通常将每次模型训练的运行称为“试验”。整个
    HPO 实验是一个试验循环，在此循环中我们运行一个试验接着运行另一个试验，直到满足结束条件。
- en: Note To have a fair evaluation, the same dataset is used for each HPO trial.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 注意为了公正评估，每个 HPO 试验都使用相同的数据集。
- en: Each trial has four steps, as shown in figure 5.1\. Step 1 is training the neural
    network with a set of hyperparameter values. Step 2 is evaluating the training
    output (the model).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每次试验分为四个步骤，如图 5.1. 所示。第一步是使用一组超参数值训练神经网络。第二步是评价训练输出（模型）。
- en: In step 3, the HPO process checks whether the end criteria have been met—for
    example, whether we have run out of our trial budget or whether the model produced
    in this trial has reached our performance evaluation target. If the trial result
    meets the end condition, the trial loop breaks and the experiment ends. The hyperparameter
    values that produced the best model evaluation result are considered the optimal
    hyperparameters.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 3 步中，HPO 过程检查是否已满足结束条件，例如是否已用完试验预算，或者是否在此试验中产生的模型已达到我们的性能评估目标。如果试验结果满足结束条件，则试验循环中断，实验结束。产生最佳模型评估结果的超参数值被视为最优超参数。
- en: 'If the end condition is not met, the process moves to step 4: the HPO process
    will produce a new set of hyperparameter values and start a new trial by triggering
    a model training run. The hyperparameter values used in each trial are generated
    either manually or automatically by an HPO algorithm. Let’s look closer at these
    two approaches and the HPO algorithms in the next two sections.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未满足结束条件，则过程进入步骤 4：HPO 过程将产生一组新的超参数值，并通过触发模型训练运行来开始一个新的试验。每个试验中使用的超参数值可以通过手动或自动由
    HPO 算法生成。让我们在接下来的两个部分中更详细地看看这两种方法和 HPO 算法。
- en: Manual HPO
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 手动 HPO
- en: As data scientists, we often manually pick the hyperparameter values to run
    the HPO process shown in figure 5.1\. Though, admittedly, choosing the optimal
    hyperparameter values manually is more like improvisation than science. But we
    are also drawing from our experience and the intuition that comes from that experience.
    We tend to start training a model with empirical hyperparameter values, such as
    the values used in a relevant published paper, and then make some small adjustments
    and test the model. After a few trials, we manually compare the model performance
    and choose the best-performing model from these trials. Figure 5.2 illustrates
    this workflow.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，我们经常手动选择超参数值来运行图 5.1. 中的 HPO 过程。尽管，可以承认的是，手动选择最佳超参数值更像是即兴表演而不是科学。但是我们也在借鉴我们的经验以及从其中获得的直觉。我们通常会使用经验性的超参数值开始模型训练，例如在相关的已发表论文中使用的值，然后进行一些微小的调整并测试模型。经过几次试验后，我们手动比较模型性能并从这些试验中选择表现最佳的模型。图
    5.2. 演示了这个工作流程。
- en: '![](../Images/05-02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-02.png)'
- en: Figure 5.2 Manually picking hyperparameter values can be tedious and time-consuming.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2. 手动选择超参数值可能会很繁琐且耗时。
- en: 'The biggest problem with manual HPO is not knowing whether our hyperparameter
    values are optimal because we just choose some empirical values and tweak them.
    To get the optimal values, we need to try all possible hyperparameter values,
    aka search spaces. In the example of figure 5.2, we want to optimize two hyperparameters:
    learning rate and dataset batch size. In the HPO process, the goal is to find
    the pair of `batch_size` and `learning_rate` that produces the best model. Let’s
    say we define a search space for `batch_size` as {8, 16, 32, 64, 128, 256} and
    define another search space for `learning_rate` as {0.1, 0.01, 0.001, 0.5, 0.05,
    0.005}. Then the total number of hyperparameter values we need to verify is 36
    (62).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 手动 HPO 的最大问题在于我们不知道我们的超参数值是否最佳，因为我们只是选择一些经验值并对其进行微调。为了获得最优值，我们需要尝试所有可能的超参数值，也就是搜索空间。在图
    5.2 的示例中，我们想要优化两个超参数：学习速率和数据集批处理大小。在 HPO 过程中，目标是找到产生最佳模型的 `batch_size` 和 `learning_rate`
    对。假设我们将 `batch_size` 的搜索空间定义为 {8, 16, 32, 64, 128, 256}，并将 `learning_rate` 的另一个搜索空间定义为
    {0.1, 0.01, 0.001, 0.5, 0.05, 0.005}。那么我们需要验证的超参数值的总数是 36（62）。
- en: Because we run the HPO manually, we have to run the model training process (HPO
    trial) 36 times and record the model evaluation result and the hyperparameters’
    values used in each trial. After completing all 36 trials and comparing the results,
    which is usually the model accuracy, we find the optimal `batch_size` and `learning_rate`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们要手动运行 HPO，我们必须运行模型训练过程（HPO 试验）36 次，并记录每个试验中使用的模型评估结果和超参数值。完成所有 36 次试验并比较结果后，通常是模型准确率，我们找到了最佳的
    `batch_size` 和 `learning_rate`。
- en: Manually running HPO for the entire hyperparameter search space can be time-consuming,
    error prone, and tedious, as you can see. Moreover, deep learning hyperparameters
    usually have a complex configuration space, which often consists of a combination
    of continuous, categorical, and conditional hyperparameters as well as high dimensions.
    The deep learning industry is currently moving toward automatic HPO because manual
    HPO is simply not feasible.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 手动运行整个超参数搜索空间的 HPO 可能会耗时、容易出错且繁琐，正如你所见。此外，深度学习超参数通常具有复杂的配置空间，通常由连续、分类和条件超参数的组合以及高维度组成。目前，深度学习行业正在向自动
    HPO 迈进，因为手动 HPO 简单不可行。
- en: Automatic HPO
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 自动 HPO
- en: Automatic HPO is the process of using compute power and algorithms to automatically
    find the optimal hyperparameters for a training code. The idea is to use an efficient
    search algorithm to discover the optimal hyperparameters without human intervention.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自动 HPO 是利用计算能力和算法自动找到训练代码的最佳超参数的过程。这一想法是使用高效的搜索算法在没有人类干预的情况下发现最佳超参数。
- en: We also want the automatic HPO to run in a black-box fashion, so it is agnostic
    about the training code it is optimizing, and therefore we can easily onboard
    existing model training code to the HPO system. Figure 5.3 shows the automatic
    HPO workflow.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望自动 HPO 以黑盒方式运行，因此它对其正在优化的训练代码无知，因此我们可以轻松地将现有的模型训练代码引入到 HPO 系统中。图 5.3 显示了自动化的
    HPO 工作流程。
- en: '![](../Images/05-03.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-03.png)'
- en: Figure 5.3 An automatic HPO workflow
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 自动化的 HPO 工作流程
- en: In step 1, data scientists submit HPO requests to the automatic HPO system,
    which runs the HPO process in a black-box fashion (figure 5.3). They input the
    hyperparameters to be optimized and their value search space into the black box
    (the “automatic HPO” box in figure 5.3)—for example, the learning rate’s search
    space may be [0.005, 0.1] and dataset batch size’s search space may be {8, 16,
    32, 64, 128, 256}. Data scientists also need to configure the training execution,
    such as the training code; an evaluation method; an exit objective; and a trial
    budget, such as 24 total trials for this experiment.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 1 步，数据科学家向自动 HPO 系统提交 HPO 请求，该系统以黑盒方式运行 HPO 过程（图 5.3）。他们将要优化的超参数及其值搜索空间输入黑盒（图
    5.3 中的“自动 HPO”框）--例如，学习速率的搜索空间可能是 [0.005, 0.1]，数据集批处理大小的搜索空间可能是 {8, 16, 32, 64,
    128, 256}。数据科学家还需要配置训练执行，例如训练代码；评估方法；退出目标；以及试验预算，比如这次实验总共 24 次试验。
- en: Once users submit the HPO request, the HPO experiment (step 2) starts. The HPO
    system schedules all the trials and manages their training executions; it also
    runs an HPO algorithm to generate hyperparameter values (picking values from the
    search space) for each trial. When the trial budget runs out or the training objective
    is met, the system returns a set of optimal hyperparameter values (step 3).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户提交了 HPO 请求，HPO 实验（步骤 2）就会开始。HPO 系统安排所有试验并管理其训练执行；它还运行 HPO 算法为每个试验生成超参数值（从搜索空间中挑选值）。当试验预算用完或达到训练目标时，系统会返回一组最优的超参数值（步骤
    3）。
- en: 'Automatic HPO relies on two key components: the HPO algorithm and trial training
    execution management. We can find the optimal hyperparameter values with fewer
    compute resources using an efficient HPO algorithm. By using a sophisticated training
    management system, data scientists can be hands-free for the entire HPO process.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 自动 HPO 依赖于两个关键组件：HPO 算法和试验训练执行管理。使用高效的 HPO 算法，我们可以使用更少的计算资源找到最优的超参数值。通过使用复杂的训练管理系统，数据科学家可以在整个
    HPO 过程中无需手动操作。
- en: NOTE Because of the inefficiency of manual HPO, automatic HPO is the mainstream
    approach. To keep things concise, we will use the term *HPO* to refer to “automatic
    hyperparameter optimization” in the rest of this chapter.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：由于手动 HPO 的低效性，自动 HPO 是主流方法。为了简洁起见，在本章的其余部分中，我们将使用术语 *HPO* 来指代“自动超参数优化”。
- en: 5.2.2 Popular HPO algorithms
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 流行的 HPO 算法
- en: 'Most of the HPO algorithms can be categorized into three buckets: model-free
    optimization, Bayesian optimization, and multifidelity optimization.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 HPO 算法可以归类为三个桶：无模型优化、贝叶斯优化和多途径优化。
- en: 'Note Because the main goal of this chapter is teaching HPO engineering, the
    HPO algorithms discussed here will stay at a high level. The goal of this section
    is to provide you with enough background knowledge on HPO algorithms to be able
    to build or set up an HPO system. If you want to know the mathematical reasoning
    behind the algorithms, please check out chapter 1, “Hyperparameter Optimization,”
    by Matthias Feurer and Frank Hutter, of *AutoML: Methods, Systems, Challenges*
    ([http://mng.bz/AlGx](http://mng.bz/AlGx)) and the paper “Algorithms for Hyper-Parameter
    Optimization,” by Bergstra et al. ([http://mng.bz/Zo9A](http://mng.bz/Zo9A)).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '注意：因为本章的主要目标是教授 HPO 工程，所以这里讨论的 HPO 算法将保持在高级别。本节的目标是为您提供足够的 HPO 算法背景知识，以便能够构建或设置
    HPO 系统。如果您想了解算法背后的数学推理，请查看 *AutoML: Methods, Systems, Challenges* 一书的第 1 章“Hyperparameter
    Optimization”，作者是 Matthias Feurer 和 Frank Hutter ([http://mng.bz/AlGx](http://mng.bz/AlGx))，以及
    Bergstra 等人的论文“Algorithms for Hyper-Parameter Optimization” ([http://mng.bz/Zo9A](http://mng.bz/Zo9A))。'
- en: Model-free optimization methods
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 无模型优化方法
- en: In model-free methods, data scientists make no assumptions about training code,
    and the correlation between HPO trials is ignored. Grid search and random search
    are the most commonly used methods.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在无模型方法中，数据科学家不对训练代码做任何假设，并忽略 HPO 试验之间的相关性。网格搜索和随机搜索是最常用的方法。
- en: In grid search, users specify a limited set of values for each hyperparameter
    and then choose trial hyperparameters from the Cartesian product of those values.
    For example, we can first specify value sets (search space) for the learning rate
    as {0.1, 0.005, 0.001} and data batch size as {10, 40, 100} and then build the
    grid with Cartesian products (as grid value) of these sets, such as (0.1, 10),
    (0.1, 40), and (0.1, 100). After the grid is built, we can start the HPO trial
    with the grid values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索中，用户为每个超参数指定了一组有限的值，然后从这些值的笛卡尔积中选择试验超参数。例如，我们可以首先指定学习率的值集（搜索空间）为{0.1, 0.005,
    0.001}，数据批量大小为{10, 40, 100}，然后用这些集合的笛卡尔积（作为网格值）构建网格，例如 (0.1, 10)，(0.1, 40)，和 (0.1,
    100)。构建网格后，我们可以使用网格值开始 HPO 试验。
- en: Grid search suffers when the number of hyperparameters becomes larger or the
    parameter’s search space becomes bigger because the required number of evaluations
    will grow exponentially in this case. Another problem with grid search is its
    ineffectiveness. Because grid search treats each set of hyperparameter candidates
    equally, it will waste a lot of compute resources in the nonoptimal configuration
    space while not spending enough compute power on the optimal space.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当超参数数量变大或参数的搜索空间变大时，网格搜索会遇到困难，因为在这种情况下所需的评估数量会呈指数增长。网格搜索的另一个问题是其效率低下。因为网格搜索将每组超参数候选视为相等，所以它会在非最优配置空间浪费大量计算资源，而在最优空间上则没有足够的计算资源。
- en: Random search works by sampling the hyperparameter configuration space at random
    until a certain budget for the search is run out. For example, we can set the
    search space for the learning rate to [0.001, 0.1] and data batch size to [10,
    100] and then set the search budget to 100, which means it will run up to a total
    of 100 HPO trials. In each trial, a random value is selected between 0.001 and
    0.1 as the learning rate, and a random value is selected between 10 and 100 as
    the data batch size.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索通过在超参数配置空间中随机采样，直到搜索的某个预算用尽为止来工作。例如，我们可以将学习速率的搜索空间设置为[0.001, 0.1]，数据批量大小设置为[10,
    100]，然后将搜索预算设置为100，这意味着它将运行总共100次HPO试验。在每次试验中，会在0.001和0.1之间随机选择一个值作为学习速率，并在10和100之间随机选择一个值作为数据批量大小。
- en: This approach has two advantages over grid search. First, random search can
    evaluate more values for each hyperparameter, which increases the chance of finding
    the optimal hyperparameter set. Second, random search has easier parallelization
    requirements; because all evaluation workers can run completely parallel, they
    don’t need to communicate with each other, and a failed worker doesn’t leave holes
    in the search space. But in grid search, a failed worker can skip the trial hyperparameters
    assigned to the worker in the HPO.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法比网格搜索有两个优点。首先，随机搜索可以评估每个超参数的更多值，这增加了找到最优超参数集的机会。其次，随机搜索具有更简单的并行化要求；因为所有评估工作者可以完全并行运行，它们无需彼此通信，并且失败的工作者不会在搜索空间中留下空缺。但是在网格搜索中，失败的工作者可以跳过分配给HPO工作者的试验超参数。
- en: The downside of random search is uncertainty; there is no guarantee an optimal
    set of hyperparameters can be found within a finite computing budget. In theory,
    if we allow for enough resources, random search can add sufficient random points
    in the search, so it will, as expected, find the optimum hyperparameter set. In
    practice, random search is used as a baseline.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索的缺点是不确定性；不能保证在有限的计算预算内找到最优的超参数集。理论上，如果我们允许足够的资源，随机搜索可以在搜索中添加足够的随机点，因此它将如预期地找到最优超参数集。在实践中，随机搜索被用作基线。
- en: '![](../Images/05-04.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-04.png)'
- en: 'Figure 5.4 Comparison of grid search and random search for minimizing a function
    with one important and one unimportant parameter. (Source: Figure 1.1\. of “Hyperparameter
    Optimization,” by Matthias Feurer and Frank Hutter, in *AutoML: Methods, Systems,
    Challenges*, eds. Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren; Springer,
    2019\. [www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf))'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '图5.4网格搜索和随机搜索的比较，以最小化具有一个重要参数和一个不重要参数的函数。（来源：Matthias Feurer和Frank Hutter的“超参数优化”的图1.1。在*AutoML:
    Methods, Systems, Challenges*中，由Frank Hutter，Lars Kotthoff和Joaquin Vanschoren编辑;
    Springer, 2019. [www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf)）'
- en: Figure 5.4 illustrates the comparison between grid search and random search.
    The trial hyperparameter candidates (black dots) in grid search are Cartesian
    products of important parameter values (in rows) and unimportant value points
    (in columns). Their distribution can be seen as a grid in the search space (the
    white square canvas). The random search algorithm obtains the hyperparameter candidates
    randomly from the search space. When given enough of a search budget, its search
    point has a better chance of getting closer to the optimal position.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4展示了网格搜索和随机搜索之间的比较。网格搜索中的试验超参数候选项（黑色点）是重要参数值（行中）和不重要值点（列中）的笛卡尔积。它们的分布可以看作是搜索空间中的一个网格（白色方形画布）。随机搜索算法从搜索空间中随机获取超参数候选项。当给定足够的搜索预算时，其搜索点更有可能接近最优位置。
- en: Model-based Bayesian optimization
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的贝叶斯优化
- en: Bayesian optimization is a state-of-the-art optimization framework for the global
    optimization of expensive black-box functions. It’s used widely for various problem
    settings, such as image classification, speech recognition, and neural language
    modeling.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化是一种用于全局优化昂贵黑箱函数的最先进的优化框架。它广泛应用于各种问题设置，例如图像分类，语音识别和神经语言建模。
- en: The Bayesian optimization methods can use different samplers, such as Gaussian
    process regression (see “An Intuitive Tutorial to Gaussian Processes Regression,”
    by Jie Wang; [https://arxiv.org/abs/2009.10862](https://arxiv.org/abs/2009.10862))
    and tree-structured Parzen estimator approach (TPE), to calculate hyperparameter
    candidates in the search space. In less rigorous words, the Bayesian optimization
    methods use statistical methods to calculate new hyperparameter value suggestions
    from the values used in past trials and their evaluation results.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化方法可以使用不同的采样器，例如高斯过程回归 (见“高斯过程回归的直观教程”，Jie Wang; [https://arxiv.org/abs/2009.10862](https://arxiv.org/abs/2009.10862))
    和基于树结构的 Parzen 估计方法 (TPE)，来计算搜索空间中的超参数候选。简单来说，贝叶斯优化方法使用统计方法根据过去试验中使用的值及其评估结果计算新的超参数值建议。
- en: Note Why is it called Bayesian optimization? Bayesian analysis ([https://www.britannica.com/science/Bayesian-analysis](https://www.britannica.com/science/Bayesian-analysis))
    is a widely used statistical inference method, named after English mathematician
    Thomas Bayes ([https://www.britannica.com/biography/Thomas-Bayes](https://www.britannica.com/biography/Thomas-Bayes)),
    that allows you to combine prior information about a population parameter with
    evidence from information contained in a sample to guide the statistical inference
    process. Based on this method, Jonas Mockus introduced the term Bayesian optimization
    (see “Bayesian Linear Regression,” Bruna Wundervald; [https://www.researchgate.net/publication/333917874_Bayesian_Linear_
    Regression](https://www.researchgate.net/publication/333917874_Bayesian_Linear_Regressionin))
    in his 1970s and 1980s work on global optimization.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 为什么叫贝叶斯优化？贝叶斯分析 ([https://www.britannica.com/science/Bayesian-analysis](https://www.britannica.com/science/Bayesian-analysis))
    是一种广泛使用的统计推断方法，以英国数学家托马斯·贝叶斯 ([https://www.britannica.com/biography/Thomas-Bayes](https://www.britannica.com/biography/Thomas-Bayes))
    命名，它允许您将有关总体参数的先验信息与样本中包含的信息的证据相结合，以指导统计推断过程。基于这种方法，乔纳斯·莫库斯 (Jonas Mockus) 在他在
    1970 年代和 1980 年代的全局优化工作中引入了贝叶斯优化 (见“贝叶斯线性回归”，布鲁娜·温德瓦尔德; [https://www.researchgate.net/publication/333917874_Bayesian_Linear_Regression](https://www.researchgate.net/publication/333917874_Bayesian_Linear_Regressionin))
    这个术语。
- en: The concept behind Bayesian optimization methods is that the optimal hyperparameters
    search would be more efficient if the algorithm could learn from past trials.
    In practice, the Bayesian optimization method can find the optimal hyperparameters
    set with fewer evaluation runs (trials) and is more stable than the other search
    methods. Figure 5.5 shows the data sampling difference between random search and
    the Bayesian approach.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化方法背后的概念是，如果算法能够从过去的试验中学习，那么寻找最佳超参数的过程将更加高效。在实践中，贝叶斯优化方法可以通过较少的评估运行（试验）找到最佳超参数集，并且比其他搜索方法更稳定。图
    5.5 显示了随机搜索和贝叶斯方法之间的数据采样差异。
- en: '![](../Images/05-05.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-05.png)'
- en: Figure 5.5 A data sampler comparison of random search (a) and Bayesian approach
    (b) using 10 trials
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 随机搜索 (a) 和贝叶斯方法 (b) 的数据采样器比较，使用 10 次试验
- en: Let’s assume the optimal hyperparameter value is at (x,y) = (0.5, 1), and we
    try to use random search and Bayesian search to find it. In figure 5.5 (a), we
    see the data is randomly sampled in the search space where x := [–1.0, 1.0] and
    y := [1, 5]. In figure 5.5 (b), we see that the data is sampled heavily in the
    area (x := [0.3, 0.7] and y := [1,1.5]), where the optimal value is located. This
    comparison shows that the Bayesian search is more likely to find the optimal hyperparameters
    in the given search space, and with a limited execution budget, the selected (sampled)
    hyperparameter values become closer and closer to the optimal value after each
    experiment in the search process.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 假设最佳超参数值在 (x,y) = (0.5, 1)，我们试图使用随机搜索和贝叶斯搜索找到它。在图 5.5 (a) 中，我们看到数据在搜索空间中随机抽样，其中
    x := [–1.0, 1.0]，y := [1, 5]。在图 5.5 (b) 中，我们看到数据在区域 (x := [0.3, 0.7]，y := [1,1.5])
    中密集抽样，最佳值位于该区域。这种比较表明，在给定的搜索空间中，贝叶斯搜索更有可能找到最佳超参数，并且在有限的执行预算下，选择的（抽样的）超参数值在搜索过程中的每次实验后越来越接近最佳值。
- en: 'There are other advanced HPO algorithms, such as Hyperband ([http://mng.bz/Rlwv](http://mng.bz/Rlwv)),
    TPE ([http://mng.bz/2a6a](http://mng.bz/2a6a)), and covariance matrix adaptation
    evolution strategy (CMA-ES; [http://mng.bz/1M5q](http://mng.bz/1M5q)). Although
    they do not follow the exact same mathematical theory as the Bayesian–Gaussian
    process method, they share the same hyperparameter selection strategy: calculating
    the next suggested value by considering the historical evaluation results.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他先进的超参数优化算法，例如 Hyperband（[http://mng.bz/Rlwv](http://mng.bz/Rlwv)）、TPE（[http://mng.bz/2a6a](http://mng.bz/2a6a)）和协方差矩阵适应进化策略（CMA-ES；[http://mng.bz/1M5q](http://mng.bz/1M5q)）。尽管它们不完全遵循与贝叶斯-高斯过程方法相同的数学理论，但它们共享相同的超参数选择策略：通过考虑历史评估结果来计算下一个建议的值。
- en: Multifidelity optimization
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 多信度优化
- en: Multifidelity methods improve the efficiency of model-free and Bayesian optimization
    methods. Nowadays, tuning hyperparameters on large datasets can take several hours
    and even days. To speed up the HPO, multifidelity methods were developed. With
    this approach, we minimize the loss function using so-called low-fidelity approximations
    of the actual loss function. As a result, we can skip a lot of computations during
    HPO.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 多信度方法提高了无模型和贝叶斯优化方法的效率。如今，在大型数据集上调整超参数可能需要几个小时甚至几天。为了加速超参数优化，开发了多信度方法。采用这种方法，我们使用实际损失函数的所谓低信度近似来最小化损失函数。因此，在超参数优化过程中我们可以跳过很多计算。
- en: Note In the machine learning context, the loss function ([https://www.datarobot.com/blog/introduction-to-loss-functions/](https://www.datarobot.com/blog/introduction-to-loss-functions/))
    is a method of evaluating how well a training algorithm models your dataset. If
    the model output (predictions) is far off from the expected results, the loss
    function should output a higher number; otherwise, it should output a lower number.
    The loss function is a key component of ML algorithm development; the design of
    the loss function directly affects model accuracy.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，损失函数（[https://www.datarobot.com/blog/introduction-to-loss-functions/](https://www.datarobot.com/blog/introduction-to-loss-functions/)）是评估训练算法对数据集建模效果的一种方法。如果模型输出（预测）与期望结果相差很远，损失函数应该输出较高的数字；否则，应该输出较低的数字。损失函数是机器学习算法开发的关键组成部分；损失函数的设计直接影响模型准确性。
- en: Although the approximation introduces a tradeoff between optimization performance
    and run time, in practice, the speedups often outweigh the approximation errors.
    For more details, refer to “Hyperparameter Optimization,” by Matthias Feurer and
    Frank Hutter ([www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种近似方法在优化性能和运行时间之间引入了一种权衡，但在实践中，加速往往超过了近似误差。有关更多详细信息，请参阅 Matthias Feurer 和
    Frank Hutter 的“超参数优化”（[www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf)）。
- en: Why does the Bayesian-like HPO algorithm work?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯式超参数优化算法为什么有效？
- en: The blog post “Intuition behind Gaussian Processes,” by Michael McCourt ([https://sigopt.com/blog/intuition-behind-gaussian-processes/](https://sigopt.com/blog/intuition-behind-gaussian-processes/))
    gives an excellent explanation for why the Bayesian-like optimization algorithm
    can find the optimum hyperparameter set without checking every possible value
    in the search space. In some settings, the experiments we observe are independent,
    such as flipping a coin 50 times; knowledge of one does not imply knowledge of
    others. But, fortunately, many settings have a more helpful structure from which
    previous observations provide insight into unobserved outcomes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Michael McCourt 的博客文章“高斯过程背后的直觉”（[https://sigopt.com/blog/intuition-behind-gaussian-processes/](https://sigopt.com/blog/intuition-behind-gaussian-processes/)）对为什么贝叶斯优化算法可以在不检查搜索空间中的每个可能值的情况下找到最佳超参数集提供了很好的解释。在某些情况下，我们观察到的实验是独立的，例如抛硬币50次；一个的知识并不意味着对其他的了解。但是，幸运的是，许多情况具有更有用的结构，从中以往的观察结果能够提供对未观察到的结果的见解。
- en: In the machine learning context, we assume there is some relationship between
    historical experiment (training trial) results and future experiment results.
    More specifically, we believe there is a math model for this relationship. Although
    using the Bayesian approach—for example, in the Gaussian process—to model this
    relationship is a very strong assumption, we are given great power to make provable
    optimal predictions. A side bonus is we now have a way to handle the uncertainty
    of the model prediction result.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，我们假设历史实验（训练试验）结果与未来实验结果之间存在某种关系。更具体地说，我们相信存在一个数学模型来描述这种关系。虽然使用贝叶斯方法——例如，高斯过程——来建模这种关系是一个非常强的假设，但我们得到了强大的力量来做出可证明的最优预测。一个额外的好处是，我们现在有一种处理模型预测结果不确定性的方法。
- en: Note If you are interested in applying Bayesian optimization to deep learning
    projects, Quan Nguyen’s book *Bayesian Optimization in Action* (Manning, 2022;
    [https://www.manning.com/books/bayesian-optimization-in-action](https://www.manning.com/books/bayesian-optimization-in-action))
    is a good resource.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 如果您有兴趣将贝叶斯优化应用于深度学习项目，Quan Nguyen 的书籍 *贝叶斯优化实战*（Manning, 2022; [https://www.manning.com/books/bayesian-optimization-in-action](https://www.manning.com/books/bayesian-optimization-in-action)）是一个很好的资源。
- en: Which HPO algorithm works the best?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种 HPO 算法效果最好？
- en: No single HPO algorithm works best. Different optimization algorithms may fit
    different tuning tasks under different constraints. Some of those variables might
    include how the search space looks (e.g., hyperparameter types, value ranges),
    how the trial budget looks, and what the goal is (eventual optimality or optimal
    anytime performance). Figure 5.6 shows an HPO algorithm selection guideline from
    the Optuna ([https://optuna.org/](https://optuna.org/)) HPO framework.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 没有单一的 HPO 算法最好。不同的优化算法可能适用于不同的调优任务，在不同的约束条件下。其中一些变量可能包括搜索空间的外观（例如，超参数类型、值范围）、试验预算的外观以及目标是什么（最终最优性或随时最优性能）。图
    5.6 显示了来自 Optuna ([https://optuna.org/](https://optuna.org/)) HPO 框架的 HPO 算法选择指南。
- en: '![](../Images/05-06.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-06.png)'
- en: Figure 5.6 A HPO algorithm selection cheat sheet from the Optuna HPO framework
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 来自 Optuna HPO 框架的 HPO 算法选择备忘单
- en: 'In figure 5.6, we see a decision graph for when to use the following three
    HPO algorithms: Gaussian process, TPE, and CMA-ES. Because HPO is a fast-developing
    field, new efficient algorithms can be published at any time, so algorithm selection
    cheat sheets like this will quickly become outdated. For example, FLAML ([https://github.com/microsoft/FLAML](https://github.com/microsoft/FLAML))
    is a newly developed Python HPO library that checks the hyperparameter correlation
    during the HPO process; it is definitely worth a try. So please check with your
    data science team for the latest HPO algorithm selection guideline.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 5.6 中，我们看到一个关于何时使用以下三种 HPO 算法的决策图：高斯过程、TPE 和 CMA-ES。由于 HPO 是一个快速发展的领域，新的高效算法随时可能被发布，因此像这样的算法选择备忘单将很快过时。例如，FLAML
    ([https://github.com/microsoft/FLAML](https://github.com/microsoft/FLAML)) 是一个新开发的
    Python HPO 库，它在 HPO 过程中检查超参数之间的相关性；它绝对值得一试。因此，请咨询您的数据科学团队以获取最新的 HPO 算法选择指南。
- en: Note The HPO algorithm is not the primary focus of HPO engineering. The math
    behind the HPO algorithm can be intimidating, but luckily, it is not the engineer’s
    focus. Normally, it’s the data scientist’s job to determine which HPO algorithm
    to use for a certain training job. As engineers, our role is to build a flexible,
    extensible, black-box–fashion HPO system, so data scientists can run their model
    training code with arbitrary HPO algorithms easily.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 HPO 算法不是 HPO 工程的主要关注点。HPO 算法背后的数学可能会让人望而生畏，但幸运的是，这不是工程师的重点。通常，确定要为某个特定训练任务使用哪种
    HPO 算法是数据科学家的工作。作为工程师，我们的角色是构建一个灵活、可扩展的黑盒式 HPO 系统，以便数据科学家可以轻松地使用任意 HPO 算法运行其模型训练代码。
- en: 5.2.3 Common automatic HPO approaches
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 常见的自动 HPO 方法
- en: 'Fortunately, many mature frameworks and systems already exist today for conducting
    HPO. Depending on the usage, they fall into two different categories: the HPO
    library approach and the HPO service approach. Figure 5.7 illustrates the two
    approaches. Let’s now discuss them one by one.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，今天已经存在许多成熟的框架和系统用于进行 HPO。根据使用情况，它们分为两种不同的类别：HPO 库方法和 HPO 服务方法。图 5.7 说明了这两种方法。现在让我们逐一讨论它们。
- en: HPO library approach
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: HPO 库方法
- en: In figure 5.7 (a), the library approach, we see that data scientists manage
    the HPO process themselves, from coding to execution. They code the entire HPO
    flow by using an HPO library, such as Hyperopt—an open source Python HPO library—and
    integrate it with the training code together in one training application. Next,
    data scientists run this application on their local machine or on the servers
    to which they have direct access. The HPO library inside the application will
    execute the HPO workflow that we see in figure 5.3.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.7（a）中，库方法，我们看到数据科学家自己管理HPO过程，从编码到执行。他们使用HPO库（例如Hyperopt——一个开源的Python HPO库）编写整个HPO流程，并将其与训练代码一起集成到一个训练应用程序中。接下来，数据科学家在本地计算机或直接访问的服务器上运行此应用程序。应用程序内的HPO库将执行我们在图5.3中看到的HPO工作流。
- en: '![](../Images/05-07.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-07.png)'
- en: 'Figure 5.7 Two different HPO approaches: library vs. service. (a) HPO libraries
    can run HPO experiments (training) on a local machine or a group of servers with
    preconfiguration; (b) HPO service can run HPO experiments in a fully remote and
    automatic fashion.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 两种不同的HPO方法：库 vs 服务。（a）HPO库可以在本地计算机或经过预配置的服务器组上运行HPO实验（训练）；（b）HPO服务可以以完全远程和自动化的方式运行HPO实验。
- en: Flexibility and agility are the biggest advantages of the library approach;
    you can choose any HPO algorithm/libraries you like, integrate them into your
    training code, and start the HPO process right away because everything (training
    plus hyperparameter calculation) happens on your local machine. Some HPO libraries—for
    example, Ray Tune (section 5.4.3)—also support parallel distributed execution
    but not in a fully automatic manner. This requires setting up a distributed computing
    group with specific software that allows cross-machine communication, and it also
    requires manually kicking off the parallel process on each server.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 灵活性和敏捷性是库方法的最大优势；你可以选择任何你喜欢的HPO算法/库，将它们集成到你的训练代码中，立即开始HPO过程，因为一切（训练加上超参数计算）都发生在你的本地计算机上。一些HPO库——例如Ray
    Tune（5.4.3节）——也支持并行分布式执行，但不是完全自动化的。这需要设置一个具有特定软件的分布式计算组，允许跨计算机通信，并且需要在每台服务器上手动启动并行过程。
- en: The biggest challenges for the library approach are scalability, reusability,
    and stability. HPO requires lots of compute resources to execute its trials, so
    a single server is often not capable of HPO. Even with the distributed functionality,
    it still can’t scale. Imagine we want to use 20 servers for an HPO task that requires
    10,000 trial runs; we need to manually set up the HPO process on 20 servers and
    redo the setup every time the training or HPO code changes. Also, if 1 of the
    20 parallel workers fails, the entire HPO work group comes to a halt. To address
    these problems, the HPO service approach is introduced.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 库方法面临的最大挑战是可扩展性、可重用性和稳定性。HPO需要大量的计算资源来执行其试验，因此单个服务器通常无法执行HPO。即使具有分布功能，它仍然无法扩展。想象一下，我们想要使用20台服务器进行需要10,000次试验的HPO任务；我们需要在20台服务器上手动设置HPO过程，并在每次训练或HPO代码更改时重新设置。此外，如果20个并行工作中的1个失败，整个HPO工作组都会停止。为了解决这些问题，引入了HPO服务方法。
- en: HPO service approach
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: HPO服务方法
- en: Now let’s take a closer look at the HPO service approach; we repeat figure 5.7
    for clarity, presented here as figure 5.8\. In figure 5.8 (b), the service approach,
    we see that the HPO happens in a remote compute cluster, managed by a service—the
    HPO service. A data scientist only provides training code and a selected HPO algorithm
    configuration to the service and starts the HPO job. The service manages both
    compute resource allocation and the HPO workflow (figure 5.3) execution; it tracks
    each trial’s result (model performance metric, such as accuracy) and returns the
    final optimal hyperparameters to the data scientist when all trials are complete.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更仔细地看看HPO服务方法；我们为清晰起见重复图5.7，这里呈现为图5.8。在图5.8（b）中，服务方法，我们看到HPO发生在一个远程计算集群中，由一个服务——HPO服务管理。数据科学家只向服务提供训练代码和选定的HPO算法配置，并启动HPO作业。该服务管理计算资源分配和HPO工作流程（图5.3）的执行；它跟踪每个试验的结果（模型性能指标，例如准确性），并在所有试验完成时向数据科学家返回最终的最佳超参数。
- en: '![](../Images/05-08.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-08.png)'
- en: 'Figure 5.8 Two different HPO approaches: library vs. service'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 两种不同的HPO方法：库 vs 服务
- en: The service approach provides a real black-box experience. Data scientists don’t
    need to worry about managing their own servers, setting up trial workers, and
    learning how to modify training code to work with different HPO algorithms. The
    HPO service takes care of all of these tasks. As the HPO service user, we just
    pass parameters into the service, and then the service runs the HPO automatically
    and returns the optimal hyperparameters at the end. The service also takes care
    of autoscaling and failure recovery of failed trial jobs. Because of these advantages,
    the service approach is now the dominant HPO approach in the deep learning production
    environment. Because you are now familiar with HPO concepts and approaches, let’s
    look at how to design an HPO service and how to use HPO libraries in the next
    two sections.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 该服务方法提供了真正的黑盒体验。数据科学家无需担心管理自己的服务器、设置试验工作者，以及学习如何修改训练代码以适应不同的 HPO 算法。HPO 服务会处理所有这些任务。作为
    HPO 服务的用户，我们只需将参数传递给服务，然后服务会自动运行 HPO 并在最后返回最优超参数。该服务还负责自动缩放和失败试验作业的故障恢复。由于这些优点，服务方法现在是深度学习生产环境中的主导
    HPO 方法。由于您现在熟悉了 HPO 的概念和方法，让我们在接下来的两节中看看如何设计 HPO 服务以及如何使用 HPO 库。
- en: Note HPO is *not* a one-time job. If training with a different dataset, you
    need to redo the HPO even if the model architecture didn’t change. If the dataset
    changes, the optimal set model weights that fit best with the given data change
    as well, so you need a new HPO searching effort.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 HPO *不是*一次性工作。如果使用不同的数据集进行训练，即使模型架构没有改变，您也需要重新进行 HPO。如果数据集发生变化，最优模型权重集也会发生变化，因此您需要进行新的
    HPO 搜索工作。
- en: 5.3 Designing an HPO service
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 设计一个 HPO 服务
- en: Now that you have a good understanding of the HPO library approach, let’s review
    the HPO service approach. In this section, we will look at how to design an HPO
    service to support HPO for arbitrary model training in an automatic and black-box
    fashion.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对 HPO 库方法有了很好的理解，让我们来回顾一下 HPO 服务方法。在这一节中，我们将看看如何设计一个 HPO 服务，以支持对任意模型训练进行自动和黑盒方式的
    HPO。
- en: 5.3.1 HPO design principles
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 HPO 设计原则
- en: Before we look at the concrete design proposal, let’s first check out the five
    design principles for building an HPO service.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看具体的设计方案之前，让我们先来了解一下构建 HPO 服务的五个设计原则。
- en: 'Principle 1: Training code agnostic'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 1：训练代码不可知
- en: The HPO service needs to be agnostic to training code and model training frameworks.
    In addition to supporting arbitrary machine learning frameworks like TensorFlow,
    PyTorch, and MPI, we would like the service to be able to tune hyperparameters
    of training code written in any programming language.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: HPO 服务需要对训练代码和模型训练框架保持不可知。除了支持像 TensorFlow、PyTorch 和 MPI 这样的任意机器学习框架之外，我们希望该服务能够调整任何编程语言编写的训练代码的超参数。
- en: 'Principle 2: Extensibility and consistency in supporting different HPO algorithms'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 2：在支持不同 HPO 算法方面具有可扩展性和一致性
- en: From the HPO algorithms discussion in section 5.2.2, we know the hyperparameters
    search algorithm is the brain of the HPO process. The efficiency of the hyperparameter
    search decides the HPO performance. A good HPO algorithm can find optimal hyperparameters
    with a large hyperparameter number and arbitrary search spaces in a small number
    of trials.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从第 5.2.2 节的 HPO 算法讨论中，我们知道超参数搜索算法是 HPO 过程的核心。超参数搜索的效率决定了 HPO 的性能。一个好的 HPO 算法可以在少量试验中找到大量超参数和任意搜索空间的最优超参数。
- en: Because HPO algorithm research is an active field, a new effective algorithm
    is published every few months. Our HPO service needs to integrate with these new
    algorithms easily and expose them as algorithm options to customers (data scientists).
    Also, the newly added algorithm should behave consistently with the existing algorithms
    in terms of user experience.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 HPO 算法研究是一个活跃的领域，每隔几个月就会发表一个新的有效算法。我们的 HPO 服务需要轻松集成这些新算法，并将它们作为算法选项暴露给客户（数据科学家）。此外，新添加的算法在用户体验方面应该与现有算法保持一致。
- en: 'Principle 3: Scalability and fault tolerance'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 3：可扩展性和容错性
- en: Besides HPO algorithms, another important responsibility of an HPO service is
    to manage the computing resources used for HPO—the model training with various
    hyperparameter values. From an HPO experiment perspective, we want distributed
    execution at both the experiment level and trial level. More specifically, we
    want to not only run trials in a distributed and parallel manner but also be able
    to run a single training trial distributedly—for example, running distributed
    training for the model training in one trial. From a resource utilization perspective,
    the system needs to support autoscaling, which allows the compute cluster size
    to be automatically adjusted to the current workload, so there is no under- or
    overutilization of resources.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Fault tolerance is also another important aspect of HPO trial execution management.
    Fault tolerance is important because some HPO algorithms are required to execute
    trials sequentially. For example, trial 2 must happen after trial 1 because the
    algorithm needs the past hyperparameter values and results to deduce the hyperparameters
    before the next trial starts. In this case, when one trial fails unexpectedly—for
    example, because of a node restart or a network problem—the entire HPO process
    fails. The system should recover from the previous failure automatically. The
    common approach is to record the latest state of each trial, so we can resume
    from the last recorded checkpoint.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 4: Multitenancy'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: An HPO process is essentially a set of model training executions. Similar to
    model training, HPO services must provide resource isolation for various users
    or groups. This will ensure that different user activities stay within their boundaries.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 5: Portability'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, the concept of “cloud neutral” has become very popular. People want
    to run their model training job in different environments—Amazon Web Services,
    Google Cloud Platform, and Azure—so the HPO service we build needs to decouple
    from the underlying infrastructure. Running HPO service on Kubernetes is a good
    choice here.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.2 A general HPO service design
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Because the HPO workflow (figure 5.3) is quite standard and there are not many
    variations, the HPO service system design (figure 5.9) can be applied to most
    of the HPO scenarios. It consists of three main components: an API interface,
    HPO job manager, and hyperparameter (HP) suggestion maker. (They are marked as
    A, B, and C in figure 5.9.)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/05-09.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 A general system design of an HPO service
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: The API interface (component A) is the entrance point for users to submit HPO
    jobs. To start an HPO experiment, users submit an API request (step 1) to the
    interface; the request provides model training code, such as a Docker image; hyperparameters
    and their search space; and an HPO algorithm.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The HP suggestion maker (component C) is a wrapper/adapter for different HPO
    algorithms. It provides a unified interface for users to run each different HPO
    algorithm, so users can select an algorithm without worrying about the execution
    details. To add a new HPO algorithm, it must be registered in this suggestion-maker
    component to become an algorithm option for users.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: HP 建议制定者（组件 C）是不同 HPO 算法的包装器/适配器。它为用户运行每个不同的 HPO 算法提供了一个统一的接口，因此用户可以选择算法而不必担心执行细节。要添加新的
    HPO 算法，必须在此建议制定者组件中注册它，以成为用户的算法选项。
- en: The HPO job manager (component B) is the core component of the HPO service;
    it manages the HPO experiments for customer requests. For each HPO request, the
    job manager starts an HPO trial loop (step 2). Within the loop, it first calls
    the HP suggestion maker to obtain a set of suggested hyperparameter values (step
    2.a) and then creates a trial to run model training with these hyperparameter
    values (steps 2.b and 2.c).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: HPO 作业管理器（组件 B）是 HPO 服务的核心组件；它管理客户请求的 HPO 实验。对于每个 HPO 请求，作业管理器启动一个 HPO 试验循环（步骤
    2）。在循环中，它首先调用 HP 建议制定者来获得建议的超参数值集合（步骤 2.a），然后创建一个试验以使用这些超参数值运行模型训练（步骤 2.b 和 2.c）。
- en: 'For each training trial, the HPO job manager creates a trial object. This object
    has two responsibilities: first, it collects the output of a trial execution,
    such as the training progress, model metrics, model accuracy, and tried hyperparameters;
    second, it manages the training process. It handles the training process launching,
    distributed training setup, and failure recovery.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个训练试验，HPO 作业管理器都会创建一个试验对象。该对象有两个职责：首先，它收集试验执行的输出，例如训练进度、模型指标、模型准确性和尝试的超参数；其次，它管理训练过程。它处理训练过程的启动、分布式训练设置和失败恢复。
- en: HPO service end-to-end execution workflow
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: HPO 服务的端到端执行流程
- en: Let’s walk through the end-to-end user workflow, as shown in figure 5.9\. For
    your convenience, we repeat figure 5.9, shown here as figure 5.10.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照图 5.9 显示的端到端用户工作流程来走一遍。为了方便起见，我们重复了图 5.9 并将其显示为图 5.10。
- en: '![](../Images/05-10.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-10.png)'
- en: Figure 5.10 A general system design of an HPO service
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 HPO 服务的一般系统设计
- en: First, the user submits an HPO request to the API interface (step 1). The request
    defines the training code, a list of hyperparameters and their value search space,
    the training objective, and an HPO algorithm. Then, the HPO job manager starts
    an HPO trial loop for this request (step 2). This loop launches a set of trials
    to determine which set of hyperparameter values works the best. In the end, when
    the trial budgets run out or one trial meets the training objective, the trial
    loop breaks, and the best hyperparameters are returned (step 3).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，用户向 API 接口提交 HPO 请求（步骤 1）。该请求定义了训练代码、超参数及其值搜索空间的列表、训练目标和一个 HPO 算法。然后，HPO
    作业管理器为该请求启动 HPO 试验循环（步骤 2）。该循环启动一组试验来确定哪组超参数值最好。最后，当试算预算用尽或一次试验达到训练目标时，试验循环会中断，最优超参数会被返回（步骤
    3）。
- en: Within a trial loop, the job manager first queries the HP suggestion maker to
    recommend hyperparameter candidates (step 2.a). The suggestion maker will run
    the selected HPO algorithm to calculate a set of hyperparameter values and return
    it to the job manager (step 2.b). The job manager then creates a trial object
    that launches a model training process with the suggested hyperparameter values
    (step 2.c). The trial object will also monitor the training process and continue
    reporting training metrics to the trial history database until the training completes
    (step 2.d). When the job manager notices the current trial is complete, it pulls
    the trial history (trial metrics and hyperparameter values used in past trials)
    and passes it to the HP suggestion maker to obtain a new set of HP candidates
    (step 2.e).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在试验循环中，作业管理器首先查询 HP 建议制定者以推荐超参数候选项（步骤 2.a）。制定者将运行所选的 HPO 算法来计算一组超参数值，并将其返回给作业管理器（步骤
    2.b）。然后，作业管理器创建一个试验对象，以使用建议的超参数值启动模型训练过程（步骤 2.c）。试验对象还将监视训练过程，并继续向试验历史数据库报告训练指标，直到训练完成（步骤
    2.d）。当作业管理器注意到当前试验已完成时，它将拉取试验历史记录（试验指标和用于过去试验的超参数值）并将其传递给 HP 建议制定者以获得新的 HP 候选项（步骤
    2.e）。
- en: Because the HPO use cases are quite standard and generic and there are already
    multiple open source HPO projects that work out of the box, we think it’s better
    to learn how to use them instead of rebuilding a new system that has no added
    value. So in appendix C, we will introduce you to a powerful and highly portable
    Kubernetes-based HPO service—Kubeflow Katib.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Open source HPO libraries
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The HPO service might seem like too much overhead for a small data scientist
    team, especially if all their models are trained on a few servers they manage
    themselves. In this case, using HPO libraries to optimize model training in local
    machines or managed clusters (small scale, 1–10 servers) is a better option.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will introduce three useful HPO open source libraries:
    Optuna, Hyperopt, and Ray Tune. They all run as HPO libraries, and they are easy
    to learn and simple to use. Because Optuna, Hyperopt, and Ray Tune all have clear
    onboarding docs and suitable examples, we will focus on the general overview and
    feature introduction so you can decide which one to use based on your own circumstances.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: In the following discussion about different HPO libraries, especially in the
    “How to Use” sections, you will see the term *objective function* a lot. What
    is an objective function? Figure 5.11 demonstrates the process.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: For an HPO algorithm, such as Bayesian search, to generate a hyperparameter
    suggestion so that the next trial works better, it needs to know how well the
    previous HPO trial operated. Therefore, the HPO algorithm requires that we define
    a function to score each training trial and continue minimizing or maximizing
    the return value of the function (score) in the subsequent trials. We named this
    the objective function.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: In figure 5.11, we see that an objective function receives hyperparameters as
    input and returns a float value, or score. The objective function executes the
    model training with given hyperparameters and evaluates the output model when
    the training completes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/05-11.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 An objective function receives the hyperparameters as input and
    returns a score.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.1 Hyperopt
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hyperopt ([http://hyperopt.github.io/hyperopt/#getting-started](http://hyperopt.github.io/hyperopt/#getting-started))
    is a lightweight and easy-to-use Python library for serial and parallel HPO. Random
    search, TPE, and adaptive TPE are the three HPO algorithms implemented in Hyperopt.
    Bayesian optimization algorithms (based on Gaussian processes) and regression
    trees have been designed to accommodate but were not yet implemented at the time
    this book was written.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: How to use
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you want to know which classifiers work best for your deep learning
    case. We can use Hyperopt to obtain the answer in three steps.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: First, we create an objective function that is basically a wrapper function
    of the actual training code but reads the hyperparameter values from the `args`
    variable. Second, we define search space for the selected hyperparameter. Third,
    we choose an HPO algorithm, which selects hyperparameter values from the search
    space and passes them to the objective function to start the optimization process.
    Listing 5.1 implements this scenario.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we want to determine which classifier leads to the best model
    accuracy, so we choose to optimize the `classifier_type` hyperparameter among
    three candidates: `naive_bayes`, `svm`, and `dtree`. You may also notice that
    each classifier has its own value search space, such as `hp.lognormal(''svm_rbf_width'',`
    `0,` `1)` for the `svm` classifier. In the `fmin` function (in step 3), we specify
    TPE as the HPO algorithm with 10 max trials and pass in the objective function
    and search space as the required parameters.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.1 Getting started with Hyperopt
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Trains the model with the passed in hyperparameters and evaluates the result
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Declares three classifier candidates
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Defines search space for the parameters of the SVM classifier
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: ❹ The fmin function minimizes the objective over the space with the selected
    algorithm.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Parallelization
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Although Hyperopt is a standalone library, we can run it parallelly in a cluster
    of machines. The basic idea is to run Hyperopt workers on different machines and
    let them talk to a central database for coordination. Hyperopt can also use Spark
    computing to run HPO parallelly. You can check out the following two articles
    for more details: “On Using Hyperopt: Advanced Machine Learning,” by Tanay Agrawal
    ([http://mng.bz/PxwR](http://mng.bz/PxwR)) and “Scaling Out Search with Apache
    Spark” ([http://hyperopt.github.io/hyperopt/scaleout/spark/](http://hyperopt.github.io/hyperopt/scaleout/spark/)).'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: When to use
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Hyperopt is a good option for small or early-phase model training projects.
    First, it’s easy to use. You can run HPO in three steps on a local machine or
    on servers to which you have direct access. Second, it’s friendly to modification.
    Because it takes a library approach, the HPO code is placed with training code
    in the same code project. So, trying different optimization plans, such as choosing
    various hyperparameters to tune, is very convenient.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.2 Optuna
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similar to Hyperopt, Optuna is also a lightweight Python library designed to
    automate hyperparameter searches. It supports large space search and early pruning
    on the unpromising trials, as well as parallelization on multiple threads or processes
    without modifying code.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: In our opinion, Optuna is an advanced version of Hyperopt, and its visualization
    capabilities are much better. By examining the interactions between parameters
    in a graph, the visualization in hyperparameter search gives you a lot of insight,
    so you can easily determine which parameters are more effective than others. Optuna’s
    visualization is beautiful and interactive.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Optuna has another advantage over Hyperopt concerning its documentation. Optuna’s
    documentation is excellent. In addition to its detailed API doc and well-organized
    tutorials, it has well-maintained source code. If you look at its GitHub project
    issue section, you will find a very active and growing community, and great features
    and GitHub pull requests are still to come.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: How to use
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 5.2 shows a quick three-step example of how to use Optuna: step 1,
    define the objective function; step 2, create a study object to represent the
    HPO process; and step 3, start the HPO process with a max trials quota.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Compared to Hyperopt, Optuna requires most of the HPO logic to be defined in
    the objective function. The general code pattern is as follows. First, define
    the search space and generate the hyperparameter values by `trial.suggest_xxx`
    function. Next, start the model training with the sampled hyperparameter values.
    Then run the evaluation method to calculate model performance and return the objective
    value. In the following example, the evaluation score is calculated by `mean_squared_error`.
    You can find more Optuna examples at [https://github.com/optuna/optuna-examples](https://github.com/optuna/optuna-examples).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.2 Getting started with Optuna
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Sets classifier candidates
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Invokes suggest_XXX methods to generate the hyperparameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Chooses max_depth in the range of 2 and 32
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Runs model training with the Optuna regressor
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Sets mean square error as the objective value and links to the trial object
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Parallelization
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run distributed HPO on one machine or a cluster of machines with Optuna.
    The distributed execution setup is fairly simple and can be done in three steps:
    first, start a relational database server, such as MySQL; second, create a study
    with storage argument; and third, share the study among multiple nodes and processes.
    Compared to Hyperopt, Optuna’s distributed execution setup is simpler, and it
    can scale up from a single machine to multiple machines without code modifications.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: When to use
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Optuna can be seen as the successor of Hyperopt; it has better documentation,
    visualization, and parallel execution. For any deep learning model training project
    that can run on one or more machines, you can use Optuna to find the optimal hyperparameters.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Optuna will hit its limit with a large data science team or multiple HPO projects
    to support because it requires managing a central machine cluster to provide the
    computing resource. But Optuna’s parallel/distributed execution is manual; people
    need to distribute the code to each server and execute it one server at a time,
    manually. To manage distributed computing jobs in an automatic and programmatic
    fashion, we can use Kubeflow Katib (appendix C) or Ray Tune.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.3 Ray Tune
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ray ([https://docs.ray.io/en/latest/index.html](https://docs.ray.io/en/latest/index.html))
    provides a simple, universal API for building distributed applications. Ray Tune
    ([https://docs.ray.io/en/latest/tune/index.html](https://docs.ray.io/en/latest/tune/index.html))
    is a Python library built on top of Ray for HPO at any scale.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The Ray Tune library supports almost any machine learning framework, including
    PyTorch, XGBoost, MXNet, and Keras. It also supports state-of-the-art HPO algorithms
    such as Population Based Training (PBT), BayesOptSearch, and HyperBand/ ASHA.
    In addition, Tune provides a mechanism to integrate HPO algorithms from other
    HPO libraries, such as Hyperopt integration.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: By using Ray as its distributed executing support, we can launch a multinode
    HPO experimentation in a few lines of code. Ray will take care of code distribution,
    distributed computing management, and fault tolerance.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: How to use
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Using Ray Tune to execute an HPO task is very straightforward. First, define
    an objective function. In the function, read hyperparameter values from the `config`
    variable, start model training, and return the evaluation score. Second, define
    hyperparameters and their value search space. Third, start the HPO execution by
    linking the objective function and search space together. Listing 5.3 implements
    the aforementioned three steps.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.3 Getting started with Ray Tune
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ ConvNet is a self-defined neural network.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Reads the hyperparameter value from the input config
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Starts model training
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Sends the evaluation result (accuracy) back to Tune
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Samples a float value uniformly between 0.1 and 0.9 for "momentum"
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: You may notice a scheduler object, `ASHAScheduler``,` is passed to the `tune.run`
    function in step 3\. ASHA ([http://mng.bz/JlwZ](http://mng.bz/JlwZ)) is a scalable
    algorithm for principled early stopping (see “Massively Parallel Hyperparameter
    Optimization,” by Liam Li; [http://mng.bz/wPZ5](http://mng.bz/wPZ5)). At a high
    level, ASHA terminates trials that are less promising and allocates time and resources
    to more promising trials. By properly adjusting the parameter `num_samples`, the
    search can be much more efficient, and it can support a larger search space.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Parallelization
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Distributed execution is Ray Tune’s biggest advantage compared with Optuna.
    Ray Tune allows you to transparently parallelize across multiple GPUs and multiple
    nodes (see Ray documentation at [http://mng.bz/qdRx](http://mng.bz/qdRx)). Tune
    even has seamless fault tolerance and cloud support. Unlike Optuna and Hyperopt,
    we don’t need to manually set up a distributed environment and execute worker
    scripts one machine after another. Ray Tune takes care of these steps automatically.
    Figure 5.12 shows how Ray Tune distributes HPO Python code to a cluster of machines.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 相比于Optuna，Ray Tune的最大优势就是分布式执行。Ray Tune允许你透明地在多个GPU和多个节点上并行执行（请参阅[Ray文档](http://mng.bz/qdRx)）。Tune甚至具备无缝的容错和云支持。与Optuna和Hyperopt不同，我们不需要手动设置分布式环境，并逐台执行工作脚本。Ray
    Tune会自动处理这些步骤。图5.12展示了Ray Tune如何将HPO Python代码分发到一组机器上。
- en: '![](../Images/05-12.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-12.png)'
- en: Figure 5.12 Ray Tune running distributed HPO on a cluster of machines
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 Ray Tune在一组机器上运行分布式HPO
- en: 'First, we set up a Ray cluster with the command `"ray` `up` `tune-cluster.yaml"`;
    the `tune-cluster.yaml` is a cluster configuration that declares the computing
    resources for the cluster. Then we run the following command to submit the HPO
    code from the local machine to the head node of the cluster: `"ray` `submit` `tune-cluster.yaml`
    `tune_ script.py` `--start` `--` `--ray-address={server_address}"`. Next, Ray
    assigns resources, copies the HPO code to the servers, and starts the distributed
    execution. For further details, please see “Tune Distributed Experiments” ([http://mng.bz/71QQ](http://mng.bz/71QQ)).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们用命令`"ray``` `up` `tune-cluster.yaml"`建立了一个Ray集群；`tune-cluster.yaml`是一个声明集群计算资源的集群配置。然后，我们运行以下命令将HPO代码从本地机器提交到集群的head节点：`"ray`
    `submit` `tune-cluster.yaml` `tune_ script.py` `--start` `--` `--ray-address={server_address}"`。接下来，Ray分配资源，将HPO代码复制到服务器，并启动分布式执行。更多详情，请参见“Tune
    Distributed Experiments” ([http://mng.bz/71QQ](http://mng.bz/71QQ))。
- en: Besides distributed HPO execution, Ray Tune also supports running distributed
    training for single-trial, automatic checkpoint management and TensorBoard logging.
    These features add great value to Ray Tune for their high fault tolerance and
    simple troubleshooting.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分布式HPO执行，Ray Tune还支持单次试验的分布式训练，自动检查点管理和TensorBoard日志记录。这些功能为Ray Tune增添了巨大的价值，因为它们具有高容错性和简单的故障排除能力。
- en: When to use
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 什么时候使用
- en: Compared with other HPO libraries, is Ray Tune the way to go for HPO? Provisionally,
    yes. As this book is being written, Ray provides integration between the underlying
    training framework (such as TensorFlow and PyTorch) and the cutting-edge HPO algorithm
    (such as Bayesian search and TPE), as well as early stopping (ASHA). It allows
    us to run HPO searches distributedly in a straightforward and reliable manner.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他HPO库相比，Ray Tune是否是进行HPO的最佳选择？暂时是的。在撰写本书时，Ray提供了底层训练框架（如TensorFlow和PyTorch）与最新的HPO算法（例如贝叶斯搜索和TPE），以及提前停止（ASHA）的集成。它允许我们以简单且可靠的方式分布式地运行HPO搜索。
- en: 'For most of the data science team, who don’t want to own an HPO service, Ray
    Tune is the suggested approach. It’s simple to use, and it meets almost every
    model training project’s HPO requirement: great documents, cutting-edge HPO algorithms,
    and efficient and simple distributed execution management.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数数据科学团队，不希望拥有HPO服务的情况下，Ray Tune是建议的方法。它使用简单，并且几乎满足每个模型训练项目的HPO需求：丰富的文档，最新的HPO算法，高效且简单的分布式执行管理。
- en: 'Note We recommend using Ray Tune over other HPO libraries for the following
    five reasons: (1) it is simple to use; (2) it has great documents and examples;
    (3) its distributed execution is automatic and programmatic; (4) Ray Tune supports
    distributed training for a single trial; and (5) Ray Tune has a scheduler feature
    (for example, `ASHAScheduler`) that can greatly reduce computing cost by terminating
    unpromising trials earlier.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们推荐使用Ray Tune而不是其他HPO库，理由如下：(1) 使用简单；(2) 文档和示例丰富；(3) 其分布式执行是自动和程序化的；(4)
    Ray Tune支持单次试验的分布式训练；(5) Ray Tune具有调度程序功能（例如，`ASHAScheduler`），可以通过提前终止不太被看好的试验大大降低计算成本。
- en: The limitation of Ray Tune
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Ray Tune的局限性
- en: Ray Tune and other HPO libraries will hit their limits when we need to support
    different teams and different deep learning projects in one shared HPO system.
    Ray Tune is missing computing isolation, which leads to two big problems.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要在一个共享的HPO系统中支持不同团队和不同的深度学习项目时，Ray Tune和其他HPO库将受到限制。Ray Tune缺乏计算隔离，这导致了两个大问题。
- en: First, package versions of different training codes can cause conflicts between
    Ray workers. When performing distributed HPO in Ray Tune, we submit the HPO code
    to the Ray cluster’s head server and then run this code in the cluster workers
    in parallel. This means every Ray worker server needs to install the dependent
    libraries for every training code that it needs to run. Imagine how we manage
    the package installation and potential version conflicts when you have to run
    10 different HPO tasks in one Ray cluster; the worker machine needs to install
    hundreds of packages for these 10 different training codes and also resolve their
    version conflicts. Second, Ray Tune doesn’t enforce user segregation. It’s very
    difficult to build a virtual boundary in Ray Tune for different data science teams
    to limit their computing resource usage.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.4 Next steps
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When you encounter the aforementioned problems with HPO libraries, it’s time
    to switch to an HPO service. We strongly recommend you read appendix C before
    you consider building your own HPO. It introduces a solid open source HPO service
    called Kubeflow Katib, which is a well-designed, general-purpose HPO service.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A hyperparameter is a parameter whose value is used to control the learning
    process. This type of parameter is not learnable in model training; therefore,
    we need to tune it.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HPO is a process to discover a set of hyperparameters that yields an optimal
    model, which minimizes a predefined loss function on a given dataset.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic HPO is the process of using compute power and algorithms (HPO algorithms)
    to automatically find the optimal hyperparameters for a training code.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic HPO now is a standard step for model training.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most HPO algorithms can be categorized into one of three buckets: model-free
    optimization, Bayesian optimization, or multifidelity optimization.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no single best HPO algorithm. Different optimization algorithms may
    fit different HPO tasks under different constraints.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HPO can run with a library or in a remote service. The library approach is simple,
    flexible, and suitable for small teams and projects in the prototyping phase whereas
    the service approach is for large organizations and production use cases.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HPO service approach provides a fully automatic black-box HPO experience,
    including computing resource management; therefore, we recommend taking a service
    approach if you are building a deep learning system for large teams.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The five design principles for building an HPO service are training code agnostic,
    high extensibility, high scalability and reliability, HPO execution and resource
    consumption segregation, and high portability.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To expedite an HPO experiment, we can parallelize training executions of different
    trials, introduce distributed training, and stop the unpromising trials early.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We encourage you to adopt Kubeflow Katib as your HPO service instead of building
    a new service yourself.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Among three commonly used open source HPO libraries—Optuma, Hyperopt, and Ray
    tune—Ray Tune has so far proven to be the best.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在三个常用的开源 HPO（超参数优化）库中——Optuna、Hyperopt 和 Ray Tune 中，到目前为止，Ray Tune 被证明是最好的。
