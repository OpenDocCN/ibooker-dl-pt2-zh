- en: 11 Information extraction and knowledge graphs (grounding)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Extracting named entities from text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the structure of the sentence using dependency parsing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting a dependency tree into a knowledge (fact)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a knowledge graph from text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the previous chapter (Chapter 10) you learned how to use large transformers
    to generate smart *sounding* words. But language models on their own are just
    faking it by predicting the next word that will *sound* reasonable to you. Your
    AI can’t reason about the real world until you give them access to facts and knowledge
    about the world. In Chapter 2 you learned how to do exactly this, but you didn’t
    know it then. You were able to tag tokens with their part of speech and their
    logical role in the meaning of a sentence (dependency tree). This old-fashioned
    token tagging algorithm is all you need to give your generative language models
    (AI) knowledge about the real world. The goal of this chapter is to teach your
    bot to understand what it reads. And you’ll put that understanding into a flexible
    data structure designed to store knowledge, known as *knowledge graph*. Then your
    bot can use that knowledge to make decisions and say smart stuff about the world.
  prefs: []
  type: TYPE_NORMAL
- en: Correctly parsing your text into *entities* and discovering the *relations*
    between them is how you’ll go about extracting facts from the text. A *knowledge
    graph*, also called *knowledge database* (knowledge base) or a *semantic net*,
    is a database that stores knowledge as relationships between concepts. Though
    you can use a relational database to store the relations and concepts, sometimes
    it is more appropriate to use a *graph* data structure. The nodes in the graph
    would be *entities*, while the edges would be relations between these entities.
  prefs: []
  type: TYPE_NORMAL
- en: You can see an example of a knowledge graph in Figure [11.1](#figure-knowledge-graph).
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 An example of a knowledge graph
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![kg 150 biotech company graphviz](images/kg_150_biotech_company_graphviz.png)'
  prefs: []
  type: TYPE_IMG
- en: Each fact you extract will create a new connection between the nodes of the
    graph - or possibly, create new nodes. This allows you to ask questions about
    the relationships between things using a query language such as GraphQL, Cypher
    or even SQL.
  prefs: []
  type: TYPE_NORMAL
- en: And your algorithms can then do fact-checking, not only on the text written
    by humans but also text generated by your NLP pipeline or AI. Finally, your AI
    algorithms will be able to do introspection to let you know if what they are telling
    you might actually have some semblance of truth to it.
  prefs: []
  type: TYPE_NORMAL
- en: Your AI can use knowledge graphs to fill the *common sense knowledge* gap in
    large language models and perhaps live up to a little bit of the hype around LLMs
    and AI. This is the missing link in the NLP chain that you need to create true
    AI. And you can use a knowledge graph to programmatically generate text that makes
    sense because it is grounded in facts in your database. You can even infer new
    facts or *logical inferences* about the world that aren’t yet included in your
    knowledge base.
  prefs: []
  type: TYPE_NORMAL
- en: You may remember hearing about "inference" when people talk about forward propagation
    or prediction using deep learning models. A deep learning language model uses
    statistics to estimate or guess the next word in the text that you prompt it with.
    And deep learning researchers hope that one day, neural networks will be able
    to match the natural human ability to logically infer things and reason about
    the world. But this isn’t possible, because words don’t contain all the knowledge
    about the world that a machine would need to process to make factually correct
    inferences. So you’re going to use a tried and true logical inference approach
    called "symbolic reasoning."
  prefs: []
  type: TYPE_NORMAL
- en: If you’re familiar with the concept of a compiler then you may want to think
    of the dependency tree as a parse tree or abstract syntax tree (AST). An AST defines
    the logic of a machine language expression or program. You’re going to use the
    natural language dependency tree to extract the logical relations within natural
    language text. And this logic will help you *ground* the statistical deep learning
    models so they can do more than merely make statistical "guesses" about the world
    as they did in previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1 Grounding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have a knowledge graph, your chatbots and AI agents will have a way
    to correctly reason about the world in an explainable way. And if you can extract
    facts from the text your deep learning model generates, you can check to see if
    that text agrees with the knowledge you’ve collected in your knowledge graph.
    This is called *grounding* when you maintain a knowledge graph and then use it
    to double-check the facts and reasoning in the generated text. When you ground
    your language model you attach it to some ground truth facts about the world.
  prefs: []
  type: TYPE_NORMAL
- en: Grounding can also benefit your NLP pipeline in other ways. Using a knowledge
    graph for the reasoning part of your algorithm can free up your language model
    to do what it does best — generate plausible, grammatical text. So you can fine
    tune your language model to have the tone that you want, without trying to build
    a chameleon that pretends to understand and reason about the world. And your knowledge
    graph can be designed to contain just the facts about a world that you want your
    AI to understand — whether it is facts about the real world that you have in mind
    or some fictional world that you are creating. By separating the reasoning from
    the language you can create an NLP pipeline that both sounds correct and *is*
    correct.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few other terms that are often used when referring to this grounding
    process. Sometimes it’s referred to as *symbolic reasoning* as opposed to the
    probabilistic reasoning of machine learning models. *First order logic* is one
    system for symbolic reasoning.^([[1](#_footnotedef_1 "View footnote.")]) This
    was the preferred approach to building expert systems and theorem provers before
    the data and processing power was available for machine learning and deep learning.
    It’s also called Good Old Fashioned AI or GOFAI, pronounced "Go Fie". GOFAI is
    back in fashion as researchers attempt to build generally intelligent systems
    that we can rely on to make important decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of grounding your NLP pipeline is that you can use the facts
    in your knowledge base to *explain* its reasoning. If you ask an ungrounded LLM
    to explain why it said something unreasonable, it will just keep digging a hole
    for itself (and you) by making up more and more nonsense reasons. You saw this
    in the previous chapters when LLMs confidently hallucinated (fabricated) nonexistent
    but plausible references and fictional people to explain where they got their
    nonsense from. The key to creating AI you can trust is to put a floor of reason
    underneath it using a knowledge graph. The first, and perhaps most important algorithm
    in this grounding process is *knowledge extraction*.
  prefs: []
  type: TYPE_NORMAL
- en: '11.1.1 Going old-fashioned: information extraction with patterns'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we’ll also get back to methods you see in the very early chapters,
    like regular expressions. Why return to hard-coded (manually composed) regular
    expressions and patterns? Because your statistical or data-driven approach to
    NLP has limits. You want your machine learning pipeline to be able to do some
    basic things, such as answer logical questions or perform actions such as scheduling
    meetings based on NLP instructions. And machine learning falls flat here.
  prefs: []
  type: TYPE_NORMAL
- en: Plus, as you’ll see here, you can define a compact set of condition checks (a
    regular expression) to extract key bits of information from a natural language
    string. And it can work for a broad range of problems.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern matching (and regular expressions) continues to be the state-of-the-art
    approach for information extraction and related tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Enough of a preamble. Let’s start the journey of knowledge extraction and grounding!
    But we have to cover an important step in processing your documents, to generate
    a proper input to your knowledge extraction pipeline. We need to break our text
    into smaller units.
  prefs: []
  type: TYPE_NORMAL
- en: '11.2 First things first: segmenting your text into sentences'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you can dive into extracting your knowledge from raw text, you need to
    break it down into chunks that your pipeline can work on. Document "chunking"
    is useful for creating semi-structured data about documents that can make it easier
    to search, filter, and sort documents for information retrieval. And for information
    extraction, if you’re extracting relations to build a knowledge base such as NELL
    or Freebase (more about them in a bit), you need to break it into parts that are
    likely to contain a fact or two. When you divide natural language text into meaningful
    pieces, it’s called *segmentation*. The resulting segments can be phrases, sentences,
    quotes, paragraphs, or even entire sections of a long document.
  prefs: []
  type: TYPE_NORMAL
- en: Sentences are the most common chunk for most information extraction problems.
    Sentences are usually punctuated with one of a few symbols (".", "?", "!", or
    a new line). And grammatically correct English language sentences must contain
    a subject (noun) and a verb, which means they’ll usually have at least one fact
    worth extracting. Sentences are often self-contained packets of meaning that don’t
    rely too much on preceding text to convey most of their information.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to facilitating information extraction, you can flag some of those
    statements and sentences as being part of a dialog or being suitable for replies
    in a dialog. Using a sentence segmenter (sentencizer) allows you to train your
    chatbot on longer texts, such as books. Choosing those books appropriately gives
    your chatbot a more literary, intelligent style than if you trained it purely
    on Twitter streams or IRC chats. And these books give your chatbot access to a
    much broader set of training documents to build its common sense knowledge about
    the world.
  prefs: []
  type: TYPE_NORMAL
- en: Sentence segmentation is the first step in your information extraction pipeline.
    It helps isolate facts from each other. Most sentences express a single coherent
    thought. And many of those thoughts are about real things in the real world. And,
    most importantly, all the natural languages have sentences or logically cohesive
    sections of text of some sort. And all languages have a widely shared process
    for generating them (a set of grammar "rules" or habits).
  prefs: []
  type: TYPE_NORMAL
- en: But segmenting text and identifying sentence boundaries is a bit trickier than
    you might think. In English, for example, no single punctuation mark or sequence
    of characters always marks the end of a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.1 Why won’t split('.!?') work?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Even a human reader might have trouble finding an appropriate sentence boundary
    within each of the following quotes. Here are some example sentences that most
    humans would be tempted to split into multiple sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '*She yelled "It’s right here!" but I kept looking for a sentence boundary anyway.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*I stared dumbfounded on, as things like "How did I get here?", "Where am I?",
    "Am I alive?" flittered across the screen.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The author wrote "''I don’t think it’s conscious.'' Turing said."*'
  prefs: []
  type: TYPE_NORMAL
- en: Even a human reader would have trouble finding an appropriate sentence boundary
    within each of these quotes and nested quotes and stories within stories.
  prefs: []
  type: TYPE_NORMAL
- en: More sentence segmentation "edge cases" such as this are available at tm-town.com.
    ^([[2](#_footnotedef_2 "View footnote.")])
  prefs: []
  type: TYPE_NORMAL
- en: Technical text is particularly difficult to segment into sentences because engineers,
    scientists, and mathematicians tend to use periods and exclamation points to signify
    a lot of things besides the end of a sentence. When we tried to find the sentence
    boundaries in this book, we had to manually correct several of the extracted sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 'If only we wrote English like telegrams, with a "STOP" or unique punctuation
    mark at the end of each sentence. But since we don’t, you’ll need some more sophisticated
    NLP than just `split(''.!?'')`. Hopefully, you’re already imagining a solution
    in your head. If so, it’s probably based on one of the two approaches to NLP you’ve
    used throughout this book:'
  prefs: []
  type: TYPE_NORMAL
- en: Manually programmed algorithms (regular expressions and pattern-matching)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical models (data-based models or machine learning)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use the sentence segmentation problem to revisit these two approaches by
    showing you how to use regular expressions as well as more advanced methods to
    find sentence boundaries. And you’ll use the text of this book as a training and
    test set to show you some of the challenges. Fortunately, you haven’t inserted
    any newlines within sentences, to manually "wrap" text like in newspaper column
    layouts. Otherwise, the problem would be even more difficult. In fact, much of
    the source text for this book, in ASCIIdoc format, has been written with "old-school"
    sentence separators (two spaces after the end of every sentence), or with each
    sentence on a separate line. This was so we could use this book as a training
    and test set for your segmenters.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.2 Sentence segmentation with regular expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regular expressions are just a shorthand way of expressing the tree of “if…​then”
    rules (regular grammar rules) for finding character patterns in strings of characters.
    As we mentioned in Chapters 1 and 2, regular expressions (regular grammars) are
    a particularly succinct way to specify the structure of a finite state machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any formal grammar can be used by a machine in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: To recognize "matches" to that grammar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To generate a new sequence of symbols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not only can you use patterns (regular expressions) for extracting information
    from natural language, but you can also use them to generate strings that match
    that pattern! Check out the `rstr` (short for "random string") package if you
    ever need to generate example strings that match a regular expresssion.^([[3](#_footnotedef_3
    "View footnote.")]) for some of your information extraction patterns here.
  prefs: []
  type: TYPE_NORMAL
- en: This formal grammar and finite state machine approach to pattern matching has
    some other awesome features. A true finite state machine is guaranteed to eventually
    stop (halt) in a finite number of steps. So if you use a regular expression as
    your pattern matcher you know that you will always receive an answer to your question
    about whether you’ve found a match in your string or not. It will never get caught
    in a perpetual loop…​ as long as you don’t "cheat" and use look-aheads or look-backs
    in your regular expressions. And because a regular expression is deterministic
    it always returns a match or non-match. It will never give you less than 100%
    confidence or probability of there being a match.
  prefs: []
  type: TYPE_NORMAL
- en: So you’ll stick to regular expressions that don’t require these "look-back"
    or "look-ahead" cheats. You’ll make sure your regular expression matcher processes
    each character and moves ahead to the next character only if it matches — sort
    of like a strict train conductor walking through the seats checking tickets. If
    you don’t have one, the conductor stops and declares that there’s a problem, a
    mismatch, and he refuses to go on, or look ahead or behind you until he resolves
    the problem. There are no "go-backs" or "do-overs" for train passengers, or for
    strict regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our regex or FSM has only one purpose in this case: identifying sentence boundaries.'
  prefs: []
  type: TYPE_NORMAL
- en: If you do a web search for sentence segmenters,^([[4](#_footnotedef_4 "View
    footnote.")]) you’re likely to be pointed to various regular expressions intended
    to capture the most common sentence boundaries. Here are some of them, combined
    and enhanced to give you a fast, general-purpose sentence segmenter.
  prefs: []
  type: TYPE_NORMAL
- en: The following regex would work with a few "normal" sentences.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, this `re.split` approach gobbles up (consumes) the sentence-terminating
    token. Notice how the ellipsis and period at the end of "Hello World" are missing
    in the returned list? The splitter only returns the sentence terminator if it
    is the last character in a document or string. A regular expression that assumes
    your sentences will end in white space does do a good job of ignoring the trickery
    of periods within doubly-nested quotes, though:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: See how the returned list contains only one sentence without messing up the
    quote within a quote? Unfortunately, this regex pattern also ignores periods in
    quotes that terminate an actual sentence, so any sentences that end in a quote
    will be joined with the subsequent sentence. This may reduce the accuracy of the
    information extraction steps that follow your sentence segmenter if they rely
    on accurate sentence splits.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about text messages and tweets with abbreviated text, informal punctuation,
    and emojis? Hurried humans squish sentences together, leaving no space surrounding
    periods. The following regex could deal with periods in SMS messages that have
    letters on either side and it would safely skip over numerical values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Even combining these two regexes into a monstrosity such as `r'?<!\d)\.|\.(?!\d|([!.?]+)[\s$]+'`
    is not enough to get all the sentences right. If you parsed the AciiDoc text for
    the manuscript of this chapter, it would make several mistakes.^([[5](#_footnotedef_5
    "View footnote.")]) You’d have to add a lot more "look-ahead" and "look-back"
    to the regex pattern to improve its accuracy as a sentence segmenter. You were
    warned!
  prefs: []
  type: TYPE_NORMAL
- en: If looking for all the edge cases and designing rules around them feel cumbersome,
    that’s because it is. A better approach for sentence segmentation is to use a
    machine learning algorithm trained on a labeled set of sentences. Often a logistic
    regression or a single-layer neural network (perceptron) is enough.^([[6](#_footnotedef_6
    "View footnote.")]) Several packages contain such a statistical model you can
    use to improve your sentence segmenter. SpaCy ^([[7](#_footnotedef_7 "View footnote.")])
    and Punkt (in NLTK) ^([[8](#_footnotedef_8 "View footnote.")]) both have good
    sentence segmenters. You can guess which one we use.^([[9](#_footnotedef_9 "View
    footnote.")])
  prefs: []
  type: TYPE_NORMAL
- en: 'SpaCy has a sentence segmenter built into the default parser pipeline that
    is your best bet for mission-critical applications. It is almost always the most
    accurate, robust, performant option. Here is how you segment text into sentences
    with spaCy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: SpaCy’s accuracy relies on dependency parsing. A dependency parser identifies
    how each word depends on the other words in a sentence diagram, like the one you
    learned about in grammar school (elementary school). Having this dependency structure
    along with the token embeddings helps the spacy sentence segmenter deal with ambiguous
    punctuation and capitalization accurately. But all that sophistication takes processing
    power and time. Speed is not important when you are only processing a few sentences,
    but what if you wanted to parse the AsciiDoc manuscript for Chapter 9 of this
    book?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Wow, that *is* slow! SpaCy is about 700 times slower than a regular expression.
    If you have millions of documents instead of just this one chapter of text, then
    you will probably need to do something different. For example, on a medical records
    parsing project we needed to switch to a regular expression tokenizer and sentence
    segmenter. The regex parser reduced our processing time from weeks to days, but
    it also reduced the accuracy of the rest of our NLP pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: SpaCy has now (as of 2023) caught up with our need for customization. SpaCy
    now allows you to enable or disable any piece of the pipeline you like. And it
    has a statistical sentence segmenter that doesn’t rely on the other elements of
    the spaCy pipeline such as the word embeddings and named entity recognizer. When
    you want to speed up your spaCy NLP pipeline you can remove all the elements you
    do not need and add back just the pipeline elements you want.
  prefs: []
  type: TYPE_NORMAL
- en: First, check out the pipeline attribute of a spacy NLP pipeline to see what
    is there by default. Then use the `exclude` keyword argument to `load` clean out
    the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now that you’ve cleaned your pipes, you can add back the important pieces that
    you need. For this speed run through Chapter 9, your NLP pipeline will only need
    the `senter` pipeline element. The `senter` pipeline is the statistical sentence
    segmenter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: That is a significant time saver — 2.3 vs 11.5 seconds on an 8-core i7 laptop.
    The statistical sentence segmenter is about 5x faster than the full spaCy pipeline.
    The regular expression approach will still be much faster, but the statistical
    sentence segmenter will be more accurate. You can estimate the accuracy of these
    two algorithms by comparing the lists of sentences to see if they produced the
    same splits. This will not tell you which of the two approaches is correctly segmenting
    a particular text line, but at least you will see when the two spaCy pipelines
    agree.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: So it appears that about 93% of the sentences of this book were segmented the
    same way with the slow and fast pipelines. Look at some example segmentations
    to see which one might be better for your use cases.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It looks like that opening sentence with the leading underscore character (\_)
    is bit more difficult for the faster statistical segmenter. So you probably want
    to use the full spacy model whenever you are parsing Markdown or AsciiDoc text
    files. The formatting characters will confuse a statistic segmenter if it has
    not been trained on similar text.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.3 Sentence semantics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you have your text segmented into sentences containing discrete facts,
    you are ready to start extracting those facts and giving them structure in a knowledge
    graph. To get started, create a heatmap of the BERT embeddings of all the sentences
    of chapter 9.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Take a look at this DataFrame. It has columns that contain tags for each line
    of text. You can use the tags to filter out the lines that you don’t want to process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now you can use the 'is_body' tag to process all the sentences within the body
    of the manuscript. These lines should contain mostly complete sentences so that
    you can compare them semantically to each other to see a heatmap of how often
    we say similar things. Now that you understand transformers such as BERT, you
    can use it to give you even more meaningful representations of this text than
    what SpaCy creates.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The MiniLM model is a multipurpose BERT transformer that has been optimized
    and "distilled." It provides high accuracy and speed and should not take long
    to download from Hugging Face. Now you have 689 passages of text (mostly individual
    sentences). The MiniLM language model has embedded them into a 384-dimensional
    vector space. As you learned in Chapter 6, embedding vector semantic similarity
    is computed with the normalized dot product.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now you have a square matrix, one row and one column for each passage of text
    and its BERT embedding vector. And the value in each cell of the matrix contains
    the cosine similarity between that pair of embedding vectors. If you label the
    columns and rows with the first few characters of the text passages, that will
    make it easier to interpret all this data with a heatmap.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As usual, the cosine similarity ranges between zero and one and most values
    are less than .85 (85%) unless they are for sentences that say essentially the
    same thing. So 85% would be a good threshold for identifying redundant statements
    that might be consolidated or reworded to improve the quality of the writing in
    a book such as this. Here’s what the heatmap of these cosine similarity values
    looks like.^([[10](#_footnotedef_10 "View footnote.")])
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![ch9 heatmap](images/ch9-heatmap.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There seems to be only a small square of white-hot similarity about 60% of
    the way through Chapter 9, perhaps near the line that begins "Epoch: 13…​". This
    line corresponds to the output text from a transformer training run, so it is
    not surprising that a natural language model would see these machine-generated
    lines as semantically similar. After all, the BERT language model is just saying
    to you "It’s all just Greek to me." The regular expressions in the scripts for
    tagging lines of the manuscript as natural language or software blocks are not
    working very well.^([[11](#_footnotedef_11 "View footnote.")]) If you improved
    the regular expressions in `nlpia2.text_processing.extractors` you could have
    your heatmap skip over these irrelevant code lines. And AsciiDoc files are structured
    data, so they should be machine-readable without any regular expression guesswork…​
    if only there were an up-to-date Python library for parsing AsciiDoc text.^([[12](#_footnotedef_12
    "View footnote.")])'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s another heatmap of the Chapter 3 text. Do you see anything interesting
    here?
  prefs: []
  type: TYPE_NORMAL
- en: '![ch3 heatmap](images/ch3-heatmap.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice the giant dark red cross (*gray* cross in print) spanning the entire
    chapter? This means the text in the middle of that cross is very different from
    all the other text in the chapter. Can you guess why? That section contains a
    sentence that starts with "Ernqnov…​", an encrypted line from the "Zen of Python"
    (`import this`). And the tiny white rectangle at that location shows that each
    line of that encrypted poem is very similar to the lines near it.
  prefs: []
  type: TYPE_NORMAL
- en: A semantic heatmap is one way to find structure in your text data, but if you
    want to create knowledge from text you will need to go further. Your next step
    is to use the vector representations of sentences to create a "graph" of connections
    between entities. Entities in the real world are related by facts. Our mental
    model of the world is a belief network or a *knowledge graph* — a newtwork of
    connections between all the things (entities) you know something about.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3 A knowledge extraction pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have your sentences organized you can start extracting concepts and
    relations from natural language text. For example, imagine a chatbot user says
    "Remind me to read AI Index on Monday."^([[13](#_footnotedef_13 "View footnote.")])
    You’d like that statement to trigger a calendar entry or alarm for the next Monday
    after the current date. Easier said than done.
  prefs: []
  type: TYPE_NORMAL
- en: 'To trigger correct actions with natural language you need something like an
    NLU pipeline or parser that is a little less fuzzy than a transformer or large
    language model. You need to know that "me" represents a particular kind of named
    entity: a person. Named entities are natural language terms or n-grams that refer
    to a particular thing in the real world, such as a person, place or thing. Sound
    familiar? In English grammar, the part of speech (POS) for a person, place or
    thing is "noun". So you’ll see that the POS tag that spaCy associates with the
    tokens for a named entity is "NOUN".'
  prefs: []
  type: TYPE_NORMAL
- en: And the chatbot should know that it can expand or *resolve* that word by replacing
    it with that person’s username or other identifying information. You’d also need
    your chatbot to recognize that "aiindex.org" is an abbreviated URL, which is a
    named entity - a name of a specific instance of something, like a website or company.
    And you need to know that a normalized spelling of this particular kind of named
    entity might be " [http://aiindex.org](.html) ", " [https://aiindex.org](.html)
    ", or maybe even " [https://www.aiindex.org](.html) ". Likewise, you need your
    chatbot to recognize that Monday is one of the days of the week (another kind
    of named entity called an "event") and be able to find it on the calendar.
  prefs: []
  type: TYPE_NORMAL
- en: For the chatbot to respond properly to that simple request, you also need it
    to extract the relation between the named entity "me" and the command "remind."
    You’d even need to recognize the implied subject of the sentence, "you", referring
    to the chatbot, another person named entity. And you need to teach the chatbot
    that reminders happen in the future, so it should find the soonest upcoming Monday
    to create the reminder.
  prefs: []
  type: TYPE_NORMAL
- en: And that’s just a simple use case. You can construct a graph from scratch using
    your own common sense knowledge or the domain knowledge that you want your AI
    to know about. But if you can extract knowledge from text you can build much larger
    knowledge graphs much quicker. Plus, you will need this algorithm to double-check
    any text generated by your language models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowledge extraction requires four main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 Four stages of knowledge extraction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![knowledge graph extraction drawio](images/knowledge-graph-extraction_drawio.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fortunately, the spaCy language models include the building blocks for knowledge
    extraction: named entity recognition, coreference resolution, and relation extraction.
    You only need to know how to combine the results of each of these steps to connect
    the pieces together. Let’s look at each stage separately by looking at an article
    about Timnit Gebru, a thought leader in AI ethics. We’ll continue using the spaCy
    nlp model we initialized in the previous section.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by downloading the Wikipedia article about Timnit Gebru.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Have you heard of Timnit Gebru before? She’s famous among people in your area
    of interest and she’s written several influential papers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: That’s a pretty interesting research paper title. It certainly seems like something
    her bosses would be interested in publishing. But you aren’t interested in reading
    all of Wikipedia to find interesting tidbits about Stochastic Parrots and AI ethics
    experts such as Timnit Gebru. An information extraction pipeline can automatically
    recognize interesting named entities (people, places, things, and even dates and
    times). And if you want to support her, your NLP pipeline will be able to recognize
    mentions of her hidden behind pronouns in X messages (tweets).
  prefs: []
  type: TYPE_NORMAL
- en: 11.4 Entity Recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step in extracting knowledge about some *thing* is to find the *things*
    that you want to know about. The most important things in natural language text
    are the names of people, places, and things. In linguistics named things are called
    "named entities." These are not just names - they might be things like dates,
    locations, and any piece of information that can be placed into your knowledge
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: As with sentences, you can go two ways about the task of Named Entity Recognition
    (NER) - using pattern-matching, and using the neural approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll discover that there are cases in which regular expressions are as precise,
    or even more precise, than neural networks. Here are some keystone bits of quantitative
    information that are worth the effort of "hand-crafted" regular expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: GPS locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s make a quick detour to learn how to extract such numerical data in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: '11.4.1 Pattern-based entity recognition: extracting GPS locations'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GPS locations are typical of the kinds of numerical data you’ll want to extract
    from text using regular expressions. GPS locations come in pairs of numerical
    values for latitude and longitude. They sometimes also include a third number
    for altitude or height above sea level, but you’ll ignore that for now. Let’s
    just extract decimal latitude/longitude pairs, expressed in degrees. This will
    work for many Google Maps URLs. Though URLs are not technically natural language,
    they are often part of unstructured text data, and you’d like to extract this
    bit of information, so your chatbot can know about places as well as things.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use your decimal number pattern from previous examples, but let’s be more
    restrictive and make sure the value is within the valid range for latitude (+/-
    90 deg) and longitude (+/- 180 deg). You can’t go any farther north than the North
    Pole (+90 deg) or farther south than the South Pole (-90 deg). And if you sail
    from Greenwich England 180 deg east (+180 deg longitude), you’ll reach the date
    line, where you’re also 180 deg west (-180 deg) from Greenwich.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.1 Regular expression for GPS coordinates
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Numerical data is pretty easy to extract, especially if the numbers are part
    of a machine-readable string. URLs and other machine-readable strings put numbers
    such as latitude and longitude in a predictable order, format, and units to make
    things easy for us.
  prefs: []
  type: TYPE_NORMAL
- en: However, if we want to extract people’s names, nationalities, places and other
    things that don’t have a standard format, things become much more complicated.
    We can of course account for all the names, locations, and organizations possible.
    But keeping such a collection up to date would be a tremendously laborious task.
    For this, we’ll need the neural approach.
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.2 Named entity recognition with spaCy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because NER is just a foundational task, you can imagine researchers have started
    trying to do it efficiently way before Neural Nets.
  prefs: []
  type: TYPE_NORMAL
- en: However, the neural networks gave a huge boost to how fast and accurate NER
    can be performed on a text. Note that recognizing and categorizing named entities
    is not as straightforward as you might think. One of the common challenges of
    NER is *segmentation*, or defining boundaries of the named entity (is "New York"
    one named entity or two separate ones?) Another, even trickier one, is categorizing
    the type of the entity. For example, the name Washington can be used to signify
    a person (such as the writer Washington Irving), a location (Washington DC), an
    organization (Washington Post) and even a sports team (as in "Washington won two
    games in the last season").
  prefs: []
  type: TYPE_NORMAL
- en: So you can see how the *context* of the entity - both the words that came before
    it and after it, potentially much later in the sentence - matters. That’s why
    the popular approaches to NER with neural networks include multi-level CNNs, and
    bi-directional transformers such as BERT, or bi-directional LSTMs. The last one,
    combined with a technique called Conditional Random Weights (CRF) is what spaCy
    uses in its named entity recognition module.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you don’t have to know how to build neural networks in order to extract
    the named entities from a text. The 'ents' attribute of a `doc` object that gets
    created once you run spaCy on a text contains a list of all those named entities.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The challenge of named entity recognition is closely related to a more basic
    problem - part-of-speech (POS) tagging. To recognize named entities in the sentence,
    you need to know which part of speech each word belongs to. In English grammar,
    the *part of speech* (POS) for a person, place or thing is "noun". And your named
    entity will often be a proper noun - a noun that refers to a *particular* person,
    place or thing in the real world. And the part of speech tag for relations is
    a *verb*. The verb tokens will be used to connect the named entities to each other
    as the edges in your knowledge graph.
  prefs: []
  type: TYPE_NORMAL
- en: Part-of-speech tagging is also crucial to the next stage in our pipeline - dependency
    parsing. To determine the relationships between different entities inside the
    sentence, we will need to recognize the verbs in our sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, spaCy already did that for you the moment you fed the text to it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Can you make sense of this? PUNCT, NOUN and VERB are pretty self-explanatory;
    and you can guess that PROPN stands for Proper Noun. But what about CCONJ? Luckily,
    you can let spaCy explain it to you.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Another tool spaCy gives you is the `tag_` property of each token. While the
    `pos_` tag gives you the part of speech or a particular token, the `tag_` gives
    you more information and details about the token. Let’s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Wow, this looks much more cryptic. You can vaguely intuit the connection between
    PROPN and NNP, but what is VBZ?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: That’s for sure much more information, albeit served in a more cryptical form.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s bring all the information about your tokens together in one table.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Now you have a function you can use to extract the tags you are interested in
    for any sentence or text (document). If you coerce a list of dictionaries into
    a DataFrame you will be able to see the sequence of tokens and tags side by side.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: You are already familiar with the 'POS' and 'TAG' labels for tokens. The fourth
    column 'ENT_TYPE', gives you information about the type of the named entity that
    token is a part of. Many named entities span several tokens, such as "Timnit Gebru"
    with spans two tokens. You can see that the small spaCy model didn’t do that well;
    it missed Timnit Gebru as a named entity at the beginning of the text. And when
    spaCy did finally recognize it towards the end of the Wikipedia article, it labeled
    its entity type as "organization."
  prefs: []
  type: TYPE_NORMAL
- en: A larger spaCy model should be able to improve your accuracy a little bit, especially
    for words that aren’t very common in the datasets used to train spaCy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This looks better! "Timnit Gebru" is now correctly classified as a `PERSON`,
    and "Wikimedia" is properly tagged as `ORG` (organization). So this will usually
    be the first algorithm in your knowledge extraction pipeline, the spaCy language
    model that tokenizes your text and tags each token with the linguistic features
    you need for knowledge extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Once you understand how a named entity recognizer works, you can expand the
    kinds of nouns and noun phrases you want to recognize and include them in your
    knowledge graph. This can help generalize your knowledge graph and create a more
    generally intelligent NLP pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: But you have yet to use the last column in your DataFrame of token tags, `DEP`
    (dependency). The `DEP` tag indicates the token’s role in the dependency tree.
    Before you move on to dependency parsing and relation extraction, you need to
    learn how to deal with step 2 of the knowledge extraction pipeline, coreference
    resolution.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5 Coreference Resolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you’re running NER on a text, and you obtain the list of entities that
    the model has recognized. On closer inspection, you realize over half of them
    are duplicates because they’re referring to the same terms! This is where *Coreference
    resolution* comes in handy because it identifies all the mentions of a noun in
    a sentence. This will consolidate mentions of the same *things* in your knowledge
    graph instead of creating redundant nodes and edges and potentially creating incorrect
    relations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can you see the coreferences to "Timnit Gebru" in this sentence about that
    paper and her bosses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As a human, you can understand that "Gebru", "she" and "her" all relate. But
    it’s trickier for a machine to recognize that, especially if "she" is mentioned
    before "Gebru" (a phenomenon called *cataphora*).
  prefs: []
  type: TYPE_NORMAL
- en: 'And that’s a relatively simple case! Consider this sentence: "The city councilmen
    refused the demonstrators a permit because they feared violence". Who does "they"
    in the sentence refer to? Our common sense tells us that it refers to the "city
    councilmen" and the answer seems to be easy for us, but this task of identifying
    mentions using common sense is surprisingly difficult for deep learning models.
    This task is called the Winograd schema challenge, or a "common-sense reasoning"
    or "common-sense inference" problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how NLP deals with this difficult NLP task. Deep problems call for
    deep learning!
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.1 Coreference resolution with spaCy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As of this writing NeuralCoref 4.0 was the fastest and most accurate entity
    resolver available in the open-source community. As the name suggests NeuralCoref
    uses a deep learning neural network (transformer) to resolve coreferences to named
    entities. SpaCy incorporated transformers and NeuralCoref into its "Universe"
    collection of pipelines and models. NeuralCoref uses the original spaCy pipelines
    for `POS` tagging, named entity recognition, and extracting *coreferences* (secondary
    mentions of entities) in the text. It then takes the words surrounding each mention
    of an entity and feeds them into a feed-forward neural network or transformer
    to compute a score estimating whether each pair of mentions refer to the same
    object (entity). Comparing these scores is how the network resolves what each
    mention refers to.
  prefs: []
  type: TYPE_NORMAL
- en: The `spacy-experimental` package includes coreference resolution algorithms
    within the `CoreferenceResolver` class, but to use NeuralCoref directly you will
    need to install and import the `coreferee` package. The original NeuralCoref is
    no longer actively maintained but spaCy has ported the algorithms to the `coreferee`
    package which works as a custom pipeline within spaCy. You will also need to download
    a transformer-based spaCy language model to use the `coreferee` pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Like other spacy language models, you must first download "en_core_web_trf"
    before you can `load` and run it. The `trf` suffix indicates that this language
    model is a recent addition to the spaCy toolbox that incorporates a *transformer*
    neural network into the pipeline. This is a very large language model, so you
    probably don’t want to run the `cli.download()` function any more than you need
    to.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: So this pipeline was able to find 2 *coreference chains* that link mentions
    of entities together. These two chains represent two distinct real-world objects,
    "Gebru" and "advice". The "Gebru" token at position 13 is linked to the three
    "she" pronouns at positions 16, 26 and 34\. The "advice" token is linked to the
    word "it" at position 56.
  prefs: []
  type: TYPE_NORMAL
- en: So now you have consolidated all the mentions of Gebru in this single sentence
    from Wikipedia, and you can use those coreferences to extract important relations
    and facts about her.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5.2 Entity name normalization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Closely related to coreference resolution is the issue of *normalization* of
    entities. The normalized representation of an entity is usually a string, even
    for numerical information such as dates. For example, the normalized ISO format
    for Timnit Gebru’s date of birth would be "1983-05-13". A normalized representation
    for entities enables your knowledge base to connect all the different things that
    happened in the world on that same date to that same node (entity) in your graph.
  prefs: []
  type: TYPE_NORMAL
- en: You’d do the same for other named entities. You’d correct the spelling of words
    and attempt to resolve ambiguities for names of objects, animals, people, places,
    and so on. For example, San Francisco may be referred to, in different places
    as "San Fran", "SF", "'Frisco" or "Fog City". Normalization of named entities
    ensures that spelling and naming variations don’t pollute your vocabulary of entity
    names with confounding, redundant names.
  prefs: []
  type: TYPE_NORMAL
- en: A knowledge graph should normalize each kind of entity the same way, to prevent
    multiple distinct entities of the same type from sharing the same "name." You
    don’t want multiple person name entries in your database referring to the same
    physical person. Even more importantly, the normalization should be applied consistently — both
    when you write new facts to the knowledge base or when you read or query the knowledge
    base.
  prefs: []
  type: TYPE_NORMAL
- en: If you decide to change the normalization approach after the database has been
    populated, the data for existing entities in the knowledge should be "migrated",
    or altered, to adhere to the new normalization scheme. Schemaless databases (key-value
    stores), like the ones used to store knowledge graphs or knowledge bases, are
    not free from the migration responsibilities of relational databases. After all,
    schemaless databases are interface wrappers for relational databases under the
    hood.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6 Dependency Parsing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you learned how to recognize and tag named entities
    in text. Now you’ll learn how to find relationships between these entities. A
    typical sentence may contain several named entities of various types, such as
    geographic entities, organizations, people, political entities, times (including
    dates), artifacts, events, and natural phenomena. And a sentence can contain several
    *relations*, too — facts about the relationship between the named entities in
    the sentence
  prefs: []
  type: TYPE_NORMAL
- en: 'NLP researchers have identified two separate problems or models that can be
    used to identify how the words in a sentence work together to create meaning:
    *dependency parsing* and *constituency parsing*. *Dependency parsing* will give
    your NLP pipelines the ability to diagram sentences like you learned to do in
    grammar school (elementary school). And these tree data structures give your model
    a representation of the logic and grammar of a sentence. This will help your applications
    and bots become a bit smarter about how they interpret sentences and act on them.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Constituency parsing* is another technique, and it’s concerned with identifying
    the *constituent subphrases* in a sentence. While dependency parsing deals with
    relationships between words, constituency parsing aims to parse a sentence into
    a series of constituents. These constituents can be, for example, a noun phrase
    ("My new computer") or a verb phrase ("has memory issues"). Its approach is more
    top-down, trying to iteratively break constituents into smaller units and relationships
    between them. Though constituency parsing can capture more syntactic information
    about the sentence, its results are slower to compute and more difficult to interpret.
    So we will focus on dependency parsing for now.'
  prefs: []
  type: TYPE_NORMAL
- en: But wait, you’re probably wondering why understanding relationships between
    entities and sentence diagrams are so important. After all, you’ve probably already
    forgotten how to create them yourself and have probably never used them in real
    life. But that’s only because you’ve internalized this model of the world. We
    need to create that understanding in bots so they can be used to do the same things
    you do without thinking, from simple tasks like grammar checking to complex virtual
    assistants.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, dependency parsing will help your NLP pipelines for all those applications
    mentioned in Chapter 1…​ better. Have you noticed how chatbots like GPT-3 often
    fall on their face when it comes to understanding simple sentences or having a
    substantive conversation? As soon as you start to ask them about the logic or
    reasoning of the words they are "saying" they stumble. Chatbot developers and
    conversation designers get around this limitation by using rule-based chatbots
    for substantive conversations like therapy and teaching. The open-ended neural
    network models like PalM and GPT-3 are only used when the user tries to talk about
    something that hasn’t yet been programmed into it. And the language models are
    trained with the objective of steering the conversation back to something that
    the bot knows about and has rules for.
  prefs: []
  type: TYPE_NORMAL
- en: Dependency parsing, as the name suggests, relies on "dependencies" between the
    words in a sentence to extract information. "Dependencies" between two words could
    refer to their grammatical, phrasal, or any custom relations. But in the context
    of dependency parse trees, we refer to the grammatical relationships between word
    pairs of the sentence, one of them acting as the "head" and the other one acting
    as the "dependent". There exists only one word in a sentence that is not dependent
    on any other word in the parse tree, and this word is called the "root" ("ROOT").
    The root is the starting point for the dependency tree just as the main root of
    a tree in the forest starts the growth of its trunk and branches (relations).
    There are 37 kinds of dependency relations that a word could have, and these relations
    are adapted from the *Universal Stanford Dependencies* system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The spaCy package knows how to recognize these relations between words and
    phrases, and even plot the dependency diagrams for you. Let’s try to do dependency
    parsing of a single sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the ROOT of the sentence is the verb "fired". This is because
    in our sentence, the word "fired" happens to be the main verb when you organize
    it into a Subject-Verb-Object triple. And the dependency (`DEP`) role that the
    word "Gebru" serves is as the "passive nominal subject" (`nsubjpass`). Is there
    a dependency between them "fired" and "Gebru" that you can use to create a relationship
    or fact in a knowledge graph? The `children` attribute gives you a list of all
    the words that depend on a particular token. These dependencies are the key to
    connecting tokens in a relationship to construct a fact.
  prefs: []
  type: TYPE_NORMAL
- en: So you will need to include the `children` attribute in your `token_dict` function
    if you want it to show you children of each token in a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: It may seem weird to you that the token "Gebru" doesn’t have any children (dependents)
    in this sentence. It’s the subject of the sentence, after all. The child-parent
    relationship of natural language grammar rules will be a little confusing at first,
    but you can use `displacy` and your `doc2df` function to help you develop a mental
    model for how words depend on each other.
  prefs: []
  type: TYPE_NORMAL
- en: Redefine the doc2df function to add the `children` attribute as a column so
    you can see if any other words in this sentence have dependents (children).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Looks like the sentence root (labeled `ROOT`) has the most children. "Fired"
    is the most important word in the sentence and all the other words depend on it.
    Every word in a dependency tree is connected to another word elsewhere in the
    sentence. To see this, you need to examine that long list of children in the sentence
    root, 'fired'.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The sentence root branches out to the word "Gebru" and several other words including
    "from." And the word "from" leads to "team", then to "her" and "AI". And "AI"
    leads to "Ethical." You can see that children modify their parents.
  prefs: []
  type: TYPE_NORMAL
- en: The `ROOT` of the dependency tree is the main verb of a sentence. This is where
    you will usually find tokens with the most children. Verbs become relationships
    in a knowledge graph and children become the objects of that relationship in the
    relationship tripple. The token "Gebru" is a child of the passive verb fired,
    so you know that she was the one being fired, but this sentence does not say who
    is responsible for firing her. Since you do not know the subject of the verb "fired"
    you cannot determine who deserves the "unethically" adverb that describes their
    actions.
  prefs: []
  type: TYPE_NORMAL
- en: Time for dependency diagrams to shine! We’ll use one of spaCy’s sub-libraries
    called `displacy`. It can generate a *scalable vector graphics* SVG string (or
    a complete HTML page), which can be viewed as an image in a browser. This visualization
    can help you find ways to use the tree to create tag patterns for relation extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.2 Visualize a dependency tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: When you open the file, you should see something like Figure [11.3](#figure-dependency-diagram).
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 Dependency diagram for a sentence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![dependency diagram](images/dependency_diagram.png)'
  prefs: []
  type: TYPE_IMG
- en: Before we explain the connection between dependency parsing and relation extraction,
    let’s briefly dive into another tool at our disposal - constituency parsing.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6.1 Constituency parsing with benepar
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Berkeley Neural Parser and Stanza have been the go-to options for the extraction
    of constituency relations in text. Let’s explore one of them, Berkeley Neural
    Parser.
  prefs: []
  type: TYPE_NORMAL
- en: This parser cannot be used on its own and requires either spaCy or NLTK to load
    it along with their existing models. You want to use spaCy as your tokenizer and
    dependency tree parse because it is continually improving.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.3 Download the necessary packages
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: After downloading the packages, we can test it out with a sample sentence. But
    we will be adding `benepar` to spaCy’s pipeline first.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Looks quite cryptic, right? In the example above, we generated a parsed string
    for the test sentence. The parse string includes various phrases and the POS tags
    of the tokens in the sentence. Some common tags you may notice in our parse string
    are NP ("Noun Phrase"), VP ("Verb Phrase"), S ("Sentence"), and PP ("Prepositional
    Phrase"). Now you can see how it’s a bit more difficult to extract information
    from the constituency parser’s output. However, it can be useful to identify all
    the phrases in the sentence and use them in sentence simplification and/or summarization.
  prefs: []
  type: TYPE_NORMAL
- en: You now know how to extract the syntactic structure of sentences. How will it
    help you in your quest for an intelligent chatbot?
  prefs: []
  type: TYPE_NORMAL
- en: 11.7 From dependency parsing to relation extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ve come to the crucial stage of helping our bot learn from what it reads.
    Take this sentence from Wikipedia:'
  prefs: []
  type: TYPE_NORMAL
- en: '*In 1983, Stanislav Petrov, a lieutenant colonel of the Soviet Air Defense
    Forces, saved the world from nuclear war.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you were to take notes in a history class after reading or hearing something
    like that, you’d probably paraphrase things and create connections in your brain
    between concepts or words. You might reduce it to a piece of knowledge, that thing
    that you "got out of it." You’d like your bot to do the same thing. You’d like
    it to "take note" of whatever it learns, such as the fact or knowledge that Stanislav
    Petrov was a lieutenant colonel. This could be stored in a data structure something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This is an example of two named entity nodes ('Stanislav Petrov' and 'lieutenant
    colonel') and a relation or connection ('is a') between them in a knowledge graph
    or knowledge base. When a relationship like this is stored in a form that complies
    with the RDF standard (resource description format) for knowledge graphs, it’s
    referred to as an RDF triplet. Historically these RDF triplets were stored in
    XML files, but they can be stored in any file format or database that can hold
    a graph of triplets in the form of `(subject, relation, object)`. A collection
    of these triplets will be your knowledge graph!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go ahead and create some fodder for your knowledge graph using the two
    approaches we know - patterns and machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.1 Pattern-based relation extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember how you used regular expressions to extract character patterns? Word
    patterns are just like regular expressions but for words instead of characters.
    Instead of character classes, you have word classes. For example, instead of matching
    a lowercase character, you might have a word pattern decision to match all the
    singular nouns ("NN" POS tag).^([[14](#_footnotedef_14 "View footnote.")]) Some
    seed sentences are tagged with some correct relationships (facts) extracted from
    those sentences. A POS pattern can be used to find similar sentences where the
    subject and object words might change or even the relationship words.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest way to extract relations out of the text is to look for all "Subject-Verb-Object"
    triplets using the "nsubj" and "dobj" tags of the ROOT word. But let’s do something
    a bit more complex. What if we want to extract information about meetings between
    historical figures from Wikipedia? You can use the spaCy package in two different
    ways to match these patterns in \(O(1)\) (constant time) no matter how many patterns
    you want to match:'
  prefs: []
  type: TYPE_NORMAL
- en: PhraseMatcher for any word/tag sequence patterns ^([[15](#_footnotedef_15 "View
    footnote.")])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matcher for POS tag sequence patterns ^([[16](#_footnotedef_16 "View footnote.")])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with the latter.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s look at an example sentence and see the POS for every word:'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.4 Helper functions for spaCy tagged strings
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can see the sequence of POS or TAG features that will make a good pattern.
    If you’re looking for "has-met" relationships between people and organizations,
    you’d probably like to allow patterns such as "PROPN met PROPN", "PROPN met the
    PROPN", "PROPN met with the PROPN", and "PROPN often meets with PROPN". You could
    specify each of those patterns individually, or try to capture them all with some
    * or ? operators on "any word" patterns between your proper nouns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Patterns in spaCy are a lot like this pseudocode, but much more powerful and
    flexible. SpaCy patterns are very similar to regular expressions for tokens. Like
    regular expressions, you have to be very verbose to explain exactly the word features
    you’d like to match at each position in the token sequence. In a spaCy pattern,
    you use a dictionary of lists to capture all the parts-of-speech and other features
    that you want to match for each token or word.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.5 Example spaCy POS pattern
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: You can then extract the tagged tokens you need from your parsed sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.6 Creating a POS pattern matcher with spaCy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: A spacy matcher will list the pattern matches as 3-tuples containing match ID
    integers, plus the start and stop token indices (positions) for each match. So
    you extracted a match from the original sentence from which you created the pattern,
    but what about similar sentences from Wikipedia?
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.7 Using a POS pattern matcher
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: You need to add a second pattern to allow for the verb to occur after the subject
    and object nouns.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.8 Combine patterns together to handle more variations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: So now you have your entities and a relationship. You can even build a pattern
    that is less restrictive about the verb in the middle ("met") and more restrictive
    about the names of the people and groups on either side. Doing so might allow
    you to identify additional verbs that imply that one person or group has met another,
    such as the verb "knows" or even passive phrases such as "had a conversation"
    or "became acquainted with". Then you could use these new verbs to add relationships
    for new proper nouns on either side.
  prefs: []
  type: TYPE_NORMAL
- en: But you can see how you’re drifting away from the original meaning of your seed
    relationship patterns. This is called semantic drift. To ensure that the new relations
    found in new sentences are truly analogous to the original seed (example) relationships,
    you often need to constrain the subject, relation, and object word meanings to
    be similar to those in the seed sentences. The best way to do this is with some
    vector representation of the meaning of words. Fortunately for you, spaCy tags
    words in a parsed document with not only their POS and dependency tree information
    but also provides the Word2Vec word vector. You can use this vector to prevent
    the connector verb and the proper nouns on either side from drifting too far away
    from the original meaning of your seed pattern.^([[17](#_footnotedef_17 "View
    footnote.")])
  prefs: []
  type: TYPE_NORMAL
- en: Using semantic vector representations for words and phrases has made automatic
    information extraction accurate enough to build large knowledge bases automatically.
    But human supervision and curation are required to resolve much of the ambiguity
    in natural language text.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7.2 Neural relation extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that you’ve seen the pattern-based method for relation extraction, you
    can imagine that researchers have already tried to do the same with a neural network.
    The neural relation extraction task is traditionally classified into two categories:
    closed and open.'
  prefs: []
  type: TYPE_NORMAL
- en: In *closed* relation extraction, the model extracts relations only from a given
    list of relation types. The advantages of this are that we can minimize the risk
    of getting untrue and bizarre relation labels between entities which makes us
    more confident about using them in real life. But the limitation is that it needs
    human labelers to come up with a list of relevant labels for every category of
    text, which as you can imagine, can get tedious and expensive.
  prefs: []
  type: TYPE_NORMAL
- en: In *open* relation extraction, the model tries to come up with its own set of
    probable labels for the named entities in the text. This is suitable for processing
    large and generally unknown texts like Wikipedia articles and news entries.
  prefs: []
  type: TYPE_NORMAL
- en: Over the past few years, experiments with Deep Neural Networks have given strong
    results on triplet extraction and subsequently, most of the research on the topic
    now follow neural methods.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there aren’t as many out-of-the-box solutions for relation extraction
    as there are for the previous stages of the pipeline. What’s more, your relation-extraction
    is usually going to be pretty targeted. In most cases, you wouldn’t want to extract
    ALL possible relations between entities, but only those that are relevant to the
    task you’re trying to perform. For example, you might want to extract interactions
    between drugs from a set of pharmaceutical documents.
  prefs: []
  type: TYPE_NORMAL
- en: One of the state-of-the-art models that is used nowadays to extract relations
    is LUKE (Language Understanding with Knowledge-based Embeddings). LUKE uses *entity-aware
    attention* - meaning that its training data included information on whether each
    token is an entity or not. It was also trained to be able to "guess" a masked
    entity in a Wikipedia-based dataset (rather than just guessing all masked words,
    like the BERT model was trained).
  prefs: []
  type: TYPE_NORMAL
- en: SpaCy also includes some infrastructure to create your own relation extraction
    component, but that requires quite a bit of work. We won’t cover it as part of
    this book. Fortunately, authors like Sofie Van Landeghem have created great resources
    ^([[18](#_footnotedef_18 "View footnote.")]) for you to learn from if you want
    to custom-train a relation extractor for your particular needs.
  prefs: []
  type: TYPE_NORMAL
- en: Training your relation extraction model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When training your relation extractor, you will need labeled data where the
    relations relative to your task are tagged properly in order for the model to
    learn to recognize them. But big datasets are hard to create and label, so it’s
    worth checking if some of the existing datasets used for benchmarking and finetuning
    state-of-the-art models already have the data that you need.
  prefs: []
  type: TYPE_NORMAL
- en: DocRED and Stanford TACRED together are the de-facto benchmark datasets and
    models for relation extraction methods because of their size and the generality
    of the knowledge graphs
  prefs: []
  type: TYPE_NORMAL
- en: Stanford’s Text Analysis Conference Relation Extraction Dataset (TACRED) contains
    more than 100,000 example natural language passages paired with their corresponding
    relations and entities. It covers 41 relation types. Over the past few years,
    researchers have improved TACRED’s data quality and reduced ambiguity in the relation
    classes with datasets such as Re-TACRED and DocRED.
  prefs: []
  type: TYPE_NORMAL
- en: The Document Relation Extraction Dataset (DocRED) expands the breadth of natural
    language text that can be used for relation extraction because it includes relations
    that require parsing of multiple sentences of natural language text. The training
    and validation dataset used to train DocRED is currently (in 2023) the largest
    human-annotated dataset for document-level relation extraction. Most of the human-annotated
    knowledge graph data in DocRED is included in the Wikidata knowledge base. And
    the corresponding natural language text examples can be found in the archived
    version of Wikipedia.
  prefs: []
  type: TYPE_NORMAL
- en: Now you have a better idea of how to take an unstructured text and turn it into
    a collection of facts. Time for the last stage of our pipeline - building a knowledge
    database.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8 Building your knowledge base
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, you have your relations extracted from your text. You could put them all
    into a big table; and yet, we keep talking about knowledge *graphs*. What really
    makes this particular way of structuring data so powerful?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go back to Stanislav Petrov, whom we’ve met in the last chapter. What
    if we wanted to answer a question like "What is Stanislav Petrov’s military rank?"
    This is a question that a single relation triple 'Stanislav Petrov', 'is-a', 'lieutenant
    colonel' isn’t enough to answer - because your question-answering machine also
    needs to know that "lieutenant colonel" is a military rank. However, if you organize
    your knowledge as a graph, answering the question becomes possible. Take a look
    at Figure [11.4](#figure-stanislav-knowledge-graph) to understand how it happens.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.4 Stanislav knowledge graph
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![Stanislav Knowledge Graph](images/Stanislav-Knowledge-Graph.png)'
  prefs: []
  type: TYPE_IMG
- en: The red edge and node in this knowledge graph represent a fact that could not
    be directly extracted from the statement about Stanislav. But this fact that "lieutenant
    colonel" is a military rank could be inferred from the fact that the title of
    a person who is a member of a military organization is a military rank. This logical
    operation of deriving facts from a knowledge graph is called knowledge graph *inference*.
    It can also be called querying a knowledge base, analogous to querying a relational
    database. A whole field called Knowledge Base Question Answering is focused on
    finding ways to answer questions like this (they are called "multi-hop questions")
    more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: For this particular inference or query about Stanislov’s military ranks, your
    knowledge graph would have to already contain facts about militaries and military
    ranks. It might even help if the knowledge base had facts about the titles of
    people and how people relate to occupations (jobs). Perhaps you can see now how
    a base of knowledge helps a machine understand more about a statement than it
    could without that knowledge. Without this base of knowledge, many of the facts
    in a simple statement like this will be "over the head" of your chatbot. You might
    even say that questions about occupational rank would be "above the pay grade"
    of a bot that only knew how to classify documents according to randomly allocated
    topics. (See Chapter 4 if you’ve forgotten about how random topic allocation can
    be.)
  prefs: []
  type: TYPE_NORMAL
- en: It may not be obvious how big a deal this is, but it is a *BIG* deal. If you’ve
    ever interacted with a chatbot that doesn’t understand "which way is up", literally,
    you’d understand. One of the most daunting challenges in AI research is the challenge
    of compiling and efficiently querying a knowledge graph of common sense knowledge.
    We take common-sense knowledge for granted in our everyday conversations.
  prefs: []
  type: TYPE_NORMAL
- en: Humans start acquiring much of their common sense knowledge even before they
    acquire language skills. We don’t spend our childhood writing about how a day
    begins with light and sleep usually follows sunset. And we don’t edit Wikipedia
    articles about how an empty belly should only be filled with food rather than
    dirt or rocks. This makes it hard for machines to find a corpus of common sense
    knowledge to read and learn from. No common-sense knowledge Wikipedia articles
    exist for your bot to do information extraction on. And some of that knowledge
    is instinct, hard-coded into our DNA.^([[19](#_footnotedef_19 "View footnote.")])
  prefs: []
  type: TYPE_NORMAL
- en: All kinds of factual relationships exist between things and people, such as
    "kind-of", "is-used-for", "has-a", "is-famous-for", "was-born", and "has-profession."
    NELL, the Carnegie Mellon Never Ending Language Learning bot is focused almost
    entirely on the task of extracting information about the `'kind-of'` relationship.
  prefs: []
  type: TYPE_NORMAL
- en: Most knowledge bases normalize the strings that define these relationships,
    so that "kind of" and "type of" would be assigned a normalized string or ID to
    represent that particular relation. And some knowledge bases also normalize the
    nouns representing the objects in a knowledge base, using coreference resolution
    that we described before. So the bigram "Stanislav Petrov" might be assigned a
    particular ID. Synonyms for "Stanislav Petrov", like "S. Petrov" and "Lt Col Petrov",
    would also be assigned to that same ID, if the NLP pipeline suspected they referred
    to the same person.
  prefs: []
  type: TYPE_NORMAL
- en: 11.8.1 A large knowledge graph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you’ve ever heard of a "mind map" they can give a pretty good mental model
    of what knowledge graphs are: connections between concepts in your mind. To give
    you a more concrete mental model of the concept of knowledge graphs you probably
    want to explore the oldest public knowledge graph on the web: NELL (Never Ending
    Language Learning) graph, created by the bot we met in the last section.'
  prefs: []
  type: TYPE_NORMAL
- en: The NLPiA2 Python package has several utilities for making the NELL knowledge
    graph a bit easier to wrap your head around. Later in the chapter, you’ll see
    the details about how these work so you can prettify whatever knowledge graph
    you are working with.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The entity names are very precise and well-defined within a hierarchy, like
    paths for a file or name-spaced variable names in Python. All of the entity and
    value names start with "concept:" so you can strip that from your name strings
    to make the data a bit easier to work with. To simplify things further, you can
    eliminate the namespacing hierarchy and focus on just the last name in the hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The `nlpia2.nell` module simplifies the names of things even further. This makes
    it easier to navigate the knowledge graph in a network diagram. Otherwise, the
    names of entities can fill up the width of the plot and crowd each other out.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: NELL scrapes text from Twitter, so the spelling and wording of facts can be
    quite varied. In NELL the names of entities, relations and objects have been normalized
    by lowercasing them and removing all punctuation like apostrophes and hyphens.
    Only proper names are allowed to retain their spaces, to help distinguish between
    names that contain spaces and those that are smashed together. However, in NELL,
    just as in Word2vec token identifiers, proper names are joined with underscore
    ("\_") characters.
  prefs: []
  type: TYPE_NORMAL
- en: Entity and relation names are like variable names in Python. You want to be
    able to query them like field names in a database, so they should not have ambiguous
    spellings. The original NELL dataset contains one row per triple (fact). Triples
    can be read like a terse, well-defined sentence. Knowledge triples describe a
    single isolated fact about the world. They give you one piece of information about
    an entity (object) in the world.
  prefs: []
  type: TYPE_NORMAL
- en: As a minimum, a knowledge triple consists of an entity, relation and value.
    The first element of a knowledge triple gives you the name of the entity that
    the fact is about. The second column, "relation," contains the relationship to
    some other quality (adjective) or object (noun) in the world called its value.
    A relation is usually a verb phrase that starts with or implies words like "is"
    or "has." The third column, "value," contains an identifier for some quality of
    that relation. The "value" is the object of the relationship and is a named entity
    just as the subject ("entity") of the triple is.
  prefs: []
  type: TYPE_NORMAL
- en: Because NELL crowdsources the curation of the knowledge base, you also have
    a probability or confidence value that you can use to make inferences on conflicting
    pieces of information. And NELL has 9 more columns of information about the fact.
    It lists all the alternative phrases that were used to reference a particular
    entity, relation or value. NELL also identifies the iteration (loop through Twitter)
    that the fact was created during. The last column provides the source of the data
    - a list of all the texts that created the fact.
  prefs: []
  type: TYPE_NORMAL
- en: NELL contains facts about more than 800 unique relations and more than 2 million
    entities. Because Twitter is mostly about people, places and businesses, it’s
    a good knowledge base to use to augment a common sense knowledge base. And it
    can be useful for doing fact-checking about famous people or businesses and places
    that are often the targets of misinformation campaigns. There’s even a "latitudelongitude"
    relation that you could use to verify any facts related to the location of things.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Now you have learned how facts can be organized into a knowledge graph. But
    what do we do when we need to use this knowledge - for example, for answering
    questions? That’s what we’ll be dealing with in the last section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 11.9 Finding answers in a knowledge graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that our facts are all organized in a graph database, how do we retrieve
    that knowledge? As with any database, graph databases have special query languages
    to pull information from them. Just as SQL and its different dialects are used
    to query relational databases, a whole family of languages such as SPARQL (SPARQL
    Protocol and RDF Query Language), Cypher, and AQL exist to query graph databases.
    In this book, we’ll focus on SPARQL, as it was adopted as a standard by the open-source
    communities. Other languages, such as Cypher or AQL, are used to query specific
    graph knowledge bases, such as Neo4j and ArangoDB.
  prefs: []
  type: TYPE_NORMAL
- en: 'As our knowledge base, we’ll use an even bigger knowledge graph than NELL:
    Wikidata, the knowledge database version of Wikipedia. It contains more than 100
    million data items (entities and relations) and is maintained by volunteer editors
    and bots, just like all the other Wikimedia projects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Wikidata, the relations between entities are called *properties*. There
    are more than 11,000 properties in Wikidata system, and each one has its "P-id",
    a unique identifier that is used to represent that property in queries. Similarly,
    every entity has its own unique "Q-id". You can easily retrieve the Q-id of any
    Wikipedia article by using Wikidata’s REST API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: You can confirm your findings by heading to ([http://www.wikidata.org/entity/Q59753117](entity.html))
    and finding there more properties of this entity, that link it to different entities.
    As you can see, this is a simple "GET" query that only works if we already have
    the entity’s name and want to find the Q-id (or vice-versa). For more complex
    queries, we will need to use SPARQL. Let’s write your first query then!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you want to find out who were Timnit Gebru’s co-authors on her notable
    paper about Stochastic Parrots. If you don’t remember the name of the paper exactly,
    you can actually find it with a simple query. For this, you’ll need a couple of
    property and entity IDs - for simplicity, we just list them in the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Important
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Don’t forget to double escape the curly braces in f-strings! And you cannot
    use a backslash as an escape character in f-strings. *WRONG*: f"\{" Instead you
    must double the curly braces. *RIGHT*: f"{{"'
  prefs: []
  type: TYPE_NORMAL
- en: And if you are familiar with the `jinja2` package, be careful mixing using Python
    f-strings to populate jinja2 templates, you would need four curly braces to create
    a literal double curly brace.
  prefs: []
  type: TYPE_NORMAL
- en: Cryptic at first sight, what this query means is "Find an entity A such that
    Timnit Gebru has A as notable work, and also A is an instance of an academic article".
    You can see how each relational condition is codified in SPARQL, with operand
    `wd:` preceding entity Q-ids and the operand `wdt:` preceding property P-ids.
    Each relation constraint has a form of "ENTITY has-property ENTITY".
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now use WIKIDATA’s SPARQL API to retrieve the results of our query. For
    this, we will use a dedicated `SPARQLWrapper` package that will simplify the process
    of querying for us. First, let’s set up our wrapper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Once that’s set, you can execute your query and examine the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This looks right! Now that you’ve got the Q-id of the article - you can retrieve
    its authors by using the ''author'' property of the article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: And here you have the answer to your question!
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of doing two queries, we could have achieved the same result by nesting
    our queries, within each other, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: SPARQL is a well-developed language whose functionality includes much more than
    just simple queries. Wikidata itself has a pretty good manual on SPARQL.^([[20](#_footnotedef_20
    "View footnote.")]) The deeper you dig into Wikidata using SPARQL the more uses
    you will find for it in your NLP applications. It is one of the only ways you
    can automatically evaluate the quality and correctness of the facts that your
    NLP pipeline asserts to your users.
  prefs: []
  type: TYPE_NORMAL
- en: 11.9.1 From questions to queries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So, you managed to find the answer to a pretty complex question in a knowledge
    database. That would have been pretty much impossible to do if your database was
    relational, or if all you had was unstructured text.
  prefs: []
  type: TYPE_NORMAL
- en: However, looking for the answer took us quite a lot of work and two SPARQL queries.
    How do you transform a natural-language question into a query in a structured
    language like SPARQL?
  prefs: []
  type: TYPE_NORMAL
- en: You already did this kind of transformation before, back in Chapter 9\. Translating
    human language into machine language is a bit harder than translating between
    human languages, but it’s still the same basic problem for a machine. And now
    you know that transformers are good at transforming (pun intended) one language
    into another. LLMs, being huge transformers, are especially good at it. Sachin
    Charma created a great example of constructing a knowledge graph using another
    graph database, ArangoDB. She used OpenAI’s models to enable natural language
    question answering on the database he created.^([[21](#_footnotedef_21 "View footnote.")])
  prefs: []
  type: TYPE_NORMAL
- en: 11.10 Test yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Give an example of a question that’s easier to answer with a graph database
    than with a relational database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert a `networkx` directed graph to an edge list in a Pandas DataFrame with
    two columns `source_node` and `target_node`. How long does it take to retrieve
    all the target_node IDs for a single source node? What about all the target_nodes
    for those new source nodes? How would you speed up the Pandas graph query with
    an index?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a Spacy Matcher that can more of Timnit Gebru’s places of work out of
    the Wikipedia articles about her. How many could you retrieve?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there anything a graph database can do that a relational database cannot?
    Can a relational database do anything that a graph database cannot?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a Large Language Model to generate a SPARQL wikidata query from natural
    language. Did it work correctly without you editing the code? Will it work for
    a query that requires five relationship (edge) traversals in your knowledge graph?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use `extractors.py` and `heatmaps.py` in `nlpia2.text_processing` to create
    a BERT similarity heatmap for sentences extracted from a long document of your
    own (perhaps a sequence of Mastodon microblog posts about NLP). Edit the `heatmaps.py`
    code to improve it so that you can focus on just the lines that are very similar.
    Hint: You can scale the cosine similarity values with a nonlinear function and
    reset the similarity values to zero using a threshold value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.11 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A knowledge graph can be built to store relationships between entities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can isolate and extract information from unstructured text using either
    rule-based methods (like regular expressions) or neural-based methods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part-of-speech tagging and dependency parsing allow you to extract relationships
    between entities mentioned in a sentence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Languages like SPARQL can help you find the information you need in a knowledge
    graph.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[[1]](#_footnoteref_1) Wikipedia article "Symbolic AI" ( [https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence](wiki.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[2]](#_footnoteref_2) See the web page titled "Natural Language Processing
    : TM-Town" ( [https://www.tm-town.com/natural-language-processing#golden_rules](www.tm-town.com.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[3]](#_footnoteref_3) "Rstr package on PyPi ( [https://pypi.org/project/rstr/](rstr.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[4]](#_footnoteref_4) See the web page titled "Python sentence segment at
    DuckDuckGo" ( [https://duckduckgo.com/?q=Python+sentence+segment&t=canonical&ia=qa](duckduckgo.com.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[5]](#_footnoteref_5) Manuscript source code on GitLab ( [https://gitlab.com/tangibleai/nlpia2/-/tree/main/src/nlpia2/data/manuscript/adoc](manuscript.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[6]](#_footnoteref_6) Each neuron in a single-layer neural net or perceptron,
    is mathematically equivalent to a logistic regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '[[7]](#_footnoteref_7) See the web page titled "Facts & Figures : spaCy Usage
    Documentation" ( [https://spacy.io/usage/facts-figures](usage.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[8]](#_footnoteref_8) See the web page titled "nltk.tokenize package — NLTK
    3.3 documentation" ( [http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt](api.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[9]](#_footnoteref_9) SpaCy is far and away the most accurate and efficient
    NLP parser we’ve found, and it is maintained and updated regularly by a brilliant,
    supercooperating team of NLP engineers at Explosion.ai in Europe ( [https://explosion.ai/about](explosion.ai.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[10]](#_footnoteref_10) The `heatmaps.py` module in the nlpia2 package on
    GitLab ( [https://gitlab.com/tangibleai/nlpia2/-/blob/main/src/nlpia2/heatmaps.py](nlpia2.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[11]](#_footnoteref_11) The `extractors.extract_lines()` function in the nlpia2
    package on GitLab ( [https://gitlab.com/tangibleai/nlpia2/-/blob/main/src/nlpia2/text_processing/extractors.py#L69](text_processing.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[12]](#_footnoteref_12) The official AsciiDoc parser is Ruby. No Python packages
    exist yet, according to the docs ( [https://gitlab.eclipse.org/eclipse-wg/asciidoc-wg/asciidoc.org/-/blob/main/awesome-asciidoc.adoc#convert](main.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[13]](#_footnoteref_13) Statistics about AI research at the AI Index by Stanford
    University ( [https://AIIndex.org](.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[14]](#_footnoteref_14) spaCy uses the "OntoNotes 5" POS tags: ( [https://spacy.io/api/annotation#pos-tagging](api.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[15]](#_footnoteref_15) See the web page titled "Code Examples : spaCy Usage
    Documentation" ( [https://spacy.io/usage/examples#phrase-matcher](usage.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[16]](#_footnoteref_16) See the web page titled "Matcher : spaCy API Documentation"
    ( [https://spacy.io/api/matcher](api.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[[17]](#_footnoteref_17) This is the subject of active research: [https://nlp.stanford.edu/pubs/structuredVS.pdf](pubs.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[[18]](#_footnoteref_18) "Implementing a custom trainable component for relation
    extraction": ( [https://explosion.ai/blog/relation-extraction](blog.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[19]](#_footnoteref_19) There are hard-coded common-sense knowledge bases
    out there for you to build on. Google Scholar is your friend in this knowledge
    graph search.'
  prefs: []
  type: TYPE_NORMAL
- en: '[[20]](#_footnoteref_20) Wikidata SPARQL tutorial: ( [https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial](wiki.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[[21]](#_footnoteref_21) How to Build Knowledge Graph Enhanced Chatbot with
    ChatGPT and ArangoDB ( [http://archive.today/fJB7H](archive.today.html)).'
  prefs: []
  type: TYPE_NORMAL
