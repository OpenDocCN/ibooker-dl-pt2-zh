- en: 2 Dataset management service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Understanding dataset management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using design principles to build a dataset management service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a sample dataset management service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using open source approaches to dataset management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After our general discussion of deep learning systems, we are ready for the
    rest of the chapters, which focus on specific components in those systems. We
    present dataset management first not only because deep learning projects are data-driven
    but also because we want to remind you how important it is to think about data
    management before building other services.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset management (DM) often gets overlooked in the deep learning model development
    process, whereas data processing and model training and serving attract the most
    attention. A common thought in data engineering is that good data processing pipelines,
    such as ETL (extract, transform, and load) pipelines, are all we need. But if
    you avoid managing your datasets as your project proceeds, your data collection
    and dataset consumption logic become more and more complicated, model performance
    improvement becomes difficult, and eventually, the entire project slows down.
    A good DM system can expedite model development by decoupling training data collection
    and consumption; it also enables model reproducibility by versioning the training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: We guarantee that you will appreciate your wise decision to build or at least
    set up a dataset management component in addition to your existing data processing
    pipelines. And build it before working on the training and serving components.
    Your deep learning project development will go faster and can produce better results
    and simpler models in the long run. Because the DM component shields the upstream
    data complexity from your model training code, your model algorithm development
    and data development can run parallel.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is about building dataset management functionality for your deep
    learning project. Because of the variety of deep learning algorithms, data pipelines,
    and data sources, dataset management is an often-discussed topic in the deep learning
    industry. There is no unified approach, and it seems there will never be one.
    To be beneficial to you in practice, therefore, we will focus on teaching the
    design principles instead of advocating one single approach. The sample dataset
    management service we build in this chapter demonstrates one possible way to implement
    these principles.
  prefs: []
  type: TYPE_NORMAL
- en: In section 2.1, you will learn why dataset management is needed, the challenges
    it should address, and the crucial role it plays in a deep learning system. We
    will also introduce its key design principles to prepare you for the concrete
    examples in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: In section 2.2, we will demonstrate a dataset management service based on the
    concepts and design principles introduced in section 2.1\. First, we will set
    up the service on your local machine and experiment with it. Second, we will discuss
    the internal dataset storage and data schema, user scenarios, data ingestion API,
    and dataset fetching API, as well as provide an overview of design and user scenarios.
    During the tour, we will also discuss the pros and cons of some important decisions
    we made in the service design.
  prefs: []
  type: TYPE_NORMAL
- en: In section 2.3, we will look at two open source approaches. If you don’t want
    a DIY dataset management service, you can use the components that are already
    built, available, and adaptable. For instance, you can use Delta Lake with Petastorm
    for dataset management if your existing data pipeline is built on top of Apache
    Spark. Or you can adopt Pachyderm if your data comes directly from a cloud object
    storage such as AWS Simple Storage Service (S3) or Azure Blob. We use image dataset
    preparation as an example to show how these two approaches can work with unstructured
    data in practice. By the end of this chapter, you will have a deep understanding
    of the intrinsic characteristics of dataset management and its design principles,
    so you can either build a dataset management service on your own or improve an
    existing system in your work.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Understanding dataset management service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A dataset management component or service is a specialized data store for organizing
    data in favor of model training and model performance troubleshooting. It processes
    raw data fed from upstream data sources and returns training data in a well-defined
    structure—a dataset—for use in model training. Figure 2.1 shows the core value
    a dataset management service delivers. In the figure, we see that a dataset management
    component converts the raw data into a consistent data format that favors model
    training, so downstream model training applications can just focus on algorithm
    development.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 A dataset management service is a specialized data store; it ingests
    data into its internal storage with its own raw data format. During training,
    it converts the raw data into training data in a consistent data format that favors
    model training.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 Why deep learning systems need dataset management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s take a moment to explain why DM is a crucial part of any deep learning
    system before we start looking at the sample dataset management service. This
    section is important because, from our experience, it is impossible to design
    a system that solves a real problem unless you fully understand the *why*.
  prefs: []
  type: TYPE_NORMAL
- en: There are two answers to the why question. First, DM can help to expedite model
    development by decoupling the *collection* of training data from the *consumption*
    of that data. Second, a well-designed DM service supports model reproducibility
    by having version tracking on training datasets. Let’s look at both of these points
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Decoupling the training data collection and consumption
  prefs: []
  type: TYPE_NORMAL
- en: 'If you work on a deep learning project completely by yourself, the project
    development workflow is an iterative loop of the following steps: data collection,
    dataset preprocess, training, and evaluation (see figure 2.2). Although you can
    break the downstream dataset preprocess code or training code if you change the
    data format in the data collection component, it’s not a big problem. Because
    you are the single code owner, you make free changes; no other people are affected.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 The workflow for a single-person deep learning project development
    is an iterative loop of linear steps.
  prefs: []
  type: TYPE_NORMAL
- en: When we are building a serious deep learning platform catering to tens of different
    deep learning projects and opening it to multiple people and teams, the simple
    data flow chart will dilate quickly to a bewildering 3D diagram (figure 2.3).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-03.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 Deep learning model development in enterprise runs in multidimensions.
    Multiple teams of people work together to ship a project in different phases.
    Each team focuses on one step of the workflow and also works on multiple projects
    in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.3 shows the complexity of an enterprise deep learning development
    environment. In this setting, each person only works on a single step instead
    of the entire workflow, and they develop their work for multiple projects. Ideally,
    this process is efficient because people build their expertise by focusing on
    one particular problem. But here is the catch: the communication cost is often
    ignored.'
  prefs: []
  type: TYPE_NORMAL
- en: When we divide the steps of a workflow (figure 2.2) between multiple teams,
    data schemas are needed for the handshake. Without a data contract, the downstream
    team doesn’t know how to read the data sent from the upstream team. Let’s go back
    to figure 2.3\. Imagine how many data schemas we need to communicate between teams
    if there are 10 projects developed by four teams in parallel, especially if every
    team handles different steps of the workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Now, if we want to add a new feature or attribute (such as text language) to
    a training dataset, we need to gather every team, obtain a consensus on the new
    data format, and implement the change. This is a huge effort because cross-team
    collaboration in corporations is complicated. It often takes months to make a
    small change; because each team has its own priority, you have to wait on its
    to-do list.
  prefs: []
  type: TYPE_NORMAL
- en: To make the situation worse, deep learning model development is an iterative
    process. It demands constantly tuning the training dataset (including the upstream
    data pipelines) to improve model accuracy. This requires data scientists, data
    developers, and platform developers to interact at a high frequency, but because
    of the cross-team workflow setting, the data iteration happens slowly, which is
    one of the reasons why model development is so slow in a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem is that when we have multiple types of projects (image, video,
    and text) developing in parallel, the number of data schemas will explode. If
    we let each team define new data schemas freely and don’t manage them properly,
    keeping the system backward compatible is almost impossible. The new data updates
    will become more and more difficult because we have to spend extra time to make
    sure the new data update doesn’t break the projects built in the past. As a consequence,
    the project development velocity will slow down significantly.
  prefs: []
  type: TYPE_NORMAL
- en: To address the slow iteration and data schema management problem, we can build
    a dataset management service. Let’s look at figure 2.4 to help determine the changes
    in the project development workflow after introducing the dataset management service.
  prefs: []
  type: TYPE_NORMAL
- en: 'In figure 2.4, we see a dataset management service that splits the model development
    workflow into two separate spaces: data developer space and data scientist space.
    The long iteration loop (figure 2.2) is now divided into two small loops (figure
    2.4), and each loop is owned by a single team, so the data developer and data
    scientist can iterate on data collection and model training separately; therefore,
    the deep learning project can iterate much faster.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-04.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 A dataset management component creates a good separation between
    training data collection and consumption by defining strongly typed schemas for
    both, which allows data development and model algorithm development to iterate
    in their own loop, thus expediting the project development.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may also notice that we now have all data schemas in one place: a dataset
    management service, which manages two strongly typed data schemas—the ingestion
    data schema and the training data schema—for each type of dataset. By having two
    separate data schemas for data ingestion and training while doing data transformation
    inside DM, you ensure that the data changes in the upstream data collection won’t
    break the downstream model training. Because the data schemas are strongly typed,
    future data upgrades can easily be made backward compatible.'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a strongly typed dataset may not be a good idea for projects in the
    beginning or experimental phase because we are still exploring all kinds of data
    options. Therefore, we also recommend defining a special schema-free dataset type,
    such as `GENERIC` type, which has no strong schema restriction. For data in this
    dataset type, DM just accepts the data as is and does not perform data validation
    and transformation (for a detailed example, see section 2.2.6). The data collected
    from the data processing pipeline can be consumed directly by the training process.
    Although the whole workflow would be fragile, a free dataset type addresses the
    need to be flexible for projects in the early phase. Once the project matures,
    we can create strongly typed schemas and define a dataset type for them.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize this section, managing two data schemas of a dataset type is the
    secret sauce that decouples data scientists and data developers. In section 2.2.6,
    we will show how these schemas can be implemented in our sample dataset management
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling model reproducibility
  prefs: []
  type: TYPE_NORMAL
- en: A well-designed dataset management service supports model reproducibility by
    having version tracking on training datasets—for example, using a version string
    to obtain the exact training files used in previous model training runs. The advantage
    of model reproducibility with respect to the data scientist (model algorithm development)
    is that you can repeatedly run a deep learning algorithm (such as the self-attention
    transformer in NLP) on a certain dataset and gain the same or similar quality
    of results. This is called *algorithm reproducibility*.
  prefs: []
  type: TYPE_NORMAL
- en: From the view of a deep learning system developer, model reproducibility is
    the superset of algorithm reproducibility. It requires the dataset management
    system to be able to reproduce its output artifacts (datasets). For example, we
    need to obtain the exact training data and training configuration to reproduce
    models that were trained in the past.
  prefs: []
  type: TYPE_NORMAL
- en: Model reproducibility is crucial to machine learning projects for two main reasons.
    The first is trust. Reproducibility creates trust and credibility for the system
    that produces the model. For any system, if the output can’t be reproduced, people
    simply won’t trust the system. This is extremely relevant to machine learning
    projects because applications will make decisions based on model output—for example,
    a chatbot will transfer a user call to proper service departments according to
    the user intent prediction. If we can’t reproduce a model, the applications built
    on top of the model are nondeterministic and untrustworthy.
  prefs: []
  type: TYPE_NORMAL
- en: The second reason is that model reproducibility facilitates performance troubleshooting.
    When detecting a model performance regression, people first want to find out what
    has changed in the training dataset and training algorithm code. If model reproducibility
    is not supported, performance troubleshooting will be very difficult.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 Dataset management design principles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We want to outline five design principles for DM before we start building one.
  prefs: []
  type: TYPE_NORMAL
- en: Note We consider these five principles to be the most important elements in
    this chapter. For data applications, the principles we follow in design are more
    important than the actual design. Because data could be anything in any form,
    there is no paradigm for data storage, in general, and there is no standard design
    that suits all kinds of data processing use cases. So, in practice, we build our
    own data application by following certain general principles. Therefore, these
    principles are critical.
  prefs: []
  type: TYPE_NORMAL
- en: The five principles here will give you clear design targets for building a new
    DM service or improving your existing DM service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 1: Support dataset reproducibility for reproducing models'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset reproducibility means that the DM always returns the same exact training
    examples it has returned in the past. For instance, when the training team starts
    training a model, the DM provides a dataset with a version string. Anytime the
    training team—or any other team—needs to retrieve the same training data, it can
    use this version string to query DM to retrieve the same training data.
  prefs: []
  type: TYPE_NORMAL
- en: We believe all DM systems should support dataset reproducibility. Even better
    would be to also offer data diff functionally, so we can see the data difference
    between two different dataset versions easily. This is very convenient for troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 2: Provide unified API across different types of datasets'
  prefs: []
  type: TYPE_NORMAL
- en: A dataset of deep learning might be structured (text, such as sales records
    or the transcript of a user conversation) or unstructured (image, voice recording
    file). No matter how a DM system processes and stores these different forms of
    data internally, it should provide a unified API interface for uploading and fetching
    different types of datasets. The API interface also abstracts away the data source
    from the data consumer; no matter what happens under the hood, such as data parsing
    changes and internal storage format changes, downstream consumers shouldn’t be
    affected.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, our users, both data scientists and data developers, only need to
    learn one API to work with all the different types of datasets. This makes the
    system simple and easy to use. Also, the code maintenance cost will be greatly
    reduced because we only expose one public API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 3: Adopt a strongly typed data schema'
  prefs: []
  type: TYPE_NORMAL
- en: A strongly typed data schema is the key to avoiding unexpected failures caused
    by data changes. With data schema enforcement, the DM service can guarantee that
    the raw data it ingests and the training data it produces are consistent with
    our specs.
  prefs: []
  type: TYPE_NORMAL
- en: The strongly typed data schema acts as a safety guard to ensure the downstream
    model training code does not get affected by the upstream data collection changes,
    and it also ensures backward compatibility for both upstream and downstream clients
    of DM. Without data schema protection, the dataset consumer—the downstream model
    training code—can easily be broken by upstream data changes.
  prefs: []
  type: TYPE_NORMAL
- en: Data schemas can be versioned as well, but this will add another layer of complexity
    to management. An additional option is to only have one schema per dataset. When
    introducing new data changes, make sure that the schema update is backward compatible.
    If a new data requirement requires a breaking change, create a new dataset type
    with a new schema instead of updating the existing one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 4: Ensure API consistency and handle scaling internally'
  prefs: []
  type: TYPE_NORMAL
- en: The current trend in the deep learning field is model architecture that keeps
    getting bigger as datasets continue to grow larger. For example, GPT-3 (a generative
    pretrained transformer language model for language understanding) uses more than
    250 TB of text materials with hundreds of billions of words; in Tesla, the autonomous
    driving model consumes an immense amount of data at the petabyte level. On the
    other hand, we still use small datasets (around 50 MB) for some easy tasks in
    narrow domains, such as customer support ticket classification. Dataset management
    systems should handle the data scaling challenges internally, and the API exposed
    to users (data developers and data scientists) should be consistent for both large-
    and small-sized datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Principle 5: Guarantee data persistency'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, datasets used for deep learning training should be stored immutably
    to reproduce training data and troubleshoot. Data removal should be soft deletions
    with only a few exceptions for hard deletions, such as deleting customer data
    permanently when a customer chooses to opt out of or cancel their account.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3 The paradoxical character of datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To close out our conceptual discussion on dataset management, we would like
    to clarify an ambiguous aspect of datasets. We have seen dozens of poorly designed
    dataset management systems fail on this point.
  prefs: []
  type: TYPE_NORMAL
- en: 'A dataset has a paradoxical trait: it is both dynamic and static. From a data
    scientist’s point of view, a dataset is static: it is a fixed set of files with
    annotations (also known as labels). From a data developer’s point of view, a dataset
    is dynamic: it is a file-saving destination in a remote storage to which we keep
    adding data.'
  prefs: []
  type: TYPE_NORMAL
- en: So, from a DM perspective, a dataset should be a logic file group and satisfy
    both data collection and data training needs. To help you get a concrete understanding
    of how to accommodate both the dynamic and static nature of datasets, let’s look
    at figure 2.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5 A dataset is a logic file group: it’s both dynamic and static, and
    it''s editable for data collection but fixed for model training.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can read figure 2.5 from two angles: data ingestion and data fetching. First,
    from the data ingestion side, we see that the data collection pipeline (from the
    left of the graph) keeps pumping in new data, such as text utterances and labels.
    For example, at time T0, an example data batch (example batch T0) is created in
    the dataset—the same for time T1, T2, and T3; we have a total of four data batches
    created over time. So, from the data developer’s view, this dataset is mutable,
    because the pipeline keeps adding data to it.'
  prefs: []
  type: TYPE_NORMAL
- en: Second, on the training data fetching side (from the top of the graph), we see
    that when fetching training data, the DM reads all the current data from the dataset
    at the same time point. We see that the data is returned as a static versioned
    snapshot, which has a version string to uniquely identify the actual data it picked
    from a dataset. For example, when we fetch training data from the dataset at time
    T2, the dataset has three data batches (batch T0, batch T1, and batch T2). We
    package these three data batches into a snapshot, assign a version string (“version1”),
    and return it as training data.
  prefs: []
  type: TYPE_NORMAL
- en: From a model training perspective, the dataset fetched from DM is a static snapshot
    of the dataset—a time-filtered plus customer logic-filtered dataset. The static
    snapshot is crucial to model reproducibility because it represents the exact training
    files used in a training run. When we need to rebuild the model, we can use the
    snapshot version string to find the snapshot that was used in the past model training.
  prefs: []
  type: TYPE_NORMAL
- en: Our theoretical introductions have been thoroughly covered, and you should be
    able to grasp the needs, goals, and unique characteristics of the dataset management
    component. The next section is a concrete example of how to design a dataset management
    service.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Touring a sample dataset management service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will walk you through a sample DM service. We built this
    sample to give you an idea of how the principles presented in section 2.1.2 can
    be implemented. We will first run the service locally, play with it, and then
    look at its API design and internal implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Playing with the sample service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To make this easy for you, we built seven shell scripts to automate the entire
    DM lab. These shell scripts are the recommended way to experience the demo scenarios
    in this section because they not only automate services’ local setup but also
    take care of setting the environment variables, preparing sample data, and initializing
    the local network.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find these scripts at [https://github.com/orca3/MiniAutoML/tree/main/scripts](https://github.com/orca3/MiniAutoML/tree/main/scripts),
    starting with the search: “dm”. The “function demo” doc in our GitHub repo ([https://github.com/orca3/MiniAutoML/tree/main/data-management](https://github.com/orca3/MiniAutoML/tree/main/data-management))
    provides detailed instructions for how to complete the lab and sample outputs
    of these scripts.'
  prefs: []
  type: TYPE_NORMAL
- en: Note Before running the function demo, the system requirement should be met
    first. Please refer to [https://github.com/orca3/MiniAutoML#system-requirements](https://github.com/orca3/MiniAutoML#system-requirements).
  prefs: []
  type: TYPE_NORMAL
- en: 'This lab consists of three sections: first, run the sample dataset management
    service; second, create a dataset and upload data to it; and third, fetch training
    data from the dataset just created.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up service locally
  prefs: []
  type: TYPE_NORMAL
- en: The sample service is written in Java 11\. It uses MinIO as the file blob server
    to mimic cloud object storage (such as Amazon S3), so we can run everything locally
    without any remote dependency. If you have set up the lab in appendix A, you can
    run the following commands (listing 2.1) in your terminal at the root of the scripts
    folder to start the service.
  prefs: []
  type: TYPE_NORMAL
- en: Note Starting with a clean setup is highly recommended before running DM demo
    scripts. You can execute `./scripts/lab-999-tear-down.sh` to clean up previous
    labs.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.1 Starting the service locally
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note To keep the service setup to a bare minimum, we maintain all the dataset
    records in memory to avoid using databases. Please be aware that you will lose
    all datasets if you restart the dataset management service.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and updating a language intent dataset
  prefs: []
  type: TYPE_NORMAL
- en: Our sample DM service offers three API methods for users to create/update a
    dataset and check the result. These API methods are `CreateDataset`, `UpdateDataset`,
    and `GetDatasetSummary`. We will discuss them in detail in the next few sections.
  prefs: []
  type: TYPE_NORMAL
- en: In this example scenario, first we call the `CreateDataset` API method on the
    data management service to create a new language intent dataset; then we use the
    `UpdateDataset` API method to append more data to the dataset. Finally, we use
    the `GetDatasetSummary` API method to obtain the dataset’s statistics and commit
    (data change) history.
  prefs: []
  type: TYPE_NORMAL
- en: Note The scripts dm-003-create-dataset.sh and dm-004-add-commits.sh automate
    the previous steps. Please use them to run the demo scenario. Please note that
    the following code listings are only for illustration purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s run the lab now. First, we’ll create a dataset using the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.2 Creating a language intent dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Uploads raw data (upload/001.csv) to cloud storage
  prefs: []
  type: TYPE_NORMAL
- en: ❷ gRPC request to create a dataset
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Dataset type
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Data URL of the raw data in MinIO, for example, upload/001.csv
  prefs: []
  type: TYPE_NORMAL
- en: ❺ API name
  prefs: []
  type: TYPE_NORMAL
- en: 'It should be noted that the `CreateDataset` API expects users to provide a
    downloadable URL in the gRPC request, not the actual data, which is why we first
    upload the 001.csv file to the local MinIO server. After the dataset is created,
    the `CreateDataset` API will return a JSON object that contains a data summary
    and commits the history of the dataset. See a sample result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Commits are the snapshot dataset updates.
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Commit ID; this commit captures the data from upload/001.csv.
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Commit tags are used to filter commits when building a training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Data summary of the commit
  prefs: []
  type: TYPE_NORMAL
- en: After creating a dataset, you can keep updating it by appending more data; see
    the dataset update gRPC request as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.3 Updating a language intent dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Uploads raw data (upload/002.csv) to cloud storage
  prefs: []
  type: TYPE_NORMAL
- en: ❷ A request to append more data (upload/002.csv)
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Replace the dataset ID with the value returned from the CreateDataset API.
  prefs: []
  type: TYPE_NORMAL
- en: ❹ The data URL of raw data, created by raw data upload
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Updates the dataset API name
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the dataset update completes, the `UpdateDataset` API returns a data summary
    JSON object in the same way as the `CreateDataset` API does; see a sample responsible
    object as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The commit created by the create dataset request
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Commit ID; this commit captures the data from upload/002.csv.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also fetch the data summary and commit history of a dataset by using
    the `GetDatasetSummary` API. See the following sample gRPC request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ❶ The ID of the dataset to query
  prefs: []
  type: TYPE_NORMAL
- en: Fetch training dataset
  prefs: []
  type: TYPE_NORMAL
- en: Now we have a dataset (ID = 1) created with raw data; let’s try to build a training
    dataset from it. In our sample service, it’s a two-step process.
  prefs: []
  type: TYPE_NORMAL
- en: We first call the `PrepareTrainingDataset` API to start the dataset-building
    process. And then we use the `FetchTrainingDataset` API to query the dataset preparation
    progress until the request completes.
  prefs: []
  type: TYPE_NORMAL
- en: Note Scripts dm-005-prepare-dataset.sh, dm-006-prepare-partial-dataset.sh, and
    dm-007-fetch-dataset-version.sh automate the steps that follow. Please try to
    use them to run the sample dataset fetching demo in code listings 2.4 and 2.5.
  prefs: []
  type: TYPE_NORMAL
- en: To use the `PrepareTrainingDataset` API, we only need to provide a dataset ID.
    If you just want a portion of data to be in the training dataset, you can use
    `tag` as a filter in the request. See a sample request as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.4 Preparing a training dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ❶ A request to prepare the training dataset with all data commits
  prefs: []
  type: TYPE_NORMAL
- en: ❷ A request to prepare the training dataset with partial data commits by defining
    filter tags
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Data filters
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the data preparation gRPC request succeeds, it returns a JSON object as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: ❶ ID of the training dataset snapshot
  prefs: []
  type: TYPE_NORMAL
- en: ❷ The selected data commits of the raw dataset
  prefs: []
  type: TYPE_NORMAL
- en: Among the data that the `PrepareTrainingDataset` API returns is the `"version_hash"`
    string. It is used to identify the data snapshot produced by the API. Using this
    hash as an ID, we can call the `FetchTrainingDatasetc` API to track the progress
    of building the training dataset; see the following example.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.5 Checking dataset prepare progress
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: ❶ ID of the training dataset snapshot
  prefs: []
  type: TYPE_NORMAL
- en: 'The `FetchTrainingDatasetc` API returns a JSON object that describes the training
    dataset. It tells us the status of the background dataset-building process: `RUNNING`,
    `READY`, or `FAILED`. If the training data is ready for consumption, the response
    object will display a list of downloadable URLs for the training data. In this
    demo, the URLs point to the local MinIO server. See a sample response as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Status of the training dataset
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Data URLs of the training data
  prefs: []
  type: TYPE_NORMAL
- en: Good job! You just experienced all the major data APIs offered by our sample
    dataset management service. By trying to upload data and build training datasets
    by yourself, we hope you have gained a feeling for how this service can be used.
    In the next few sections, we will look at user scenarios, service architecture
    overview, and code implementation of our sample dataset management services.
  prefs: []
  type: TYPE_NORMAL
- en: Note If you encounter any problems when running the mentioned scripts, please
    refer to the instructions in the “function demo” doc of our GitHub repo. Also,
    if you want to try the labs in chapters 3 and 4, please keep the containers running
    because they are the prerequisites for the model training labs.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Users, user scenarios, and the big picture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When designing backend services, the method we found very useful is thinking
    from the outside in. First, figure out who the users are, what value the service
    will provide, and how customers will interact with the service. Then the inner
    logic and storage layout should come naturally to you. For touring this sample
    DM service, we will show you using the same approach. So let’s look at our users
    and user scenario first.
  prefs: []
  type: TYPE_NORMAL
- en: Note The reason we look at the use cases first is that we believe any system
    design should consider the user the most. Our approach to efficiency and scalability
    will come up naturally if we identify how customers use the system. If the design
    is taken in the reverse order (consider technology first and usability second),
    the system often is clumsy to use because it’s designed for technology and not
    for customers.
  prefs: []
  type: TYPE_NORMAL
- en: Users and user scenarios
  prefs: []
  type: TYPE_NORMAL
- en: 'Our sample DM service is built for two fictional users: Jianguo, a data engineer,
    and Julia, a data scientist. They work together to train a language-intent classification
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: Jianguo works on training data collection. He continuously collects data from
    different data sources (such as parsing user activity logs and conducting customer
    surveys) and labels them. Jianguo uses a DM data ingestion API to create datasets,
    append new data to existing datasets, and query datasets’ summary and status.
  prefs: []
  type: TYPE_NORMAL
- en: Julia uses the dataset built by Jianguo to train intent classification models
    (usually written in PyTorch or Tensorflow). At the training time, Julia’s training
    code will first call the DM service’s fetch training data API to get the training
    dataset from the DM and then start the training process.
  prefs: []
  type: TYPE_NORMAL
- en: The service’s overall architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Our sample DM service is built in three layers: the data ingestion layer, dataset
    fetching layer, and dataset internal storage layer. The data ingestion API set
    is built so that Jianguo can upload new training data and query dataset status.
    The dataset fetching API is built so that Julia can obtain the training dataset.
    See figures 2.6 and 2.7 for the whole picture.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-06.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 System overview of the sample dataset management service. The sample
    service contains three main components, a data ingestion API, internal storage,
    and a dataset fetching API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The central big box in figure 2.6 shows the overall design of our sample dataset
    management service. It has an internal dataset storage system and two public-facing
    interfaces: a data ingestion API and a dataset fetching API—one for data ingestion
    and another for dataset fetching. The system supports both strongly typed schema
    datasets (text and image types) and nonschema datasets (`GENERIC` type).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-07.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 The internal storage structure for storing a dataset
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 displays the overall data structure the sample DM service uses to
    store a dataset. The commits are created by the data ingestion API, and versioned
    snapshots are created by the data fetching API. The concepts of commit and versioned
    snapshot are introduced to address the dynamic and static nature of a dataset.
    We will discuss storage in detail in section 2.2.5.
  prefs: []
  type: TYPE_NORMAL
- en: In the remaining subsections, we will walk you through every detail of the previous
    two diagrams, component by component. We first start with the API and then move
    to the internal storage and data schema.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3 Data ingestion API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data ingestion API allows creating, updating, and querying datasets in the
    sample dataset management service. The gray box in figure 2.8 shows the definition
    of four service methods in the data ingestion layer that support ingesting data
    into DM. Their names are self-explanatory; let’s look at their gRPC method definition
    in listing 2.6.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8 Four methods to support data ingestion: create the dataset, update
    the dataset, get the dataset summary, and list the datasets'
  prefs: []
  type: TYPE_NORMAL
- en: Note To reduce boilerplate code, we chose gRPC to implement the public interface
    for our sample DM service. This doesn’t mean gRPC is the best approach for a dataset
    management service, but compared to the RESTful interface, gRPC’s concise coding
    style is perfect for demonstrating our idea without exposing you to unnecessary
    Spring Framework details.
  prefs: []
  type: TYPE_NORMAL
- en: Definition of data ingestion methods
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at what our sample data ingestion API looks like.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.6 Data ingestion API service definition
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Defines dataset type, "TEXT_INTENT" or "GENERIC"
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Defines the file URL of the uploading data in MinIO server
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Sets data filter by using tags
  prefs: []
  type: TYPE_NORMAL
- en: Note The topic of data deletion and modification is not covered in this sample
    service, but the service can be easily extended to support them.
  prefs: []
  type: TYPE_NORMAL
- en: Data URL vs. data streaming
  prefs: []
  type: TYPE_NORMAL
- en: 'You may notice in our API design that we require users to provide data URLs
    as raw data input instead of uploading files directly to our service. In section
    2.2.4, we also choose to return data URLs as a training dataset instead of returning
    files directly via a streaming endpoint. The main reason is that we want to offload
    the file-transferring work to a cloud object storage service, such as Amazon S3
    or Azure Blob. Doing this has two benefits: first, it saves network bandwidth
    because there are no actual files passed between client and service, and second,
    it reduces code complexity because keeping data streaming working with high availability
    can be complicated when files are large and API usage is high.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new dataset
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at how the gRPC `CreateDataset` method is implemented. Before calling
    the DM (c`reateDataset` API) to create a dataset, the user (Jianguo) needs to
    prepare a downloadable URL for the data they want to upload (steps 1 and 2); the
    URL can be a downloadable link in a cloud object storage service, like Amazon
    S3 or Azure Blob. In our sample service, we use the MinIO server to run on your
    local to mock Amazon S3\. Jianguo also can name the dataset and assign tags in
    the dataset creation request. Listing 2.7 highlights the key pieces of code (`dataManagement/DataManagementService
    .java`) that implement the workflow pictured in figure 2.9.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.7 New dataset creation implementation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Receives dataset creation request (step 3)
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Creates a dataset object with metadata from user request (step 4a)
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Downloads data from URL and uploads it to DM’s cloud storage (step 4b)
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Saves the dataset with downloaded data as the initial commit (step 5)
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Returns the dataset summary to the client (steps 6 and 7)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9 A high-level overview of the seven steps to creating a new dataset:
    (1) upload data to the cloud object storage; (2) get a data link; (3) call `createDataset`
    API with a data link as the payload; (4) DM first downloads data from the data
    link and then finds the right dataset transformer (`IntentTextTransformer``)`
    to do data parsing and conversion; (5) DM saves the transformed data; and (6 and
    7) DM returns the dataset summary (ID, commit history, data statistics) to the
    user.'
  prefs: []
  type: TYPE_NORMAL
- en: The implementation details of `DatasetIngestion.ingest()` will be discussed
    in section 2.2.5.
  prefs: []
  type: TYPE_NORMAL
- en: Updating an existing dataset
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning model development is a continuous process. Once we create a dataset
    for a model training project, data engineers (like Jianguo) will keep adding data
    to it. To accommodate this need, we provide the `UpdateDataset` API.
  prefs: []
  type: TYPE_NORMAL
- en: To use the `UpdateDataset` API, we need to prepare a data URL for the new data.
    We can also pass in a commit message and some customer tags to describe the data
    change; these metadata are useful for data history tracking and data filtering.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset update workflow is almost identical to the dataset creation workflow
    (figure 2.9). It creates a new commit with the given data and appends the commit
    to the dataset’s commit list. The only difference is that the dataset update workflow
    won’t create a new dataset but will work on an existing dataset. See the following
    code listing.
  prefs: []
  type: TYPE_NORMAL
- en: Note Because every dataset update is saved as a commit, we could easily remove
    or soft delete those commits with some dataset management API if Jianguo mistakenly
    uploads some mislabeled data to a dataset. Because of space limitations, these
    management APIs are not discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.8 Dataset update implementation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Receives dataset creation request (step 3)
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Finds the existing dataset and creates a new commit object (step 4a)
  prefs: []
  type: TYPE_NORMAL
- en: We will talk more about the concept of commits in section 2.2.3\. For now, you
    just need to be aware that every dataset update request creates a new commit object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note Why save data updates in commits? Can we merge the new data with the current
    data so we only store the latest state? In our update dataset implementation,
    we create a new commit every time the `UpdateDataset` API is called. There are
    two reasons we want to avoid an in-place data merge: first, an in-place data merge
    can cause irreversible data modification and silent data loss. Second, to reproduce
    the training dataset used in the past, we need to make sure the data batches DM
    receives are stored immutably because they are the source data we used to create
    the training dataset at any time.'
  prefs: []
  type: TYPE_NORMAL
- en: List datasets and get datasets summary
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides `CreateDataset` and `UpdateDataset` API, our users need methods to
    list existing datasets and query the overview of a dataset, such as the number
    of a dataset’s examples and labels and its audit history. To accommodate these
    needs, we build two APIs: `ListDatasets` and `GetDatasetSummary`. The first one
    can list all the existing datasets, and the second one provides detailed information
    about a dataset, such as commit history, example and label count, and dataset
    ID and type. The implementation for these two APIs is straightforward; you can
    find them in our Git repo (`miniAutoML/DataManagementService.java)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.4 Training dataset fetching API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will look at the dataset fetching layer, which is highlighted
    as a gray box in figure 2.10\. To build training data, we designed two APIs. The
    data scientist (Julia) first calls the `PrepareTrainingDataset` API to issue a
    training data preparation request; our DM service will kick off a background thread
    to start building the training data and return a version string as a reference
    handle for the training data. Next, Julia can call the `FetchTrainingDataset`
    API to obtain the training data if the background thread is completed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10 Two methods in the dataset fetching layer to support dataset fetching:
    `PrepareTrainingDataset` and `FetchTrainingDataset`'
  prefs: []
  type: TYPE_NORMAL
- en: Definition of dataset fetching methods
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s see the gRPC service method definition (`grpc-contract/src/main/proto/`
    `data_management.proto)` for the two dataset fetching methods—`PrepareTrainingDataset`
    and `FetchTrainingDataset`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.9 Training dataset fetching service definition
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Prepares training dataset API
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Fetches training dataset API
  prefs: []
  type: TYPE_NORMAL
- en: ❸ The payload of dataset preparation API
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Specifies which dataset to build training data
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Specifies which commit of a dataset to build training data, optional
  prefs: []
  type: TYPE_NORMAL
- en: ❻ Filters data by commit tags, optional
  prefs: []
  type: TYPE_NORMAL
- en: ❼ The payload of the training dataset fetch API
  prefs: []
  type: TYPE_NORMAL
- en: ❽ Version hash string represents the training dataset snapshot.
  prefs: []
  type: TYPE_NORMAL
- en: Why we need two APIs (two steps) to fetch a dataset
  prefs: []
  type: TYPE_NORMAL
- en: If we only publish one API for acquiring training data, the caller needs to
    wait on the API call until the backend data preparation completes to obtain the
    final training data. If the data preparation takes a long time, this request will
    time out.
  prefs: []
  type: TYPE_NORMAL
- en: A deep learning dataset is normally big (at the gigabyte level); it can take
    minutes or hours to complete the network I/O data transfer and local data aggregation.
    So the common solution to acquiring large data is to offer two APIs—one for submitting
    data preparation requests and another for querying the data status—and pull down
    the result when the request is complete. In this way, the dataset fetching API
    performs consistently regardless of the size of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Sending the prepare training dataset request
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look at the code workflow of the `PrepareTrainingDataset` API. Figure
    2.11 shows how our sample service handles Julia’s preparation training dataset
    request.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11 A high-level overview of the eight steps to responding to a dataset
    build request: (1) the user submits a dataset preparation request with data filters;
    (2) DM selects data from commits that satisfy the data filters; (3 and 4) DM generates
    a version string to represent the training data; and (5–8) DM starts a background
    job to produce the training data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When DM receives a dataset preparation request (figure 2.11, step 1), it carries
    out three acts:'
  prefs: []
  type: TYPE_NORMAL
- en: Tries to find the dataset in its storage with the given dataset ID.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applies the given data filter to select commits from the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates a `versionedSnapshot` object to track training data in its internal
    storage (`versionHashRegistry)`. The ID of the `versionedSnapshot` object is a
    hash string generated from the selected commits’ ID list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `versionedSnapshot` object is the training dataset Julia wants; it is a
    group of immutable static files from the selected commits. Julia could use the
    hash string (snapshot ID) returned at step 3 to query the dataset preparation
    status and get the data-downloadable URL when the training dataset is ready. With
    this version string, Julia can always obtain the same training data (`versionedSnapshot`)
    from any time in the future, which is how dataset reproducibility is supported.
  prefs: []
  type: TYPE_NORMAL
- en: A side benefit of `versionedSnapshot` is that it can be used as a cache across
    different `PrepareTrainingDataset` API calls. If the snapshot ID—a hash string
    of a list of commits—already exists, we return the existing `versionedSnapshot`
    without rebuilding the same data, which can save computation time and network
    bandwidth.
  prefs: []
  type: TYPE_NORMAL
- en: Note In our design, the data filtering happens at the commit level, not at the
    individual example level; for example, having a filter tag `"DataType=Training"`
    in the preparation request indicates that the user only wants data from the commits
    that are labeled `"DataType=Training"`.
  prefs: []
  type: TYPE_NORMAL
- en: After step 3, DM will spawn a background thread to build the training dataset.
    In the background job, DM will download the files of each dataset commit from
    the MinIO server to the local, aggregate and compress them into one file in a
    predefined format, and upload them back to the MinIO server in a different bucket
    (steps 6 and 7). Next, DM will put the data URL of the actual training data in
    the `versionedSnapshot` object and update its status to `"READY"` (step 8). Now
    Julia can find the data URLs from the returned `versionedSnapshot` object and
    start to download the training data.
  prefs: []
  type: TYPE_NORMAL
- en: What we haven’t covered is the data schema. In the dataset management service,
    we save the ingested data (`commit`) and the generated training data (`versionedSnapshot`)
    in two different data formats. A data merge operation (figure 2.11, steps 6 and
    7) aggregates the raw ingested data (the selected commits) and converts it into
    training data in an intent classification training data schema. We will discuss
    data schemas in detail in section 2.2.6\. Listing 2.10 highlights the code implemented
    for figure 2.11.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.10 Preparing training data request API
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Creates VersionedSnapshot object to represent the training dataset
  prefs: []
  type: TYPE_NORMAL
- en: Fetching the training dataset
  prefs: []
  type: TYPE_NORMAL
- en: Once the DM service receives a training dataset preparation request on the `prepareTrainingDataset`
    API, it will spawn a background job to build the training data and return a `version_hash`
    string for tracking purposes. Julia can use the `FetchTrainingDataset` API and
    the `version_hash` string to query the dataset-building progress and eventually
    get the training dataset. Figure 2.12 shows how dataset fetching requests are
    handled in DM.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12 A high-level overview of the three steps to serving a dataset fetching
    request: (1) the user calls the `FetchTrainingDataset` API with a dataset ID and
    a version string; (2) DM will search the `versionHashRegistry` of the dataset
    in its internal storage and return a `versionedSnapshot` object; and (3) the `versionedSnapshot`
    object will have a download URL when the data preparation job is completed.'
  prefs: []
  type: TYPE_NORMAL
- en: The fetch training dataset is essentially querying the training data preparation
    request status. For each dataset, the DM service creates a `versionedSnapshot`
    object to track each training dataset produced by the `prepareTrainingDataset`
    request.
  prefs: []
  type: TYPE_NORMAL
- en: When a user sends a fetch dataset query, we simply use the hash string in the
    request to search its corresponding `versionedSnapshot` object in the dataset’s
    training snapshots (`versionHashRegistry`) and return it to the user if it exists.
    The `versionedSnapshot` object will keep being updated by the background training
    data process job (figure 2.11, steps 5–8). When the job completes, it will write
    the training data URL to the `versionedSnapshot` object; therefore, the user gets
    the training data at the end. See the code implementation in the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.11 Preparing the training data request API
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Searches versionedSnapshot in a dataset’s training snapshots
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Returns versionedSnapshot; it contains the latest progress of dataset preparation.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.5 Internal dataset storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The internal storage of the sample service is simply a list of in-memory dataset
    objects. Earlier we talked about how a dataset can be both dynamic and static.
    On one hand, a dataset is a logical file group, changing dynamically as it continuously
    absorbs new data from a variety of sources. On the other hand, it’s static and
    reproducible for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'To showcase this concept, we design each dataset containing a list of commits
    and a list of versioned snapshots. A commit represents the dynamically ingested
    data: data added by a data ingestion call (`CreateDataset` or `UpdateDataset`);
    a commit also has tags and messages for annotation purposes. A versioned snapshot
    represents the static training data, which, produced by the prepare training dataset
    request (`PrepareTrainingDataset`), is converted from a list of selected commits.
    Each snapshot is associated with a version; once the training dataset is built,
    you can use this version string to fetch the corresponding training data (`FetchTrainingDataset`)
    at any time to reuse. Figure 2.13 visualizes the internal storage structure of
    a dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.13 An internal dataset storage overview. A dataset stores two types
    of data: commits for the ingested raw data and versioned snapshots for the training
    dataset. The dataset metadata and data URLs are stored in the dataset management
    service, and the actual data is stored in the cloud object storage service.'
  prefs: []
  type: TYPE_NORMAL
- en: Note Although the individual training examples of different types of datasets
    can be in different forms, such as images, audios, and text sentences, the dataset’s
    operations (creating, updating, and querying dataset summary) and its dynamic/static
    characters are the same. Because we designed a unified API set across all dataset
    types, we can use one uniformed storage structure to store all different kinds
    of datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In our storage, the actual files (commit data, snapshot data) are stored in
    cloud object storage (such as Amazon S3), and we only keep dataset metadata (see
    explanation later) in our DM system. By offloading file storage work and only
    tracking the file links, we can focus on organizing the datasets and tracking
    their metadata, such as edit history, data statistics, training snapshots, and
    ownership.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset metadata
  prefs: []
  type: TYPE_NORMAL
- en: We define dataset metadata as everything except actual data files, such as the
    dataset ID, data owner, change history (audits), training snapshots, commits,
    data statistics, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: For demonstration purposes, we store the datasets’ metadata in a memory dictionary
    with the ID as key and put all data files into the MinIO server. But you can extend
    it to use a database or NoSQL database to store the dataset’s metadata.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have talked about dataset storage concepts, but how do the actual
    dataset writing and reading work? How do we serialize commits and snapshots for
    different dataset types, such as `GENERIC` and `TEXT_INTENT` types?
  prefs: []
  type: TYPE_NORMAL
- en: 'In the storage backend implementation, we use a simple inheritance concept
    to handle file operations for different dataset types. We define a `DatasetTransformer`
    interface as follows: the `ingest()` function saves input data into internal storage
    as a commit, and the `compress()` function merges data from selected commits into
    a version snapshot (training data).'
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, for the `"TEXT_INTENT"` type dataset, we have `IntentTextTransformer`
    to apply the strong type of file schema on file conversion. For a `"GENERIC"`
    type dataset, we have `GenericTransformer` to save data in the original format
    without any checks or format conversions. Figure 2.14 illustrates these.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 Implement `DatasetTransformer` interface to handle different dataset
    types; implement ingest function to save raw input data as commit; and implement
    compress function to aggregate commit data to training data.
  prefs: []
  type: TYPE_NORMAL
- en: From figure 2.14, we see that the raw intent classification data from data ingestion
    API (section 2.2.3) is saved as a commit by `IntentTextTransformer:Ingest()`;
    the intent classification training data produced by training dataset fetching
    API (section 2.2.4) is saved as a versioned snapshot by `IntentTextTransformer:Compress()`.
    Because they are plain Java code, we leave it for your own discovery; you can
    find the implementation code at our Git repo (org/orca3/miniAutoML/dataManagement/
    transformers/IntentTextTransformer.java).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.6 Data schemas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So far, we have seen all the APIs, workflows, and internal storage structures.
    Now let’s consider what the data looks like in the DM service. For each kind of
    strongly typed dataset, such as a “`TEXT_INTENT`” dataset, we defined two data
    schemas: one for data ingestion and one for training data fetching (figure 2.15).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.15 Each type of dataset has two data schemas: ingestion data schema
    and training data schema. These two schemas will ensure that the data we accept
    and the data we produce follow our data spec.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 shows how the DM service uses two data schemas to implement its
    data contract. Step 1 uses the ingestion data schema to validate the raw input
    data; step 2 uses the training data schema to convert the raw data to the training
    data format; step 3 saves the converted data as a commit; and step 4 merges the
    selected commits into one versioned snapshot when building a training dataset
    but still obeys the training data schema.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two different data schemas are the data contract that DM service provides
    to our two different users: Jianguo and Julia. No matter how Jianguo collects
    the data, it needs to be converted to the ingestion data format to insert into
    DM. Alternatively, because DM guarantees that the output training data follows
    the training data schema, Julia feels comfortable consuming the dataset without
    worrying about being affected by the data collection changes made by Jianguo.'
  prefs: []
  type: TYPE_NORMAL
- en: A data ingestion schema
  prefs: []
  type: TYPE_NORMAL
- en: 'We have seen the data schema concept; now let’s look at the ingestion data
    schema we defined for the `TEXT_INTENT` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'For simplicity, our ingestion data schema requires that all the input data
    for the `TEXT_INTENT` dataset must be in a CSV file format. The first column is
    text utterance, and the remainder of the columns are labels. See a sample CSV
    file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Labels
  prefs: []
  type: TYPE_NORMAL
- en: A training dataset schema
  prefs: []
  type: TYPE_NORMAL
- en: 'For `TEXT_INTENT` training data, our schema defines the output data as a zip
    file that contains two files: examples.csv and labels.csv. Labels.csv defines
    a label name to a label ID mapping, and the examples.csv defines training text
    (utterance) to label ID mapping. See the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Why we use a self-defined data structure
  prefs: []
  type: TYPE_NORMAL
- en: We build `TEXT_INTENT` with the self-defined data schema instead of using the
    PyTorch or Tensorflow dataset format (like TFRecordDataset) to create abstraction
    from model training frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: By choosing a framework-specific dataset format, your training code will also
    need to be written in the framework, which is not ideal. Introducing a self-defined
    intermediate dataset format can make the DM framework-neutral, so no framework-specific
    training codes are required.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of having two strongly typed data schemas in one dataset
  prefs: []
  type: TYPE_NORMAL
- en: By having two strongly typed data schemas in a dataset and letting DM do the
    data transformation from the ingestion data format to the training data format,
    we could parallelize data collection development and training code development.
    For example, when Jianguo wants to add a new feature—“text language”—to the `TEXT_INTENT`
    dataset, he can work with the DM service developers to update the data ingestion
    schema to add a new data field.
  prefs: []
  type: TYPE_NORMAL
- en: Julia won’t be affected because the training data schema is not changed. Julia
    may come to us later to update the training data schema when she has the bandwidth
    to consume the new feature in her training code. The key point is that Jianguo
    and Julia don’t have to work synchronously to introduce a new dataset enhancement;
    they can work independently.
  prefs: []
  type: TYPE_NORMAL
- en: Note For simplicity and demo purpose, we choose to use a CSV file to store data.
    The problem with using plain CSV files is their lack of backward compatibility
    support and data-type validation support. In production, we recommend using Parquet,
    Google protobuf, or Avro to define data schemas and store data. They come with
    a set of libraries for data validation, data serialization, and schema backward-compatible
    support.
  prefs: []
  type: TYPE_NORMAL
- en: 'A generic dataset: A dataset with no schema'
  prefs: []
  type: TYPE_NORMAL
- en: Although we emphasize at multiple places that defining strongly typed dataset
    schemas is fundamental to dataset management service, we will make an exception
    here by adding a free format dataset type—the `GENERIC` dataset. Unlike the strongly
    typed TEXT_ INENT dataset, a `GENERIC`-type dataset has no data schema validation.
    Our service will save any raw input data as is, and when building training data,
    the service simply packs all the raw data together in its original format into
    a training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: A `GENERIC` dataset type may sound like a bad idea because we basically pass
    whatever data we receive from upstream data sources to the downstream training
    application, which can break the data parsing logic in the training code easily.
    This is definitely not an option for production, but it provides the agility necessary
    for experimental projects.
  prefs: []
  type: TYPE_NORMAL
- en: Although a strongly typed data schema offers good data type safety protection,
    it comes at the cost of maintaining it. It is quite annoying when you have to
    make frequent schema changes in the DM service to adopt the new data format required
    by a new experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: At the beginning of a deep learning project, a lot of things are uncertain,
    such as which deep learning algorithm works the best, what kind of data we can
    collect, and what data schema we should choose. To move forward with all these
    uncertainties, we need a flexible way to handle arbitrary data to enable model
    training experimentations. This is what `GENERIC` dataset type designs are for.
  prefs: []
  type: TYPE_NORMAL
- en: Once the business value is proven and the deep learning algorithm is chosen,
    we are now clear about how the training data looks; then it’s time for us to define
    a strongly typed dataset in the dataset management service. In the next section,
    we will discuss how to add a new strongly typed dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.7 Adding new dataset type (IMAGE_CLASS)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s imagine one day Julia asks us (the platform developers) to promote her
    experimental image classification project to a formal project. Julia and her team
    is developing an image classification model by using a `GENERIC` dataset, and
    because they get good results, they now want to define a strongly typed dataset
    (`IMAGE_CLASS`) to stabilize the data schema for raw data collection and training
    data consumption. This will protect the training code from future dataset updates.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a new dataset type—`IMAGE_CLASS`—we can follow three steps. First, we
    must define the training data format. After discussing with Julia, we decide the
    training data produced by `FetchTrainingDataset` API will be a zip file; it will
    contain these three files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The examples.csv and labels.csv files are manifest files that define labels
    for each training image. The actual image files are stored in the examples folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, define the ingestion data format. We need to discuss the ingestion
    data schema with Jianguo, the data engineer who collects images and labels them.
    We agree that the payload data for each `CreateDataset` and `UpdateDataset` request
    is also a zip file; its directory looks as follows: the zip file should be a folder
    with only subdirectories. Each subdirectory under the root folder represents a
    label; the images under it belong to this label. The subdirectory should only
    contain images and not any nested directories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The last step is the code change. After having two data schemas in mind, we
    need to create an `ImageClassTransformer` class that implements the `DatasetTransformer`
    interface to build the data reads and writes logic.
  prefs: []
  type: TYPE_NORMAL
- en: We first implement the `ImageClassTransformer.ingest()` function. The logic
    needs to use the input data format—defined in step 2—to parse the input data in
    the dataset creation and update requests and then convert the input data to a
    training data format and save it as a commit of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We then implement the `ImageClassTransformer.compress()` function, which first
    selects commits by matching data filters and then merges the matched commits into
    a single training snapshot. As the last step, we register the `ImageClassTransformer
    .ingest()` function to the `DatasetIngestion.ingestion()` function with an IMAGE_
    CLASS type and register `ImageClassTransformer.compress()` to `DatasetCompressor
    .run()` with an `IMAGE_CLASS` type.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, with proper dataset structure, we can support new dataset types
    by just adding a few new code snippets. The existing types of datasets and the
    public data ingestion and fetching APIs are not affected.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.8 Service design recap
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s recap how this sample dataset management service addresses the five design
    principles introduced in section 2.1.2:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Principle 1*—Support dataset reproducibility. Our sample DM service saves
    all the generated training data as a versioned snapshot with a version hash string
    as key. Users can apply this version string to obtain the training data snapshot
    at any time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Principle 2*—Provide a unified experience across different dataset types.
    The data ingestion API and training data fetching API work the same way for all
    dataset types and sizes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Principle 3*—Adopt strongly typed data schema. Our sample TEXT_INENT type
    and `IMAGE_CLASS` type datasets apply a self-defined data schema to both raw ingestion
    data and training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Principle 4*—Ensure API consistency and handle scaling internally. Although
    we save all datasets’ metadata in memory in our sample code (for simplicity),
    we can easily implement the dataset storage structure in cloud object storage;
    in theory, it has infinite capacity. Also, we require data URLs to send data and
    return data, so no matter how large a dataset is, our API remains consistent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Principle 5*—Guarantee data persistency. Every dataset creation request and
    update request creates a new commit; every training data prepare request creates
    a versioned snapshot. Both commit and snapshot are immutable and persist with
    no data expiration limits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note We have trimmed many important features from the sample dataset management
    service to keep it simple. Management APIs, for example, allow you to delete data,
    revert data commits, and view data audit history. Feel free to fork the repo and
    try to implement them.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Open source approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are interested in employing open source approaches to set up dataset
    management functionality, we select two approaches for you: Delta Lake and Pachyderm.
    Let’s look at them individually.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Delta Lake and Petastorm with Apache Spark family
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this approach, we propose to save data in a Delta Lake table and use the
    Petastorm library to convert the table data to PyTorch and Tensorflow dataset
    objects. The dataset can be consumed in training code seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: Delta Lake
  prefs: []
  type: TYPE_NORMAL
- en: Delta Lake is a storage layer that brings scalable, ACID (atomicity, consistency,
    isolation, durability) transactions to Apache Spark and other cloud object stores
    (e.g., Amazon S3). Delta Lake is developed as open source by Databricks, a respected
    data and AI company.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud storage services, such as Amazon S3, are some of the most scalable and
    cost-effective storage systems in the IT industry. They are ideal places to build
    large data warehouses, but their key-values store design makes it difficult to
    achieve ACID transactions and high performance. The metadata operations such as
    listing objects are expensive, and consistency guarantees are limited.
  prefs: []
  type: TYPE_NORMAL
- en: Delta Lake is designed to fill the previously discussed gaps. It works as a
    file system that stores batch and streaming data in object storage (such as Amazon
    S3). In addition, Delta Lake manages metadata, caching, and indexing for its table
    structure and schema enforcement. It provides ACID properties, time travel, and
    significantly faster metadata operations for large tabular datasets. See figure
    2.16 for the Delta Lake concept graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.16 Delta Lake data ingestion and processing workflow. Both stream data
    and batch data can be saved as Delta Lake tables, and the Delta Lake tables are
    stored in the cloud object storage, such as Amazon S3.
  prefs: []
  type: TYPE_NORMAL
- en: The Delta Lake table is the core concept of the system. When working with Delta
    Lake, you are usually dealing with Delta Lake tables. They are like SQL tables;
    you can query, insert, update, and merge table content. Schema protection in Delta
    Lake is one of its advantages. It supports schema validation on table writing,
    which prevents data pollution. It also tracks table history, so you can roll back
    a table to any of its past stages (known as time travel).
  prefs: []
  type: TYPE_NORMAL
- en: 'For building data processing pipelines, Delta Lake recommends naming your tables
    in three categories: bronze, silver, and gold. First, we use bronze tables to
    keep the raw input from different sources (some of which are not so clean). Then
    the data flows constantly from bronze tables to silver tables with data cleaning
    and transformation (ETL). Finally, we perform data filtering and purification
    and save the results to gold tables. Each table is in a machine learningstate;
    they are reproducible and type-safe.'
  prefs: []
  type: TYPE_NORMAL
- en: Why Delta Lake is a good option for deep learning dataset management
  prefs: []
  type: TYPE_NORMAL
- en: The following are three features that make Delta Lake a good option for managing
    datasets for deep learning projects.
  prefs: []
  type: TYPE_NORMAL
- en: First, Delta Lake supports dataset reproducibility. It has a “time travel” feature
    that has the ability to query the data as it existed at a certain point in time
    using data versioning. Imagine you have set up a continuously running ETL pipeline
    to keep your training dataset (gold table) up to date. Because Delta Lake tracks
    table updates as snapshots, every operation is automatically versioned as the
    pipeline writes into the dataset. This means all the training data snapshots are
    kept for free, and you can browse table update history and roll back to past stages
    easily. The following listing provides a few sample commands.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.12 Delta Lake time travel commands
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Finds the dataset in Delta Lake
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Lists the full history of the data
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Gets the last operation on the dataset
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Rolls back the dataset by time stamp
  prefs: []
  type: TYPE_NORMAL
- en: ❺ Rolls back dataset by version
  prefs: []
  type: TYPE_NORMAL
- en: Second, Delta Lake supports continuously streaming data processing. Its tables
    can handle the continuous flow of data from both historical and real-time streaming
    sources seamlessly. For example, your data pipeline or stream data source can
    keep adding data to the Delta Lake table while querying data from the table at
    the same time. This saves you extra steps when writing code to merge the new data
    with existing data.
  prefs: []
  type: TYPE_NORMAL
- en: Third, Delta Lake offers schema enforcement and evolvement. It applies schema
    validation on write. It will ensure that new data records match the table’s predefined
    schema; if the new data isn’t compatible with the table’s schema, Delta Lake will
    raise an exception. Having data type validation at writing time is better than
    at reading time because it’s difficult to clean data if it’s polluted.
  prefs: []
  type: TYPE_NORMAL
- en: Besides strong schema enforcement, Delta Lake also allows you to add new columns
    to existing data tables without causing breaking changes. The dataset schema enforcement
    and adjustment (evolvement) capabilities are critical to deep learning projects.
    These capabilities protect the training data from being polluted by unintended
    data writes and offer safe data updates.
  prefs: []
  type: TYPE_NORMAL
- en: Petastorm
  prefs: []
  type: TYPE_NORMAL
- en: Petastorm is an open source data access library developed at Uber ATG (Advanced
    Technologies Group). It enables single-machine or distributed training and evaluation
    of deep learning models directly from datasets in the Apache Parquet format (a
    data file format designed for efficient data storage and retrieval).
  prefs: []
  type: TYPE_NORMAL
- en: Petastorm can convert Delta Lake tables to Tensorflow and PyTorch format datasets
    easily, and it also supports distributed training data partitions. With Petastorm,
    the training data from a Delta Lake table can be simply consumed by downstream
    training applications without worrying about the details of data conversion for
    a specific training framework. It also creates good isolation between the dataset
    format and training frameworks (Tensorflow, PyTorch, and PySpark). Figure 2.17
    visualizes the data conversion process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-17.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.17 Petastorm converts the Delta Lake table to datasets that can be
    read by the PyTorch or Tensorflow framework.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 depicts the Petastorm data conversion workflow. You can create a
    Petastorm spark converter that reads Delta Lake tables into its cache as Parquet
    files and generates Tensorflow or Pytorch dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Preparing training data for a flower image classification'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a general idea of Delta Lake and Petastorm, let’s see a concrete
    model training example. The following code snippets—code listings 2.13 and 2.14—demonstrate
    an end-to-end image classification model training workflow in two steps. First,
    they define an image process ETL pipeline that parses a group of image files into
    the Delta Lake table as an image dataset. Second, they use Petastorm to convert
    the Delta Lake table to a dataset that can be loaded into the PyTorch framework
    directly to start model training.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first visit the four-step ETL data processing pipeline in code listing
    2.13\. You can also find the complete code at [http://mng.bz/JVPz](http://mng.bz/JVPz).
  prefs: []
  type: TYPE_NORMAL
- en: In the beginning step of the pipeline, we load the images from a folder, `flower_`
    `photos`, to spark as binary files. Second, we define the extract functions to
    obtain metadata from each image file, such as label name, file size, and image
    size. Third, we construct the data processing pipeline with the extract functions
    and then pass the image files to the pipeline, which will produce a data frame.
    Each row of the data frame represents an image file and its metadata, including
    file content, label name, image size, and file path. In the last step, we save
    this data frame as a Delta Lake table—`gold_table_training_dataset`. You can also
    see this Delta Lake table’s data schema at the end of the following code listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.13 An ETL to create an image dataset in Delta Lake
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Reads images as binaryFile
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Extracts labels from the image’s subdirectory name
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Extracts image dimensions
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Data schema of the Delta Lake table—gold_table_training_dataset
  prefs: []
  type: TYPE_NORMAL
- en: Note The raw data used in the demo is the flowers dataset from the TensorFlow
    team. It contains flower photos stored under five subdirectories, one per class.
    The subdirectory name is the label name for the images it contains.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have an image dataset built in a Delta Lake table, we can start
    to train a PyTorch model by using this dataset with the help of Petastorm. In
    code listing 2.14, we first read the Delta Lake table `gold_table_training_dataset`
    produced by the ETL pipeline defined in code listing 2.13 and then split the data
    into two data frames: one for training and one for validation. Next, we load these
    two data frames to two Petastorm spark converters; the data will be converted
    to Parquet files inside the converter. At the end, we use the Petastorm API `make_torch_dataloader`
    to read training examples in PyTorch for model training. See the following code
    for the entire three-step process. You can also find the full sample code at:
    [http://mng.bz/wy4B](http://mng.bz/wy4B).'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.14 Consuming a Delta Lake image dataset in PyTorch with Petastorm
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '❶ Splits Delta Lake table data into two data frames: training and validation'
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Creates the PyTorch data loader from the Petastorm converter for training
    and evaluation
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Consumes the training data in the training iterations
  prefs: []
  type: TYPE_NORMAL
- en: When to use Delta Lake
  prefs: []
  type: TYPE_NORMAL
- en: The common misconception about Delta Lake is that it can only handle structured
    text data, such as sales records and user profiles. But the previous example shows
    it can also deal with unstructured data like images and audio files; you can write
    the file content as a bytes column into a table with other file properties and
    build datasets from them.
  prefs: []
  type: TYPE_NORMAL
- en: Delta Lake is a great choice for doing dataset management if you already use
    Apache Spark to build your data pipeline; it supports both structured and unstructured
    data. It’s also cost-effective because Delta Lake keeps data in cloud object storage
    (e.g., Amazon S3, Azure Blob), and Delta Lake’s data schema enforcement and live
    data updated table support mechanism simplify your ETL pipeline development and
    maintenance. Last but not least, the time travel function keeps track of all the
    table updates automatically, so you can feel safe to make data changes and roll
    back to previous versions of the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of Delta Lake
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest risks of using Delta Lake are lock-in technology and its steep
    learning curve. Delta Lake stores tables in its own mechanism: a combination of
    Parquet-based storage, a transaction log, and indexes, which means it can only
    be written/read by a Delta cluster. You need to use Delta ACID API for data ingestion
    and Delta JDBC to run queries; thus, the data migration cost would be high if
    you decide to move away from Delta Lake in the future. Also, because Delta Lake
    goes with Spark, there is a lot of learning ahead of you if you are new to Spark.'
  prefs: []
  type: TYPE_NORMAL
- en: Regarding data ingestion performance, Delta Lake stores data to the underlying
    cloud object store, and it’s difficult to achieve low-latency streaming (millisecond
    scale) when using object store operations, such as table creation and saving.
    In addition, Delta Lake needs to update indexes for each ACID transaction; it
    also introduces latency compared with some ETLs performing append-only data writes.
    But in our opinion, data ingestion latency at the second level is not a problem
    for deep learning projects. If you are unfamiliar with Spark and don’t want the
    heavy lifting of setting up Spark and Delta Lake clusters, we have another lightweight
    approach for you—Pachyderm.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Pachyderm with cloud object storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we want to propose a lightweight, Kubernetes-based tool—Pachyderm—to
    handle dataset management. We will show you two examples of how to use Pachyderm
    to accomplish image data processing and labeling. But before that, let’s look
    at what Pachyderm is.
  prefs: []
  type: TYPE_NORMAL
- en: Pachyderm
  prefs: []
  type: TYPE_NORMAL
- en: Pachyderm is a tool for building version-controlled, automated, end-to-end data
    pipelines for data science. It runs on Kubernetes and is backed by an object store
    of your choice (e.g., Amazon S3). You can write your own Docker images for data
    scraping, ingestion, cleaning, munging, and wrangling and use the Pachyderm pipeline
    to chain them together. Once you define your pipelines, Pachyderm will handle
    the pipeline scheduling, executing, and scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Pachyderm offers dataset version control and provenance (data lineage) management.
    It sees every data update (create, write, delete, etc.) as a commit, and it also
    tracks the data source that generates the data update. So you not only can see
    the change history of a dataset, but you can also roll back the dataset to a past
    version and find the data provenance of the change. Figure 2.18 gives a high-level
    view of how Pachyderm works.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-18.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.18 The Pachyderm platform runs with two kinds of objects—a pipeline
    and versioned data. The pipeline is the computational component, and the data
    is the version-control primitive. A data change in the “raw dataset” can trigger
    a pipeline job to process the new data and save the result to the “mature dataset.”
  prefs: []
  type: TYPE_NORMAL
- en: In Pachyderm, data is version-controlled with a Git style. Each dataset is a
    repository (repo) in Pachyderm, which is the highest-level data object. A repo
    contains commits, files, and branches. Pachyderm only keeps metadata (such as
    audit history and branch) internally and stores the actual files in cloud object
    storage.
  prefs: []
  type: TYPE_NORMAL
- en: The Pachyderm pipeline performs various data transformations. The pipelines
    execute a user-defined piece of code—for example, a docker container—to perform
    an operation and process the data. Each of these executions is called a job. Listing
    2.15 shows a simple pipeline definition. This “edges” pipeline watches an “images”
    dataset. When there is a new image added to the images dataset, the pipeline will
    launch a job to run the `"pachyderm/opencv"` docker image to parse the image and
    save its edge picture into the edges dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.15 A Pachyderm pipeline definition
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: ❶ A Pachyderm pipeline
  prefs: []
  type: TYPE_NORMAL
- en: ❷ A Pachyderm dataset
  prefs: []
  type: TYPE_NORMAL
- en: Version and data provenance
  prefs: []
  type: TYPE_NORMAL
- en: 'In Pachyderm, any changes applied to both the dataset and pipeline are versioned
    automatically, and you can use the Pachyderm command tool `pachctl` to connect
    to the Pachyderm workspace to check file history and even roll back those changes.
    See the following example for using the `pachctl` command to check the edges dataset’s
    change history and the change provenance. First, we run the `pachctl` `list` command
    to list all the commits in the edges dataset. In our example, there are three
    changes (commits) applied to the edges dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: To get the provenance of a data change, we can use pachctl inspect command to
    check on the commit. For example, we can use the following command to check the
    data origin of commit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'From the following response, we can see the commit `eb58294a976347abaf06e35fe3b0da5b`
    of the edges dataset is computed from the images dataset’s `66f4ff89a017412090dc4a542d9b1142`
    commit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Data provenance
  prefs: []
  type: TYPE_NORMAL
- en: The data provenance feature is great for reproducibility and troubleshooting
    datasets, as you can always find the exact data that was used in the past, along
    with the data process code that created it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Using Pachyderm for labeling and training an image dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Having seen how Pachyderm works, let’s see a design proposal for using Pachyderm
    to build an automated object detection training pipeline. For object detection
    model training, we first need to prepare the training dataset by labeling the
    target object with a bounding box on each image and then send the dataset—the
    bounding box label file and images—to the training code to start the model training.
    Figure 2.19 shows the process of using Pachyderm to automate this workflow.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02-19.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.19 Automated object detection model training in Pachyderm. The training
    process starts automatically when new images are labeled.
  prefs: []
  type: TYPE_NORMAL
- en: In this design, we use two pipelines, the labeling pipeline and the training
    pipeline, and two datasets to build this training workflow. In step 1, we upload
    image files to the “raw image dataset.” In step 2, we kick off the labeling pipeline
    to launch a labeling application that opens up a UI for the user to label objects
    by drawing bounding boxes on the images; these images are read from the raw image
    dataset. Once the user finishes the labeling work, the image and the generated
    label data will be saved to the “labeled dataset.” In step 3, we add new training
    data to the labeled dataset, which will trigger the training pipeline to launch
    the training container and start the model training. In step 4, we save the model
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the automation, data including the raw image dataset, the labeled dataset,
    and the model files are all versioned by Pachyderm automatically. Also, by leveraging
    the data provenance feature, we can tell with any given model file which version
    of the labeled dataset is used in its training and from which version of the raw
    image dataset this training data is made.
  prefs: []
  type: TYPE_NORMAL
- en: When to use Pachyderm
  prefs: []
  type: TYPE_NORMAL
- en: Pachyderm is a lightweight approach to help you build data engineering pipelines
    easily and offers data versioning support in Git style. It is data scientist–centric
    and easy to use. Pachyderm is Kubernetes based and uses cloud object storage as
    a data store, so it’s cost-effective, simple to set up, and easy to maintain for
    small teams. We would suggest using Pachyderm, and not using Spark, for any data
    science teams that own their infrastructure. Pachyderm works really well with
    unstructured data, like image and audio files.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations with Pachyderm
  prefs: []
  type: TYPE_NORMAL
- en: What is missing in Pachyderm are schema protection and data analysis efficiency.
    Pachyderm sees everything as files; it keeps snapshots for each file version but
    doesn’t care about the file content. There is no data type validation on data
    writing or reading; it completely depends on the pipeline to protect the data
    consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Lack of schema awareness and protection introduces a lot of risk for any continuous-running
    deep learning training pipeline because any code changes in the upstream data
    processing code might break the downstream data processing or training code. Also,
    without knowing the schema of the data, dataset comparison is hard to implement.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The primary goal of dataset management is to continuously receive fresh data
    from a variety of data sources and deliver datasets to model training while supporting
    training reproducibility (data version tracking).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having a dataset management component can expedite deep learning project development
    by parallelizing model algorithm development and data engineering development.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The principles to validate the design of a dataset management service are as
    follows: supporting dataset reproducibility; employing strongly typed data schema;
    designing unified API and keeping API behavior consistent across different dataset
    types and sizes; and guaranteeing data persistence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset management system should at least support (training) dataset versioning,
    which is crucial for model reproducibility and performance troubleshooting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset is a logic file group for a deep learning task; it’s static from the
    model training perspective and dynamic from the data collection perspective.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sample dataset management service is made of three layers—the data ingestion
    layer, internal dataset storage layer, and training dataset fetching layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We define two data schemas for each dataset type in the sample dataset management
    service, one for data ingestion and one for dataset fetching. Each data update
    is stored as a commit, and each training dataset is stored as a versioned snapshot.
    Users can employ a version hash string to fetch the related training data at any
    time (dataset reproducibility).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sample dataset management service supports a special dataset type—a `GENERIC`
    dataset. A `GENERIC` dataset has no schema and no data validation, and users can
    upload and download data freely, so it’s good for prototyping new algorithms.
    Once the training code and dataset requirements become mature, the dataset format
    can be promoted to a strongly typed dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delta Lake and Petastorm can work together to set up a dataset management service
    for Spark-based, deep learning projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pachyderm is a lightweight, Kubernetes-based data platform that offers data
    versioning support in Git style and allows easy pipeline setup. A pipeline is
    made by docker containers; it can be used to automate data process workflow and
    training workflow for a deep learning project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
