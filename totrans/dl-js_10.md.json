["```js\nexport function multiLayerPerceptronRegressionModel1Hidden() {\n  const model = tf.sequential();\n  model.add(tf.layers.dense({\n    inputShape: [bostonData.numFeatures],\n    units: 50,\n    activation: 'sigmoid',\n    kernelInitializer: 'leCunNormal'        ***1***\n  }));\n  model.add(tf.layers.dense({units: 1}));   ***2***\n\n  model.summary();                          ***3***\n  return model;\n};\n```", "```js\n_________________________________________________________________\nLayer (type)                 Output shape              Param #\n=================================================================\ndense_Dense1 (Dense)         [null,50]                 650\n _________________________________________________________________\ndense_Dense2 (Dense)         [null,1]                  51\n=================================================================\nTotal params: 701\nTrainable params: 701\nNon-trainable params: 0\n```", "```js\n_________________________________________________________________\nLayer (type)                 Output shape              Param #\n=================================================================\ndense_Dense3 (Dense)         [null,1]                  13\n=================================================================\nTotal params: 13\nTrainable params: 13\nNon-trainable params: 0\n```", "```js\n[[1.0], [0.5], ..., [0.0]],\n```", "```js\n[[S(1.0)], [S(0.5)], ..., [S(0.0)]] = [[0.731], [0.622], ..., [0.0]]\n```", "```js\nf(x) = k1 * x + b1\n```", "```js\ng(x) = k2 * x + b2\n```", "```js\nh(x) = g(f(x)) = k2 * (k1 * x + b1) + b2 = (k2 * k1) * x + (k2 * b1 + b2)\n```", "```js\nexport function multiLayerPerceptronRegressionModel2Hidden() {\n  const model = tf.sequential();\n  model.add(tf.layers.dense({               ***1***\n    inputShape: [bostonData.numFeatures],   ***1***\n    units: 50,                              ***1***\n    activation: 'sigmoid',                  ***1***\n    kernelInitializer: 'leCunNormal'        ***1***\n  }));                                      ***1***\n  model.add(tf.layers.dense({               ***2***\n    units: 50,                              ***2***\n    activation: 'sigmoid',                  ***2***\n    kernelInitializer: 'leCunNormal'        ***2***\n  }));                                      ***2***\n  model.add(tf.layers.dense({units: 1}));\n\n  model.summary();                          ***3***\n  return model;\n};\n```", "```js\nexport function multiLayerPerceptronRegressionModel1Hidden() {\n  const model = tf.sequential();\n  model.add(tf.layers.dense({\n    inputShape: [bostonData.numFeatures],\n    units: 50,\n    // activation: 'sigmoid',          ***1***\n    kernelInitializer: 'leCunNormal'\n  }));\n  model.add(tf.layers.dense({units: 1}));\n\n  model.summary();\n  return model;\n};\n```", "```js\nmodel.layers[0].getWeights()[0].print();\n```", "```js\nTensor\n    [[-0.5701274, -0.1643915, -0.0009151, ..., 0.313205  , -0.3253246],\n     [-0.4400523, -0.0081632, -0.2673715, ..., 0.1735748 , 0.0864024 ],\n     [0.6294659 , 0.1240944 , -0.2472516, ..., 0.2181769 , 0.1706504 ],\n     [0.9084488 , 0.0130388 , -0.3142847, ..., 0.4063887 , 0.2205501 ],\n     [0.431214  , -0.5040522, 0.1784604 , ..., 0.3022115 , -0.1997144],\n     [-0.9726604, -0.173905 , 0.8167523 , ..., -0.0406454, -0.4347956],\n     [-0.2426955, 0.3274118 , -0.3496988, ..., 0.5623314 , 0.2339328 ],\n     [-1.6335299, -1.1270424, 0.618491  , ..., -0.0868887, -0.4149215],\n     [-0.1577617, 0.4981289 , -0.1368523, ..., 0.3636355 , -0.0784487],\n     [-0.5824679, -0.1883982, -0.4883655, ..., 0.0026836 , -0.0549298],\n     [-0.6993552, -0.1317919, -0.4666585, ..., 0.2831602 , -0.2487895],\n     [0.0448515 , -0.6925298, 0.4945385 , ..., -0.3133179, -0.0241681]]\n```", "```js\nfunction hyperparameterGridSearch():\n  for units of [10, 20, 50, 100, 200]:\n    for learningRate  of [1e-5, 1e-4, 1e-3, 1e-2]:\n       Create a model using whose dense layer consists of `units` units\n       Train the model with an optimizer with `learningRate`\n       Calculate final validation loss as validationLoss\n       if validationLoss < minValidationLoss\n         minValidationLoss := validationLoss\n         bestUnits := units\n         bestLearningRate := learningRate\n\n  return [bestUnits, bestLearningRate]\n```", "```js\ngit clone https://github.com/tensorflow/tfjs-examples.git\ncd tfjs-examples/website-phishing\nyarn && yarn watch\n```", "```js\nconst model = tf.sequential();\nmodel.add(tf.layers.dense({\n  inputShape: [data.numFeatures],\n  units: 100,\n  activation: 'sigmoid'\n}));\nmodel.add(tf.layers.dense({units: 100, activation: 'sigmoid'}));\nmodel.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));\nmodel.compile({\n  optimizer: 'adam',\n  loss: 'binaryCrossentropy',\n  metrics: ['accuracy']\n});\n```", "```js\nAccuracy = (#TP + #TN) / #examples = (#TP + #TN) / (#TP + #TN + #FP + #FN)\n```", "```js\nAccuracy = (4 + 93) / 100 = 97%\n```", "```js\nprecision = #TP / (#TP + #FP)\n```", "```js\nprecision = 4 / (4 + 1) = 80%\n```", "```js\nrecall = #TP / (#TP + #FN)\n```", "```js\nrecall = 4 / (4 + 2) = 66.7%\n```", "```js\nFPR = #FP / (#FP + #TN)\n```", "```js\nTPR = #TP / (#TP + #FN) = recall\n```", "```js\n  await model.fit(trainData.data, trainData.target, {\n    batchSize,\n    epochs,\n    validationSplit: 0.2,\n    callbacks: {\n    onEpochBegin: async (epoch) => {\n        if ((epoch + 1)% 100 === 0 ||\n                        epoch === 0 || epoch === 2 || epoch === 4) {\n                                                            ***1***\n            const probs = model.predict(testData.data);\n            drawROC(testData.target, probs, epoch);\n        }\n      },\n      onEpochEnd: async (epoch, logs) => {\n        await ui.updateStatus(\n                `Epoch ${epoch + 1} of ${epochs} completed.`);\n        trainLogs.push(logs);\n        ui.plotLosses(trainLogs);\n        ui.plotAccuracies(trainLogs);\n      }\n    }\n  });\n```", "```js\nfunction drawROC(targets, probs, epoch) {\n  return tf.tidy(() => {\n    const thresholds = [                                                ***1***\n      0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45,            ***1***\n      0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85,                       ***1***\n      0.9, 0.92, 0.94, 0.96, 0.98, 1.0                                  ***1***\n    ];                                                                  ***1***\n    const tprs = [];  // True positive rates.\n    const fprs = [];  // False positive rates.\n    let area = 0;\n    for (let i = 0; i < thresholds.length; ++i) {\n           const threshold = thresholds[i];\n      const threshPredictions =                                         ***2***\n               utils.binarize(probs, threshold).as1D();                 ***2***\n      const fpr = falsePositiveRate(                                    ***3***\n               targets,                                                 ***3***\n      threshPredictions).arraySync();                                   ***3***\n      const tpr = tf.metrics.recall(targets, threshPredictions).arraySync();\n      fprs.push(fpr);\n      tprs.push(tpr);\n\n      if (i > 0) {                                                      ***4***\n        area += (tprs[i] + tprs[i - 1]) * (fprs[i - 1] - fprs[i]) / 2;  ***4***\n      }                                                                 ***4***\n    }\n    ui.plotROC(fprs, tprs, epoch);\n    return area;\n  });\n}\n```", "```js\nmodel.compile({\n  optimizer: 'adam',\n  loss: 'binaryCrossentropy',\n  metrics: ['accuracy']\n});\n```", "```js\nfunction binaryCrossentropy(truthLabel, prob):\n  if truthLabel is 1:\n        return -log(prob)\n  else:\n   return -log(1 - prob)\n```", "```js\ngit clone https://github.com/tensorflow/tfjs-examples.git\ncd tfjs-examples/iris\nyarn && yarn watch\n```", "```js\nconst ys = tf.oneHot(tf.tensor1d(shuffledTargets).toInt(), IRIS_NUM_CLASSES);\n```", "```js\nconst ys = tf.oneHot(tf.tensor1d(shuffledTargets).toInt(), IRIS_NUM_CLASSES);\n// Added lines for printing the values of `targets` and `ys`.\nconsole.log('Value of targets:', targets);\nys.print();[[11](#ch03fn11)]\n```", "```js\nValue of targets: (50) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n     0, 0, 0, 0, 0, 0, 0, 0]\n\nTensor\n    [[1, 0, 0],\n     [1, 0, 0],\n     [1, 0, 0],\n     ...,\n     [1, 0, 0],\n     [1, 0, 0],\n     [1, 0, 0]]\n```", "```js\nValue of targets: (50) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n     1, 1, 1, 1, 1, 1, 1, 1]\n\nTensor\n    [[0, 1, 0],\n     [0, 1, 0],\n     [0, 1, 0],\n     ...,\n     [0, 1, 0],\n     [0, 1, 0],\n     [0, 1, 0]]\n```", "```js\n  const model = tf.sequential();\n  model.add(tf.layers.dense(\n      {units: 10, activation: 'sigmoid', inputShape: [xTrain.shape[1]]}));\n  model.add(tf.layers.dense({units: 3, activation: 'softmax'}));\n  model.summary();\n\n  const optimizer = tf.train.adam(params.learningRate);\n  model.compile({\n    optimizer: optimizer,\n    loss: 'categoricalCrossentropy',\n    metrics: ['accuracy'],\n  });\n```", "```js\n_________________________________________________________________\nLayer (type)                 Output shape              Param #\n=================================================================\ndense_Dense1 (Dense)         [null,10]                 50\n________________________________________________________________\ndense_Dense2 (Dense)         [null,3]                  33\n=================================================================\nTotal params: 83\nTrainable params: 83\nNon-trainable params:\n________________________________________________________________\n```", "```js\nsoftmax([x1, x2, ..., xn]) =\n    [exp(x1) / (exp(x1) + exp(x2) + ... + exp(xn)),\n     exp(x2) / (exp(x1) + exp(x2) + ... + exp(xn)),\n     ...,\n     exp(xn) / (exp(x1) + exp(x2) + ... + exp(xn))]\n```", "```js\n[-3, 0, -8]\n```", "```js\n[0.0474107, 0.9522698, 0.0003195]\n```", "```js\nconst x = tf.tensor1d([-3, 0, -8]);\ntf.softmax(x).print();\n```", "```js\nconst predictOut = model.predict(input);\nconst winner = data.IRIS_CLASSES[predictOut.argMax(-1).dataSync()[0]];\n```", "```js\n    [[0  , 0.6, 0.4],\n     [0.8, 0  , 0.2]]\n```", "```js\n    [1, 0]\n```", "```js\n    model.compile({\n      optimizer: optimizer,\n      loss: 'categoricalCrossentropy',\n      metrics: ['accuracy'],\n     });\n```", "```js\nfunction categoricalCrossentropy(oneHotTruth, probs):\n  for i in (0 to length of oneHotTruth)\n    if oneHotTruth(i) is equal to 1\n      return -log(probs[i]);\n```", "```js\nconst oneHotTruth = tf.tensor1d([0, 1, 0]);\nconst probs = tf.tensor1d([0.2, 0.5, 0.3]);\ntf.metrics.categoricalCrossentropy(oneHotTruth, probs).print();\n```"]