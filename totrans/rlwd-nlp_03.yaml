- en: 1 Introduction to natural language processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: What natural language processing (NLP) is, what it is not, and why it’s such
    an interesting, yet challenging, field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How NLP relates to other fields, including artificial intelligence (AI) and
    machine learning (ML)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What typical NLP applications and tasks are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How a typical NLP application is developed and structured
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is not an introductory book to machine learning or deep learning. You won’t
    learn how to write neural networks in mathematical terms or how to compute gradients,
    for example. But don’t worry, even if you don’t have any idea what they are. I’ll
    explain those concepts as needed, not mathematically but conceptually. In fact,
    this book contains no mathematical formulae—not a single one. Also, thanks to
    modern deep learning libraries, you don’t really need to understand the math to
    build practical NLP applications. If you are interested in learning the theories
    and the math behind machine learning and deep learning, you can find a number
    of great resources out there.
  prefs: []
  type: TYPE_NORMAL
- en: But you do need to be at least comfortable enough to write in Python and know
    its ecosystems. However, you don’t need to be an expert in software engineering
    topics. In fact, this book’s purpose is to introduce software engineering best
    practices for developing NLP applications. You also don’t need to know NLP in
    advance. Again, this book is designed to be a gentle introduction to the field.
  prefs: []
  type: TYPE_NORMAL
- en: You need Python version 3.6.1 or higher and AllenNLP 2.5.0 or higher to run
    the code examples in this book. Note that we do not support Python 2, mainly because
    AllenNLP ([https://allennlp.org/](https://allennlp.org/)), the deep natural language
    processing framework I’m going to heavily use in this book, supports only Python
    3\. If you haven’t done so, I strongly recommend upgrading to Python 3 and familiarizing
    yourself with the latest language features such as type hints and new string-formatting
    syntax. This will be helpful, even if you are developing non-NLP applications.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry if you don’t have a Python development environment ready. Most of
    the examples in this book can be run via the Google Colab platform ([https://colab.research.google.com](https://colab.research.google.com)).
    You need only a web browser to build and experiment with NLP models!
  prefs: []
  type: TYPE_NORMAL
- en: This book will use PyTorch ([https://pytorch.org/](https://pytorch.org/)) as
    its main choice of deep learning framework. This was a difficult decision for
    me, because several deep learning frameworks are equally great choices for building
    NLP applications, namely, TensorFlow, Keras, and Chainer. A few factors make PyTorch
    stand out among those frameworks—it’s a flexible and dynamic framework that makes
    it easier to prototype and debug NLP models; it’s becoming increasingly popular
    within the research community, so it’s easy to find open source implementations
    of major models; and the deep NLP framework AllenNLP mentioned earlier is built
    on top of PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 What is natural language processing (NLP)?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NLP is a principled approach to processing human language. Formally, it is a
    subfield of artificial intelligence (AI) that refers to computational approaches
    to process, understand, and generate human language. The reason it is part of
    AI is because language processing is considered a huge part of human intelligence.
    The use of language is arguably the most salient skill that separates humans from
    other animals.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.1 What is NLP?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: NLP includes a range of algorithms, tasks, and problems that take human-produced
    text as an input and produce some useful information, such as labels, semantic
    representations, and so on, as an output. Other tasks, such as translation, summarization,
    and text generation, directly produce text as output. In any case, the focus is
    on producing some output that is useful per se (e.g., a translation) or as input
    to other downstream tasks (e.g., parsing). I’ll touch upon some popular NLP applications
    and tasks in section 1.3.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might wonder why NLP explicitly has “natural” in its name. What does it
    mean for a language to be natural? Are there any *un*natural languages? Is English
    natural? Which is more natural: Spanish or French?'
  prefs: []
  type: TYPE_NORMAL
- en: The word “natural” here is used to contrast natural languages with formal languages.
    In this sense, all the languages humans speak are natural. Many experts believe
    that language emerged naturally tens of thousands of years ago and has evolved
    organically ever since. Formal languages, on the other hand, are types of languages
    that are invented by humans and have strictly and explicitly defined syntax (i.e.,
    what is grammatical) and semantics (i.e., what it means).
  prefs: []
  type: TYPE_NORMAL
- en: Programming languages such as C and Python are good examples of formal languages.
    These languages are defined in such a strict way that it is always clear what
    is grammatical and ungrammatical. When you run a compiler or an interpreter on
    the code you write in those languages, you either get a syntax error or not. The
    compiler won’t say something like, “Hmm, this code is maybe 50% grammatical.”
    Also, the behavior of your program is always the same if it’s run on the same
    code, assuming external factors such as the random seed and the system states
    remain constant. Your interpreter won’t show one result 50% of the time and another
    the other 50% of the time.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is not the case for human languages. You can write a sentence that is
    *maybe* grammatical. For example, do you consider the phrase “The person I spoke
    to” ungrammatical? There are some grammar topics where even experts disagree with
    each other. This is what makes human languages interesting but challenging, and
    why the entire field of NLP even exists. Human languages are ambiguous, meaning
    that their interpretation is often not unique. Both structures (how sentences
    are formed) and semantics (what sentences mean) can have ambiguities in human
    language. As an example, let’s take a close look at the next sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '*He saw a girl with a telescope.*'
  prefs: []
  type: TYPE_NORMAL
- en: When you read this sentence, who do you think has a telescope? Is it the boy,
    who’s using a telescope to see a girl (from somewhere far), or the girl, who has
    a telescope and is seen by the boy? There seem to be at least two interpretations
    of this sentence as shown in figure 1.1.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F01_Hagiwara](../Images/CH01_F01_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 Two interpretations of “He saw a girl with a telescope.”
  prefs: []
  type: TYPE_NORMAL
- en: The reason you are confused upon reading this sentence is because you don’t
    know what the phrase “with a telescope” is about. More technically, you don’t
    know what this prepositional phrase (PP) modifies. This is called a *PP-attachment*
    problem and is a classic example of *syntactic ambiguity*. A syntactically ambiguous
    sentence has more than one interpretation of how the sentence is structured. You
    can interpret the sentence in multiple ways, depending on which structure of the
    sentence you believe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another type of ambiguity that may arise in natural language is *semantic ambiguity*.
    This is when the meaning of a word or a sentence, not its structure, is ambiguous.
    For example, let’s look at the following sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I saw a bat.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is no question how this sentence is structured. The subject of the sentence
    is “I” and the object is “a bat,” connected by the verb “saw.” In other words,
    there is no syntactical ambiguity in it. But how about its meaning? “Saw” has
    at least two meanings. One is the past tense of the verb “to see.” The other is
    to cut some object with a saw. Similarly, “a bat” can mean two very different
    things: is it a nocturnal flying mammal or a piece of wood used to hit a ball?
    All in all, does this sentence mean that I observed a nocturnal flying mammal
    or that I cut a baseball or cricket bat? Or even (cruelly) that I cut a nocturnal
    animal with a saw? You never know, at least from this sentence alone.'
  prefs: []
  type: TYPE_NORMAL
- en: Ambiguity is what makes natural languages rich but also challenging to process.
    We can’t simply run a compiler or an interpreter on a piece of text and just “get
    it.” We need to face the complexities and subtleties of human languages. We need
    a scientific, principled approach to deal with them. That’s what NLP is all about.
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the beautiful world of natural languages.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.2 What is not NLP?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now let’s consider the following scenario and think how you’d approach this
    problem: you are working as a junior developer at a midsized company that has
    a consumer-facing product line. It’s 3 p.m. on a Friday. The rest of the team
    is becoming more and more restless as the weekend approaches. That’s when your
    boss drops by at your cubicle.'
  prefs: []
  type: TYPE_NORMAL
- en: “Hey, got a minute? I’ve got something interesting to show you. I just sent
    it to you.”
  prefs: []
  type: TYPE_NORMAL
- en: Your boss just sent you an email with a huge zip file attached to it.
  prefs: []
  type: TYPE_NORMAL
- en: “OK, so this is a giant TSV file. It contains all the responses to the survey
    questions about our product. I just got this data from the marketing team.”
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the marketing team has been collecting user opinions about one of
    the products through a series of survey questions online.
  prefs: []
  type: TYPE_NORMAL
- en: “The survey questions include standard ones like ‘How did you know about our
    product?’ and ‘How do you like our product?’ There is also a free-response question,
    where our customers can write whatever they feel about our product. The thing
    is, the marketing team realized there was a bug in the online system and the answers
    to the second question were not recorded in the database at all.”
  prefs: []
  type: TYPE_NORMAL
- en: “Wait, so there’s no way to tell how the customers are feeling about our product?”
    This sounds weirdly familiar. This must be a copy-and-paste error. When you first
    created an online data-collection interface, you copied and pasted the backend
    code without modifying the ID parameters, resulting in a loss of some data fields.
  prefs: []
  type: TYPE_NORMAL
- en: “So,” your boss continues. “I was wondering if we can recover the lost data
    somehow. The marketing team is a little desperate now because they need to report
    the results to the VP early next week.”
  prefs: []
  type: TYPE_NORMAL
- en: At this point, your bad feeling has been confirmed. Unless you come up with
    a way to get this done as quickly as possible, your weekend plans will be ruined.
  prefs: []
  type: TYPE_NORMAL
- en: “Didn’t you say you were interested in some machine learning? I think this is
    a perfect project for you. Anyway, it’d be great if you can give it a stab and
    let me know what you find. Do you think you can have some results by Monday?”
  prefs: []
  type: TYPE_NORMAL
- en: “Well, I’ll give it a try.”
  prefs: []
  type: TYPE_NORMAL
- en: You know “no” is not an acceptable answer here. Satisfied with your answer,
    your boss smiles and walks off.
  prefs: []
  type: TYPE_NORMAL
- en: You start by skimming the TSV file. To your relief, its structure is fairly
    standard—it has several fields such as timestamps and submission IDs. At the end
    of each line is a lengthy field for the free-response question. Here they are,
    you think. At least you know where to look for some clues.
  prefs: []
  type: TYPE_NORMAL
- en: 'After a quick glance over the field, you find responses such as “A very good
    product!” and “Very bad. It crashes all the time!” Not too bad, you think. At
    least you can capture these simple cases. You start by writing the following method
    that captures those two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then you run this method on the responses in the file and log the results, along
    with the original input. As intended, this method seems to be able to capture
    a dozen or so of the responses that contains “good” or “bad.”
  prefs: []
  type: TYPE_NORMAL
- en: 'But then you start to see something alarming, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '“I can’t think of a single good reason to use this product”: positive'
  prefs: []
  type: TYPE_NORMAL
- en: '“It’s not bad.”: negative'
  prefs: []
  type: TYPE_NORMAL
- en: 'Oops, you think. *Negation*. Yeah, of course. But this is pretty easy to deal
    with. You modify the method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You run the script again. This time, it seems to be behaving as intended, until
    you see an even more complicated example:'
  prefs: []
  type: TYPE_NORMAL
- en: '“The product is not only cheap but also very good!”: negative'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hmm, you think. This is probably not as straightforward as I initially thought
    after all. Maybe the negation has to be somewhere near “good” or “bad” for it
    to be effective. Wondering what steps you could take next, you scroll down to
    see more examples, which is when you see responses like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '“I always wanted this feature badly!”: negative'
  prefs: []
  type: TYPE_NORMAL
- en: '“It’s very badly made.”: negative'
  prefs: []
  type: TYPE_NORMAL
- en: You silently curse to yourself. How could a single word in a language have two
    completely opposite meanings? At this point, your little hope for enjoying the
    weekend has already disappeared. You are already wondering what excuses you use
    with your boss next Monday.
  prefs: []
  type: TYPE_NORMAL
- en: As a reader of this book, you’ll know better. You’ll know that NLP is not about
    throwing a bunch of ifs and thens at natural language text. It is a more principled
    approach to processing natural language. In the following chapters, you’ll learn
    how you should approach this problem before writing a single line of code and
    how to build a custom-made NLP application just for your task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.3 AI, ML, DL, and NLP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before delving into the details of NLP, it’d be useful to clarify how it relates
    to other, similar fields. Most of you have at least heard about artificial intelligence
    (AI) and machine learning (ML). You may also have heard of deep learning (DL),
    because it’s generating a lot of buzz in popular media these days. Figure 1.2
    illustrates how those different fields overlap with each other.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F02_Hagiwara](../Images/CH01_F02_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2 The relationship among different fields: AI, ML, DL, and NLP'
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence (AI) is a broad umbrella field that is concerned with
    achieving human-like intelligence using machines. It encompasses a wide range
    of subfields, including machine learning, natural language processing, computer
    vision, and speech recognition. The field also includes subfields such as reasoning,
    planning, and search, which do not fall under either machine learning or natural
    language processing and are not in the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning (ML) is usually considered a subfield of artificial intelligence
    that is about improving computer algorithms through experience and data. This
    includes learning a general function that maps inputs to outputs based on past
    experience (supervised learning), drawing hidden patterns and structures from
    data (unsupervised learning), and learning how to act in a dynamic environment
    based on indirect rewards (reinforcement learning). Throughout this book, we’ll
    make a heavy use of supervised machine learning, which is the main paradigm for
    training NLP models.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning (DL) is a subfield of machine learning that usually uses deep
    neural networks. These neural network models are called “deep” because they consist
    of a number of layers. A *layer* is just a fancy word for a substructure of neural
    networks. By having many stacked layers, deep neural networks can learn complex
    representations of data and can capture highly complicated relationships between
    the input and the output.
  prefs: []
  type: TYPE_NORMAL
- en: As the amount of available data and computational resources increases, modern
    NLP makes a heavier and heavier use of machine learning and deep learning. Modern
    NLP applications and tasks are usually built on top of machine learning pipelines
    and trained from data. But also notice in figure 1.2 that a part of NLP does not
    overlap with machine learning. Traditional methods such as counting words and
    measuring similarities between text are usually not considered to be machine learning
    techniques per se, although they can be important building blocks for ML-based
    models.
  prefs: []
  type: TYPE_NORMAL
- en: I’d also like to mention some other fields that are related to NLP. One such
    field is *computational linguistics* (CL). As its name suggests, computational
    linguistics is a subfield of linguistics that uses computational approaches to
    study human language. The main distinction between CL and NLP is that the former
    encompasses scientific approaches to study language, whereas the latter is concerned
    with engineering approaches for making computers perform something useful related
    to language. People often use those terms interchangeably, partly due to some
    historical reasons. For example, the most prestigious conference in the field
    of NLP is called ACL, which actually stands for “the Association for Computational
    Linguistics!”
  prefs: []
  type: TYPE_NORMAL
- en: Another related field is *text mining*. Text mining is a type of data mining
    targeted at textual data. Its focus is on drawing useful insights from unstructured
    textual data, which is a type of text data that is not formatted in a form that
    is easily interpretable by computers. Such data is usually collected from various
    sources, such as crawling the web and social media. Although its purpose is slightly
    different from that of NLP, these two fields are similar, and we can use the same
    tools and algorithms for both.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.4 Why NLP?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are reading this, you have at least some interest in NLP. Why is NLP
    exciting? Why is it worth learning more about NLP and, specifically, real-world
    NLP?
  prefs: []
  type: TYPE_NORMAL
- en: The first reason is that NLP is booming. Even without the recent AI and ML boom,
    NLP is more important than ever. We are witnessing the advent of practical NLP
    applications in our daily lives, such as conversational agents (think Apple Siri,
    Amazon Alexa, and Google Assistant) and near human-level machine translation (think
    Google Translate). A number of NLP applications are already an integral part of
    our day-to-day activities, such as spam filtering, search engines, and spelling
    correction, as we’ll discuss later. The number of Stanford students enrolled in
    NLP classes grew fivefold from 2008 to 2018 ([http://realworldnlpbook.com/ch1.html#tweet1](http://realworldnlpbook.com/ch1.html#tweet1)).
    Similarly, the number of attendees for EMNLP (Empirical Methods in Natural Language
    Processing), one of the top NLP conferences, doubled within just one year ([http://realworldnlpbook
    .com/ch1.html#tweet2](http://realworldnlpbook.com/ch1.html#tweet2)). Other major
    NLP conferences are also experiencing similar increases in participants and paper
    submissions ([http://realworldnlpbook.com/ch1 .html#nivre17](http://realworldnlpbook.com/ch1.html#nivre17)).
  prefs: []
  type: TYPE_NORMAL
- en: The second reason is that NLP is an evolving field. The field of NLP itself
    has a long history. The first experiment to build a machine translation system,
    called *The Georgetown-IBM Experiment*, was attempted back in 1954\. For more
    than 30 years since this experiment, most NLP systems relied on handwritten rules.
    Yes, it was not much different from what you just saw in section 1.1.1\. The first
    milestone, which came in the late 1980s, was the use of statistical methods and
    machine learning for NLP. Many NLP systems started leveraging statistical models
    trained from data. This led to some recent successes in NLP, including, most notably,
    IBM Watson. The second milestone was more drastic. Starting around the late 2000s,
    the use of so-called deep learning, that is, deep neural network models, took
    the field by storm. By the mid-2010s, deep neural network models became the new
    standard in the field.
  prefs: []
  type: TYPE_NORMAL
- en: This second milestone was so drastic and fast that it’s worth noting here. New
    neural network-based NLP models are not only more effective but also a lot simpler.
    For example, it used to take a lot of expertise and effort to replicate even a
    simple, baseline machine translation model. One of the most popular open source
    software packages for statistical machine translation, called Moses ([http://www.statmt.org/moses/](http://www.statmt.org/moses/)),
    is a behemoth, consisting of 100,000s of lines of code and dozens of supporting
    modules and tools. Experts spent hours just installing the software and making
    it work. On the other hand, as of 2018, anyone with some prior programming experience
    could run a neural machine translation system more powerful than traditional statistical
    models with a fraction of the code size—less than a few thousand lines of code
    (e.g., see TensorFlow’s neural machine translation tutorial at [https://github.com/tensorflow/nmt](https://github.com/tensorflow/nmt)).
    Also, the new neural network models are trained “end-to-end,” which means that
    those big, monolithic networks take the input and directly produce the output.
    Entire models are trained to match the desired output. On the other hand, traditional
    machine learning models consist of (at least) several submodules. These submodules
    are trained separately using different machine learning algorithms. In this book,
    I’ll mainly discuss modern neural network-based approaches to NLP but also touch
    upon some traditional concepts as well.
  prefs: []
  type: TYPE_NORMAL
- en: The third and final reason is that NLP is challenging. Understanding and producing
    language is the central problem of artificial intelligence, as we saw in the previous
    section. The accuracy and performance in major NLP tasks such as speech recognition
    and machine translation got drastically better in the past decade or so. But human-level
    understanding of language is far from being solved.
  prefs: []
  type: TYPE_NORMAL
- en: 'To verify this quickly, open up your favorite machine translation service (or
    simply Google Translate), and type this sentence: “I saw her duck.” Try to translate
    it to Spanish or some other language you understand. You should see words like
    “*pato*,” which means “a duck” in Spanish. But did you notice another interpretation
    of this sentence? See figure 1.3 for the two interpretations. The word “duck”
    here could be a verb meaning “to crouch down.” Try adding another sentence after
    this, such as “She tried to avoid a flying ball.” Did the machine translation
    change the first translation in any way? The answer is probably no. You should
    still see the same “*pato*” in the translation. As you can see, most (if not all)
    commercial machine translation systems that are available as of today do not understand
    the context outside of the sentence that is being translated. A lot of research
    effort is spent on this problem in academia, but this is still one of many problems
    in NLP that is considered unsolved.'
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F03_Hagiwara](../Images/CH01_F03_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 Two interpretations of “I saw her duck.”
  prefs: []
  type: TYPE_NORMAL
- en: Compared to other AI fields such as robotics and computer vision, language has
    its own quirks. Unlike images, utterances and sentences have variable length.
    You can say a very short sentence (“Hello.”) or a very long one (“A quick brown
    fox . . .”). Most machine learning algorithms are not good at dealing with something
    of variable length, and you need to come up with ways to represent languages with
    something more fixed. If you look back at the history of the field, NLP is largely
    concerned with the problem of how to *represent* language mathematically. Vector
    space models and word embeddings (discussed in chapter 3) are some examples of
    this.
  prefs: []
  type: TYPE_NORMAL
- en: Another characteristic of language is that it is *discrete*. What this means
    is that things in languages are separate as concepts. For example, if you take
    a word “rat” and change its first letter to the next one, you’ll have “sat.” In
    computer memory, the difference is just a single bit. However, there is no relationship
    between those two words except they both end with “at,” and maybe a rat can sit.
    There is no such thing as something that is in between “rat” and “sat.” These
    two are totally discrete, separate concepts that happen to have similar spelling.
    On the other hand, if you take an image of a car and change the value of a pixel
    by a single bit, you still have a car that is almost identical to the one before
    this change. Maybe it has a slightly different color. In other words, images and
    sounds are continuous, meaning that you can make small modifications without greatly
    affecting what they are. Many mathematical toolkits, such as vectors, matrices,
    and functions, are good at dealing with something continuous. The history of NLP
    is actually a history of challenging this discreteness of language, and only recently
    have we begun to see some successes on this front, for example, with word embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 How NLP is used
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As I mentioned previously, NLP is already an integral part of our daily life.
    In modern life, a larger and larger portion of our daily communication is done
    online, and our online communication is still largely conducted in natural language
    text. Think of your favorite social networking services, such as Facebook and
    Twitter. Although you can post photos and videos, a large portion of communication
    is still in text. As long as you are dealing with text, there is a need for NLP.
    For example, how do you know if a particular post is spam? How do you know which
    posts are the ones you are most likely to “like?” How do you know which ads you
    are most likely to click?
  prefs: []
  type: TYPE_NORMAL
- en: Because many large internet companies need to deal with text in one way or another,
    chances are many of them are already using NLP. You can also confirm this from
    their “careers” page—you’ll see that they are always hiring NLP engineers and
    data scientists. NLP is also used to a varying extent in many other industries
    and products including, but not limited to, customer service, e-commerce, education,
    entertainment, finance, and health care, which all involve text in some ways.
  prefs: []
  type: TYPE_NORMAL
- en: Many NLP systems and services can be classified into or built by combining some
    major types of NLP applications and tasks. In this section, I’m going to introduce
    some of the most popular applications of NLP as well as common NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.1 NLP applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An NLP application is a software application whose main purpose is to process
    natural language text and draw some useful information from it. Similar to general
    software applications, it can be implemented in various ways, such as an offline
    data-processing script, an offline standalone application, a backend service,
    or a full-stack service with a frontend, depending on its scope and use cases.
    It can be built for end users to use directly, for other backend services to consume
    its output, or for other businesses to use as a SaaS (software as a service).
  prefs: []
  type: TYPE_NORMAL
- en: You can use many NLP applications out of the box, such as machine translation
    software and major SaaS products (e.g., Google Cloud API), if your requirement
    is generic and doesn’t require a high level of customization. You can also build
    your own NLP applications if you need customizations and/or you need to deal with
    a specific target domain. This is exactly what you’ll learn throughout this book!
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation is probably one of the most popular and easy-to-understand
    NLP applications. Machine translation (MT) systems translate a given text from
    one language to another language. An MT system can be implemented as a full-stack
    service (e.g., Google Translate), as well as a pure backend service (e.g., NLP
    SaaS products). The language the input text is written in is called *the source
    language*, whereas the one for the output is called *the target language*. MT
    encompasses a wide range of NLP problems, including language understanding and
    generation, because MT systems need to understand the input and then generate
    the output. MT is one of the most well-studied areas in NLP, and it was one of
    the earliest applications of NLP as well.
  prefs: []
  type: TYPE_NORMAL
- en: One challenge in MT is the tradeoff between *fluency* and *adequacy*. Translation
    needs to be fluent, meaning that the output has to sound natural in the target
    language. Translation also needs to be adequate, meaning that the output has to
    reflect the meaning expressed by the input as closely as possible. These two are
    often in conflict, especially when the source and the target languages are not
    very similar (e.g., English and Mandarin Chinese). You can write a sentence that
    is a precise, verbatim translation of the input, but doing so often leads to something
    that doesn’t sound natural in the target language. On the other hand, you can
    make up something that sounds natural but might not reflect the precise meaning.
    Good human translators address this tradeoff in a creative way. It’s their job
    to come up with translations that are natural in the target language while reflecting
    the meaning of the original.
  prefs: []
  type: TYPE_NORMAL
- en: Grammatical and spelling error correction
  prefs: []
  type: TYPE_NORMAL
- en: Most major web browsers nowadays support spelling correction. Even if you forget
    how to spell “Mississippi,” you can do your best and type what you remember, and
    the browser highlights it with a correction. Some word-processing software applications,
    including recent versions of Microsoft Word, do more than just correct spelling.
    They point out grammatical errors such as uses of “it’s” instead of “its.” This
    is not an easy feat, because both words are, in a sense, “correct” (no mistakes
    in spelling), and the system needs to infer whether they are used correctly from
    the context. Some commercial products (most notably, Grammarly, [https://www.grammarly.com/](https://www.grammarly.com/))
    specialize in grammatical error correction. Some products go a long way and point
    out incorrect usage of punctuation and even writing styles. These products are
    popular among both native and non-native speakers of the language.
  prefs: []
  type: TYPE_NORMAL
- en: Research into grammatical error correction has been active due to the increasing
    number of non-native English speakers. Traditionally, grammatical error correction
    systems for non-native English speakers dealt with individual types of mistakes
    one by one. For example, you could think of a subcomponent of the system that
    detects and corrects only incorrect uses of articles (*a*, *an*, *the*, etc.),
    which is very common among non-native English speakers. More recent approaches
    to grammatical error correction are similar to the ones for machine translation.
    You can think of the (potentially incorrect) input as one language and the corrected
    output as another. Then your job is to “translate” between these two languages!
  prefs: []
  type: TYPE_NORMAL
- en: Search engine
  prefs: []
  type: TYPE_NORMAL
- en: Another application of NLP that is already an integral part of our daily lives
    is search engines. Few people would think of search engines as an NLP application,
    yet NLP plays such an important role in making search engines useful that they
    are worth mentioning here.
  prefs: []
  type: TYPE_NORMAL
- en: Page analysis is one area where NLP is heavily used for search engines. Ever
    wonder why you don’t see any “hot dog” pages when you search for “dogs?” If you
    have any experience building your own full-text search engines using open source
    software such as Solr and Elasticsearch, and if you simply used a word-based index,
    your search result pages would be littered with “hot dogs,” even when you want
    just “dogs.” Major commercial search engines solve this problem by running the
    page content being indexed through NLP pipelines that recognize that “hot dogs”
    are not a type of “dogs.” But the extent and types of NLP pipelines that go into
    page analysis is confidential information for search engines and is difficult
    to know.
  prefs: []
  type: TYPE_NORMAL
- en: Query analysis is another NLP application in search engines. If you have noticed
    Google showing a box with pictures and bios when you search for a celebrity or
    a box with the latest news stories when you search for certain current events,
    that’s query analysis in action. Query analysis identifies the intent (what the
    user wants) of the query and shows relevant information accordingly. A common
    way to implement query analysis is to make it a classification problem, where
    an NLP pipeline classifies queries into classes of intent (e.g., celebrity, news,
    weather, videos), although again, the details of how commercial search engines
    run query analysis are usually highly confidential.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, search engines are not only about analyzing pages and classifying queries.
    They have many other functionalities that make your searches easier, one of which
    is query correction. This comes into play when you make a spelling or a grammatical
    mistake when formulating the query, and Google and other major search engines
    show corrections with labels such as “showing results for:” and “Did you mean.”
    How this works is somewhat similar to grammatical error correction that I mentioned
    earlier, except it is optimized for the types of mistakes and queries that search
    engine users use.
  prefs: []
  type: TYPE_NORMAL
- en: Dialog systems
  prefs: []
  type: TYPE_NORMAL
- en: Dialog systems are machines that humans can have conversations with. The field
    of dialog systems has a long history. One of the earliest dialog systems, ELIZA,
    was developed in 1966.
  prefs: []
  type: TYPE_NORMAL
- en: But it’s only recently that dialog systems have found their ways into our daily
    lives. We have seen an almost exponential increase in their popularity in recent
    years, mainly driven by the availability of consumer-facing “conversational AI”
    products such as Amazon Alexa and Google Assistant. In fact, according to a survey
    in 2018, 20% of US homes already own a smart speaker. You may also remember being
    mind-blown watching the keynote at Google IO in 2018, where Google’s conversational
    AI called Google Duplex was shown making a phone call to a hair salon and a restaurant,
    having natural conversations with the staff at the business, and making an appointment
    on behalf of its user.
  prefs: []
  type: TYPE_NORMAL
- en: The two main types of dialog systems are task-oriented and chatbots. Task-oriented
    dialog systems are used to achieve specific goals (for example, reserving a plane
    ticket), obtaining some information, and, as we saw, making a reservation at a
    restaurant. Task-oriented dialog systems are usually built as an NLP pipeline
    consisting of several components, including speech recognition, language understanding,
    dialog management, response generation, and speech synthesis, which are usually
    trained separately. Similar to machine translation, though, there are new deep
    learning approaches where dialog systems (or their subsystems) are trained end-to-end.
  prefs: []
  type: TYPE_NORMAL
- en: The other type of dialog system is chatbots, whose main purpose is to have conversations
    with humans. Traditional chatbots are usually managed by a set of handwritten
    rules (e.g., when the human says this, say that). Recently, the use of deep neural
    networks, particularly sequence-to-sequence models and reinforcement learning,
    has become increasingly popular. However, because the chatbots do not serve particular
    purposes, the evaluation of chatbots, that is, assessing how good a particular
    chatbot is, remains an open question.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.2 NLP tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Behind the scenes, many NLP applications are built by combining multiple NLP
    components that solve different NLP problems. In this section, I introduce some
    notable NLP tasks that are commonly used in NLP applications.
  prefs: []
  type: TYPE_NORMAL
- en: Text classification
  prefs: []
  type: TYPE_NORMAL
- en: Text classification is the process of classifying pieces of text into different
    categories. This NLP task is one of the simplest yet most widely used. You might
    not have heard of the term “text classification” before, but I bet most of you
    benefit from this NLP task every day. For example, spam filtering is one type
    of text classification. It classifies emails (or other types of text, such as
    web pages) into two categories—spam or not spam. This is why you get very few
    spam emails when you use Gmail and you see so few spammy (low-quality) web pages
    when you use Google.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of text classification is called *sentiment analysis*, which is
    what we saw in section 1.1\. Sentiment analysis is used to automatically identify
    subjective information, such as opinions, emotions, and feelings, within text.
  prefs: []
  type: TYPE_NORMAL
- en: Part-of-speech tagging
  prefs: []
  type: TYPE_NORMAL
- en: A *part of speech* (POS) is a category of words that share the similar grammatical
    properties. In English, for example, nouns describe the names of things like objects,
    animals, people, and concepts, among many other things. A noun can be used as
    a subject of a verb, an object of a verb, and an object of a preposition. Verbs,
    in contrast, describe actions, states, and occurrences. Other English parts of
    speech include adjectives (*green*, *furious*), adverbs (*cheerfully*, *almost*),
    determiners (*a*, *the*, *this*, *that*), prepositions (*in*, *from*, *with*),
    conjunctions (*and*, *yet*, *because*), and many others. Almost all languages
    have nouns and verbs, but other parts of speech differ from language to language.
    For example, many languages, such as Hungarian, Turkish, and Japanese, have *postpositions*
    instead of prepositions, which are placed *after* words to add some extra meaning
    to them. A group of NLP researchers came up with a set of tags that cover frequent
    parts of speech that exist in most languages, called a *universal part-of-speech
    tagset* ([http://realworldnlpbook.com/ch1.html#universal-pos](http://realworldnlpbook.com/ch1.html#universal-pos)).
    This tagset is widely used for language-independent tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Part-of-speech tagging is the process of tagging each word in a sentence with
    a corresponding part-of-speech tag. Some of you may have done this at school.
    As an example, let’s take the sentence “I saw a girl with a telescope.” The POS
    tags for this sentence are shown in figure 1.4.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F04_Hagiwara](../Images/CH01_F04_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 Part-of-speech (POS) tagging
  prefs: []
  type: TYPE_NORMAL
- en: These tags come from the Penn Treebank POS tagset, which is the most popular
    standard corpus for training and evaluating various NLP tasks such as POS tagging
    and parsing. Traditionally, POS tagging was solved by sequential labeling algorithms
    such as hidden Markov models (HMMs) and conditional random fields (CRFs). Recently,
    recurrent neural networks (RNNs) have become a popular and practical choice for
    training a POS tagger with high accuracy. The results of POS tagging are often
    used as the input to other downstream NLP tasks, such as machine translation and
    parsing. I’ll cover part-of-speech tagging in more detail in chapter 5.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing
  prefs: []
  type: TYPE_NORMAL
- en: Parsing is the task of analyzing the structure of a sentence. Broadly speaking,
    there are two main types of parsing, *constituency parsing* and *dependency parsing*,
    which we’ll discuss in detail next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Constituency parsing uses *context-free grammars* to represent natural language
    sentences. (See [http://mng.bz/GO5q](http://mng.bz/GO5q) for a brief introduction
    to context-free grammars). A context-free grammar is a way to specify how smaller
    building blocks of a language (e.g., words) are combined to form larger building
    blocks (e.g., phrases and clauses) and eventually sentences. To put it another
    way, it specifies how the largest unit (a sentence) is broken down to phrases
    and clauses and all the way down to words. The ways the linguistic units interact
    with each other are specified by a set of *production rules as follows*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: A production rule describes a transformation from the symbol on the left-hand
    side (e.g., “S”) to the symbols on the right-hand side (e.g., “NP VP”). The first
    rule means that a sentence is a noun phrase (NP) followed by a verb phrase (VP).
    Some of the symbols (e.g., DT, NN, VBD) may look familiar to you—yes, they are
    the POS tags we just saw in the POS tagging section. In fact, you can consider
    POS tags as the smallest grammatical categories that behave in similar ways (because
    they are!).
  prefs: []
  type: TYPE_NORMAL
- en: Now the parser’s job is to figure out how to reach the final symbol (in this
    case, “S”) starting from the raw words in the sentence. You can think of those
    rules as transformation rules from the symbols on the right to the ones on the
    left by traversing the arrow backward. For example, using the rule “DT  a” and
    “NN  girl,” you can convert “a girl” to “DT NN.” Then, if you use “NP  DT NN,”
    you can reduce the entire phrase to “NP.” If you illustrate this process in a
    tree-like diagram, you get something like the one shown in figure 1.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F05_Hagiwara](../Images/CH01_F05_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 Subtree for “a girl”
  prefs: []
  type: TYPE_NORMAL
- en: Tree structures that are created in the process of parsing are called *parse
    trees**,* or simply *parses*. The figure is a subtree because it doesn’t cover
    the entirety of the tree (i.e., it doesn’t show all the way from “S” to words).
    Using the sentence “I saw a girl with a telescope” that we discussed earlier and
    see if you can parse it by hand. If you keep breaking down the sentence using
    the production rules until you get the final “S” symbol, you get the tree-like
    structure shown in figure 1.6.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F06_Hagiwara](../Images/CH01_F06_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.6 Parse tree for “I saw a girl with a telescope.”
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry if the tree in figure 1.6 is different from what you got. Actually,
    there’s another parse tree that is a valid parse of this sentence, shown in figure
    1.7.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F07_Hagiwara](../Images/CH01_F07_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.7 Another parse tree for “I saw a girl with a telescope.”
  prefs: []
  type: TYPE_NORMAL
- en: If you look at those two trees carefully, you’ll notice a difference where the
    “PP” (prepositional phrase) is located, or attached. In fact, these two parse
    trees correspond to the two different interpretations of this sentence we discussed
    in section 1.1\. The first tree (figure 1.6), where the PP attaches the verb “saw,”
    corresponds to the interpretation where the boy is using a telescope to see the
    girl. In the second tree (figure 1.7), where the PP attaches to the noun “a girl,”
    the boy saw the girl who has a telescope. Parsing is a great step forward to reveal
    the structure and the semantics of a sentence, but in cases like this one, parsing
    alone cannot uniquely decide what is the single most likely interpretation of
    a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: The other type of parsing is called *dependency parsing*. Dependency parsing
    uses dependency grammars to describe the structure of sentences, not in terms
    of phrases but in terms of words and the binary relations between them. For example,
    the result of dependency parsing of the earlier sentence is shown in figure 1.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F08_Hagiwara](../Images/CH01_F08_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.8 Dependency parse for “I saw a girl with a telescope.”
  prefs: []
  type: TYPE_NORMAL
- en: Notice that each relation is directional and labeled. A relation specifies which
    word depends on which word and the type of relationship between the two. For example,
    the relation connecting “a” to “girl” is labeled “det,” meaning the first word
    is the determiner of the second. If you take the most central word, “saw,” and
    pull it upward, you’ll notice that these words and relations form a tree. Such
    trees are called *dependency trees*.
  prefs: []
  type: TYPE_NORMAL
- en: One advantage of dependency grammars is that they are agnostic regarding some
    word-order changes, meaning that the order of certain words in the sentence will
    not change the dependency tree. For example, in English, there is some freedom
    as to where to put an adverb in a sentence, especially when the adverb describes
    the manner in which the action referred to by the verb is done. For example, “I
    carefully painted the house” and “I painted the house carefully” are both acceptable
    and mean the same thing. If you represent these sentences by a dependency grammar,
    the word “carefully” always modifies the verb “painted,” and the two sentences
    have completely identical dependency trees. Dependency grammars capture more than
    just phrasal structures of sentences—they capture something more fundamental about
    the relationship of the words. Therefore, dependency parsing is considered an
    important step toward semantic analysis of natural language. A group of researchers
    is working on a formal language-independent dependency grammar, called Universal
    Dependencies, that is linguistically motivated and applicable to many languages,
    similar to the universal POS tagset.
  prefs: []
  type: TYPE_NORMAL
- en: Text generation
  prefs: []
  type: TYPE_NORMAL
- en: Text generation, also called *natural language generation* (NLG), is the process
    of generating natural language text from something else. In a broader sense, machine
    translation, which we discussed previously, involves a text-generation problem,
    because MT systems need to generate text in the target language. Similarly, summarization,
    text simplification, and grammatical error correction all produce natural language
    text as output and are instances of text-generation tasks. Because all of these
    tasks take natural language text as their input, they are called *text-to-text*
    generation.
  prefs: []
  type: TYPE_NORMAL
- en: Another class of text-generation task is called *data-to-text* generation. For
    those tasks, the input is data that is not text. For example, a dialog system
    needs to generate natural utterances based on the current state of the conversation.
    A publisher may wish to generate news text based on events such as sports game
    outcomes and weather. There is also a growing interest in generating natural language
    text that best describes a given image, called *image captioning*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a third class of text classification is unconditional text generation,
    where natural language text is generated randomly from a model. You can train
    models so that they can generate random academic papers, Linux source code, or
    even poems and play scripts. For example, Andrej Karpathy trained an RNN model
    from all of Shakespeare’s works and succeeded in generating pieces of text that
    look exactly like his work ([http://realworldnlpbook.com/ch1.html#karpathy15](http://realworldnlpbook.com/ch1.html#karpathy15)),
    as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Traditionally, text generation has been solved by handcrafted templates and
    rules for generating text from some information. You can think of this as the
    reverse of parsing, where rules are used to infer information about natural language
    text, as we discussed earlier. In recent years, neural network models are an increasingly
    popular choice for natural language generation, be it text-to-text generation
    (sequence-to-sequence models), data-to-text generation (encoder-decoder models),
    and unconditional text generation (neural language models and generative adversarial
    networks, or GANs). We’ll discuss text generation more in chapter 5.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Building NLP applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, I’m going to show you how NLP applications are typically developed
    and structured. Although details may vary on a case-by-case basis, understanding
    the typical process helps you plan and budget before you start developing an application.
    It also goes a long way if you know best practices in developing NLP applications
    beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.1 Development of NLP applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The development of NLP applications is a highly iterative process, consisting
    of many phases of research, development, and operations (figure 1.9). Most learning
    materials such as books and online tutorials focus mainly on the training phase,
    although all the other phases of application development are equally important
    for real-world NLP applications. In this section, I briefly introduce what each
    stage involves. Note that no clear boundary exists between these phases. It is
    not uncommon that application developers (researchers, engineers, managers, and
    other stakeholders) go back and forth between some of these phases through trial
    and error.
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F09_Hagiwara](../Images/CH01_F09_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.9 The development cycle of NLP applications
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection
  prefs: []
  type: TYPE_NORMAL
- en: Most modern NLP applications are based on machine learning. Machine learning,
    by definition, requires data on which NLP models are trained (remember the definition
    of ML we talked about previously—it’s about improving algorithms through data).
    In this phase, NLP application developers discuss how to formulate the application
    as an NLP/ML problem and what kind of data should be collected. Data can be collected
    from humans (e.g., by hiring in-house annotators and having them go through a
    bunch of text instances), crowdsourcing (e.g., using platforms such as Amazon
    Mechanical Turk), or automated mechanisms (e.g., from application logs or clickstreams).
  prefs: []
  type: TYPE_NORMAL
- en: You may choose not to use machine learning approaches for your NLP application
    at first, which could totally be the right choice depending on various factors,
    such as time, budgets, the complexity of the task, and the expected amount of
    data you might be able to collect. Even in that case, it may be a good idea to
    collect a small amount of data for validation purposes. I’ll talk more about training,
    validation, and testing of NLP applications in chapter 11.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis and experimenting
  prefs: []
  type: TYPE_NORMAL
- en: 'After collecting the data, you move on to the next phase where you analyze
    and run some experiments. For analyses, you usually look for signals such as:
    What are the characteristics of the text instances? How are the training labels
    distributed? Can you come up with signals that are correlated with the training
    labels? Can you come up with some simple rules that can predict the training labels
    with reasonable accuracy? Should we even use ML? This list goes on and on. This
    analysis phase includes aspects of data science, where various statistical techniques
    may come in handy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You run experiments to try a number of prototypes quickly. The goal in this
    phase is to narrow down the possible set of approaches to a couple of promising
    ones, before you go all-in and start training a gigantic model. By running experiments,
    you wish to answer questions including: What types of NLP tasks and approaches
    are appropriate for this NLP application? Is this a classification, parsing, sequence
    labeling, regression, text generation, or some other problem? What is the performance
    of the baseline approach? What is the performance of the rule-based approach?
    Should we even use ML? What is the estimate of training and serving time for the
    promising approaches?'
  prefs: []
  type: TYPE_NORMAL
- en: I call these first two phases the “research” phase. The existence of this phase
    is arguably the biggest difference between NLP applications and other generic
    software systems. Due to its nature, it is difficult to predict the performance
    and the behavior of a machine learning system, or an NLP system, for that matter.
    At this point, you might not have written a single line of production code, and
    that’s totally fine. The point of this research phase is to prevent you from wasting
    your effort writing production code that turns out to be useless at a later stage.
  prefs: []
  type: TYPE_NORMAL
- en: Training
  prefs: []
  type: TYPE_NORMAL
- en: At this point you have pretty clear ideas what the approaches will be for your
    NLP application. This is when you start adding more data and computational resources
    (e.g., GPUs) for training your model. It is not uncommon for modern NLP models
    to take days if not weeks to train, especially if they are based on neural network
    models. It is always a good practice to gradually ramp up the amount of the data
    and the size of the model you train. You don’t want to spend weeks training a
    gigantic neural network model only to find that a smaller and simpler model performs
    just as well, or even worse, that you introduced a bug in the model and that the
    model you spent weeks training is simply useless!
  prefs: []
  type: TYPE_NORMAL
- en: It is critical at this phase that you keep your training pipeline reproducible.
    Chances are, you will need to run this several times with different sets of hyperparameters,
    which are tuning values set before starting the model’s learning process. It is
    also likely that you will need to run this pipeline several months later, if not
    years. I’ll touch upon some best practices when training NLP/ML models in chapter
    10.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have a model that is working with acceptable performance, you move
    on to the implementation phase. This is when you start making your application
    “production ready.” This process basically follows software engineering best practices,
    including: writing unit and integration tests for your NLP modules, refactoring
    your code, having your code reviewed by other developers, improving the performance
    of your NLP modules, and dockerizing your application. I’ll talk more about this
    process in chapter 11.'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying
  prefs: []
  type: TYPE_NORMAL
- en: Your NLP application is finally ready to deploy. You can deploy your NLP application
    in many ways—it can be an online service, a recurring batch job, an offline application,
    or an offline one-off task. If this is an online service that needs to serve its
    predictions in real time, it is a good idea to make this a *microservice* to make
    it loosely coupled with other services. In any case, it is a good practice to
    use continuous integration (CI) for your application, where you run tests and
    verify that your code and model are working as intended every time you make changes
    to your application.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs: []
  type: TYPE_NORMAL
- en: 'An important final step for developing NLP applications is monitoring. This
    not only includes monitoring the infrastructure such as server CPU, memory, and
    request latency, but also higher-level ML statistics such as the distributions
    of the input and the predicted labels. Some of the important questions to ask
    at this stage are: What do the input instances look like? Are they what you expected
    when you built your model? What do the predicted labels look like? Does the predicted
    label distribution match the one in the training data? The purpose of the monitoring
    is to check that the model you built is behaving as intended. If the incoming
    text or data instances or the predicted labels do not match your expectation,
    you may have an out-of-domain problem, meaning that the domain of the natural
    language data you are receiving is different from the one in which your model
    is trained. Machine learning models are usually not good at dealing with out-of-domain
    data, and the prediction accuracy may suffer. If this issue becomes obvious, it
    may be a good idea to repeat the whole process again, starting from collecting
    more in-domain data.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.2 Structure of NLP applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The structures of modern, machine learning-based NLP applications are becoming
    surprisingly similar for two main reasons—one is that most modern NLP applications
    rely on machine learning to some degree, and they should follow best practices
    for machine learning applications. The other is that, due to the advent of neural
    network models, a number of NLP tasks, including text classification, machine
    translation, dialog systems, and speech recognition, can now be trained end-to-end,
    as I mentioned before. Some of these tasks used to be hairy, enormous monsters
    with dozens of components with complex plumbing. Now, however, some of these tasks
    can be solved by less than 1,000 lines of Python code, provided that there’s enough
    data to train the model end-to-end.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.10 illustrates the typical structure of a modern NLP application.
    There are two main infrastructures: the training and the serving infrastructure.
    The training infrastructure is usually offline and serves the purpose of training
    the machine learning model necessary for the application. It takes the training
    data, converts it to some data structure that can be handled by the pipeline,
    and further processes it by transforming the data and extracting the features.
    This part varies greatly from task to task. Finally, if the model is a neural
    network, data instances are batched and fed to the model, which is optimized to
    minimize the loss. Don’t worry if you don’t understand what I’m talking about
    in that last sentence—we’ll talk about those technical terms used with neural
    networks in chapter 2\. The trained model is usually serialized and stored to
    be passed to the serving infrastructure.'
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F10_Hagiwara](../Images/CH01_F10_Hagiwara.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.10 Structure of typical NLP applications
  prefs: []
  type: TYPE_NORMAL
- en: The serving infrastructure’s job is to, given a new instance, produce the prediction,
    such as classes, tags, or translations. The first part of this infrastructure,
    which reads the instance and transforms it into some numbers, is similar to the
    one for training. In fact, you must keep the dataset reader and the transformer
    identical. Otherwise, discrepancies will arise in the way those two process the
    data, also known as *training-serving skew*. After the instance is processed,
    it’s fed to the pretrained model to produce the prediction. I’ll talk more about
    designing your NLP applications in chapter 11.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Natural language processing (NLP) is a subfield of artificial intelligence (AI)
    that refers to computational approaches to process, understand, and generate human
    language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the challenges for NLP is ambiguity in natural languages. There is syntactic
    and semantic ambiguity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where there is text, there is NLP. Many tech companies use NLP to draw information
    from a large amount of text. Typical NLP applications include machine translation,
    grammatical error correction, search engines, and dialog systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLP applications are developed in an iterative way, with more emphasis on the
    research phase.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many modern NLP applications rely heavily on machine learning (ML) and are structurally
    similar to ML systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
