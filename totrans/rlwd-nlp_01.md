# 前言

## 前言

在过去二十年里，我一直在机器学习（ML）、自然语言处理（NLP）和教育的交叉领域工作，我一直热衷于教育和帮助人们学习新技术。这就是为什么当我听说有机会出版一本关于 NLP 的书时，我毫不犹豫地接受了。

过去几年，人工智能（AI）领域经历了许多变化，包括基于神经网络的方法的爆炸式普及和大规模预训练语言模型的出现。这一变化使得许多先进的语言技术成为可能，其中包括你每天都会与之交互的语音虚拟助手、语音识别和机器翻译等。然而，NLP 的“技术堆栈”，以预训练模型和迁移学习为特征，最近几年已经稳定下来，并预计将保持稳定，至少在未来几年内。这就是为什么我认为现在是开始学习 NLP 的好时机。

编写一本关于 AI 的书绝非易事。感觉就像你在追逐一个不会减速等待你的移动目标。当我开始写这本书时，Transformer 刚刚发布，BERT 还不存在。在写作过程中，我们在这本书中使用的主要 NLP 框架 AllenNLP 经历了两次重大更新。很少有人使用 Hugging Face Transformer，这是一款广受欢迎的深度 NLP 库，目前被全球许多实践者使用。在两年内，由于 Transformer 和预训练语言模型（如 BERT）的出现，NLP 领域的格局发生了彻底的变化。好消息是，现代机器学习的基础，包括单词和句子嵌入、RNN 和 CNN，尚未过时，并且仍然重要。本书旨在捕捉帮助您构建真实世界 NLP 应用程序的思想和概念的“核心”。

市场上有许多关于 ML 和深度学习的优秀书籍，但其中一些过分强调数学和理论。书籍教授的内容与行业需求存在差距。我希望这本书能填补这一差距。

## 致谢

没有许多人的帮助，这本书是不可能完成的。我必须首先感谢 Manning 出版社的开发编辑 Karen Miller。在编写这本书的过程中，感谢你的支持和耐心。我还要感谢 Manning 团队的其他成员：技术开发编辑 Mike Shepard、审稿编辑 Adriana Sabo、制作编辑 Deirdre Hiam、副本编辑 Pamela Hunt、校对员 Keri Hales 和技术校对员 Mayur Patil。Denny（[`www.designsonline.id/`](http://www.designsonline.id/)）还为本书创作了一些高质量的插图。

我还要感谢在阅读本书手稿后提供宝贵反馈的审稿人：Al Krinker、Alain Lompo、Anutosh Ghosh、Brian S. Cole、Cass Petrus、Charles Soetan、Dan Sheikh、Emmanuel Medina Lopez、Frédéric Flayol、George L. Gaines、James Black、Justin Coulston、Lin Chen、Linda Ristevski、Luis Moux、Marc-Anthony Taylor、Mike Rosencrantz、Nikos Kanakaris、Ninoslav Čerkez、Richard Vaughan、Robert Diana、Roger Meli、Salvatore Campagna、Shanker Janakiraman、Stuart Perks、Taylor Delehanty 和 Tom Heiman。

我要感谢 Allen Institute for Artificial Intelligence 的 AllenNLP 团队。我与该团队的 Matt Gardner、Mark Neumann 和 Michael Schmitz 进行了很好的讨论。我一直钦佩他们的优秀工作，使深度 NLP 技术易于访问并普及于世界。

最后，但同样重要的是，我要感谢我的出色妻子 Lynn。她不仅帮助我选择了本书的正确封面图像，而且在整本书的编写过程中一直理解和支持我的工作。

## 关于本书

*实战自然语言处理*不是一本典型的 NLP 教材。我们专注于构建实际的 NLP 应用程序。这里的*实战*有两层含义：首先，我们关注构建实际 NLP 应用程序所需的内容。作为读者，您将学习不仅如何训练 NLP 模型，还将学习如何设计、开发、部署和监控它们。在这一过程中，您还将了解到现代 NLP 模型的基本构建模块，以及对构建 NLP 应用程序有用的 NLP 领域的最新发展。其次，与大多数入门书籍不同，我们采用自顶向下的教学方法。我们不是采用自下而上的方法，一页页地展示神经网络理论和数学公式，而是专注于快速构建“只管用”的 NLP 应用程序。然后，我们深入研究构成 NLP 应用程序的各个概念和模型。您还将学习如何使用这些基本构建模块构建符合您需求的端到端定制 NLP 应用程序。

### 谁应该阅读本书

本书主要面向希望学习 NLP 基础知识以及如何构建 NLP 应用程序的软件工程师和程序员。我们假设您，读者，在 Python 中具有基本的编程和软件工程技能。如果您已经从事机器学习工作，但希望转入 NLP 领域，本书也会很有用。无论哪种情况，您都不需要任何 ML 或 NLP 的先前知识。您不需要任何数学知识来阅读本书，尽管对线性代数的基本理解可能会有所帮助。本书中没有一个数学公式。

### 本书的组织方式：路线图

本书共分三部分，共包括 11 章。第一部分涵盖了自然语言处理（NLP）的基础知识，在这里我们学习如何使用 AllenNLP 快速构建 NLP 应用程序，包括情感分析和序列标注等基本任务。

+   第一章从介绍自然语言处理的“什么”和“为什么”开始——什么是自然语言处理，什么不是自然语言处理，自然语言处理技术如何被使用，以及自然语言处理与其他人工智能领域的关系。

+   第二章演示了如何构建您的第一个自然语言处理应用程序，即情感分析器，并介绍了现代自然语言处理模型的基础——词嵌入和循环神经网络（RNNs）。

+   第三章介绍了自然语言处理应用程序的两个重要构建块，即词嵌入和句子嵌入，并演示了如何使用和训练它们。

+   第四章讨论了最简单但最重要的自然语言处理任务之一，即句子分类，以及如何使用循环神经网络（RNNs）来完成此任务。

+   第五章涵盖了诸如词性标注和命名实体提取之类的序列标注任务。它还涉及到一种相关技术，即语言建模。

第二部分涵盖了包括序列到序列模型、Transformer 以及如何利用迁移学习和预训练语言模型来构建强大的自然语言处理应用在内的高级自然语言处理主题。

+   第六章介绍了序列到序列模型，它将一个序列转换为另一个序列。我们在一个小时内构建了一个简单的机器翻译系统和一个聊天机器人。

+   第七章讨论了另一种流行的神经网络架构，卷积神经网络（CNNs）。

+   第八章深入探讨了 Transformer，这是当今最重要的自然语言处理模型之一。我们将演示如何使用 Transformer 构建一个改进的机器翻译系统和一个拼写检查器。

+   第九章在上一章的基础上展开，并讨论了迁移学习，这是现代自然语言处理中的一种流行技术，使用预训练的语言模型如 BERT。

第三部分涵盖了在开发对真实世界数据具有鲁棒性、并进行部署和提供的自然语言处理应用程序时变得相关的主题。

+   第十章详细介绍了开发自然语言处理应用程序时的最佳实践，包括批处理和填充、正则化以及超参数优化。

+   第十一章通过讨论如何部署和提供自然语言处理模型来结束本书。它还涵盖了如何解释和解释机器学习模型。

### 关于代码

本书包含许多源代码示例，既有编号列表，也有与普通文本一样的行内代码。在这两种情况下，源代码都以像这样的固定宽度字体格式化，以使其与普通文本分开。有时代码也会**加粗**，以突出显示与章节中的先前步骤有所不同的代码，例如当一个新功能添加到现有代码行时。

在许多情况下，原始源代码已经被重新格式化；我们已经添加了换行符并重新安排了缩进以适应书中可用的页面空间。在罕见情况下，即使这样做还不够，列表中也包括了行继续标记（➥）。此外，当文本中描述代码时，源代码中的注释通常会被从列表中移除。代码注释伴随着许多列表，突出显示重要概念。

本书示例中的代码可从 Manning 网站（[`www.manning.com/books/real-world-natural-language-processing`](https://www.manning.com/books/real-world-natural-language-processing)）和 GitHub（[`github.com/mhagiwara/realworldnlp`](https://github.com/mhagiwara/realworldnlp)）下载。

大部分代码也可以在 Google Colab 上运行，这是一个免费的基于网络的平台，您可以在其中运行您的机器学习代码，包括 GPU 硬件加速器。

### liveBook 讨论论坛

购买《实用自然语言处理》包含免费访问 Manning Publications 运行的私人网络论坛，您可以在该论坛上对书籍发表评论，提出技术问题，并从作者和其他用户那里获得帮助。要访问论坛，请转到 [`livebook.manning.com/book/real-world-natural -language-processing/discussion`](https://livebook.manning.com/book/real-world-natural-language-processing/discussion)。您还可以在 [`livebook.manning.com/#!/discussion`](https://livebook.manning.com/#!/discussion) 上了解更多关于 Manning 论坛和行为规则的信息。

Manning 对我们的读者的承诺是提供一个场所，让个体读者和读者与作者之间进行有意义的对话。这不是对作者参与的任何具体数量的承诺，作者对论坛的贡献仍然是自愿的（且无偿的）。我们建议您尝试向作者提出一些具有挑战性的问题，以免他的兴趣减退！只要本书在印刷状态下，论坛和之前讨论的存档将可以从出版商的网站上访问到。

### 其他在线资源

我们在本书中大量使用的两个自然语言处理框架，AllenNLP 和 Hugging Face Transformers，都有很棒的在线课程（[`guide.allennlp.org/`](https://guide.allennlp.org/) 和 [`huggingface.co/course`](https://huggingface.co/course)），您可以在这些课程中学习自然语言处理的基础知识以及如何使用这些库来解决各种自然语言处理任务。

## 关于作者

| ![Hagiwara](img/Hagiwara.jpg) | **萩原真人**于 2009 年从名古屋大学获得计算机科学博士学位，专注于自然语言处理和机器学习。他曾在谷歌和微软研究院实习，并在百度、乐天技术研究所和 Duolingo 工作过，担任工程师和研究员。他现在经营自己的研究和咨询公司 Octanove Labs，专注于自然语言处理在教育应用中的应用。 |
| --- | --- |

## 关于封面插图

封面上的图案*Real-World Natural Language Processing*的标题是“Bulgare”，或者来自保加利亚的人。 这幅插图摘自雅克·格拉塞·德·圣索维尔（1757–1810）的各国服装收藏品，该收藏品名为*Costumes de Différents Pays*，于 1797 年在法国出版。 每幅插图都是精细绘制和手工上色的。 格拉塞·德·圣索维尔收藏的丰富多样性生动地提醒我们，仅 200 年前世界各地的城镇和地区在文化上是多么独立。 人们相互隔离，使用不同的方言和语言。 在街头或乡间，仅凭着他们的服装就可以轻易辨别他们住在哪里，以及他们的职业或生活地位。

自那时以来，我们的着装方式已经发生了变化，那时如此丰富的地区多样性已经消失。 现在很难区分不同大陆的居民，更不用说不同的城镇、地区或国家了。 或许我们已经用文化多样性换取了更丰富多彩的个人生活——当然也换来了更丰富多样和快节奏的技术生活。

在很难辨认出一本计算机书籍与另一本书籍之时，曼宁通过基于两个世纪前区域生活丰富多样性的书籍封面，庆祝计算机业的创造力和主动性，这些生活被格拉塞·德·圣索维尔的图片重新唤起。
