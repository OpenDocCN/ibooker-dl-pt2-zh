- en: Appendix. Solutions to the exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A.1 Chapter 2: Gaussian processes as distributions over functions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we train a GP on a real-world dataset we saw in chapter 1\.
    The solution is included in the CH02/02 - Exercise.ipynb notebook. Complete the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the four-dimensional dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first import the necessary libraries: PyTorch for array/tensor manipulation,
    GPyTorch for GP modeling, and Matplotlib for visualization:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then store the numbers in the table in two PyTorch tensors, `train_x` and
    `train_y`, which, respectively, contain the features and labels of our dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Normalize the fifth column by subtracting the mean from all values and dividing
    the results by their standard deviation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We normalize the labels as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When printed out, `train_y` should contain the following values: `tensor([-0.4183,`
    `1.4974,` `-0.5583,` `-0.5207])`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Treat the first four columns as features and the fifth as labels. Train a GP
    on this data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We reimplement our GP model class as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then initialize an object of this class with our training data:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a test dataset containing compositions with zero percent germanium and
    manganese.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To assemble our test dataset, we first create a mesh grid for the first and
    second columns that spans over the unit square:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'These first two columns are stored in `grid_x1` and `grid_x2`. We then append
    two additional, all-zero columns to `grid_x1` and `grid_x2`, completing the test
    set with four columns:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ First column
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Second column
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Third column, containing all zeros
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Forth column, containing all zeros
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Predict the mixing temperature on this test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To make predictions on this test set, we simply pass `xs` through our GP model
    under the `torch.no_grad()` context:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Visualize the predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To visualize these predictions, we first create a figure with two panels (that
    is, two Matplotlib subplots):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then use `plt.imshow()` to visualize the mean and standard deviation vectors
    as heat maps, making sure to reshape the two vectors into square matrices:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Heat map for the predictive mean
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Heat map for the predictive standard deviation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This will create plots similar to those in figure A.1.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A.1 Predictions made by a GP on a 2-dimensional space
  prefs: []
  type: TYPE_NORMAL
- en: Note If you are using a different GP implementation, it’s entirely possible
    to produce heat maps that are slightly different from those in figure A.1\. As
    long as the general trend of the heat maps is the same, your solution is correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'A.2 Chapter 3: Incorporating prior knowledge with the mean and covariance functions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise provides practice for implementing a GP model with automatic
    relevance determination (ARD). The solution is included in CH03/03 - Exercise.ipynb.
    Complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Implement the two-dimensional function in Python using PyTorch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first import the necessary libraries—PyTorch for array/tensor manipulation,
    GPyTorch for GP modeling, and Matplotlib for visualization:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then implement the objective function using the given formula:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Visualize the function over the domain [`0,` `2`]².
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To visualize the function, we need to create a mesh grid the domain. We store
    this grid in `xs`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ One-dimensional grid
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Two-dimensional grid
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We then can obtain the function values over this grid by passing `xs` to `f()`.
    The results are stored in `ys`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We use `plt.imshow()` to visualize `ys` as a heat map:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Randomly draw 100 data points from the domain [`0,` `2`]². This will be used
    as our training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To randomly sample 100 points within the domain, we use `torch.rand()` to sample
    from the unit square, and then we multiply the result by 2 to scale it to our
    domain:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The function values of these points can be obtained by calling `f(train_x)`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement a GP model with a constant mean function and a Matérn 5/2 kernel
    with an output scale implemented as a `gpytorch.kernels.ScaleKernel` object. We
    implement our GP model as specified:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Set to None to disable ARD and 2 to enable ARD.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Don’t specify the `ard_num_dims` parameter when initializing the kernel object
    or set the parameter to `None`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is done in the previous code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Train the hyperparameters of the GP model using gradient descent, and inspect
    the length scale after training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We initialize our GP and train it using gradient descent for 500 iterations
    as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Enables the training model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Gradient descent to optimize the GP’s hyperparameters
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Enables the prediction model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After these 500 iterations, we inspect the length scale by printing out the
    following value:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In other words, the optimized length scale is equal to roughly 1.15.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Redefine the GP model class, this time setting `ard_num_dims` `=` `2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Setting `ard_num_dims=2` in the `GPModel` class and rerunning all the code
    cells, we obtain the following values for the length scales:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, the length scale of the first dimension is large (roughly 1.70), while
    the length scale of the second dimension is small (roughly 0.87). This corresponds
    to the fact that the objective function varies more along the second dimension.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.3 Chapter 4: Refining the best result with improvement-based policies'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two exercises in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The first covers a way of refining the Probability of Improvement (PoI) policy,
    allowing it to better explore the search space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second applies the two BayesOpt policies we have learned to a simulated
    real-world task of hyperparameter tuning.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A.3.1 Exercise 1: Encouraging exploration with Probability of Improvement'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise, implemented in the CH04/02 - Exercise 1.ipynb notebook, walks
    us through how to modify PoI to encourage exploration. Complete the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt loop in the CH04/01 - BayesOpt loop notebook, which uses
    the one-dimensional Forrester function as the optimization objective.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before the `for` loop that implements BayesOpt, declare a variable named `epsilon`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the `for` loop, initialize the PoI policy as before, but this time,
    specify that the incumbent threshold, set by the `best_f` argument, is the incumbent
    value *plus* the value stored in `epsilon`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Rerun the notebook, and observe whether this modification leads to better optimization
    performance than the original PoI policy by encouraging more exploration, as shown
    in figure A.2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-02.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.2 Optimization progress of the modified PoI at the last iteration.
    The policy has found the optimum.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, the modified PoI has found the optimum.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How much more explorative PoI becomes heavily depends on the minimum improvement
    threshold stored in `epsilon`. Setting this variable to 0.001 doesn’t sufficient
    encourage exploration, and the policy once again gets stuck. Setting this variable
    to 0.5 works well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement a relative minimum improvement threshold with a 110% improvement
    requirement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Omitted
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Relative improvement
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.3.2 Exercise 2: BayesOpt for hyperparameter tuning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise, implemented in CH04/03 - Exercise 2.ipynb, applies BayesOpt
    to an objective function that simulates the accuracy surface of a support-vector
    machine model in a hyperparameter tuning task. Complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt loop in CH04/01 - BayesOpt loop.ipynb. Our objective function
    is implemented as
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare the corresponding test data with `xs` for a two-dimensional grid representing
    the domain and `ys` for the function values of `xs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Modify the helper function that visualizes optimization progress. We declare
    this function as `visualize_progress_and_policy()`, which only needs to take in
    a policy object and `next_x` as the next point to query. First, the function computes
    the acquisition scores for the test data `xs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ To be continued
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we declare the two Matplotlib subplots and, for the first, plot the ground
    truth stored in `ys`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Heat map showing the ground truth
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Scattered points showing labeled data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, we plot another heat map in the second subplot, showing the acquisition
    scores:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Heat map showing the acquisition scores
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We optionally show `next_x`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Copy the GP class from the exercise in chapter 3, which implements a Matérn
    2.5 kernel with ARD. Further modify this class to make it integratable with BoTorch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ BoTorch-related modifications
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Matérn 2.5 kernel with ARD
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Omitted
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Reuse the helper function `fit_gp_model()` and the `for` loop that implements
    BayesOpt. We copy `fit_gp_model()` and declare the initial dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then declare the BayesOpt loop:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Placeholder for policy initialization
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Making the search more exhaustive
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Calling the new visualization helper function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the PoI policy on this objective function. Observe that the policy once
    again gets stuck at a local optimum. Replace the line that initializes the BayesOpt
    policy with
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Running the entire notebook shows that the policy once again gets stuck at a
    local optimum, as shown in figure A.3.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-03.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.3 Optimization progress of PoI at the last iteration. The policy is
    stuck at a local optimum.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the modified version of PoI, where the minimum improvement threshold is
    set at 0.1\. Replace the line that initializes the BayesOpt policy with
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This policy is more explorative and outperforms regular PoI. Figure A.4 shows
    the progress of this policy at iteration 17, where it first achieves an accuracy
    of at least 90%.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-04.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.4 Optimization progress of the modified PoI at iteration 17, where
    the policy first achieves an accuracy of at least 90%
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, C = 1.6770 and *γ* = 1.9039 are the parameters giving this accuracy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the Expected Improvement (EI) policy on this objective function. Replace
    the line that initializes the BayesOpt policy with
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This policy performs well on our objective function, finding an accuracy of
    at least 90% at iteration 15, as shown in figure A.5.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-05.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.5 Optimization progress of EI at iteration 4, where the policy first
    achieves an accuracy of at least 90%
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, *C* = 1.6331 and *γ* = 1.8749 are the parameters giving this accuracy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Implement repeated experiments, and visualize the average incumbent values
    and error bars across 10 experiments. We first put the code that implements our
    BayesOpt loop in an outer loop that iterates over multiple experiments. We store
    the best-seen value at each step across the experiments in `incumbents`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Uniformly samples a data point in the search space as the starting point
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Keeps track of the best-seen value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ The mitted code is the same as before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Saves results to a file so that we can visualize them later
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We then implement a helper function that plots the average incumbent values
    and error bars. This function reads in a PyTorch tensor saved at `path`, which
    should be the saved version of `incumbents` in the previous step:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Helper subfunction to compute the error bars
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Loads saved optimization results
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Computes the mean results and error bars
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Visualizes the mean results and error bars
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We then can run the preceding policies we have in the previous code and compare
    their performance:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This generates figure A.6, which shows the optimization performance of PoI,
    the modified version of PoI, and EI.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-06.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.6 Optimization progress of various policies, aggregated across 10 repeated
    experiments
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We see that figure A.6 gives us more insight than inspecting the policies in
    a single run. Here, not only does PoI perform worse than the other two policies,
    but its performance is also less robust, as seen from the large error bars. The
    modified PoI and EI perform comparably, and it’s hard to tell if one is better
    than the other, as their error bars overlap.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.4 Chapter 5: Exploring the search space with bandit-style policies'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two exercises in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The first exercise explores a potential method to set the tradeoff parameter
    for the UCB policy that considers how far along we are in optimization.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second exercise applies the two policies we have learned in this chapter
    to the hyperparameter tuning problem seen in previous chapters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A.4.1 Exercise 1: Setting an exploration schedule for Upper Confidence Bound'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise, implemented in CH05/02 - Exercise 1.ipynb, discusses a strategy
    of adaptively setting the value of the tradeoff parameter β of the UCB policy.
    Complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt loop in CH04/02 - Exercise 1.ipynb, which uses the one-dimensional
    Forrester function as the optimization objective.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since there are 10 iterations in the BayesOpt loop, β is multiplied by the
    multiplier *m* 10 times to go from 1 to 10\. That is, 1 × *m*10 = 10\. Solving
    this equation gives the code for the multiplier:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Implement this scheduling logic, and observe the resulting optimization performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We modify the BayesOpt loop as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Obtains the trained GP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Finds the point that maximizes the acquisition score, queries the objective
    function, and updates the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This code produces figure A.7.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-07.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.7 Progress made by the adaptive version of the UCB policy. The policy
    is able to escape the local optimum and get closer to the global optimum.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We see that the policy inspects a local optimum at the fifth iteration but ultimately
    is able to escape and get closer to the global optimum at the end.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.4.2 Exercise 2: BayesOpt for hyperparameter tuning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise, implemented in CH05/03 - Exercise 2.ipynb, applies BayesOpt
    to an objective function that simulates the accuracy surface of a support-vector
    machine model in a hyperparameter tuning task. Complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt loop in CH04/03 - Exercise 2.ipynb, including the outer
    loop that implements repeated experiments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the UCB policy, setting the value of the tradeoff parameter to β ∈ { 1,
    3, 10, 30 }, and observe the values’ aggregated performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The value of the tradeoff parameter can be set when the policy object is initialized:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Figure A.8 shows the optimization performance of the four versions of UCB. We
    see that when β *=* 1, the policy is too exploitative and achieves the worst performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-08.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.8 Progress made by the various UCB policies
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As the value of the tradeoff parameter increases, performance increases, but
    when β = 30, over-exploration causes UCB to be slower at locating an accuracy
    of 90%. Overall, β = 10 achieves the best performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the adaptive version of UCB (see Exercise 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We modify the BayesOpt loop as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Randomly generates the initial training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Records the incumbent value and retrains the model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Finds the point maximizing the acquisition score, queries the objective function,
    and updates the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure A.9 shows the optimization performance of the two adaptive versions against
    the best performing fixed value β = 10.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-09.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.9 Progress made by two adaptive versions of the UCB policy. The policy
    is robust against the end value of the tradeoff parameter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These versions are comparable, and changing the end value from 10 to 30 doesn’t
    affect optimization performance much.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the Thompson sampling (TS) policy, and observe its aggregated performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We implement TS as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Randomly generates the initial training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Records the incumbent value and retrains the model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Finds the point maximizing the acquisition score, queries the objective function,
    and updates the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure A.10 shows the optimization performance of TS. We see that the policy
    makes significant progress at the beginning and is comparable to EI from chapter
    6 and slightly worse than the best version of UCB.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-10.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.10 Progress made by TS. The policy is comparable to EI and slightly
    worse than the best version of UCB.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.5 Chapter 6: Using information theory with entropy-based policies'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two exercises in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The first exercise covers a variant of binary search in which prior information
    can be taken into account when making decisions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second walks us through the process of implementing Max-value Entropy Search
    (MES) in the hyperparameter tuning problem seen in previous chapters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A.5.1 Exercise 1: Incorporating prior knowledge into entropy search'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise, implemented in CH06/02 - Exercise 1.ipynb, shows us an instance
    of using different priors when finding the information-theoretically optimal decision
    and will ultimately help us further appreciate the elegance and flexibility of
    entropy search as a generic decision-making-under-uncertainty procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: Prove that *Pr*(*X* = 1) + *Pr*(*X* = 2) + ... + *Pr*(*X* = 10) = 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can do this by simply adding the probabilities together:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 1 / 2 + 1 / 4 + ... + 1 / 2⁹ + 1 / 2⁹ = 1 / 2 + 1 / 4 + ... + 1 / 2⁸ + 1 / 2⁸
    = ... = 1 / 2 + 1 / 2 = 1.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Calculate the entropy of this prior distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Remember the formula for the entropy is –Σ*[i]**p[i]* log *p[i]*. We can write
    a Python function that computes this sum:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Get the current probability.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Sum over the terms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This function takes `first` and `last` as parameters, which correspond to the
    smallest and biggest numbers *X* could be (which start out as 1 and 10), respectively.
    We then iterate through the numbers between `first` and `last` and add up the
    –*p[i]* log *p[i]* terms. Here, `marginal_probability()` is a helper function
    that computes *Pr*(*X* = *n*), which we implement as
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ An edge case when the floor is the highest possible floor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Running `compute_entropy(1,` `10)` gives us 1.99609375\. This is the entropy
    of the prior distribution for *X*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Given the prior distribution defined between 1 and 10, what is the probability
    the phone will break when dropped from the second floor? What is this probability
    for the fifth floor? How about the first floor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The probability that the phone will break when dropped from the second floor
    is exactly *Pr*(*X* = 1), which is 0.5.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The probability that the phone will break from the fifth floor is the probability
    that *X* ≤ 4, which is *Pr*(*X* = 1) + *Pr*(*X* = 2) + *Pr*(*X* = 3) + *Pr*(*X*
    = 4) = 15/16 = 0.9375.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'These two calculations could be implemented as a function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Sum over the probabilities for X less than the threshold.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Since our prior knowledge dictates that the phone won’t break if dropped from
    the first floor, this probability is 0.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compute the entropy of the fictitious posterior distribution in the two cases
    where we conduct a trial on the fifth floor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the `compute_entropy()` function we implemented, we can compute the entropy
    in two cases. If the phone breaks, we set `first` `=` `1` and `last` `=` `4`;
    otherwise, we set `first` `=` `5` and `last` `=` `10`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Given the prior distribution, compute the expected posterior entropy after you
    conduct a trial on the fifth floor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We have already done the necessary calculations for this expected posterior
    entropy computation. First, the probability that the phone will break from the
    fifth floor is 0.9375, in which case the posterior entropy is 1.75\. Second, the
    probability that the phone won’t break from the fifth floor is 1 – 0.9375 = 0.0625,
    in which case the posterior entropy is 1.9375.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Taking the average of the two cases gives (0.9375) 1.75 + (0.0625) 1.9375 =
    1.76171875\. This is the expected posterior entropy after you conduct a trial
    on the fifth floor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compute this expected posterior entropy for other floors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can implement a function that does the calculation we just went over:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ The probability that the phone will break from a given floor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Takes the average of the two cases
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using this function, we can plot out the expected posterior entropy for numbers
    between 1 and 10.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This plot is shown in figure A.11, which tells us that the information-theoretically
    optimal location for our first trial is the second floor, since 2 gives us the
    lowest expected posterior entropy (and, therefore, uncertainty).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-11.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.11 The expected posterior entropy as a function of the location to
    conduct the trial
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We see that this is not the same as the decision binary search suggests, 5\.
    This is a direct effect of the domain knowledge we are encoding using the prior
    distribution for *X*: since there’s a high chance that *X* = 2 (50%), it’s actually
    better to simply try out that number first in case we can immediately find our
    answer if the phone breaks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Interestingly, dropping the phone from the first floor gives us no reduction
    in entropy. This is because we know for sure that the phone won’t break from this
    floor, so our knowledge of the world won’t change after conducting this trial.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.5.2 Exercise 2: BayesOpt for hyperparameter tuning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise, implemented in the CH06/03 - Exercise 2.ipynb notebook, applies
    BayesOpt to an objective function that simulates the accuracy surface of a support-vector
    machine model in a hyperparameter tuning task:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt loop in CH04/03 - Exercise 2.ipynb, including the outer
    loop that implements repeated experiments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the MES policy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since our objective function is two-dimensional, we should set the size of
    the Sobol sequence used by MES as 2,000:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Randomly generates the initial training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Records the incumbent value and retrains the model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Finds the point maximizing the acquisition score, queries the objective function,
    and updates the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure A.12 shows the optimization performance of MES. We see that the policy
    is competitive against all the BayesOpt policies we have learned thus far.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-12.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.12 Progress made by MES. The policy performs the best of the four policies
    shown.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.6 Chapter 7: Maximizing throughput with batch optimization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two exercises in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The first covers the implementation of TS under the batch setting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second shows us how to run BayesOpt policies on a four-dimensional aerostructural
    optimization problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A.6.1 Exercise 1: Extending TS to the batch setting via resampling'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember that TS in the sequential setting, which we learned in section 5.3,
    draws one sample from the current GP belief about the objective function and queries
    the data point that maximizes that sample. In the batch setting, we simply repeat
    this process of sampling from the GP and maximizing the sample multiple times
    to assemble a batch of queries of the desired size. The code for this exercise
    can be found in the CH07/02 - Exercise 1.ipynb notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the batch BayesOpt loop in CH05/01 - BayesOpt loop.ipynb notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement TS with a Sobol sampler, as described in section 5.3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We implement the policy as follows, where we use a 2,000-element Sobol sequence
    and specify the number of samples as the batch size:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Specifies the length of the Sobol sequence
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Randomly picks the initial training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Retrains the GP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Initializes the Sobol sequence
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❺ Draws multiple samples from the GP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❻ Queries the objective function and updates the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run this TS policy on the hyperparameter tuning objective function, and observe
    its performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After running batch TS, we can plot the progress made by the policy against
    other policies we have learned, as shown in figure A.13\. Here, TS is able to
    make significant progress after only the first batch of queries.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-13.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.13 Progress made by batch TS in the hyperparameter tuning example.
    The policy makes significant progress after only the first batch of queries.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.6.2 Exercise 2: Optimizing airplane designs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise provides an objective function that simulates this process of
    benchmarking the performance of an airplane design. The code is provided in the
    CH07/04 - Exercise 2.ipynb notebook. Complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Implement the objective function that simulates the performance benchmarking.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code for the objective function is already provided, so we simply copy
    and paste it in our program:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Implement a GP model with a constant mean function and a Matérn 2.5 kernel with
    an output scale implemented as a `gpytorch.kernels.ScaleKernel` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The class implementation of this GP model is mostly the same as before, except
    that we need to specify the correct number of dimensions in the ARD kernel:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ A Matérn 2.5 kernel for four dimensions
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Implement a helper function that trains the GP on a given training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can simply copy the same helper function `fit_gp_model()` from other notebooks
    in this chapter, namely 02 - Exercise 1.ipynb, as we don’t need to modify anything
    in this helper function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Define the settings of our optimization problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first define the bounds of our search space:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then specify how many queries can be made, the batch size, and the number
    of experiments to repeat for each policy:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run each batch BayesOpt policy we learn in this chapter on the objective function
    implemented previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first use this code to implement the optimization loop and the outer loop
    that repeats the experiments for each policy. Specifically, for each individual
    experiment, we randomly sample one data point inside the search space and then
    run each BayesOpt policy until we run out of queries. We see how each policy is
    defined in the next step:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Randomly initializes the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Keeps track of optimization progress and updates the predictive model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Defines the policy and finds the next batch to query
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Queries the points recommended by the policy and updates the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For the PoI policy, we use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the EI policy, we use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the UCB policy, we use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'These three policies can then be optimized using the helper function `optimize_
    acqf()` as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Otherwise, for either TS or MES, we first need to define the Sobol sequence:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Specifies the number of dimensions to be 4
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For the TS policy, we use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the MES, we use the following code, which uses the helper function `optimize_acqf_cyclic()`
    to implement cyclic optimization. Note that we are specifying that cyclic optimization
    should only take a maximum of 5 iterations:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Specifies the maximum number of iterations in cyclic optimization
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Plot the optimization progress of the BayesOpt policies we have run and observe
    their performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure A.14 shows the optimization results obtained by the policies we’ve implemented.
    We see that most policies are comparable, except for TS; batch PoI has a slight
    edge.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-14.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.14 Progress made by various BayesOpt policies in the airplane design
    optimization example. Most policies are comparable, except for TS.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.7 Chapter 8: Satisfying extra constraints with constrained optimization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two exercises in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The first verifies that the result we obtain from BoTorch’s implementation of
    the constrained EI policy is the same as the product of the regular EI score and
    the probability of feasibility.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second shows us how to run constrained BayesOpt on a four-dimensional aerostructural
    optimization problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A.7.1 Exercise 1: Manual computation of constrained EI'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The acquisition score of the constrained EI policy is the product of the EI
    score and the probability of feasibility. Although the `ConstrainedExpectedImprovement`
    class from BoTorch provides an implementation of the constrained EI score, we
    can, in fact, perform the computation manually. In this exercise, we explore this
    manual computation and verify our result against that of the `ConstrainedExpectedImprovement`
    class. The solution of this exercise is in the CH08/02 - Exercise 1.ipynb notebook
    amd can be explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the constrained BayesOpt problem used in CH08/01 - Constrained optimization.ipynb,
    including the objective function, the cost function, the GP implementation, and
    the helper function that trains a GP on some training data `fit_gp_model()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a PyTorch tensor that is a dense grid between -5 and 5\. This tensor
    will act as our test set. We use `torch.linspace()` to create a dense grid:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a toy training dataset by randomly sampling three data points from our
    search space (between –5 and 5), and evaluate the objective and cost functions
    at these points. We use `torch.rand()` to randomly sample between 0 and 1 and
    scale the samples to our search space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Fixes the seed for reproducibility
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Samples between 0 and 1 and then scales the samples to our search space
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Train a GP on the data from the objective function and another GP on the data
    from the cost function using the helper function `fit_gp_model()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Trains a GP on the objective function’s data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Trains a GP on the cost function’s data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Use the GP trained on the data from the cost function to compute the probability
    of feasibility for each point in the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first compute the predictive distribution of the cost GP on our test set:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then initialize a normal distribution object, with the mean and standard
    deviation corresponding to the means and standard deviations of `cost_pred_dist`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we call the `cdf()` method on this object to compute the probability
    of feasibility. The argument this method takes is the upper bound of our cost
    constraint, which is 0:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Initialize a regular EI policy, with the `model` argument being the GP trained
    on the data from the objective function and the `best_f` argument being the current
    feasible incumbent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We compute the current feasible incumbent with `train_utility[train_cost` `<=`
    `0].max()`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then compute the EI score by calling the EI policy object on `xs[:,` `None,`
    `None]`, which is the test dense grid reshaped to make sure it’s of appropriate
    shape:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize a constrained EI policy, and compute the constrained EI score for
    each point in the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also compute the constrained EI score with the reshaped test set:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the product of the EI scores and the probabilities of feasibility,
    and verify that this manual computation leads to the same results as those from
    BoTorch’s implementation. Run an assertion to make sure all corresponding terms
    match up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Plot the EI scores and the constrained EI scores in a graph, and visually verify
    that the former is always greater than or equal to the latter. Prove this is the
    case.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We plot out the scores we have computed thus far as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code generates figure A.15, which shows that the EI score is, indeed, always
    at least the constrained EI score.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-15.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.15 The acquisition score of EI (solid line) and constrained EI (dashed
    line). The former is always greater than or equal to the latter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can mathematically prove this by noting that the constrained EI score is
    equal to the regular EI score multiplied by the probability of feasibility. This
    probability of feasibility is always a maximum of 1, so the EI score is always
    greater than or equal to the constrained EI score.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.7.2 Exercise 2: Constrained optimization of airplane design'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we tackle a constrained optimization problem using the airplane-utility
    objective function in exercise 2 of chapter 7\. This process allows us to run
    constrained BayesOpt on a higher-dimensional problem in which it’s not obvious
    where the feasibility optimal solution is. The solution to this exercise is included
    in the CH08/03 - Exercise 2.ipynb notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: Recreate the BayesOpt problem used in the CH07/04 - Exercise 2.ipynb notebook,
    including the airplane-utility objective function named `flight_utility()`, the
    bounds of our search space (the four-dimensional unit hypercube), the GP implementation,
    and the helper function that trains a GP on some training data `fit_gp_model()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement the following cost function, which simulates the cost of making the
    airplane design specified by a four-dimensional input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Our goal is to maximize the objective function `flight_utility()`, while following
    the constraint that the cost, as computed by `flight_cost()`, is less than or
    equal to 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To this end, we set the number of queries a BayesOpt policy can make in each
    experiment as 50, and designate that each policy needs to run 10 repeated experiments:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The default value quantifying optimization progress if no feasible solution
    is found should be set to –2.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the constrained EI policy as well as the regular EI policy on this problem;
    visualize and compare their average progress (along with error bars).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We implement the constrained EI policy in the same way as we did in chapter
    8, where we set `best_f` to be either the current feasible incumbent if a feasible
    solution has been found or the default value –2 otherwise. Our model list contains
    the objective GP, which has an index of 0, and the cost GP, which has an index
    of 1:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Finds the appropriate value of the current incumbent
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ The list of GP models
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Index of the objective model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Index of the constraint model and the lower and upper bounds
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We implement the regular EI policy as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Figure A.16 shows the optimization results obtained by the two preceding policies
    we implemented. We see that constrained EI completely dominates the regular EI
    policy by accounting for the cost constraint we impose.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-16.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.16 Progress made by various Bayesian optimization policies in the constrained
    airplane design optimization example. Compared to the regular EI, the constrained
    variant finds a more feasible solution on average.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.8 Chapter 9: Balancing utility and cost with multifidelity optimization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two exercises in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 1 walks through the process of measuring and visualizing the average
    performance of an optimization policy across multiple experiments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exercise 2 applies the optimization policies we know to a two-dimensional problem
    with three functions we can query from.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A.8.1 Exercise 1: Visualizing average performance in multifidelity optimization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we run the optimization loop multiple times and learn how
    to take the average performance to obtain a more holistic comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the problem setup and the multifidelity optimization loop from the CH09/03
    - Measuring performance.ipynb notebook, and add another variable denoting the
    number of experiments we want to run (10, by default).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To facilitate repeated experiments, add an outer loop to the optimization loop
    code. This should be a `for` loop with 10 iterations, where a different random
    observation is generated each time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Repeats the experiment 10 times
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Generates a random initial training set specific to the current iteration
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ The inner loop that runs optimization until we exhaust our budget
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Make each of the variables `recommendations` and `spent_budget` a list of lists,
    where each inner-list keeps track of optimization performance of an individual
    experiment. We add to the code for the nested loop in the previous step as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Each variable is a (currently empty) list of lists.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Appends an empty list to each list of lists for the next experiment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Adds the optimization progress statistics to the newest list in each variable
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the multifidelity MES policy and its single-fidelity version on our optimization
    problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first make the regular grid and the currently empty interpolated recommended
    values that we will fill in later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then iterate through each list in `recommendations` (renamed to `incumbents`
    in our code) and `spend_budget`, compute the linear interpolation, and then fill
    in the values in `interp_incumbents`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use the linearly interpolated values to plot the average performance and error
    bars of the two policies we ran and compare their performance. The comparison
    is visualized in figure A.17, where we see that the multifidelity MES policy greatly
    outperforms its single-fidelity competitor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-17.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.17 Average optimization progress of the single- and multifidelity MES
    policies on the Forrester function across 10 experiments. The multifidelity policy
    greatly outperforms the single-fidelity one.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Plot the linearly interpolated curves representing individual runs’ optimization
    progress, along with the average performance and error bars. The comparison is
    visualized in figure A.18\. Indeed, our optimization progress in each run, as
    measured by the maximum posterior mean recommendation, is not monotonically increasing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-18.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.18 Linearly interpolated curves representing individual runs' optimization
    progress across 10 experiments. Our optimization progress in each run, as measured
    by the maximum posterior mean recommendation, is not monotonically increasing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.8.2 Exercise 2: Multifidelity optimization with multiple low-fidelity approximations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This exercise shows us that our multifidelity Max-value Entropy Search policy
    can balance between multiple low-fidelity functions. The solution, found in the
    CH09/05 - Exercise 2.ipynb notebook, can be explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Implement the objective function. The code for this step has already been provided
    in the instructions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Define the bounds of our search space as the unit square:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare the `fidelities` variable that stores the correlation values of the
    different functions we can query:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the fixed cost of the linear cost model to 0.2 and the weight to 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the limit of our budget in each experiment to 10 and the number of repeated
    experiments to 10 as well:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the number of candidates drawn from the Sobol sequence to 5,000, and use
    100 restarts and 500 raw samples when using helper functions to optimize the acquisition
    score of a given policy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Redefine the helper function `get_final_recommendation` that finds the posterior
    mean maximizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ The necessary changes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the multifidelity MES policy and its single-fidelity version on our optimization
    problem, and plot the average optimization progress and error bars of each policy,
    using the method described in exercise 1\. Figure A.19 shows the comparison between
    the two policies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-19.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.19 Average optimization progress of the single- and multifidelity MES
    policy on the Branin function across 10 experiments. The multifidelity policy,
    once again, outperforms the single-fidelity one.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.9 Chapter 11: Optimizing multiple objectives at the same time'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we apply the multiobjective optimization techniques we have
    learned to the problem of optimizing the aerostructural design of an airplane.
    This exercise allows us to observe the performance of the Expected Hypervolume
    Improvement (EHVI) policy in a multidimensional problem:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We copy the code for the objective functions as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ The first objective function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ The second objective function, negated from the code in exercise 2 of chapter
    8
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We implement the helper function as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We declare the bounds of the search space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We declare the reference point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The class implementation and helper function can be implemented using the same
    code as, for example, in CH08/03 - Exercise 2.ipynb.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We set the experimental settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We implement the two BayesOpt policies in the same way as in CH11/02 - Multi-objective
    BayesOpt loop.ipynb. Figure A.20 shows the performance of the two policies aggregated
    across 10 experiments. EHVI, once again, outperforms the alternating EI policy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-20.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.20 Average hypervolume and error bars as a function of the number of
    queries made by two Bayesian optimization policies. EHVI consistently outperforms
    the alternating EI policy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A.10 Chapter 12: Scaling Gaussian processes to large data sets'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This exercise demonstrates the improvement in efficiency when going from a regular
    GP model to a VGP one on a real-life dataset of housing prices in California.
    Our goal is to observe the computational benefits of a VGP—this time, in a real-world
    setting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the Pandas library to read in the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once read in, the Pandas dataframe should look similar to the output in figure
    A.21.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-21.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.21 The housing price dataset shown as a Pandas dataframe. This is the
    training set for this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We create the scatter plot as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The visualization should look similar to figure A.22.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/A-22.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure A.22 The housing price dataset shown as a scatter
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To extract our training features, we use the `torch.from_numpy()` method to
    convert a NumPy array to a PyTorch tensor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We similarly do this for the log of the house prices, which are our training
    labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We normalize the training labels `train_y` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We implement the GP model as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ The constant mean function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ An ARD Matern 5/2 kernel with an output scale
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Make a likelihood whose noise is constrained to be at least 0.1, using the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ The constraint forces the noise to be at least 0.1.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We train the previously implemented GP model using gradient descent as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ The gradient descent optimizer Adam
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ The (negative) marginal log likelihood loss function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Enable training mode
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The total training time was 24 seconds on a MacBook.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We implement the VGP model as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Variational parameters
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ The same as the GP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This VGP is trained as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ❶ Randomly picks 100 points as the initial inducing points
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❷ Prepares the mini batches
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❸ Natural gradient descent for variational parameters
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ❹ Adam for the other parameters
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the same MacBook, training took 6 seconds—a 400% improvement in speed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The solution is included in the CH12/02 - Exercise.ipynb notebook.
  prefs: []
  type: TYPE_NORMAL
