- en: B.1\. Tensor creation and tensor axis conventions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember that a *tensor* is simply a data container. Every tensor has two fundamental
    properties: data type (dtype) and shape. *dtype* controls what kinds of values
    are stored within the tensor. A given tensor can store only one kind of value.
    At the time of this writing (version 0.13.5), the supported dtypes are float32,
    int32, and bool.'
  prefs: []
  type: TYPE_NORMAL
- en: The *shape* is an array of integers indicating how many elements are in the
    tensor and how they are organized. It can be thought of as the “shape and size”
    of the container that is the tensor (see [figure B.1](#app02fig01)).
  prefs: []
  type: TYPE_NORMAL
- en: Figure B.1\. Examples of tensors of rank 0, 1, 2, 3, and 4
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](btab01_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The length of the shape is known as the tensor’s *rank*. For example, a 1D tensor,
    also known as a *vector*, has rank 1\. The shape of a 1D tensor is an array containing
    one number, and that number tells us how long the 1D tensor is. Increasing rank
    by one, we get a 2D tensor, which can be visualized as a grid of numbers in a
    2D plane (like a grayscale image). The shape of a 2D tensor has two numbers, which
    tell us how tall and how wide the grid is. Further increasing the rank by one,
    we get a 3D tensor. As shown in the example in [figure B.1](#app02fig01), you
    can visualize a 3D tensor as a 3D grid of numbers. The shape of a 3D tensor consists
    of three integers; they tell us the size of the 3D grid along the three dimensions.
    So, you see the pattern. Tensors of rank 4 (4D tensors) are harder to visualize
    directly because the world we live in has only three spatial dimensions. 4D tensors
    are frequently used in many models, such as deep convnets. TensorFlow.js supports
    tensors up to rank 6\. In practice, rank-5 tensors are used only in some niche
    cases (for example, those involving video data), while rank-6 tensors are encountered
    even more rarely.
  prefs: []
  type: TYPE_NORMAL
- en: B.1.1\. Scalar (rank-0 tensor)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A scalar is a tensor whose shape is an empty array (`[]`). It has no axes and
    always contains exactly one value. You can create a new scalar using the `tf.scalar()`
    function. At the JavaScript console (again, assuming TensorFlow.js is loaded and
    available at the `tf` symbol), do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ¹
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note that for space and clarity, we will skip the JavaScript console output
    lines that result from assignments, as they are not illustrative to the issue
    at hand.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We have created a scalar tensor holding just the value 2018\. Its shape is
    the empty list, as expected. It has the default dtype (`"float32"`). To force
    the dtype to be an integer, provide `''int32''` as an additional argument when
    calling `tf.scalar()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the data back out of the tensor, we can use the async method `data()`.
    The method is async because, in general, the tensor may be hosted out of the main
    memory, such as on GPUs, as a WebGL texture. Retrieving the value of such tensors
    involves operations that are not guaranteed to resolve immediately, and we don’t
    want those operations to block the main JavaScript thread. This is why the `data()`
    method is async. There is also a synchronous function that retrieves the values
    of tensors through polling: `dataSync()`. This method is convenient but blocks
    the main JavaScript thread, so it should be used sparingly (for example, during
    debugging). Prefer the async `data()` method whenever possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To use `dataSync()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We see that for float32-type tensors, the `data()` and `dataSync()` methods
    return the values as a JavaScript `Float32Array` primitive. This may be a little
    surprising if you expected a plain old number, but it makes more sense when considering
    that tensors of other shapes may need to return a container of multiple numbers.
    For int32-type and bool-type tensors, `data()` and `dataSync()` return `Int32Array`
    and `Uint8Array`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Note that even though a scalar always contains exactly one element, the converse
    is not true. A tensor whose rank is greater than 0 may have exactly one element
    as well, as long as the product of the numbers in its shape is 1\. For example,
    a 2D tensor of shape `[1, 1]` has only one element, but it has two axes.
  prefs: []
  type: TYPE_NORMAL
- en: B.1.2\. tensor1d (rank-1 tensor)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A 1D tensor is sometimes called a rank-1 tensor or a vector. A 1D tensor has
    exactly one axis, and its shape is a length-1 array. The following code will create
    a vector at the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This 1D tensor has four elements and can be called a 4-dimensional vector. Don’t
    confuse a 4D *vector* with a 4D *tensor*! A 4D vector is a 1D tensor that has
    one axis and contains exactly four values, whereas a 4D tensor has four axes (and
    may have any number of dimensions along each axis). Dimensionality can denote
    either the number of elements along a specific axis (as in our 4D vector) or the
    number of axes in a tensor (for example, a 4D tensor), which can be confusing
    at times. It’s technically more correct and less ambiguous to refer to a rank-4
    tensor, but the ambiguous notation 4D tensor is common regardless. In most cases,
    this shouldn’t be a problem, as it can be disambiguated based on the context.
  prefs: []
  type: TYPE_NORMAL
- en: As in the case of scalar tensors, you can use the `data()` and `dataSync()`
    methods to access the values of the 1D tensor’s elements; for example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use the synchronous version of `data()`—namely, `dataSync()`—but
    be aware that `dataSync()` may block the UI thread and should be avoided if possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In order to access the value of a specific element of the 1D tensor, you can
    simply index into the TypedArray returned by `data()` or `dataSync()`; for example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: B.1.3\. tensor2d (rank-2 tensor)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A 2D tensor has two axes. In some cases, a 2D tensor is referred to as a *matrix*,
    and its two axes can be interpreted as the row and column indices of the matrix,
    respectively. You can visually interpret a matrix as a rectangular grid of elements
    (see the third panel of [figure B.1](#app02fig01)). In TensorFlow.js,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The entries from the first axis are called the *rows*, and the entries from
    the second axis are the *columns*. In the previous example, `[1, 2, 3]` is the
    first row, and `[1, 40]` is the first column. It is important to know that when
    returning the data, using `data()` or `dataSync()`, the data will come as a flat
    array in *row-major* order. In other words, the elements of the first row will
    appear in the `Float32Array` first, followed by elements of the second row, and
    so forth:^([[2](#app02fn2)])
  prefs: []
  type: TYPE_NORMAL
- en: ²
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is different from the column-major ordering seen in some other numerical
    frameworks such as MATLAB and R.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Previously, we mentioned that the `data()` and `dataSync()` methods, when followed
    by indexing, can be used to access the value of any element of a 1D tensor. When
    used on 2D tensors, the indexing operation becomes tedious because the TypedArray
    returned by `data()` and `dataSync()` *flattens* the elements of the 2D tensor.
    For instance, in order to determine the element of the TypedArray that corresponds
    to the element in the second row and second column of the 2D tensor, you’d have
    to perform arithmetic like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Fortunately, TensorFlow.js provides another set of methods to download values
    from tensors into plain JavaScript data structures: `array()` and `arraySync()`.
    Unlike `data()` and `dataSync()`, these methods return nested JavaScript arrays
    that properly preserve the rank and shape of the original tensors. For example,'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To access an element at the second row and second column, we can simply perform
    indexing into the nested array twice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This gets rid of the need to perform index arithmetic and will be especially
    convenient for higher-dimensional tensors. `arraySync()` is the synchronous version
    of `array()`. Like `dataSync()`, `arraySync()` may block the UI thread and should
    be used with caution.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `tf.tensor2d()` call, we provided a nested JavaScript array as the argument.
    The argument consists of rows of arrays nested within another array. This nesting
    structure is used by `tf.tensor2d()` to infer the shape of the 2D tensor—that
    is, how many rows and how many columns there are, respectively. An alternative
    way to create the same 2D tensor with `tf.tensor2d()` is to provide the elements
    as a flat (non-nested) JavaScript array and accompany it by a second argument
    that specifies the shape of the 2D tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In this approach, the product of all the numbers in the `shape` argument must
    match the number of elements in the float array, or else an error will be thrown
    during the `tf.tensor2d()` call. For tensors of ranks higher than 2, there are
    also two analogous approaches to tensor creation: using either a single nested
    array as the argument or a flat array accompanied by a shape argument. You will
    see both approaches used in different examples throughout this book.'
  prefs: []
  type: TYPE_NORMAL
- en: B.1.4\. Rank-3 and higher-dimensional tensors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you pack several 2D tensors into a new array, you will get a 3D tensor,
    which you can imagine as a cube of elements (the fourth panel in [figure B.1](#app02fig01)).
    Rank-3 tensors can be created in TensorFlow.js following the same pattern as previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Another way to do the same thing is to provide a flat (non-nested) array of
    values, together with an explicit shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tf.tensor3d()` function in this example can be replaced with the more
    generic `tf.tensor()` function. This allows you to generate tensors of any rank
    up to 6\. In the following, we create a rank-3 and a rank-6 tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: B.1.5\. The notion of data batches
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In practice, the first axis (axis 0, because indexing starts at 0) in all tensors
    you’ll come across in deep learning will almost always be the *batch axis* (sometimes
    called the *samples axis* or *batch dimension*). Therefore, an actual tensor taken
    by a model as input has a rank that exceeds the rank of an individual input feature
    by 1\. This is true throughout the TensorFlow.js models in this book. The size
    of the first dimension equals the number of examples in the batch, known as *batch
    size*. For instance, in the iris-flower-classification example in [chapter 3](kindle_split_014.html#ch03)
    ([listing 3.9](kindle_split_014.html#ch03ex09)), the input feature of every example
    consists of four numbers represented as a length-4 vector (a 1D tensor of shape
    `[4]`). Hence the input to the iris-classification model is 2D and has a shape
    `[null, 4]`, where the first null value indicates a batch size that will be determined
    at the model’s runtime (see [figure B.2](#app02fig02)). This batching convention
    also applies to the output of models. For example, the iris-classification model
    outputs a one-hot encoding for the three possible types of iris for every individual
    input example, which is a 1D tensor of shape `[3]`. However, the model’s actual
    output shape is 2D and has a shape of `[null, 3]`, where the null-valued first
    dimension is the to-be-determined batch size.
  prefs: []
  type: TYPE_NORMAL
- en: Figure B.2\. Tensor shapes for individual examples (left) and batched examples
    (right). The tensor for batched examples has a rank one greater than the tensor
    for an individual example and is the format accepted by the `predict()`, `fit()`,
    and `evaluate()` methods of `tf.Model` objects. The `null` in the shape of the
    tensor for batch examples indicates that the first dimension of the tensor has
    an undetermined size, which can be every positive integer during actual calls
    to the aforementioned methods.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](btab02_alt.jpg)'
  prefs: []
  type: TYPE_IMG
- en: B.1.6\. Real-world examples of tensors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s make tensors more concrete with a few examples similar to what you’ll
    encounter in the book. The data you’ll manipulate will almost always fall into
    one of the following categories. In the previous discussion, we follow the batching
    convention and always included the number of examples in the batch (`numExamples`)
    as the first axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Vector data*—2D tensors with shape `[numExamples, features]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time-series (sequence) data*—3D tensors with shape `[numExamples, timesteps,
    features]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Images*—4D tensors with shape `[numExamples, height, width, channels]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Video*—5D tensors with shape `[numExamples, frame, height, width, channels]`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is the most common case. In such a dataset, each single data sample can
    be encoded as a vector, and thus a batch of data will be encoded as a rank-2 tensor,
    where the first axis is the samples axis, and the second axis is the features
    axis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: An actuarial dataset of people, in which we consider each person’s age, ZIP
    code, and income. Each person can be characterized as a vector of 3 values, and
    thus an entire dataset of 100,000 people can be stored in a 2D tensor with shape
    `[100000, 3]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset of text documents, where we represent each document by the counts
    of how many times each word appears in it (for example, out of an English dictionary
    of the 20,000 most common words). Each document can be encoded as a vector of
    20,000 values (one count per word in the dictionary), and thus a batch of 500
    documents can be stored in a tensor of shape `[500, 20000]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time-series or sequence data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Whenever time matters in your data (or the notion of sequence order), it makes
    sense to store it in a 3D tensor with an explicit time axis. Each sample is encoded
    as a sequence of vectors (a 2D tensor), and thus a batch of samples will be encoded
    as a 3D tensor (see [figure B.3](#app02fig03)).
  prefs: []
  type: TYPE_NORMAL
- en: Figure B.3\. A 3D time-series data tensor
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](btab03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The time axis is almost always the second axis (axis of index 1) by convention,
    as in the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: A dataset of stock prices. Every minute we store the current price of the stock,
    the highest price in the past minute, and the lowest price in the past minute.
    Thus, each minute is encoded as a vector of three values. Since there are 60 minutes
    in an hour, an hour of trading is encoded as a 2D tensor of shape `[60, 3]`. If
    we have a dataset of 250 independent hours of sequences, the shape of the dataset
    will be `[250, 60, 3].`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset of tweets in which we encode each tweet as a sequence of 280 characters
    out of an alphabet of 128 unique characters. In this setting, each character can
    be encoded as a binary vector of size 128 (all zeros except a 1 entry at the index
    corresponding to the character). Then each can be considered as a rank-2 tensor
    of shape `[280, 128]`. A dataset of 1 million tweets can be stored in a tensor
    of shape `[1000000, 280, 128]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The data of an image typically has three dimensions: height, width, and color
    depth. Although grayscale images have only a single color channel, by convention,
    image tensors are always rank 3, with a 1-dimensional color channel for grayscale
    images. A batch of 128 grayscale images of size 256 × 256 would thus be stored
    in a tensor of shape `[128, 256, 256, 1]`, and a batch of 128 color images would
    be stored in a tensor of shape `[128, 256, 256, 3]` (see [figure B.4](#app02fig04)).
    This is called the NHWC convention (see [chapter 4](kindle_split_015.html#ch04)
    for more details).'
  prefs: []
  type: TYPE_NORMAL
- en: Figure B.4\. A 4D image data tensor
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](btab04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Some frameworks put the channels dimension before the height and width, using
    the NCHW convention. We don’t use this convention in this book, but don’t be surprised
    to see an image tensor of a shape such as `[128, 3, 256, 256]` elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: Video data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Raw video data is one of the few types of common real-world data for which you’ll
    need rank-5 tensors. A video can be understood as a sequence of frames, each frame
    being a color image. Since each frame can be stored in a rank-3 tensor `[height,
    width, colorChannel]`, a sequence of frames can be stored in a 4D tensor `[frames,
    height, width, colorChannel]`, and thus a batch of different videos would be stored
    in a 5D tensor of shape `[samples, frames, height, width, colorChannel]`.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, a 60-second, 144 × 256 YouTube video clip sampled at 4 frames
    per second would have 240 frames. A batch of four such video clips would be stored
    in a tensor of shape `[4, 240, 144, 256, 3]`. That’s a total of 106,168,320 values!
    If the dtype of the tensor were `'float32'`, then each value would be stored in
    32 bits, so the tensor would represent 405 MB. This is a heavy amount of data!
    Videos you encounter in real life are much lighter because they aren’t stored
    in float32, and they’re typically compressed by a large factor (such as in the
    MPEG format).
  prefs: []
  type: TYPE_NORMAL
- en: B.1.7\. Creating tensors from tensor buffers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’ve shown how to create tensors from JavaScript arrays using functions such
    as `tf.tensor2d()` and `tf.tensor()`. To do so, you must have determined the values
    of all the elements and set them in the JavaScript arrays beforehand. In some
    cases, however, it is somewhat tedious to create such a JavaScript array from
    scratch. For instance, suppose you want to create a 5 × 5 matrix in which all
    the off-diagonal elements are zero, and the diagonal elements form an increasing
    series that equals the row or column index plus 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'If you were to create a nested JavaScript array to meet this requirement, the
    code would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you can convert the nested JavaScript array `matrixArray` into a 2D
    tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This code looks a little tedious. It involves two nested `for` loops. Is there
    a way to simplify it? The answer is yes: we can use the `tf.tensorBuffer()` method
    to create a `TensorBuffer`. A `TensorBuffer` object allows you to specify its
    elements by indices and change their values by using the `set()` method. This
    is different from a tensor object in TensorFlow.js, whose element values are *immutable*.
    When you have finished setting the values of all the elements of a `TensorBuffer`
    you wish to set, the `TensorBuffer` can be conveniently converted to an actual
    tensor object through its `toTensor()` method. Hence, if we use `tf.tensorBuffer()`
    to achieve the same tensor-creation task as the previous code, the new code will
    look like'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '***1*** Specifies the tensor shape when creating a TensorBuffer. A TensorBuffer
    has all-zero values after creation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***2*** The first arg is the desired values, while the remaining args are the
    indices of the element to be set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***3*** Gets an actual tensor object from the TensorBuffer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, by using `tf.tensorBuffer()`, we reduced the lines of code from 10
    to 5.
  prefs: []
  type: TYPE_NORMAL
- en: B.1.8\. Creating all-zero and all-one tensors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is often desirable to create a tensor of a given shape with all elements
    equal to zero. You can use the `tf.zeros()` function to achieve this. To call
    the function, provide the desired shape as the input argument; for example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The tensor created has the default dtype (float32). To create all-zero tensors
    of other dtypes, specify the dtype as the second argument to `tf.zeros()`.
  prefs: []
  type: TYPE_NORMAL
- en: A related function is `tf.zerosLike()`, which lets you create an all-zero tensor
    of the same shape and dtype as an existing tensor. For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: is equivalent to
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: but is more succinct.
  prefs: []
  type: TYPE_NORMAL
- en: 'Analogous methods allow you to create tensors of which all elements are equal
    to one: `tf.ones()` and `tf.onesLike()`.'
  prefs: []
  type: TYPE_NORMAL
- en: B.1.9\. Creating randomly valued tensors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Creating randomly valued tensors is useful in many cases, such as the initialization
    of weights. The most frequently used functions for creating randomly valued tensors
    are `tf.randomNormal()` and `tf.randomUniform()`. The two functions have similar
    syntax but lead to different distributions in element values. As its name suggests,
    `tf.randomNormal()` returns tensors in which the element values follow a normal
    (Gaussian) distribution.^([[3](#app02fn3)]) If you invoke the function with only
    a shape argument, you will get a tensor whose elements follow the *unit* normal
    distribution: a normal distribution with mean = 0 and standard deviation (SD)
    = 1\. For example,'
  prefs: []
  type: TYPE_NORMAL
- en: ³
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For readers familiar with statistics, the element values are independent from
    each other.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want the normal distribution to have a no-default mean or SD, you may
    provide them as the second and third input arguments, respectively. For instance,
    the following call creates a tensor in which the elements follow a normal distribution
    of mean = -20 and SD = 0.6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '`tf.randomUniform()` lets you create random tensors with uniformly distributed
    element values. By default, the uniform distribution is a unit one—that is, with
    lower bound 0 and upper bound 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: If you want to let the element value follow a non-unit uniform distribution,
    you can specify the lower and upper bounds as the second and third arguments to
    `tf.randomUniform()`, respectively. For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'creates a tensor with values randomly distributed in the `[-10, 10)` interval:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '`tf.randomUniform()` can be used to create randomly valued int32-type tensors.
    This is useful for cases in which you want to generate random labels. For example,
    the following code creates a length-10 vector in which the values are randomly
    drawn from the integers 0 through 100 (the interval `[0, 100)`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `'int32'` argument is the key in this example. Without it, the
    tensor you get will contain float32 values instead of int32 ones.
  prefs: []
  type: TYPE_NORMAL
