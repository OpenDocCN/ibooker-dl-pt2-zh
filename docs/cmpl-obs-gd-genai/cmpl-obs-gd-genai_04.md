# 第四章：使用生成 AI 创作：媒体资源

### 本章涵盖内容

+   生成数字图像和视频

+   生成 AI 辅助视频编辑和文本转视频

+   生成演示资源

+   生成音频到文本和文本到音频

文本和编程代码是生成 AI 的自然目标。毕竟，除了二进制之外，这些是您的计算机具有最丰富经验的语言。因此，直觉上，预计能够生成我们在上一章中讨论的资源类型。

但图像、音频和视频就会有很不同的情况。这是因为视觉和音频数据：

+   比文本本身更加复杂和高维

+   缺乏符号表示，具有更加微妙的意义，这使得直接应用传统编程技术变得困难

+   可能高度主观和模糊，这使得构建能够一致且准确地解释此类数据的自动化系统变得困难

+   缺乏固有的上下文，这使得计算机系统更难以自信地推断意义

+   需要大量的计算资源来处理

然而，用于生成媒体资源的工具一直是近期对 AI 兴趣爆发的主要推动力。因此，本章的其余部分将致力于探索 AI 驱动的数字媒体创作服务的实际应用。

## 4.1 生成图像

首先，一个大型语言模型（LLM）如何将文本提示转换为视觉工件？下图说明了构成使这一过程发生的训练过程的关键步骤。

##### 图 4.1 媒体生成 LLM 的训练过程

![gai 4 1](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-1.png)

以下是该过程的详细步骤：

1.  收集大量的音频、图像和视频以供学习。这些例子来自互联网各个地方，涵盖了各种风格和主题。

1.  使用例子来学习模式。对于音频，它学习了不同的声音以及它们之间的关系（比如一个旋律遵循特定的节奏）。对于图像，它学习了不同对象的外观以及它们如何一起出现。对于视频，它找出了不同的镜头是如何组合在一起讲述一个故事的。

1.  应用数学魔法将音频、图像和视频转换为代表性数字。这些数字帮助系统理解内容中的模式和关系。这就像系统将艺术转换为它可以理解的语言。

1.  训练模型涉及 LLM 搜索可以重建已见过的音频、图像和视频的最佳模式。

1.  当 LLM 创建某物时，我们通过将其与真实例子进行比较来应用反馈和调整。模型调整其模式以使其更擅长创建更接近我们想要的内容。

1.  LLM 通过创建新的音频、图像和视频进行（大量）练习。随着每一轮练习，它在理解模式并制作自己的内容方面变得越来越好。

需要注意的是，由 AI 生成的图像和视频只是基于训练数据学到的模式的愚蠢计算机的最佳努力，可能并不总是反映现实世界的准确性 - 对于那些见过 AI 生成的每只手有 6-10 根手指或三只手臂的人来说，这一点应该是显而易见的。对于任何一个人来说，“两只”传统上是附在任何一个人身上的手的最大数量。而且，不，我不知道为什么 LLM 经常在这个显而易见的事情上弄错。

### 4.1.1 提供详细提示

无论你使用哪种图像生成服务，你构建提示的方式将在很大程度上决定最终输出的图像的质量。你需要描述性地定义你想要的图像风格。因此，类似这样的东西：

*一些树木*

…​不如：

*一片阳光明媚的树木区，风格类似约翰·康斯特布尔*

那个例子包含了一个*主题*（“树木区”），*形容词*（“阳光明媚”）和一个*艺术风格*（“约翰·康斯特布尔”）。你应该尽量在你的提示中包含这三个元素中的至少一个。可以随意添加颜色和背景纹理等细节。

如果你感兴趣，这是稳定扩散模型对最后一个提示的响应：

##### 图 4.2 以英国浪漫主义画家约翰·康斯特布尔的风格绘制的稳定扩散图像

![gai 4 2](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-2.png)

当涉及到风格时，请考虑从这个（部分）列表中添加一些内容：

+   摄影

+   立体派的

+   油画

+   哑光的

+   超现实主义的

+   蒸汽朋克

+   可爱的生物

+   幻想世界

+   赛博朋克

+   古老的

+   文艺复兴时期的绘画

+   抽象的

+   真实的

+   表现主义

+   漫画

+   墨水

### 4.1.2 提示生成图像

尽管如此，我决定忽略所有关于风格和细节的建议，并向几个 AI 图像创作平台询问可能用于装饰这本书的封面。正如你所看到的，我的提示没有提供任何具体的描述。相反，我仅仅给了它一个抽象的概念（书名），并假设 GAI 将能够将其暗示的概念转化为图形。

##### 提示工程

*为一本名为《完全过时的生成式人工智能指南》的书创建一个 6:9 的封面。图像不应包含任何文本或字母数字字符。*

值得注意的是，我如何指定了纵横比（“6:9”）来告诉软件图像应该采取的形状。我还告诉它不要包含任何文本。AI 在处理文本方面是臭名昭著的*糟糕*。

如果曼宁艺术部门的任何人正在阅读，请看一下我收到的一些图像之一。第一个来自梦想工作室，看起来很棒，尽管他们似乎忽略了纵横比的备忘录。

##### 图 4.3 一个梦想工作室的“书籍封面”图像

![gai 4 3](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-3.png)

这张来自 Stable Diffusion 模型的图片符合很多正确的标志，并且考虑到我给它的内容很少，相当令人印象深刻。

##### 图 4.4 Stable Diffusion 的 "书封" 图像

![gai 4 4](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-4.png)

每次我在网上搜索时都会发现更多的图像生成服务。但是，目前这些是特别重要的参与者：

**Midjourney** 起步有点棘手，但似乎能生成非常高质量的图像。您需要在 midjourney.com 创建一个帐户，选择年度或月度费用帐户级别，然后将 Midjourney 服务器添加到您的 Discord 帐户中。从 Discord 中，您可以在直接消息栏中选择应该出现的 "Midjourney Bot"。要获取您的第一组图像，请在底部的文本字段中键入 `/imagine` 后输入您的提示。一旦生成，四个可能的图像将显示在您的 Midjourney UI 中。我不能说我理解为什么设计成这样，但很多人似乎觉得值得一试。

##### 图 4.5 在 Discord 帐户中访问 Midjourney

![gai 4 5](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-5.png)

**DALL-E** - 由 OpenAI 提供 - 是大多数人遇到的第一个数字图像生成工具。在它的时代，它令人震惊，并引起了对相关技术和相关可能性的关注。但或许出于设计考虑，它从未像其他竞争服务一样产生过同样范围和照片般逼真的图像。

##### 图 4.6 OpenAI 的 DALL-E 基于浏览器的界面

![gai 4 6](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-6.png)

**Stable Diffusion** 是一个可以通过像 Hugging Face 这样的服务的帐户免费访问的生成模型 - 这是一个提供许多 AI 模型、数据集和其他 AI 工具的托管服务，使用免费和按使用量付费的级别。如果您有一台带有图形处理器单元 (GPU) 并且至少有 8GB 视频内存的计算机，您实际上可以安装和运行自己的私有 Stable Diffusion 服务。

##### 图 4.7 Stable Diffusion GitHub 页面

![gai 4 7](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-7.png)

**DreamStudio** 通过他们的网站提供图像生成服务。您可以免费获得有限数量的积分，更多积分可供购买。目前，使用每 1000 积分需要花费 10 美元。每张图片的成本取决于大小和复杂度。DreamStudio 由 stability.ai 提供 - 这是 Stable Diffusion 的负责公司。

##### 图 4.8 DreamStudio 浏览器界面

![gai 4 8](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-8.png)

## 4.2 生成视频

如果 GAI 能够创建图像，它们也能够用同样的技巧制作视频，是吗？当然可以。但是你必须更具体地说明你所说的 "视频" 是什么意思。

如果你所期望的是写下一个提示（就像我们一直用于图像的那些）然后一个美丽的视频突然活灵活现地呈现在眼前，那么我们还没有完全达到那一步。Meta 和 Google 都大声宣布了技术（Meta 的 Make-a-Video 和 Google 的 Imagen Video）将做到这一点。但请记住，这两种工具绝对、肯定、毫无疑问会在未来的某个不确定日期上推出。

RunwayML 发布了一个有限访问权限的令人期待的工具。但是，考虑到目前每个输出剪辑的最大时长为 4-15 秒以及显著的渲染时间，它还不是我们所期望的一切。

但是，如果你能将“视频”的定义稍微扩展一下，那么我们可能有些东西可以谈论。

### 4.2.1 AI 辅助视频编辑

目前绝对存在的一个过程涉及采用现有视频并操纵它们，使它们讲述一个完全不同的故事。

使用样式化和遮罩效果，像 RunwayML 的 Gen-1 和开源项目 Text2Live 可以创建类似于高端好莱坞工作室一直在做的事情。不同之处在于，那些好莱坞工作室通常需要花费数月时间和数百万美元购买他们所需要的设备和专家。我们现在可以在一台性能适中的笔记本电脑上在几秒钟内获得几乎相同的质量。事实上，你可以通过下载并在自己的机器上运行它来自托 Text2Live。

你实际上可以做什么？我建议你查看 Gen-1 和 Text2Live 网站的演示视频。它们会向你展示纹理、背景、照明和其他属性如何被替换，以将现有视频，比如一个男人沿着车道跑的视频，转换成一个宇航员在外星球表面奔跑的视频。

### 4.2.2 文本到视频幻灯片

那些都非常有趣。但我们中的一些人使用视频的任务更接近办公室而不是外太空。换句话说，针对教育、IT 培训、新闻服务、营销和企业通讯等媒体内容的巨大市场存在。以传统方式制作这样的演示文稿可能需要每分钟数小时的时间（我知道，因为我靠这个谋生）。这还没有考虑到为了让你直接上镜头而需要额外的设备和工作室成本。

然而，目前有一些由人工智能驱动的服务可以接受你的脚本，并生成一个由超逼真的计算机生成的声音（使用你选择的男性或女性、口音、年龄和个性）以及相应的支持背景图像和项目符号文本组成的专业视频。你也可以上传自己的图像。这一流派的高端玩家还会添加一个看起来非常接近实际真人的类人化头像。

加上使用 ChatGPT 生成的脚本，就能在几分钟内完成一整套专业视频的制作。

有何陷阱？啊，是的。陷阱。嗯，高端的东西并不便宜。目前许多更专业的服务每年收费数百美元（甚至更多），并将输出限制为每月指定数量的视频分钟数。这个市场的领导者可以说是：

+   Synthesia

+   Elai

+   Steve AI

+   Fliki

+   Synthesys（不要与 Synthesia 混淆）

## 4.3 生成演示文稿资源

PowerPoint 演示文稿有一种特质，激发了人们对恐惧和厌恶的共鸣。会议参与者对经过粗糙计划和设计的演示文稿感到厌恶。而演讲者则面对着不情愿地逐一构建演示文稿（然后遭受观众的仇恨）的任务，感到恐惧。

当然，幻灯片演示不仅仅是会议演示。它们通常也是商业和教育视频的主要结构。这就是本章的主题所在。

你知道，生成 AI 已经完全能够为你做所有的艰苦工作：有时技术创新确实解决了问题。至少对于演讲者或视频制作者来说是这样。而可怜的观众还是几乎自顾自。

Gamma 是众多文本转演示文稿服务中的一种。我将重点介绍 Gamma，只是因为这是我迄今为止经验最丰富的一个。

利用我被允许的一些免费试用积分，我选择了 `New with AI` 选项，然后选择了他们的 `Text transform` 路径，并在说明字段中输入了这段文本（是的：这就是本章的工作标题）：

*使用以下标题生成有关使用生成 AI 创作：媒体资源的演示文稿：*

然后，我将以下主题标题粘贴到内容字段中：

+   生成图像

+   生成视频

+   AI 辅助视频编辑

+   文本转视频幻灯片演示

+   生成演示文稿资源

+   生成音乐

之后，我只需从他们的列表中选择一个格式，几分钟之内，Gamma 就为一个非常吸引人的演示文稿生成了文本内容、布局和视觉效果。你可以在我的网站上看到生成的 PDF。

当然，我可以自由编辑任何不符合我的需求的内容。但对于我们渴望逃离 PowerPoint 地狱的人来说，这是一个游戏规则的改变。

## 4.4 生成语音

不满意您的口音或者只是没有一个好的、安静的地方来录制您的播客或视频解说？有一些服务可以将文本内容转换成您选择的声音、口音、完美的节奏和没有孩子在背景尖叫的音频文件。如果您仍然希望成为叙述者，您也可以克隆您的声音，*它*可以用来生成您的音频文件。

当然，语音转文字已经发展了几十年了。我们都听过有计算机生成声音的语音信箱系统。正在改变的是，人工智能的进步大大提高了质量。

"改进了"，但不一定完美。自己试试。将一些内容上传到比如亚马逊的 Polly 服务，你会印象深刻。但是仔细听了至少一分钟之后，任何听众都可能会得出结论，这实际上不是一个真正的人在说话，尽管它很好，但它的质量永远不会被误认为是奥森·威尔斯或温斯顿·丘吉尔。

另一方面，雇佣一个具有那种口才技巧水平的人来录制您的内容，成本肯定会比亚马逊每*百万*个字符收取的 4.00 美元高得多。所以就是这样。

Polly 主要面向需要实时生成语音的组织。想象一下交互式网站支持系统。这意味着 Polly 的客户将希望通过编程方式的 API 连接来脚本化其音频的创建和管理。为了向您展示这将如何运作，这里有一个使用 AWS CLI（一种命令行 API 访问工具）的示例命令，它将请求从我称为`text.txt`的本地文件中生成的文本的音频.MP3 文件。为了使其工作，您需要一个 AWS 账户。您还需要设置和配置 AWS CLI。

```py
aws polly start-speech-synthesis-task \
    --output-s3-bucket-name mypolly345 \
    --text file://text.txt \
    --voice-id Matthew \
    --engine neural \
    --language-code en-US \
    --output-format mp3
```

注意我如何使用美式英语（`en-US`）口音指定了`Matthew`声音。Polly 还有数十种其他声音和口音选项。

一旦生成了指定的 Amazon S3 输出桶中的文件，我可以使用以下 AWS CLI 命令下载该文件：

```py
# Copy all files:
aws s3 cp s3://mypolly345 . --recursive
```

我可以使用`s3 rm`删除这些文件的远程副本。

```py
# Remove all existing files:
aws s3 rm s3://mypolly345/ --recursive
```

因为我认为玩完玩具后应该始终清理好它们。

文字转语音是一个竞争激烈的市场。除了 Polly，其他平台提供了 API 访问服务。这些包括谷歌云的巧妙命名的文字转语音服务和 IBM 的 Watson 文字转语音声音。

除此之外，还有一些服务将允许您通过网站界面逐个将文本文档转换为语音。ElevenLabs 在这个领域有着表现超常的声誉，特别是在创建定制语音或克隆*您的*声音方面。Speechify 是另一个主要参与者。

## 4.5 音频转录

这解决了文本转音频的问题。但是音频到文本（又称*语音识别*）呢？将现有视频或音频文件转录为文本文件有许多商业用途。想不出任何用途？那么试想一下，从你错过的（无聊的）两小时视频会议中提取音频。尽管当时你老板相信了你的狗吃了我的作业的借口，但你仍然需要通过观看会议的录像来重新掌握情况。

你没有不努力变得优秀和懒惰。所以这是你要反击那个邪恶命令的方法。你将录音提交给一个音频转录服务，该服务将为您提供包含完整脚本的文本文档。然后，您将脚本转换为 PDF 文件并将其上传到我们将在第五章中讨论的 ChatPDF 服务中。当 PDF 被上传时，您可以请求脚本的简短但准确的摘要。

更好的是，还有像 mindgrasp 的视频摘要工具这样的服务，可以一步完成所有这些。

一个提供简单但有效摘要的服务的例子是 Summarize.tech。为了测试它们，我将我自己的 YouTube 视频之一的地址输入到他们的 URL 字段中。几秒钟后，我就看到了这个简短但准确的摘要：

*本视频讨论了与 AWS EC2 实例相关的安全漏洞。默认情况下，这些实例缺乏防火墙并且具有开放的安全组，使其容易受到攻击。讲师提供了一个真实的例子，演示了如何在几分钟内启动具有开放入站流量的 EC2 实例并收到登录尝试。他强调了在服务器功能和基础设施安全性之间取得平衡的重要性，这将是该课程的主要目标。*

看到了吧？生活并不像你今早起床时看起来那么糟糕。

当然，还有用于转录音频的 API。其中两个是 OpenAI 的 Whisper 和 Google 的语音转文本。

Whisper 是一个会做很多花招的狗。除其他外，它可以处理语言识别、语音翻译和多语言语音识别等任务。与许多基于 GPT 的应用程序一样，Whisper 旨在使用有效的 OpenAI API 密钥在您自己的计算机上安装和运行 - 正如您已经看到的那样，可以在 OpenAI 网站上获取。

并且这并不会像你想象的那么复杂。在 Python 环境中，只需使用`pip`安装`Whisper`包：

```py
pip install -U openai-whisper
```

你还需要开源视频/音频管理工具`ffmpeg`。以下是如何将其安装到基于 Debian/Ubuntu 的 Linux 系统中的步骤：

```py
sudo apt update && sudo apt install ffmpeg
```

这是使其工作的代码：

```py
import whisper

model = whisper.load_model("base")
result = model.transcribe("MyAudio.flac")
print(result["text"])
```

我们将使用`base`模型，将我们转录的文本（基于我使用的`MyAudio.flac`输入文件）写入变量`result`，然后显示结果。非常简单。而且非常准确！

当然，你可以使用所有常见的音频和视频文件格式作为输入，并从五种模型中选择（tiny、base、small、medium 和 large）。

## 4.6 生成音乐

我想在没有谈论人工智能生成的音乐之前，我不能继续了。我不仅仅是在谈论 ChatGPT 驱动的歌词，或者甚至是能够输出乐谱的软件，而是*真正的*音乐。这意味着软件可以让你指定细节，比如流派、你希望演奏的乐器、情感色彩、速度范围、拍子、调号和和声重复，然后会有真正的音乐出现。

正如你可能听说过的，其中一些服务还可以重新创作出著名歌手的几乎完美的声音，并让其演唱你自己的新音乐。使用这种声音的确切法律意义尚不清楚。

在线 AI 音乐生成工具-大多数主要用于使用不同的流派创建背景音乐，包括 AIVA、boomy、Soundful 和 Mubert。

最近，Meta（Facebook 的所有者）已经发布了两个音频生成工具作为开源项目。

+   MusicGen 会根据文本提示生成音乐。

+   AudioGen 会为你提供音效（想象一下："警车鸣笛的繁忙街道"或者"风穿过树木"）。

此外，他们还发布了神经音频编解码器 EnCodec 和基于扩散的解码器 Multi Band Diffusion。你可以自由下载代码，但是，就像使用图像生成器一样，你需要大量的系统资源来使其正常工作。

## 4.7 总结

+   我们了解了使用稳定扩散和中途旅程等服务生成数字图像（和视频）的方法。

+   我们了解了可以使用 AI 将现有视频工件转换为新媒体的工具

+   我们学习了如何使用 Gamma 等 AI 工具根据文本提示生成演示文稿堆栈。

+   我们了解了使用 Amazon Polly 和 OpenAI Whisper 等工具进行音频转文本和文本转音频的方法。

## 4.8 试试看

为什么不使用本章中介绍的一些媒体生成工具制作一部原创培训视频呢？以下是你可能想要采取的步骤：

+   选择一个主题（也许是"如何最大限度地利用生成式人工智能工具"），并为视频转录稿提示一个 LLM（三分钟的视频将需要大约 500 个文字）。

+   作为 LLM，可以总结脚本，给出一组描述性的要点。

+   使用 Gamma，选择创建新的 > 文本转换，并将你的要点粘贴到内容字段中。然后生成幻灯片。

+   使用 Amazon Polly，从 LLM 创建的脚本生成一个解说文件。

+   使用 Mubert 生成背景音乐。

+   将你的叙述、幻灯片和背景音乐组合成视频，可以使用，比如，Vimeo 视频制作工具。

+   最后，只是为了好玩，使用 Whisper 从视频的叙述音轨中提取文本转录，并看看它与原始脚本有多接近。
