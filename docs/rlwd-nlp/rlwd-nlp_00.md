# 第一章：目录

前言

致谢

关于本书

关于作者

关于封面插图

第一部分 基础知识

自然语言处理简介

1.1 什么是自然语言处理（NLP）？

什么是 NLP？

什么不是 NLP？

AI、ML、DL 和 NLP

为什么需要 NLP？

1.2 NLP 如何应用

NLP 应用

NLP 任务

1.3 构建 NLP 应用

NLP 应用的发展

NLP 应用的结构

你的第一个 NLP 应用

2.1 介绍情感分析

2.2 使用 NLP 数据集

什么是数据集？

斯坦福情感树库

训练、验证和测试集

使用 AllenNLP 加载 SST 数据集

2.3 使用词嵌入

什么是词嵌入？

利用词嵌入进行情感分析

2.4 神经网络

什么是神经网络？

循环神经网络（RNN）和线性层

情感分析架构

2.5 损失函数和优化

2.6 训练自己的分类器

分批处理

将一切整合在一起

2.7 评估你的分类器

2.8 部署你的应用

做出预测

服务化预测

3 词语和文档嵌入

3.1 介绍嵌入

什么是嵌入？

为什么嵌入很重要？

3.2 语言构成的基石：字符、单词和短语

字符

单词、标记、形态和短语

N-grams

3.3 标记化、词干提取和词形还原

标记化

词干提取

词形还原

3.4 Skip-gram 和连续词袋 (CBOW)

词嵌入的来源

使用词关联

线性层

Softmax

在 AllenNLP 上实现 Skip-gram

连续词袋 (CBOW) 模型

3.5 GloVe

GloVe 如何学习词嵌入

使用预训练的 GloVe 矢量

3.6 fastText

利用子词信息

使用 fastText 工具包

3.7 文档级别的嵌入

3.8 可视化嵌入

4 句子分类

4.1 循环神经网络 (RNNs)

处理变量长度输入

RNN 抽象

简单的 RNNs 和非线性

4.2 长短期记忆单元 (LSTMs) 和门控循环单元 (GRUs)

梯度消失问题

长短期记忆 (LSTM)

门控循环单元 (GRUs)

4.3 准确度、精确度、召回率和 F-测量

准确率

精确度和召回率

F-测量

4.4 构建 AllenNLP 训练管道

实例和字段

词汇和标记索引器

标记嵌入和 RNNs

构建自己的模型

综合应用

4.5 配置 AllenNLP 训练管道

4.6 案例研究：语言检测

使用字符作为输入

创建数据集读取器

构建训练管道

在未见实例上运行检测器

5 顺序标注和语言建模

5.1 介绍顺序标注

什么是顺序标注？

使用 RNN 编码序列

在 AllenNLP 中实现 Seq2Seq 编码器

5.2 构建词性标注器

读取数据集

定义模型和损失

构建训练管道

多层和双向 RNNs

多层 RNNs

双向 RNNs

命名实体识别

什么是命名实体识别？

标记跨度

实现命名实体识别器

5.5 语言建模

什么是语言模型？

语言模型有何用处？

训练 RNN 语言模型

使用 RNN 生成文本

向 RNN 提供字符

使用语言模型评估文本

使用语言模型生成文本

高级模型的第二部分

序列到序列模型

6.1 介绍序列到序列模型

6.2 机器翻译入门

6.3 构建你的第一个翻译器

准备数据集

训练模型

运行翻译器

6.4 Seq2Seq 模型的工作原理

编码器

解码器

贪婪解码

束搜索解码

评估翻译系统

人工评估

自动评估

6.6 案例研究：构建聊天机器人

介绍对话系统

准备数据集

训练和运行聊天机器人

下一步

卷积神经网络

7.1 介绍卷积神经网络（CNNs）

循环神经网络（RNNs）及其缺点

用于句子分类的模式匹配

卷积神经网络（CNNs）

7.2 卷积层

使用过滤器进行模式匹配

修正线性单元（ReLU）

合并得分

7.3 池化层

7.4 案例研究：文本分类

回顾：文本分类

使用 CnnEncoder

训练和运行分类器

8 注意力和 Transformer

8.1 什么是注意力？

纯 Seq2Seq 模型的局限性

注意力机制

8.2 带注意力的序列到序列

编码器-解码器注意力

使用注意力构建 Seq2Seq 机器翻译

8.3 Transformer 和自注意力

自注意力

Transformer

实验

8.4 基于 Transformer 的语言模型

Transformer 作为语言模型

Transformer-XL

GPT-2

XLM

8.5 案例研究：拼写检查器

拼写校正作为机器翻译

训练拼写检查器

改进拼写检查器

使用预训练语言模型的迁移学习

9.1 迁移学习

传统机器学习

词嵌入

什么是迁移学习？

9.2 BERT

词嵌入的局限性

自监督学习

BERT 的预训练

调整 BERT

9.3 案例研究 1：BERT 情感分析

对输入进行分词

构建模型

训练模型

9.4 其他预训练语言模型

ELMo

XLNet

RoBERTa

DistilBERT

ALBERT

9.5 案例研究 2：BERT 自然语言推理

什么是自然语言推理？

使用 BERT 进行句对分类

使用 AllenNLP 的 Transformers

投入生产

NLP 应用程序开发的 10 条最佳实践

10.1 实例分批处理

填充

排序

掩码

10.2 神经模型的标记化

未知词汇

字符模型

子词模型

10.3 避免过拟合

正则化

提前停止

交叉验证

10.4 处理不平衡数据集

使用适当的评估指标

上采样和下采样

加权损失

10.5 超参数调整

超参数示例

网格搜索 vs. 随机搜索

使用 Optuna 进行超参数调整

11 部署和为 NLP 应用程序提供服务

11.1 构建您的 NLP 应用程序

机器学习之前

选择正确的架构

项目结构

版本控制

11.2 部署您的 NLP 模型

测试

训练-服务偏差

监控

使用 GPU

11.3 案例研究：为 NLP 应用程序提供服务和部署

使用 TorchServe 提供模型

使用 SageMaker 部署模型

11.4 解释和可视化模型预测

11.5 接下来去哪里

##### 索引
