# 第八章：人工智能不威胁我们的工作

### 本章涵盖内容

+   关于人工智能对就业影响的夸大担忧

+   人工智能面临自动化许多人类任务的挑战

+   在现实世界中应用人工智能的问题

+   不恰当设计的人工智能系统的危险影响

在本章中，我们将通过各种例子证明，尽管人们担心人工智能接管工作，但大多数人类职业仍然远远超出了当前人工智能技术的范围。

围绕着机器取代人类工作的担忧具有悠久的历史根源。早在 1589 年，英国发明家威廉·李为他的针织机寻求专利时，伊丽莎白一世因为担心王国众多的手工织布者而拒绝了他。这说明了人对技术进步影响就业的长期恐惧。在附录中，我们将简要提及卢德派和他们对 19 世纪纺织机械的反动行动。这一历史时刻强调了对自动化的抵抗，这往往源自于对工作被取代的担忧。1987 年 7 月，《哈佛商业评论》发表了一篇标题为“思考人工智能”的文章。文章开头就是这样一个声明：“有些人相信人工智能即将改变商业实践。他们声称‘智能’计算机程序即将扮演医生、律师、工厂工人和经理等角色”[1]。我们知道，这些预言都没有实现。

快进到现在，对机器取代人类工作的担忧仍在不断发展，有时带有危言耸听的语调。一些专家甚至有一套预测人工智能取代你工作可能性的公式，表明如果一个工作容易解释，它就可以被人工智能取代[2]。这种令人担忧的预测也出现在 2015 年的一份报告中[3]，由全球挑战基金会和牛津大学未来人类研究所联合发布，其中认为机器即将取代大部分劳动力。报告指出：

> 人工智能将立即受益于计算机速度和任何计算机研究方面的改进。它们可以接受特定职业的培训并随意复制，可能取代全球劳动力的大部分，造成重大的经济混乱。

前总统奥巴马在 2016 年与《WIRED》杂志的一次采访中[4]认可了人工智能对工作的替代性风险。他说：

> 有一件我们没有多加讨论，但我想强调的事情是，我们确实需要考虑人工智能的经济影响。大多数人现在并不担心“奇点”; 他们担心的是自己的工作是否会被机器取代。

媒体也为围绕人工智能导致工作岗位流失的轰动报道做出了贡献，标题如“机器人现在可以比人类更好地阅读，导致数百万个工作岗位面临风险” [5] 和预测“你最喜欢的餐厅可能很快就会雇用机器人担任厨师和服务员，可能导致数百万工人失业” [6]。

世界经济论坛发布了一份“未来的工作报告” [7]，其中包含了每个国家每个行业的广泛统计数据和预测。该报告断言第四次工业革命可能会导致劳动力减少，并列出了以下说明性预测：

+   近 50％的公司预计到 2022 年自动化将导致全职员工人数有所减少。

+   四十二％的工时将由机器执行。

+   七千五百万个工作岗位可能会因人类和机器之间劳动分工的转变而被替代。

2020 年，商人安德鲁·杨，一位民主党总统候选人，部分竞选承诺要实施普遍收入，以缓解自动化导致的工作岗位流失。此外，一家知名咨询公司做出了一个预测，预计到 2030 年，约三分之一的美国劳动力可能需要转换到新的职业 [8]。他们还强调了到 2030 年，全球多达 1.6 亿名妇女可能需要转换职业的可能性，特别是由于自动化而在诸如秘书、日程安排员和簿记员等角色中具有特殊脆弱性。IBM 前首席执行官吉尼·罗梅蒂在接受 CNBC 采访时更综合地表示，人工智能将影响到 100％的工作 [9]。

在本章中，我将阐述为什么这些反乌托邦场景缺乏坚实的基础。在第六章中，我们对人类和机器智能进行了比较分析，确定了人类和机器之间的几个基本区别。在这里，我们将讨论人工智能的局限性，特别是在工作场所的背景下。

尽管自动化很适合处理简单、重复性和潜在危险的任务，但以机器人技术闻名的汽车工业却呈现出一个有趣的悖论。人们可能预料在这样的环境中人力劳动需求会减少。然而，现实和统计数据提供了不同的视角。以德国汽车工业为例，员工人数逐年增加，2018 年达到了 833,937 人 [10]。这一现象突显了该行业内一个广泛认可的事实：机器在需要认知能力和灵活性的任务上表现不佳 [11]。

同样，人们可能预期会在会计领域看到自动化的激增，因为其基础在于计算，似乎是机器替代的理想领域。 然而，现实再次挑战了这一假设。 令人惊讶的是，自 1980 年代计算机广泛应用于工作场所以来，会计行业的人员数量与广泛预测相反，翻了一番。

在医学领域也可以发现类似于汽车和会计行业观察到的模式。 医疗人工智能的萌芽可以追溯到 20 世纪 70 年代初，当时开发了像 MYCIN 这样的系统（见第二章），以及其他系统如 CASNET 和 INTERNIST。 可预见的是，这些项目被视为传统医学新时代的开端。 1979 年 8 月 5 日《纽约时报》发表的一篇题为“医疗技术：新的革命”的文章[12]告知读者可以预期以下进展：

> 十年后如果你不得不去医院，你的访问可能会进行如下：经过不可避免的接待员，你换上一件毫无形状的医院长袍，走进一个小小的、消毒的房间。 你坐下，把手臂伸给一个长方形的机器。 机器无痛地抽取了一份血样，并在几秒钟内分析到了最小的有意义的血小板。 这些信息被传送到医院深处的中央计算机，与以前的读数进行比较，以检测你身体的任何感染。 你移到旁边的一个房间，坐在一个巨大的设备下面。 在你的身体被 X 射线或微波无声探测时，传感器检查你皮肤的表面。 热图将显示出温度升高的区域，这可以显示出初期疾病。 尽管你什么也感觉不到，什么也看不到，但你的身体内部正在被深入审查。 一个正在发育的胆结石，仍然几乎只有一粒沙子大小，被注意到并被评估了；就像一个微小的白色血栓被困在冠状动脉内，或者一个在你鼻腔中隐藏的息肉一样，它可能是无害的，但仍然值得关注。 在几分钟内，一份由计算机准备的细致详尽的工作报告已经准备好，并发送给了你的医生。

超过四十年的时间过去了，似乎我们反而退步了。 最近我去了旧金山湾区的一家医院，等了三个小时才见到一个护士，她问的问题和一个老式黑白电影中可能听到的问题一样。 唯一的区别是电影中的医院会更干净，更少拥挤，病人直接与医生交谈，而不是与护士交谈。 你见过机器接管医生通常执行的医疗任务吗？

我博士期间的一部分研究涉及利用人工智能进行医学推理和诊断。我自己没有接受过医学培训，所以我最初尝试使用专家系统来模拟我从几位医生那里学到的思维方式。为了讨论方便，我将在这里概述一下引导我设计人工智能解决方案的思维过程。

当面对一个患者时，专家系统的第一优先事项是解决任何紧急情况。例如，如果一个患者正在失血，那么需要立即解决。一旦解决了任何紧急情况，就会做出任何明显的诊断。例如，一个其他情况稳定的患者，他说自己摔倒摔断了手臂，他可能是对的。任何决定性的测试都将被进行以确认诊断，并提供必要的治疗。

如果没有紧急情况，也没有明显的结论可得，那么就要寻找可以暗示正确诊断的决定性事实。首先应优先考虑经济、安全、非侵入性的测试，只有当更合理的选择未能提供澄清时，才会采取更奢侈的措施。例如，如果有理由怀疑患者患有支气管炎，并且可以通过简单的喉咙培养来测试这个假设，那么你就要做喉咙培养，而不是订购一项费时、昂贵、不舒服的 MRI 检查。你会从可能的假设和合理的测试程序进展到不太可能的可能性和不太理想的程序，直到问题能够被确定。

在每个步骤中进行的思考过程是依赖于上下文的。例如，需要考虑患者的年龄、性别、家族史和既往病史。此外，一些测试结果具有较高的不确定性。因此，需要进行复杂的推理，而医生的许多技能是内隐的，很难表述。医生对我解释他们的推理时，往往是相当具有挑战性的，难以在算法中复制。

Faith Fitzgerald 博士得出了相同的结论[13]。她解释说，临床推理不能简化为一套规则，因为每个患者都有自己独特的情况和背景，她将医学推理的微妙性质描述如下：

> 实际上，最佳的临床诊断思维更像是拼贴而不是线性思维：它要求医生在每一个新的数据出现时不断调整诊断。一个人不断地构想许多可能的诊断，不断缩小范围，再扩大，产生不断变化的思想流；从患者那里获得的信息越多，越好。

正如之前提到的，2011 年，IBM 的 AI 程序 Watson 击败了两位前“危险边缘”节目的冠军。当时，这一成功被庆祝为一个新时代的曙光，即机器可以回答我们所有的问题。人们设想 Watson 可以快速分析医学文件，并将患者数据与最新研究相结合，提供个性化、尖端的治疗方法。IBM 在 2010 年代中期收购了四家健康数据公司，总价值约 40 亿美元，似乎将它们定位为通过 AI 改革医疗保健的理想选择。然而，到 2020 年，在投入数十亿美元进行研究和开发后，IBM 的 Watson Health 部门从未推出过任何 AI 医生产品，并且该部门最终以亏损出售，在 2022 年初售价约为 10 亿美元。

IBM 的领导层现在将 Watson Health 的发展描述为一个具有挑战性和拖延性的过程，比他们最初预期的要复杂和耗时得多[14]。类似的情况也发生在 IBM 与休斯顿德克萨斯大学安德森癌症中心的合作中。他们的联合项目旨在创建肿瘤学专家顾问工具，最终遭遇了同样的命运。2016 年，该大学进行的一项审计显示，在最终取消项目之前，已经在该项目上花费了超过 6200 万美元。

对这些失败的冒险进行更深入的审视，揭示了医疗领域的现实与当前有限、零散和不智能的机器学习技术之间的根本不匹配。用于挖掘数据、神经网络和统计方法主要适用于识别特定的、预定义的模式或构建仅适用于明确定义的、受控场景的预测模型。

这些工具往往只能揭示数据中最简单的关系。即使拥有大量数据，这些模型也无法推断出基本事实，比如血液循环是由心脏的泵血作用引起的事实。因此，当涉及到解开因果链或提出可能显著有助于诊断或治疗的关联时，它们肯定是不够的。因此，AI 可以取代医疗专业人员的想法是毫无根据的。

## 8.1 简单的人类任务易于自动化吗？

我们知道机器擅长某些任务。工厂机器人可以整天在金属件上打孔，永远不会出错或感到疲倦。如今，随着我们拥有的先进技术，大众媒体会让你觉得大多数平凡的任务很快就会自动化。这一节的前两个例子可能就足以让你改变看法，我们将以其他几个例子来结束这一章，以加深这一观点。

我们首先要考虑的任务是制作比萨。为了介绍这个故事，我们将引用 CNBC 的名人吉姆·克莱默在他赞扬科技初创公司 Zume 的一段视频片段[15]：

> 每个人都喜欢披萨，部分原因是因为很难把披萨搞砸。我的意思是，即使是糟糕的披萨也还是尝起来不错，但如果有一种更好的方法来制作和送达披萨呢？事实证明确实有，这就引出了 Zume 公司，一家位于硅谷的初创企业，他们试图将这个行业带入现代化。他们以将机器人引入生产过程而闻名，从均匀涂抹番茄酱到把比萨从烤箱里拿出来并完美地切片，机器人在生产过程中扮演了重要角色。基本上，机器人完成了各种高度重复的任务…… 我认为这是真实的。这不是一个想法，而是一个业务。

曾经，Zume 看起来拥有所有必要的人才和资源，可以彻底改变比萨生产和送货的自动化。2018 年，他们从 SoftBank 获得了 3.75 亿美元的大笔投资，并开发了一个有前途的系统。他们的创新方法涉及人类和机器人的协同作用，能够在一辆多功能卡车上每小时生产多达 120 个比萨，这辆卡车既可以用作人行道销售的食品车，也可以用作送货车。对于送货，一个人工智能系统优化了路线和比萨生产，确保在在线订购后最快 5 分钟内送达。然而，到 2020 年 1 月，在应对了许多挑战之后，Zume Pizza 停止运营。最初，他们的机器人被重新用于可持续食品包装生产[16]。然而，在 2023 年 6 月，《华尔街日报》报道称，Zume 已启动了一个清算过程[17]：“加利福尼亚初创公司 Zume，曾开发一种机器人比萨制造机，并曾被估值为 22.5 亿美元，最近已开始清算过程。”

因此，制作和送达披萨似乎仍然超出了现代人工智能的范围，或者至少存在着使取代人类不可行的物流或实际问题。也许制作和提供咖啡的任务会更可行？毕竟，约翰·斯坦贝克在他的 1962 年著作《与查理一起旅行》[18]中描述了一个自动化系统，这个系统似乎运行得相当不错：

> 我已经忽视了自己的国家太久了。在我不在的这段时间里，文明取得了巨大的进步。假设你想要一种软饮料；你选择你喜欢的种类——Sungrape 或 Cooly Cola——按下一个按钮，投入硬币，然后退后一步。一个纸杯落在指定位置，饮料倾倒出来，离杯沿仅有四分之一英寸的距离——一种冷冻的，保证是合成的清爽饮料。咖啡更有趣，因为当热的黑色液体停止流动时，一股牛奶会喷出，并且一个糖包掉到杯子旁边。但是，最惊人的是热汤机。在豌豆、鸡肉面、牛肉和蔬菜之间进行选择，然后投入硬币。巨大的机器发出隆隆声，一个标志亮起写着“加热”。一分钟后，红灯闪烁直到你打开小门，取出热气腾腾的汤纸杯。

尽管开始看似有希望，但创建一个机器人咖啡师的尝试并没有成功，这一点可以从咖啡馆中机器人的明显缺席中看出。事实上，我们继续像 1671 年法国马赛第一家咖啡馆开业时那样制备和提供咖啡。但是这是为什么呢？毕竟，制作咖啡本质上是不是关于在容器之间转移物质并开关开关？

即使是一个年幼的孩子也可以毫不费力地从最近的水龙头中用任何形状或大小的容器装满水，只要他们能够到达水龙头并且容器能放在下面。他们本能地知道应该把水龙头拧多远，以及让水流多久才停止。他们理解容器和水龙头的作用，以及水从龙头流入容器时的行为。

另一方面，机器缺乏对容器、水流或水龙头的直观理解。虽然机器手臂可以被编程移动容器到特定位置并激活水龙头一段时间，但它会继续向更小的容器倾倒水直到溢出，除非给出明确的指令来适应新情况。这还假设机器人能够拿起不同尺寸的容器，这本身就是一个具有挑战性的任务。

考虑到我们已经有能够在杯子里生产基本混合物的机器六十年了，似乎我们已经到了需要一个机器人咖啡馆的时候了。考虑到我们在自动化相对简单的任务，比如制作咖啡方面的进展缓慢，人们必须质疑“大多数工作”自动化很快会发生的可能性。

或许你认为我们在选择性地举例，以及机器人能够充分完成其他基本任务？沃尔玛在 2017 年开始试验由卡内基梅隆大学机器人研究所的分支机构 Bossa Nova Robotics 生产的机器人库存检查员。这些机器人会上下巡视走廊，确认货架上的商品。经过三年的实验，项目结束了，与项目接近的消息人士表示，“沃尔玛结束了合作，因为它找到了不同的，有时更简单的解决方案，证明它们同样有用” [19]。

人们可能会认为纺织工作是自动化的良好候选对象。例如，服装制造通常涉及根据一套图案反复缝制。甚至有人开玩笑说“现代纺织厂只雇用一个人和一条狗——人喂狗，狗让人远离机器。”然而，实际上，缝纫一直是特别难以自动化的，部分原因是因为当织物被操纵时会拉伸和聚集，而机器没有保持事物正确摆放所需的灵活性 [20]。

关于交通自动化呢？驾驶似乎是自动化的主要候选对象，因为它很单调，法律规定明确，人为错误是一个令人担忧的原因。我们在第四章中简要提到过，像凯旋门周围这样的复杂环境可能永远无法被我们今天所拥有的人工智能所驾驭。尽管进行了巨额投资，并且进行了 15 年以上的开发工作，但无人驾驶车辆项目仍在挣扎，像旧金山这样的现代化城市仍然面临着看似不可逾越的挑战。

ABC 新闻于 2023 年 6 月 29 日发布的视频突显了无人驾驶车辆仍然面临的困难 [21]。记者惊讶地发现她的车在绿灯处无缘无故停下，并说：

> 我想我们停住了。天哪。现在是绿灯，什么也没发生。我们被卡住了，而且不仅如此，我们甚至没有正确地在左边。哦-哦，它说我们的团队正在努力让你继续前进。那是一个绿灯。它不知道该怎么办。当它甚至无法“看见”一个简单的绿灯时，我如何能够依赖汽车做出正确的决定呢？

Waymo 有足够的资源来聘请最优秀的人工智能工程师，如果一家先进的公司都在努力让他们的自动驾驶车辆识别绿灯，那么还有谁会认为人工智能比人类看得更清楚呢？在支持团队的帮助下，车最终动了，但记者后来震惊地发现车不能把她送到正确的目的地。她说：

> 这很奇怪。这不是我们要去的地方。这不是随机博物馆的位置。现在我必须打电话给支持团队，看看我能做些什么，因为我现在完全不知所措。我想去的地方在那边，而它却把我放在了这个山脚下。

支持团队要求记者打开她的 Waymo 应用程序并重新输入目的地。不幸的是，车辆又犯了同样的错误，再次停在了同样错误的地方。这是另一个说明当前人工智能缺乏推理能力的例子。谁会信任或依赖一个不断犯同样明显错误的系统呢？

在航空领域，自从其诞生以来一直在用自动化补充人类灵活性，我们最现代的人工智能技术仍然导致灾难。2013 年，美国国家运输安全委员会解释了韩亚航空 214 航班坠毁事件，称机组人员“过度依赖他们并不完全理解的自动化系统”[22]。国家运输安全委员会主席说，

> 在努力弥补人类表现不可靠性的过程中，自动化控制系统的设计者们不经意地创造了可以比他们原本试图避免的错误更为严重的新错误类型的机会。

另一个被充分记录的与自动化相关的灾难案例是 2009 年法国航空 447 航班的失事。从里约热内卢飞往巴黎的途中，一些仪器上的积冰导致自动驾驶系统意外停止工作，当飞行员未能适当地做出反应时，飞机和其 228 名乘客坠入了大西洋。之后，在 2019 年 3 月，由于一些编写不当的软件导致两起造成 346 人死亡的空难，波音公司的整个 737 MAX 系列飞机被停飞。

尽管考虑到技术公司有很大的动力用机器取代人类来执行与计算机相关的任务，但自动化的前景似乎相当不乐观。一个主要例子就是内容审核。2020 年 5 月，Facebook 同意支付 5200 万美元给 11250 名员工，以补偿他们在工作中患上的心理健康问题[23]。审查在线内容的适当性工作导致焦虑、抑郁、成瘾等问题，然而，作为全球最大的技术公司之一，Facebook 每年仍然雇佣数千人来执行这项任务。

抽象地说，内容审核涉及打开图像和文本文件，审查它们，并将它们分类。鉴于这给人们带来的心理伤害，以及 Facebook 因此遭受的负面报道和财务后果，我们可以假设，如果有任何可行的方法来自动化这项任务，那么它肯定已经被自动化了。根据 The Verge 的报道，当国会询问 Facebook CEO 时，他不断地引用人工智能的力量来回避问题：“审核仇恨言论？AI 将解决。恐怖主义内容和招募？AI。假账户？AI。俄罗斯的错误信息？AI。种族歧视性广告？AI。安全？AI” [24]。

无法完全解决这个问题的事实应该让人对 Facebook 的技术到底有多先进提出新的看法，并且应该迅速地忽略那些标题，比如 “Facebook 人工智能机器人启动后开始用自己的语言交谈就必须关闭” [25]。这篇文章之所以突出来，是因为将机器赋予了生气勃勃的特征。例如，它宣称：

> 这两个聊天机器人开始创造了自己的英语变化，以使它们更容易工作——但这对看护它们的人类来说仍然是神秘的。这种奇怪的讨论发生在 Facebook 挑战其聊天机器人彼此谈判进行交易的情况下，试图交换帽子、球和书籍，每个物品都被赋予一定的价值。 “讨论”很快就僵局了，因为机器人似乎在彼此之间用一种他们各自理解但对人类来说大部分都难以理解的语言唱诵。

肯定能够编造自己的语言的机器能够识别违反 Facebook 使用条款的语言。

最后，让我们考虑看似简单的翻译任务。人们在 20 世纪 50 年代就已经期待着计算机很快就能完成所有的翻译工作。毕竟，简单的字典可以提供逐字翻译，并通过比对翻译良好的文档和原文，你可能认为很容易制定出一个足够的规则和异常列表。然而，超过 70 年的期待之后，翻译仍然是商业世界的一个不可或缺的部分。

我们只需要举一个简单的例子来证明这一观点，因为互联网上有太多类似的例子。一句常见的法语谚语“La larme est la goutte d’eau qui fait déborder l’âme”，字面上意思是“眼泪是使灵魂溢出的水滴”，被 Google 翻译如图 8.1 所示。

![图 8.1](img/8-1.png)

##### 图 8.1 是 2022 年 5 月 6 日的 Google 翻译结果。由于用户反馈，结果可能会更改。

这里发生了什么事情还不太清楚，但结果毫无意义。翻译算法显然参考了人类编制的成语库，这至少是个好的起点。法语短语“La goutte d’eau qui fait déborder le vase”字面上意思是“使花瓶溢出的一滴水”，其英文等价物是“The straw that broke the camel’s back”。由于这两个法语短语只相差两个词，算法必须用其英文等价物替换熟悉的法语成语，然后用文字的逐字翻译替换不符合该成语的词汇。

没有双语人士会犯这样的错误。他们要么熟悉习语并正确翻译，要么意识到逐字翻译是无意义的，需要进行调查。事实上，他们很可能能够通过上下文推断出它必须的意思。这个例子清楚地表明机器目前还远远没有这种能力。

法语和英语之间的翻译实际上应该是所有翻译任务中最容易的之一。这两种语言密切相关，任何人工智能系统都有大量的培训材料可供使用。例如，自从加拿大的 1969 年官方语言法案以来，所有官方文件都必须提供英语和法语版本。欧洲委员会也有同样的要求。这必须至少是数十万页的文本，经过精心编写和细致翻译，多年来，这其中的大部分都已经以电子形式可用。

如果世界顶尖科技公司的人工智能不能可靠地将法语翻译成英语的常见短语，我们对其在更晦涩的语言之间翻译的能力有多少信心？我们可能还需要几十年的时间，人工智能才能够将中文诗歌流畅地翻译成印尼语，或将越南文学翻译成芬兰语，而且很可能这一天永远不会到来。即使是法律或商业领域更简单材料的翻译在可预见的未来也将依赖于人类。

简而言之，尽管人们一直担心人工智能可能取代人类工作，但必须承认人工智能具有固有的局限性。在需要人类品质如推理、身体能力、情感理解、创造力和处理模糊情况的任务上，人工智能面临重大障碍。此外，人工智能系统严重依赖于它们所接受的数据，这可能引入偏见，使它们不适用于需要公正和公正的任务。由于这些局限性和它们固有的对世界的真实理解的缺乏，人工智能更有可能是为人类提供补充而不是取代人类。因此，人工智能更可能通过处理重复性和数据驱动的工作方面来增强人类的能力，从而提高效率，让人类专注于需要我们独特品质的任务。

现在，我们已经确定了大多数职业目前免受自动化的威胁，我们可以讨论本章开头提到的不祥“奇点”了。朋友们，请播放那些阴森的音乐。他们先是夺走了你们的工作，现在人工智能霸主们要来接管文明了。

## 摘要

+   400 年前，当新机器被引入时，人们也有类似的毫无根据的恐惧。

+   人工智能缺乏许多职业所需的直觉、同情心和推理能力，因此这些职业的人不会被人工智能取代。

+   许多任务由于现实世界的复杂性和不完美而非常难以自动化。
