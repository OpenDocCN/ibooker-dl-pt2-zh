# 第六章：机器学习的通用工作流程

*本章涵盖*

+   构建机器学习问题的步骤

+   开发可行模型的步骤

+   部署模型到生产环境并进行维护的步骤

我们先前的示例假设我们已经有了一个标记的数据集，并且我们可以立即开始训练模型。但在现实世界中，情况通常并非如此。你并不是从一个数据集开始；你是从一个问题开始的。

想象一下，你正在开设自己的机器学习咨询公司。你注册了公司，建立了一个华丽的网站，通知了你的人脉。随后，以下项目开始涌现：

+   一个为图片分享社交网络设计的个性化照片搜索引擎——输入“婚礼”并检索出你在婚礼上拍摄的所有照片，无需任何手动标记

+   在新兴的聊天应用程序的帖子中标记垃圾邮件和冒犯性文本内容

+   为在线广播电台用户构建音乐推荐系统。

+   检测电子商务网站的信用卡欺诈。

+   预测展示广告的点击率，以决定在特定时间为特定用户提供哪个广告。

+   在饼干生产线上标记异常饼干。

+   利用卫星图像来预测尚未知晓的考古遗址的位置

**伦理说明**

有时你可能会被提供伦理上可疑的项目，比如“构建一个从某人面部照片评估其可信度的人工智能。”首先，该项目的有效性存在疑问：不清楚为什么可信度会反映在某人的面部上。其次，这样的任务开启了各种伦理问题的大门。为这个任务收集数据集将意味着记录标记图片的人的偏见和成见。你用这些数据训练的模型只会将这些偏见编码到一个黑匣子算法中，这个算法会赋予它们一层薄薄的合法性。在我们这样一个主要技术文盲的社会中，“AI 算法说这个人不可信”似乎比“约翰·史密斯说这个人不可信”更具权威性和客观性，尽管前者只是对后者的一个学习近似。你的模型将以规模化的方式清洗和操作化人类判断的最糟糕的方面，对真实人生产生负面影响。

技术从来都不是中立的。如果你的工作对世界有任何影响，这种影响都具有道德方向：技术选择也是伦理选择。始终要谨慎选择你的工作要支持的价值观。

如果你可以通过 keras::data-set_mydataset() 访问正确的数据集并开始拟合一些深度学习模型，那将会非常方便。不幸的是，在现实世界中，你将不得不从零开始。

在本章中，您将学习一个通用的、逐步的蓝图，您可以使用它来处理和解决任何机器学习问题，就像前面列表中的问题一样。这个模板将汇集和 consaolidate 你在第四章和第五章中学到的一切，并给你更广泛的上下文，应该锚定你将在下一章学到的东西。

机器学习的通用工作流程大致分为三个部分：

1.  **1** *定义任务*—了解问题域和客户要求背后的业务逻辑。收集数据集，了解数据代表什么，并选择如何在任务上衡量成功。

1.  **2** *开发模型*—准备好数据，使其可以被机器学习模型处理，选择一个模型评估协议和一个简单的基准来超越，训练一个具有泛化能力的第一个模型，并且可以过拟合，然后正则化和调整你的模型，直到达到最佳的泛化性能。

1.  **3** *部署模型*—向利益相关者展示你的工作；将模型部署到 Web 服务器、移动应用程序、网页或嵌入式设备中；在实际应用中监视模型的性能；开始收集构建下一代模型所需的数据。

让我们深入了解。

## 6.1 定义任务

你如果没有对你正在做的事情的背景有深刻的理解，就无法做出好的工作。你的客户为什么要解决这个特定的问题？他们将从解决方案中获得什么价值——你的模型将如何使用，它将如何融入客户的业务流程？有哪些数据可用或可以收集？什么样的机器学习任务可以映射到业务问题上？

### 6.1.1 框架问题

框定一个机器学习问题通常涉及与利益相关者的许多详细讨论。以下是你脑海中应该考虑的问题：

你的输入数据将是什么？你想要预测什么？只有在有训练数据可用的情况下，你才能学会预测某些东西：例如，只有在有电影评论和情感注释可用时，你才能学会分类电影评论的情感。因此，在这个阶段，数据可用性通常是限制因素。在许多情况下，你将不得不自己收集和注释新的数据集（我们将在下一节中介绍）。

你面对的是什么类型的机器学习任务？它是二元分类吗？多类分类？标量回归？向量回归？多类别、多标签分类？图像分割？排名？其他一些，如聚类、生成或强化学习？在某些情况下，机器学习甚至可能不是理解数据的最佳方法，你应该使用其他方法，如纯粹的老式统计分析：

+   照片搜索引擎项目是一个多类别、多标签分类任务。

+   垃圾邮件检测项目是一个二元分类任务。如果将“攻击性内容”作为一个单独的类，那么它就是一个三元分类任务。

+   音乐推荐引擎的处理方式最好不是通过深度学习，而是通过矩阵分解（协同过滤）来处理。

+   信用卡欺诈检测项目是一个二元分类任务。

+   点击率预测项目是一个标量回归任务。

+   异常饼干检测是一个二元分类任务，但它还需要一个对象检测模型作为第一阶段，以正确裁剪原始图像中的饼干。请注意，被称为“异常检测”的一组机器学习技术在这种情况下并不适用！

+   从卫星图像中找到新考古遗址的项目是一个图像相似性排名任务：你需要检索出看起来最像已知考古遗址的新图像。

现有解决方案是什么样的？也许你的客户已经有一个手工制作的算法来处理垃圾邮件过滤或信用卡欺诈检测，其中包含大量的嵌套 if 语句。也许目前是一个人手动处理正在考虑的过程 - 监控饼干厂的传送带并手动移除坏饼干，或者制作歌曲推荐播放列表以发送给喜欢特定艺术家的用户。你应该确保你了解已经存在的系统以及它们是如何工作的。

是否有特定的约束你将需要处理？例如，你可能发现你正在为其构建垃圾邮件检测系统的应用程序是严格端到端加密的，因此垃圾邮件检测模型必须存在于最终用户的手机上，并且必须在外部数据集上进行训练。也许饼干过滤模型有这样的延迟约束，它将需要在工厂的嵌入式设备上运行，而不是在远程服务器上运行。你应该了解你的工作将适合的完整环境。

一旦你完成了研究，你应该知道你的输入是什么，你的目标是什么，以及问题映射到的机器学习任务的广泛类型是什么。在这个阶段要注意你正在做出的假设：

+   你假设你的目标可以根据你的输入来预测。

+   你假设可用的数据（或者你即将收集的数据）足够信息丰富，可以学习输入和目标之间的关系。

在你有一个工作模型之前，这些只是等待验证或无效的假设。并不是所有的问题都可以用机器学习来解决；仅仅因为你已经组装了输入 X 和目标 Y 的示例，并不意味着 X 包含足够的信息来预测 Y。例如，如果你试图根据其最近的价格历史来预测股票在股票市场上的走势，你很可能不会成功，因为价格历史并没有太多的预测信息。

### 6.1.2 收集数据集

一旦您了解任务的性质，并且知道您的输入和目标将是什么，就到了数据收集的时候——这是大多数机器学习项目中最费力、耗时和昂贵的部分：

+   照片搜索引擎项目需要您首先选择要分类的标签集——您选择了 10,000 个常见图像类别。然后，您需要手动为您过去上传的数十万张用户图片中的每一张打上这个集合中的标签。

+   对于聊天应用的垃圾邮件检测项目，由于用户聊天是端到端加密的，您无法使用其内容来训练模型。您需要获取一个包含数万条未经筛选的社交媒体帖子的单独数据集，并手动标记它们为垃圾邮件、冒犯性内容或可接受内容。

+   对于音乐推荐引擎，您可以只使用用户的“喜欢”。不需要收集新数据。同样，对于点击率预测项目：您有过去多年来广告点击率的广泛记录。

+   对于 cookie 标记模型，您将需要在传送带上方安装摄像头来收集数万张图像，然后需要有人手动标记这些图像。目前知道如何做这件事的人在饼干工厂工作，但似乎并不太困难。您应该能够培训人员来做这件事。

+   卫星图像项目将需要一支考古学家团队收集现有感兴趣地点的数据库，并且对于每个地点，您需要找到不同天气条件下拍摄的现有卫星图像。要获得一个好的模型，您将需要成千上万个不同的地点。

您在第五章学到，模型的泛化能力几乎完全来自于其所训练的数据的属性：您拥有的数据点数量，标签的可靠性，特征的质量。一个好的数据集是值得关注和投资的资产。如果您额外有 50 小时可用于项目，最有效的分配方式很可能是收集更多数据，而不是寻找增量建模改进。

关于数据比算法更重要的观点最著名的是由谷歌研究人员在 2009 年发表的一篇名为“数据的不合理有效性”的论文中提出的（标题是对尤金·维格纳于 1960 年发表的著名文章“数学在自然科学中的不合理有效性”的变种）。这是在深度学习流行之前，但值得注意的是，深度学习的兴起只是使数据的重要性更加突出。

如果你正在进行监督学习，那么一旦你收集到了输入（例如图像），你将需要对它们进行*注释*（例如图像的标签）——你将训练模型去预测的目标。有时，注释可以自动获取，例如音乐推荐任务或点击率预测任务的注释。但通常你需要手动注释你的数据。这是一个劳动密集型的过程。

### 投资于数据标注基础设施

你的数据标注过程将决定你的目标的质量，进而决定你模型的质量。仔细考虑你可用的选项：

+   是否应该自己注释数据？

+   是否应该使用像 Mechanical Turk 这样的众包平台来收集标签？

+   是否应该使用专门的数据标注公司的服务

外包可能会节省时间和金钱，但会带走控制权。使用类似 Mechanical Turk 的东西可能价格便宜且规模化效果好，但你的标注可能会非常嘈杂。

为了选择最佳选项，考虑你正在处理的约束条件：

+   数据标注员是否需要是专业领域的专家，还是任何人都可以对数据进行注释？猫狗图像分类问题的标签可以由任何人选择，但狗品种分类任务的标签需要专业知识。与此同时，标注骨折的 CT 扫描几乎需要医学学位。

+   如果注释数据需要专业知识，你是否能够培训人员来做？如果不能，你如何才能获得相关的专家？

+   你自己是否了解专家是如何提出注释的？如果不了解，你将不得不将你的数据集视为黑盒子，你将无法进行手动特征工程——这并不是关键，但可能会限制你。

如果决定在内部标注数据，问问自己你会使用什么软件记录注释。你可能需要自己开发这个软件。高效的数据标注软件会节省你大量的时间，因此在项目初期投资于它是值得的。

### 警惕非代表性数据

机器学习模型只能理解与它们以前看到的相似的输入。因此，关键是训练所使用的数据应该*代表*生产数据。这个问题应该是所有数据收集工作的基础。

假设你正在开发一个应用，用户可以拍摄一盘食物的照片以查找菜名。你使用了一个受到美食爱好者欢迎的图像分享社交网络上的图片来训练模型。但在部署后，愤怒用户的反馈开始涌现：你的应用在 10 次中有 8 次都答错了。发生了什么？你在测试集上的准确率远远超过了 90％！快速查看用户上传的数据发现，随机从随机餐厅拍摄的随机菜品的移动照片与你训练模型的专业质量、光线充足、诱人的照片完全不同：*你的训练数据不代表生产数据*。这是一个重大错误——欢迎来到机器学习地狱。

如果可能的话，直接从模型将被使用的环境中收集数据。电影评论情感分类模型应该用于新的 IMDB 评论，而不是 Yelp 餐厅评论或 Twitter 状态更新。如果你想评价一条推文的情感，首先收集和注释来自与你预期在生产中的相似用户集的实际推文。如果无法在生产数据上训练，那么确保你完全了解你的训练和生产数据的差异，并且你正在积极地纠正这些差异。

你应该注意的一个相关现象是*概念漂移*。你几乎在所有真实世界的问题中都会遇到概念漂移，尤其是那些涉及用户生成数据的问题。当生产数据的属性随时间改变时，会导致模型准确性逐渐下降，这就是概念漂移。2013 年训练的音乐推荐引擎可能今天已经不太有效。同样，你处理过的 IMDB 数据集是在 2011 年收集的，而基于它训练的模型可能在处理 2020 年的评论时与 2012 年的评论相比表现不佳，因为词汇、表达和电影类型随时间而演变。概念漂移在诸如信用卡欺诈检测之类的对抗性环境中特别严重，因为欺诈模式几乎每天都在变化。处理快速概念漂移需要不断进行数据收集、注释和模型重新训练。

请记住，机器学习只能用于记忆训练数据中存在的模式。你只能识别你以前见过的东西。使用过去数据训练的机器学习来预测未来是假设未来会像过去一样的假设。这通常并不是情况。

**采样偏差问题**

一个特别阴险而常见的非代表性数据情况是*抽样偏差*。当你的数据收集过程与你试图预测的内容互动时，就会产生偏倚的测量结果。一个著名的历史例子发生在 1948 年的美国总统选举中。在选举之夜，《芝加哥论坛报》刊登了标题“杜威击败杜鲁门”。第二天早晨，杜鲁门被宣布为胜利者。《论坛报》的编辑信任了一项电话调查的结果——但是 1948 年的电话用户并不是选民群体的随机、代表性样本。他们更有可能是富裕和保守的，更有可能投票给共和党候选人杜威。

![图片](img/f0172-01.jpg)

**“杜威击败杜鲁门”：抽样偏差的著名例子**

如今，每一次电话调查都会考虑到抽样偏差。这并不意味着在政治民意调查中抽样偏差已经成为历史——相反，与 1948 年不同的是，民意调查员们意识到了这一点，并采取措施予以纠正。

### 6.1.3 了解你的数据

把数据集当作黑匣子是相当糟糕的做法。在开始训练模型之前，您应该探索和可视化您的数据，以获取关于什么使其具有预测性的见解，这将为特征工程提供信息，并筛选出潜在问题：

+   如果你的数据包含图像或自然语言文本，请直接查看几个样本（以及它们的标签）。

+   如果你的数据包含数值特征，绘制特征值的直方图是个好主意，以了解取值范围和不同取值的频率。

+   如果你的数据包含位置信息，请在地图上标出它。是否有明显的模式出现？

+   一些样本是否缺少一些特征值？如果是，您将需要在准备数据时处理这些值（我们将在下一节介绍如何做到这一点）。

+   如果你的任务是一个分类问题，请打印出数据中每个类的实例数。各类别是否大致平衡？如果不是，你将需要考虑这种不平衡。

+   检查是否存在*目标泄露*：数据中是否存在提供有关目标信息的特征，这些信息在生产环境中可能不可用。如果你正在对医疗记录进行建模，以预测未来某人是否会接受癌症治疗，并且记录中包含“这个人被诊断为患有癌症”这个特征，那么你的目标就被人为地泄漏到了你的数据中。请时刻问自己，您的数据中的每个特征是否都是在生产中以同样的形式可用的。

### 6.1.4 选择成功的度量标准

控制某物，你需要能够观察它。要在项目上取得成功，你必须首先定义成功的含义。准确性？精确度和召回率？客户保留率？你对成功的度量将指导你在整个项目中做出的所有技术选择。它应直接与你的更高级别目标保持一致，例如你的客户的业务成功。

对于平衡分类问题，其中每个类别的概率相等，准确率和*接收器操作特征*（ROC）曲线下的面积，简称 ROC AUC，是常见的度量标准。对于类别不平衡问题、排名问题或多标签分类问题，你可以使用精确率和召回率，以及准确率或 ROC AUC 的加权形式。定义自己的自定义度量标准来衡量成功并不少见。要了解机器学习成功度量的多样性以及它们与不同问题领域的关系，浏览 Kaggle（[`kaggle.com`](https://kaggle.com)）上的数据科学竞赛是有帮助的；它们展示了各种问题和评估度量标准的广泛范围。

## 6.2 开发模型

一旦你知道如何衡量你的进展，你就可以开始模型开发。大多数教程和研究项目假定这是唯一的步骤——跳过了问题定义和数据集收集，这些都假定已经完成，并跳过了模型部署和维护，这些都假定由其他人处理。事实上，模型开发只是机器学习工作流程中的一个步骤，如果你问我，这不是最困难的步骤。机器学习中最困难的事情是框定问题、收集、注释和清理数据。所以振作起来——接下来的事情将会比较容易！

### 6.2.1 准备数据

正如你之前学到的，深度学习模型通常不会直接处理原始数据。数据预处理旨在使手头的原始数据更适合神经网络处理。这包括向量化、标准化或处理缺失值。许多预处理技术是特定于领域的（例如，特定于文本数据或图像数据）；我们将在接下来的章节中涵盖这些技术，当我们在实际示例中遇到它们时。现在，我们将回顾所有数据领域通用的基础知识。

### 向量化

神经网络中的所有输入和目标通常都必须是浮点数据张量（或者在特定情况下，整数或字符串张量）。无论你需要处理的数据是声音、图像还是文本，你都必须首先将其转换为张量，这一步称为*数据向量化*。例如，在第四章中的两个文本分类示例中，我们从文本表示为整数列表（代表单词序列）开始，然后使用一种称为独热编码的方法将它们转换为 float32 数据张量。在分类数字和预测房价的示例中，数据以向量化形式提供，因此我们可以跳过此步骤。

### 值归一化

在第二章的 MNIST 数字分类示例中，我们从图像数据开始，这些数据编码为 0-255 范围内的整数，编码灰度值。 在将这些数据馈送到我们的网络之前，我们将其除以 255，以便最终得到 0-1 范围内的浮点值。 类似地，当预测房屋价格时，我们从具有各种范围的特征开始 - 一些特征具有较小的浮点值，而另一些特征具有相当大的整数值。 在将这些数据馈送到我们的网络之前，我们必须独立地对每个特征进行归一化，使其具有标准差为 1 和平均值为 0。

通常，将相对较大的值（例如，比网络权重的初始值大得多的多位整数）或异构数据（例如，其中一个特征在 0-1 范围内，另一个特征在 100-200 范围内的数据）馈入神经网络是不安全的。 这样做可能会触发大的梯度更新，从而阻止网络收敛。 为了使网络更容易学习，您的数据应具有以下特征：

+   *取小值* - 通常，大多数值应在 0-1 范围内。

+   *要同质化* - 所有特征的值应该在大致相同的范围内。

此外，以下更严格的归一化做法是常见的，并且可能有所帮助，尽管并不总是必要的（例如，在数字分类示例中我们没有这样做）：

+   独立地对每个特征进行归一化，使其具有平均值为 0。

+   独立地对每个特征进行归一化，使其具有标准差为 1

这很容易使用 scale()函数实现：

x <- scale(x)➊

➊ **假设 x 是形状为（样本，特征）的 2D 数据矩阵**

### 处理缺失值

您的数据中有时可能会有缺失值。 例如，在房价示例中，第一个特征是人均犯罪率。 如果这个特征在所有样本中都不可用怎么办？ 然后，您在训练或测试数据中会有缺失值。 您可以简单地丢弃整个特征，但您不一定必须这样做：

+   如果该特征是分类的，则安全地创建一个新类别，表示“值丢失”。 模型将自动学习这对于目标意味着什么。

+   如果该特征是数值的，请避免输入像 0 这样的任意值，因为它可能会在由特征形成的潜在空间中创建不连续性，使得在其上训练的模型更难泛化。 相反，考虑使用数据集中该特征的平均值或中位数值替换缺失值。 您还可以训练一个模型，根据其他特征的值来预测特征值。

请注意，如果您预计测试数据中缺少分类特征，而网络是在没有任何缺失值的数据上训练的，那么该网络将无法学会忽略缺失值！在这种情况下，您应该人为生成含有缺失项的训练样本：多次复制一些训练样本，并删除您预计在测试数据中可能缺失的一些分类特征。

### 6.2.2 选择评估协议

如您在上一章中所学，模型的目的是实现泛化，而在整个模型开发过程中您做出的每个决策都将由*验证指标*指导，以衡量泛化性能。您的评估协议的目标是准确估算您选择的成功指标（例如准确率）在实际生产数据上的表现。这个过程的可靠性对于构建有用的模型至关重要。在第五章中，我们回顾了三种常见的评估协议：

+   *维护保留验证集*——当您有大量数据时，这是一种可行的方法。

+   *进行 K 折交叉验证*——当您缺乏足够样本用于保留验证时，这是一种可靠的选择。

+   *迭代 K 折验证*——这是在数据有限时进行高精度模型评估的方法。

选择其中之一。在大多数情况下，首选方法会足够有效。然而，如您所知，始终要注意验证集的*代表性*，并且要小心训练集和验证集之间没有重复的样本。

### 6.2.3 击败基准

当您开始真正着手于模型时，您的初始目标是获得*统计效力*，正如您在第五章中看到的：也就是说，开发一个能够击败简单基准的小模型。在这个阶段，您应该关注以下三点：

+   *特征工程*——过滤掉无用的特征（特征选择），并利用您对问题的了解开发可能有用的新特征。

+   *选择正确的架构先验*——您将使用哪种类型的模型架构？密集连接的网络、卷积神经网络、循环神经网络、transformers？深度学习是否适合这个任务，还是应该使用其他方法？

+   *选择足够好的训练配置*——您应该使用什么损失函数？使用多大批量和学习率？

对于大多数问题，您可以从现有的模板开始。您并不是第一个尝试构建垃圾邮件检测器、音乐推荐引擎或图像分类器的人。确保您研究了先前的技术，以确定最有可能在您的任务上表现良好的特征工程技术和模型架构。

请注意，不一定总能获得统计功效。如果在尝试了多种合理的架构后仍无法击败一个简单的基线，那么可能是你所问的问题在输入数据中没有答案。请记住，你有两个假设：

+   你假设可以根据输入来预测你的输出。

+   你假设可用数据足够信息丰富，可以学习输入和输出之间的关系。

很可能这些假设是错误的，如果是这样，你必须回到起点。

**选择合适的损失函数**

往往不可能直接优化衡量问题成功的度量标准。有时，将度量标准转化为损失函数并不容易；毕竟，损失函数需要仅通过一个小批量数据就可以计算出来（理想情况下，损失函数应该可以计算出一个数据点）并且必须可微分（否则，你不能使用反向传播来训练你的网络）。例如，广泛使用的分类度量 ROC AUC 不能直接优化。因此，在分类任务中，通常会优化 ROC AUC 的代理度量标准，例如交叉熵。一般来说，你可以期望交叉熵越低，ROC AUC 就越高。

以下表格可以帮助你为几种常见的问题类型选择最后一层激活函数和损失函数。

选择合适的最后一层激活函数和损失函数

| 问题类型 | 最后一层激活函数 | 损失函数 |
| --- | --- | --- |
| 二元分类 | sigmoid | binary_crossentropy |
| 多类别、单标签分类 | softmax | categorical_crossentropy |
| 多类别、多标签分类 | sigmoid | binary_crossentropy |

### 6.2.4 扩展规模：开发一个过拟合的模型

一旦你得到了一个具有统计功效的模型，问题就变成了，你的模型是否足够强大？它是否有足够的层和参数来正确地建模手头的问题？例如，逻辑回归模型在 MNIST 上具有统计功效，但不能很好地解决问题。请记住，机器学习中的普遍紧张关系在于优化和泛化之间。理想的模型是站在欠拟合和过拟合之间的边界上，站在容量不足和容量过大之间。要确定这个边界在哪里，首先你必须越过它。

要确定你需要多大的模型，你必须开发一个过拟合的模型。这相当容易，就像你在第五章学到的那样：

1.  **1** 增加层。

1.  **2** 使层变大。

1.  **3** 训练更多的时期。

总是监视训练损失和验证损失，以及你关心的任何指标的训练和验证值。当你发现模型在验证数据上的性能开始下降时，你就已经出现了过拟合。

### 6.2.5 正则化和调优你的模型

一旦您达到了统计功率并且能够过度拟合，您就知道您正在正确的道路上。在这一点上，您的目标是最大化泛化性能。

这个阶段将花费最多的时间：您将反复修改您的模型，训练它，在验证数据上评估（此时不是测试数据），再次修改它，然后重复，直到模型达到最佳状态。以下是一些您应该尝试的事项：

+   尝试不同的架构；添加或删除层次

+   添加丢失。

+   如果您的模型很小，可以添加 L1 或 L2 正则化。

+   尝试不同的超参数（例如每层的单元数或优化器的学习率）以找到最佳配置。

+   可选地，对数据筛选或特征工程进行迭代：收集并注释更多数据，开发更好的特征，或者删除看起来不具信息量的特征。

可以通过使用*自动化超参数调整软件*（例如 KerasTuner）自动化大部分这项工作。我们将在第十三章中介绍这个。

慎重考虑以下事项：每次您利用验证过程的反馈来调整模型时，都会将关于验证过程的信息泄漏到模型中。这样做几次是无害的；但如果系统地进行多次迭代，最终会导致您的模型过度拟合验证过程（即使没有任何模型直接在任何验证数据上进行训练）。这会使评估过程变得不太可靠。

一旦您开发出令人满意的模型配置，您可以在所有可用数据（训练和验证）上训练最终的生产模型，并最后在测试集上进行最后一次评估。如果结果显示测试集上的性能明显比在验证数据上测量的性能差，这可能意味着您的验证程序毕竟不够可靠，或者您在调整模型参数时开始对验证数据过拟合。在这种情况下，您可能希望切换到更可靠的评估协议（例如迭代的*K*-折验证）。

## 6.3 部署模型

您的模型已经成功地通过了对测试集的最终评估——它已经准备好部署并开始其生产生活。

### 6.3.1 向利益相关者解释您的工作并设定期望

成功和客户信任意味着始终满足或超越人们的期望。您提供的实际系统只是其中一部分；另一部分是在发布之前设定适当的期望。

非专业人士对人工智能系统的期望往往是不现实的。例如，他们可能期望系统“理解”其任务，并能够在任务的上下文中行使类似人类常识的能力。为了解决这个问题，您应该考虑展示一些模型的*失败模式*的示例（例如，展示一些被错误分类的样本是什么样子，特别是对于那些误分类看起来令人惊讶的样本）。

他们可能还期望人类级别的性能，特别是对于以前由人处理的过程。大多数机器学习模型，因为它们（不完美地）被训练来近似人生成的标签，所以并不完全达到那个水平。您应该清楚地传达模型的性能期望。避免使用抽象的陈述，比如“该模型的准确率为 98%”（大多数人心理上会四舍五入为 100%），而更倾向于讨论例如假阴性率和假阳性率。您可以说，“使用这些设置，欺诈检测模型的假阴性率为 5%，假阳性率为 2.5%。每天，平均会有 200 笔有效交易被标记为欺诈并发送进行手动审查，而平均会漏掉 14 笔欺诈交易。平均会正确捕捉到 266 笔欺诈交易。”将模型的性能指标清晰地与业务目标相关联。

您还应该确保与利益相关者讨论关键的启动参数选择，例如交易应该在何种概率阈值下被标记为可疑（不同的阈值会产生不同的假阴性和假阳性率）。此类决策涉及可以通过对业务背景有深入了解来处理的权衡。

### 6.3.2 运送一个推理模型

机器学习项目并不会在您获得可以保存已训练模型的脚本时结束。您很少会将在训练过程中操作的确切模型对象投入生产。首先，您可能希望将模型导出到 R 之外的其他内容：

+   您的生产环境可能根本不支持 R——例如，如果它是一个移动应用程序或嵌入式系统。

+   如果应用的其余部分不是用 R 编写的（可能是 JavaScript、C++等），则使用 R 来提供模型可能会导致显着的开销。

其次，因为您的生产模型仅用于输出预测（称为*推理*阶段），而不是用于训练，所以您可以进行各种优化，以使模型更快速、减少其内存占用。让我们快速看一下您可以使用的不同模型部署选项。

### 将模型部署为 REST API

这可能是将模型转化为产品的常见方式：在服务器或云实例上安装 TensorFlow，并通过 REST API 查询模型的预测结果。您可以使用类似 Shiny（或任何其他 R web 开发库）或 tfdeploy R 包构建自己的服务应用，后者使用 TensorFlow 自己的用于将模型作为 API 部署的库，称为*TensorFlow Serving*（[`www.tensorflow.org/tfx/guide/serving`](http://www.tensorflow.org/tfx/guide/serving)）。使用 tfdeploy 和 TensorFlow Serving，您可以在几分钟内部署一个 Keras 模型。

当您：

+   消费模型的应用程序将始终可靠地访问互联网（显然）。例如，如果您的应用程序是手机应用程序，从远程 API 提供预测意味着不成飞行模式或低网络连通性环境下应用程序将无法使用。

+   应用程序没有严格的延迟要求：请求、推理和答案的往返通常需要约 500 毫秒。

+   发送用于推理的输入数据不高度敏感：数据需要以解密的形式在服务器上可用，因为模型需要看它（但请注意，应该使用 SSL 加密 HTTP 请求和答案）。

例如，图像搜索引擎项目、音乐推荐系统、信用卡欺诈检测项目和卫星图像项目都适合通过 REST API 提供服务。

当将模型部署为 REST API 时，一个重要的问题是你是想托管自己的代码，还是想使用一个完全托管的第三方云服务，比如谷歌的 Cloud AI Platform 可以让你简单地将 TensorFlow 模型上传到 Google Cloud Storage （GCS），并提供一个 API 终端点来查询它。它会自动处理许多实际的细节，例如批量处理预测，负载均衡和扩展。

### 在设备上部署模型

有时候，你需要让模型运行在使用它的应用程序运行的同一个设备上，比如智能手机、机器人上的嵌入式 ARM CPU 或微型设备上的微控制器。你可能已经见过一款相机能够在你拍摄的场景中自动识别出人和面孔：这可能是一个小型深度学习模型直接在相机上运行。

当你需要这样一个设置的时候，你应该：

+   如果你的模型有严格的延迟限制或需要在低网络连通性环境下运行，那么从远程服务器查询可能不是一个可行的选择，比如你在开发一个沉浸式增强现实应用程序。

+   你的模型可以足够小，以便在目标设备的内存和功率约束下运行。你可以使用 TensorFlow Model Optimization Toolkit 来帮助实现这一点（[`www.tensorflow.org/model_optimization`](http://www.tensorflow.org/model_optimization)）。

+   对于你的任务，获得最高可能的准确度并不是至关重要的。运行效率和准确性之间总是存在一个权衡，因此内存和电源限制通常要求您使用一个不如在大型 GPU 上运行的最佳模型好的模型。

+   输入数据是严格保密的，因此不应该在远程服务器上解密

我们的垃圾邮件检测模型将需要作为聊天应用的一部分在最终用户的智能手机上运行，因为消息是端到端加密的，因此无法被远程托管模型读取。同样，恶意 cookie 检测模型具有严格的延迟约束，需要在工厂运行。幸运的是，在这种情况下，我们没有任何功耗或空间约束，因此实际上可以在 GPU 上运行模型。

要在智能手机或嵌入式设备上部署 Keras 模型，您的首选解决方案是 TensorFlow Lite ([`www.tensorflow.org/lite`](http://www.tensorflow.org/lite))。这是一个用于在设备上高效进行深度学习推断的框架，可在 Android 和 iOS 智能手机上运行，以及基于 ARM64 的计算机、树莓派或某些微控制器。它包括一个转换器，可以直接将您的 Keras 模型转换为 TensorFlow Lite 格式。

### 在浏览器中部署模型

深度学习经常用于基于浏览器或桌面的 JavaScript 应用程序。尽管通常可以让应用程序通过 REST API 查询远程模型，但直接在浏览器中运行模型，即在用户的计算机上运行（如果可用，则利用 GPU 资源）可能具有关键优势。

使用此设置时：

+   您希望将计算卸载到最终用户，这可以大大降低服务器成本。

+   输入数据需要保留在最终用户的计算机或手机上。例如，在我们的垃圾邮件检测项目中，聊天应用的 Web 版本和桌面版本（以 JavaScript 编写的跨平台应用程序）应使用在本地运行的模型。

+   您的应用程序具有严格的延迟约束。虽然在最终用户的笔记本电脑或智能手机上运行的模型很可能比在您自己服务器上的大型 GPU 上运行的模型慢，但您没有额外的 100 毫秒网络往返时间。

+   在模型已被下载并缓存后，您需要您的应用程序在没有连接的情况下继续工作

只有在您的模型足够小以至于不会占用用户笔记本电脑或智能手机的 CPU、GPU 或 RAM 时，才应选择此选项。此外，由于整个模型将下载到用户的设备上，您应确保模型的任何内容都不需要保密。请注意，鉴于一个经过训练的深度学习模型，通常可以恢复一些关于训练数据的信息：如果模型是在敏感数据上进行训练的，则最好不要将您的经过训练的模型公开。

要在 JavaScript 中部署模型，TensorFlow 生态系统包括 TensorFlow.js ([`www.tensorflow.org/js`](http://www.tensorflow.org/js))，这是一个用于深度学习的 JavaScript 库，几乎实现了所有的 Keras API（最初以 WebKeras 为工作名称开发）以及许多较低级别的 TensorFlow API。您可以轻松地将保存的 Keras 模型导入到 TensorFlow.js 中，以便作为浏览器中的 JavaScript 应用程序或桌面 Electron 应用程序的一部分进行查询。

### 推断模型优化

在部署在可用功率和内存有严格限制的环境（智能手机和嵌入式设备）或具有低延迟要求的应用程序中，优化推理模型尤为重要。你应该在将模型导入到 TensorFlow.js 或将其导出到 TensorFlow Lite 之前始终寻求优化你的模型。

你可以应用两种流行的优化技术：

+   *权重剪枝*——权重张量中的每个系数对预测的贡献并不相等。通过仅保留最显著的系数，可以大大降低模型层中的参数数量。这减少了模型的内存和计算占用，但性能指标略有损失。通过决定要应用多少剪枝，你可以控制尺寸和准确度之间的权衡。

+   *权重量化*——深度学习模型是用单精度浮点（float32）权重训练的。然而，可以将权重量化为 8 位有符号整数（int8），以获得一个仅用于推理的模型，其大小是原模型的四分之一，但保持接近原模型的准确度。

TensorFlow 生态系统包括一个权重剪枝和量化工具包（[`www.tensorflow.org/model_optimization`](http://www.tensorflow.org/model_optimization)），与 Keras API 深度集成。

### 6.3.3 在野外监控你的模型

你已经导出了推理模型，将其集成到你的应用程序中，并在生产数据上进行了一次干跑——模型的行为与你预期的完全一致。你已经编写了单元测试以及日志记录和状态监控代码——完美。现在是时候按下大红按钮，部署到生产环境了。

但这还不是结束。一旦部署了模型，你需要继续监控其行为，对新数据的性能、与应用程序其余部分的交互以及对业务指标的最终影响进行监控：

+   在部署新的音乐推荐系统后，你的在线电台用户参与度是上升还是下降？切换到新的点击率预测模型后，平均广告点击率是否增加了？考虑使用*随机化 A/B 测试*来将模型本身的影响与其他变化隔离开来：一部分案例应通过新模型处理，而另一部分对照组应坚持使用旧流程。一旦处理了足够多的案例，两者之间结果的差异很可能归因于模型。

+   如果可能的话，请定期手动审计模型对生产数据的预测。通常可以重用与数据注释相同的基础设施：将一部分生产数据发送到手动注释，然后将模型的预测与新注释进行比较。例如，你绝对应该对图像搜索引擎和坏 cookie 标记系统进行这样的操作。

+   当无法进行手动审计时，考虑替代性的评估途径，例如用户调查（例如在垃圾邮件和不良内容标记系统的情况下）

### 6.3.4 维护你的模型

最后，没有一个模型能永远持续。你已经学习了关于*概念漂移*的内容：随着时间的推移，你的生产数据的特征会发生变化，逐渐降低你的模型的性能和相关性。你的音乐推荐系统的寿命将被计算为几周。对于信用卡欺诈检测系统，将是几天；图像搜索引擎的最佳情况是几年。

一旦你的模型已经启动，你应该准备好训练下一个将取代它的代代相传。因此：

+   注意生产数据的变化。有新功能可用吗？需要扩展或编辑标签集吗？

+   继续收集和注释数据，并随时间不断改进你的注释管道。特别是，你应该特别关注收集对你当前的模型分类难度较大的样本——这些样本最有可能帮助改善性能

这就是机器学习的通用工作流程——需要牢记很多东西。要成为专家，需要时间和经验，但不用担心：相对于前几章，你已经更加聪明了。现在你已经熟悉大局——机器学习项目所涉及的整个光谱。虽然本书的大部分内容都将集中在模型开发上，但你现在知道这只是整个工作流程的一部分。始终记住大局！

## 总结

+   当你接手一个新的机器学习项目时，首先定义你手头的问题：

    +   理解你所要做的更广泛的背景——终极目标和限制是什么？

    +   收集并注释数据集；确保你深入了解你的数据。

    +   选择如何衡量问题的成功：在验证数据上监测哪些度量标准？

+   一旦你理解了问题并拥有一个适当的数据集，就可以开发一个模型：

    +   准备你的数据。

    +   选择评估协议：留出验证？*K*-折验证？应该使用哪一部分数据来进行验证？

    +   获得统计力量：打败一个简单的基准。

    +   扩大规模：开发一个可以过度拟合的模型。

    +   根据验证数据上的性能进行正则化和超参数调整。许多机器学习研究往往只关注这一步，但请铭记大局。

+   当模型已准备好并在测试数据上有良好的表现时，就该开始部署了：

    +   首先，确保你与利益相关者设定适当的期望。

    +   为推理优化一个最终模型，并在选择的部署环境中发布模型——Web 服务器、移动设备、浏览器、嵌入式设备等等。

    +   监控你的模型在生产中的表现，并不断收集数据，以便开发下一代模型。
