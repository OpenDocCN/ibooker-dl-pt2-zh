# 前言

## 前言

在过去的几年里，很难忽视自然语言处理（NLP）领域的飞速发展。在此期间，您可能已经被关于流行 NLP 模型（如 ELMo、BERT，以及最近的 GPT-3）的新闻文章所淹没。这种技术周围的兴奋是有道理的，因为这些模型使我们能够实现三年前我们无法想象的 NLP 应用，比如仅仅从对代码的描述中编写出生产代码，或者自动生成可信的诗歌和博客。

推动这一进步的一个重要因素是对自然语言处理模型的越来越复杂的迁移学习技术的关注。迁移学习在自然语言处理中越来越受欢迎和激动人心，因为它使您能够将从一个场景中获得的知识适应或转移到另一个场景，例如不同的语言或任务。这对于自然语言处理的民主化以及更广泛地说人工智能（AI）是一个重大进步，允许知识以前所需资源的一小部分在新环境中得到重复使用。

作为加纳西非国家的公民，在那里，许多新兴的企业家和发明家无法获得大量的计算资源，并且许多基本的自然语言处理问题仍然有待解决，这个主题对我来说尤为重要。这种范式赋予了这样的环境中的工程师们权力，使他们能够构建潜在的拯救生命的自然语言处理技术，否则这是不可能的。

我第一次接触到这些想法是在 2017 年，当时我正在美国国防高级研究计划局（DARPA）生态系统内从事开源自动机器学习技术的工作。我们使用迁移学习来减少对标记数据的需求，首先在模拟数据上训练自然语言处理系统，然后将模型转移到少量真实标记数据上。突破性模型 ELMo 随后出现，激发了我对该主题的进一步学习和探索，以了解如何在我的软件项目中进一步利用这些想法。

自然而然地，我发现由于这些想法的绝对新颖性和领域发展速度的快速性，这个主题没有全面的实用介绍。2019 年，我有机会撰写这个主题的实用介绍，我没有犹豫。你手里拿着的是我大约两年努力的成果。这本书将快速带领你了解该领域的关键近期自然语言处理模型，并提供可执行代码，您将能够直接修改和重用在自己的项目中。尽管不可能涵盖每一个体系结构和用例，但我们战略性地涵盖了我们认为会装备您基本技能以便在这个新兴领域中进一步探索并保持最新的架构和示例。

当你决定更多了解这个话题时，你做出了一个明智的决定。涌现出机会来探索新理论、算法方法和突破性应用。我期待着听到您在周围社会上所产生的转型积极影响。

## 致谢

我非常感谢加纳自然语言处理（NLP）开源社区的成员，在那里我有幸学习更多关于这一重要主题的知识。该群体成员和我们工具的用户的反馈强调了我对这项技术变革的理解。这激励并激励我将这本书完成。

我要感谢我的 Manning 开发编辑苏珊·埃斯里奇，她花了无数小时阅读手稿，提供反馈，并指导我度过了许多挑战。我感谢我的技术开发编辑艾尔·克林克尔为帮助我改进写作的技术维度所付出的所有时间和精力。

我感谢所有编辑委员会成员、市场营销专业人员和其他努力使这本书成为现实的制作团队成员。这些人包括丽贝卡·赖恩哈特、伯特·贝茨、尼科尔·巴特菲尔德、雷哈娜·马尔卡诺维奇、亚历山大·德拉戈萨夫列维奇、梅丽莎·艾斯、布兰科·拉廷西奇、克里斯托弗·考夫曼、坎迪斯·吉尔霍利、贝基·惠特尼、帕梅拉·亨特和拉德米拉·埃尔塞戈瓦克，排名不分先后。

在这个项目的几个关键时刻，技术同行审阅者提供了宝贵的反馈，没有他们，这本书就不会那么好。我非常感谢他们的意见。其中包括安德烈斯·萨科、安吉洛·西蒙尼·斯科托、艾瑞尔·加米诺、奥斯汀·普尔、克利福德·瑟伯、迭戈·卡塞拉、豪梅·洛佩兹、曼努埃尔·R·西奥西奇、马克·安东尼·泰勒、马西耶·阿弗尔蒂特、马修·萨尔门托、迈克尔·沃尔、尼科斯·卡纳卡里斯、尼诺斯拉夫·切尔克斯、奥尔·戈兰、拉尼·夏利姆、萨亚克·保罗、塞巴斯蒂安·帕尔马、塞尔吉奥·戈沃尼、托德·库克和万斯·西斯特拉。我感谢技术校对者艾瑞尔·加米诺在校对过程中捕捉到的许多拼写错误和其他错误。我感谢所有书籍论坛参与者的优秀评论，这进一步帮助改进了本书。

我非常感谢我的妻子戴安娜对这项工作的支持和鼓励。我感激我的母亲和我的兄弟姐妹——理查德、吉迪恩和吉夫蒂——对我继续激励我。

## 关于这本书

这本书试图为自然语言处理中的迁移学习这一重要主题提供全面实用的介绍。我们强调通过代表性代码和示例建立直观理解，而不是专注于理论。我们的代码编写旨在便于快速修改和重新利用，以解决您自己的实际问题和挑战。

## 谁应该读这本书？

要充分利用本书，您应具备一些 Python 经验，以及一些中级机器学习技能，如对基本分类和回归概念的理解。具备一些基本的数据处理和预处理技能，如使用 Pandas 和 NumPy 等库，也会有所帮助。

话虽如此，我写这本书的方式使你可以通过一点额外的工作掌握这些技能。前三章将迅速带你了解你需要掌握的一切，以充分理解迁移学习 NLP 的概念，并应用于你自己的项目中。随后，通过自行查阅包含的精选参考资料，你将巩固你的先修背景技能，如果你觉得有必要的话。

## 路线图

本书分为三个部分。按照它们的出现顺序逐步学习将让您收获最多。

第一部分回顾了机器学习的关键概念，提供了使最近的迁移学习 NLP 进展成为可能的机器学习进步的历史概述，并提供了研究该主题的动机。它还通过一对示例来回顾更传统的 NLP 方法的知识，并让您亲自动手使用一些关键的现代迁移学习 NLP 方法。本书此部分涵盖的概念章节级别的分解如下：

+   第一章介绍了迁移学习的确切含义，包括在人工智能领域和自然语言处理（NLP）的背景下。它还探讨了促成迁移学习的技术进步的历史发展。

+   第二章介绍了一对代表性的自然语言处理（NLP）问题，并展示了如何获取和预处理数据。它还使用传统的线性机器学习方法——逻辑回归和支持向量机——为它们建立了基准。

+   第三章继续通过传统的基于树的机器学习方法——随机森林和梯度提升机——对第二章中的一对问题进行基准测试。它还使用关键的现代迁移学习技术 ELMo 和 BERT 对它们进行基准测试。

第二部分深入探讨了基于浅层神经网络的一些重要的迁移学习 NLP 方法，即层次相对较少的神经网络。它还通过代表性技术（如 ELMo）更详细地探讨了深度迁移学习，这些技术利用循环神经网络（RNN）进行关键功能。本书此部分涵盖的概念章节级别的分解如下：

+   第四章应用了浅层词和句子嵌入技术，如 word2vec 和 sent2vec，进一步探索了本书第一部分的一些示例。它还介绍了领域自适应和多任务学习等重要的迁移学习概念。

+   第五章介绍了一组依赖于 RNN 的深度迁移学习 NLP 方法，以及一对新的例子数据集，这些数据集将用于研究这些方法。

+   第六章更详细地讨论了第五章介绍的方法，并将其应用于同一章节中介绍的数据集。

第三部分涵盖了这一领域中可能最重要的子领域，即依赖于 transformers 神经网络进行关键功能的深度迁移学习技术，例如 BERT 和 GPT。这种模型架构类别正在证明在最近的应用中最具影响力，部分原因是在并行计算架构上比等效的先前方法具有更好的可扩展性。本部分还深入探讨了各种使迁移学习过程更有效的适应策略。书中此部分涵盖的概念的章节级细分如下：

+   第七章介绍了基本的 transformers 架构，并使用其重要变体之一—GPT—进行了一些文本生成和基本聊天机器人。

+   第八章介绍了重要的 transformers 架构 BERT，并将其应用于多种用例，包括问答、填空以及向低资源语言的跨语言转移。

+   第九章介绍了一些旨在使迁移学习过程更有效的适应策略。其中包括区分性微调和逐步解冻（来自方法 ULMFiT 的方法）以及知识蒸馏。

+   第十章介绍了额外的适应策略，包括嵌入因子分解和参数共享—这些是 ALBERT 方法背后的策略。该章还涵盖了适配器和顺序多任务适应。

+   第十一章通过回顾重要主题并简要讨论新兴的研究主题和方向来结束本书，例如需要考虑和减轻技术可能产生的潜在负面影响。这些包括对不同人群的偏见预测以及训练这些大型模型的环境影响。

## 软件要求

Kaggle 笔记本是执行这些方法的推荐方式，因为它们可以让您立即开始，无需进行任何设置延迟。此外，在编写本文时，此服务提供的免费 GPU 资源扩大了所有这些方法的可访问性，使得那些可能没有本地强大 GPU 访问权限的人也能够使用，这与“AI 民主化”议程一致，激发了许多人对 NLP 迁移学习的兴趣。附录 A 提供了 Kaggle 快速入门指南和作者个人关于如何最大程度地发挥平台作用的一些建议。但是，我们预计大多数读者应该会发现开始使用是相当简单的。我们已经在 Kaggle 上公开托管了所有笔记本，并附上了所有必需的数据，以便您只需点击几下即可开始执行代码。但是，请记住“复制并编辑”（fork）笔记本——而不是将其复制并粘贴到新的 Kaggle 笔记本中——因为这样可以确保结果库在环境中与我们为代码编写的库匹配。

## 关于代码

这本书包含了许多源代码示例，既有编号列表中的，也有与普通文本一起的。在这两种情况下，源代码都以`像这样的等宽字体`格式化，以便与普通文本分开。有时代码也会以**粗体**显示，以突出显示章节中已更改的代码，例如当新功能添加到现有代码行时。

在许多情况下，原始源代码已经重新格式化；我们添加了换行符并重新排列了缩进以适应书中可用的页面空间。在极少数情况下，即使这样还不够，列表中还包括了行继续标记（➥）。此外，在文本中描述代码时，源代码中的注释通常已从列表中删除。代码注释伴随许多列表，突出显示重要概念。

本书示例中的代码可从 Manning 网站下载，网址为[`www.manning.com/downloads/2116`](http://www.manning.com/downloads/2116)，也可以从 GitHub 上下载，网址为[`github.com/azunre/transfer-learning-for-nlp`](https://github.com/azunre/transfer-learning-for-nlp)。

## liveBook 讨论论坛

购买《自然语言处理的迁移学习》包括免费访问由 Manning Publications 运营的私人网络论坛，在该论坛上，您可以对该书发表评论，提出技术问题，并从作者和其他用户那里获得帮助。要访问论坛，请转到[`livebook.manning.com/#!/book/transfer-learning-for-natural-language-processing/discussion`](https://livebook.manning.com/#!/book/transfer-learning-for-natural-language-processing/discussion)。您还可以在[`livebook.manning.com/#!/discussion`](https://livebook.manning.com/#!/discussion)了解有关 Manning 论坛及行为规范的更多信息。

Manning 致力于为我们的读者提供一个场所，让个人读者之间以及读者与作者之间进行有意义的对话。这不是对作者参与的特定数量的承诺，作者对论坛的贡献仍然是自愿的（未付酬）。我们建议您尝试向作者提出一些具有挑战性的问题，以免他失去兴趣！ 只要这本书还在印刷，您都可以从出版商的网站访问论坛和以前的讨论档案。

## 作者简介

**Paul Azunre** 持有麻省理工学院计算机科学博士学位，并曾担任多个 DARPA 研究项目的主要研究员。他创立了 Algorine Inc.，一个致力于推动人工智能/机器学习发展并确定其可能产生重大社会影响的研究实验室。Paul 还共同创立了 Ghana NLP，一个专注于使用自然语言处理和迁移学习处理加纳语和其他资源稀缺语言的开源倡议。

## 封面插图说明

*自然语言处理的迁移学习* 封面上的图案标题为“Moluquoise”，或者说是马鲁古妇女。 这幅插图取自法国 1788 年出版的雅克·格拉塞·德·圣索维尔（Jacques Grasset de Saint-Sauveur，1757-1810）的 *所有已知民族的现代民族服饰* 系列，每个插图都经过精细手绘和上色。格拉塞·德·圣索维尔（Grasset de Saint-Sauveur）收集的丰富多样性生动地提醒我们，就在 200 年前，世界的城镇和地区文化迥然不同。 人们相互隔离，说着不同的方言和语言。 在街上或乡间，仅通过他们的服装就可以轻松辨认出他们住在哪里以及他们的贸易或生活状况。

自那时起，我们的着装方式已经发生了变化，地区的多样性也在消失。 现在很难区分不同大陆的居民，更不用说不同的城镇、地区或国家了。 或许我们已经用文化多样性换取了更丰富的个人生活，肯定是为了更丰富和快节奏的技术生活。

在很难将一本计算机书籍与另一本区分开来的时候，Manning 通过基于两个世纪前地区生活丰富多样性的丰富多样的书籍封面，庆祝了计算机业的创造力和主动性，这些封面是格拉塞·德·圣索维尔的图片重新呈现的。
